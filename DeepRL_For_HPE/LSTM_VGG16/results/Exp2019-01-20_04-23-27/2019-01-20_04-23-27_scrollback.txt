mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument
 of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(flo
at).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-20 04:23:27.271888: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that thi
s TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-20 04:23:27.343516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from S
ysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-20 04:23:27.343806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 9.86GiB
2019-01-20 04:23:27.343820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-20 04:23:27.497494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor w
ith strength 1 edge matrix:
2019-01-20 04:23:27.497516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-20 04:23:27.497521: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-20 04:23:27.497695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:loc
alhost/replica:0/task:0/device:GPU:0 with 9536 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus
 id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-20_04-23-27 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
=================================================================
Total params: 14,714,688
Trainable params: 0
Non-trainable params: 14,714,688
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 7, 7, 512)     14714688
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 25088)         0
_________________________________________________________________
time_distributed_2 (TimeDist (None, 16, 25088)         0
_________________________________________________________________
fc1024 (TimeDistributed)     (None, 16, 4096)          102764544
_________________________________________________________________
time_distributed_3 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
fc104 (TimeDistributed)      (None, 16, 4096)          16781312
_________________________________________________________________
time_distributed_4 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
fc10 (TimeDistributed)       (None, 16, 1024)          4195328
_________________________________________________________________
time_distributed_5 (TimeDist (None, 16, 1024)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                41400
_________________________________________________________________
dense_4 (Dense)              (None, 3)                 33
=================================================================
Total params: 138,497,305
Trainable params: 123,782,617
Non-trainable params: 14,714,688
_________________________________________________________________

Training model VGG16_seqLen16_lstm10_output3_inEpochs1_outEpochs20_AdamOpt_lr-0.000100__2019-01-20_04-23-27
All frames and annotations from 20 datasets have been read by 2019-01-20 04:23:33.179827
1. set (Subject 20, M12) being trained for epoch 1!
Epoch 1/1
108/108 [==============================] - 49s 452ms/step - loss: 0.1017 - mean_absolute_error: 0.2374
2. set (Subject 23, M13) being trained for epoch 1!
Epoch 1/1
111/111 [==============================] - 48s 433ms/step - loss: 0.0805 - mean_absolute_error: 0.2174
3. set (Subject 12, M06) being trained for epoch 1!
Epoch 1/1
144/144 [==============================] - 62s 429ms/step - loss: 0.0670 - mean_absolute_error: 0.2003
4. set (Subject 16, M09) being trained for epoch 1!
Epoch 1/1
180/180 [==============================] - 77s 428ms/step - loss: 0.0687 - mean_absolute_error: 0.1876
5. set (Subject 6, F06) being trained for epoch 1!
Epoch 1/1
106/106 [==============================] - 45s 427ms/step - loss: 0.0884 - mean_absolute_error: 0.2051
6. set (Subject 22, M01) being trained for epoch 1!
Epoch 1/1
130/130 [==============================] - 57s 441ms/step - loss: 0.0337 - mean_absolute_error: 0.1218
7. set (Subject 19, M11) being trained for epoch 1!
Epoch 1/1
98/98 [==============================] - 42s 427ms/step - loss: 0.0562 - mean_absolute_error: 0.1779
8. set (Subject 13, M07) being trained for epoch 1!
Epoch 1/1
94/94 [==============================] - 40s 428ms/step - loss: 0.0485 - mean_absolute_error: 0.1656
9. set (Subject 5, F05) being trained for epoch 1!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0836 - mean_absolute_error: 0.2096
10. set (Subject 10, M04) being trained for epoch 1!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.1111 - mean_absolute_error: 0.2787
11. set (Subject 7, M01) being trained for epoch 1!
Epoch 1/1
146/146 [==============================] - 62s 423ms/step - loss: 0.0950 - mean_absolute_error: 0.2297
12. set (Subject 1, F01) being trained for epoch 1!
Epoch 1/1
97/97 [==============================] - 42s 431ms/step - loss: 0.1017 - mean_absolute_error: 0.2306
13. set (Subject 15, F03) being trained for epoch 1!
Epoch 1/1
128/128 [==============================] - 54s 422ms/step - loss: 0.0706 - mean_absolute_error: 0.1883
14. set (Subject 2, F02) being trained for epoch 1!
Epoch 1/1
99/99 [==============================] - 42s 423ms/step - loss: 0.1040 - mean_absolute_error: 0.2416
15. set (Subject 3, F03) being trained for epoch 1!
Epoch 1/1
143/143 [==============================] - 60s 422ms/step - loss: 0.0823 - mean_absolute_error: 0.2115
16. set (Subject 17, M10) being trained for epoch 1!
Epoch 1/1
76/76 [==============================] - 32s 421ms/step - loss: 0.0330 - mean_absolute_error: 0.1230
17. set (Subject 14, M08) being trained for epoch 1!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1202 - mean_absolute_error: 0.2763
18. set (Subject 4, F04) being trained for epoch 1!
Epoch 1/1
146/146 [==============================] - 62s 422ms/step - loss: 0.0923 - mean_absolute_error: 0.2309
19. set (Subject 11, M05) being trained for epoch 1!
Epoch 1/1
112/112 [==============================] - 47s 420ms/step - loss: 0.0453 - mean_absolute_error: 0.1446
20. set (Subject 8, M02) being trained for epoch 1!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0743 - mean_absolute_error: 0.2010
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 04:43:55.596837
1. set (Subject 4, F04) being trained for epoch 2!
Epoch 1/1
146/146 [==============================] - 61s 418ms/step - loss: 0.0886 - mean_absolute_error: 0.2268
2. set (Subject 8, M02) being trained for epoch 2!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0715 - mean_absolute_error: 0.1964
3. set (Subject 7, M01) being trained for epoch 2!
Epoch 1/1
146/146 [==============================] - 62s 422ms/step - loss: 0.0823 - mean_absolute_error: 0.2165
4. set (Subject 3, F03) being trained for epoch 2!
Epoch 1/1
143/143 [==============================] - 60s 422ms/step - loss: 0.0772 - mean_absolute_error: 0.2099
5. set (Subject 22, M01) being trained for epoch 2!
Epoch 1/1
130/130 [==============================] - 55s 422ms/step - loss: 0.0361 - mean_absolute_error: 0.1255
6. set (Subject 11, M05) being trained for epoch 2!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0471 - mean_absolute_error: 0.1467
7. set (Subject 14, M08) being trained for epoch 2!
Epoch 1/1
157/157 [==============================] - 66s 418ms/step - loss: 0.1206 - mean_absolute_error: 0.2748
8. set (Subject 1, F01) being trained for epoch 2!
Epoch 1/1
97/97 [==============================] - 41s 418ms/step - loss: 0.1075 - mean_absolute_error: 0.2333
9. set (Subject 6, F06) being trained for epoch 2!
Epoch 1/1
106/106 [==============================] - 44s 417ms/step - loss: 0.0875 - mean_absolute_error: 0.1971
10. set (Subject 5, F05) being trained for epoch 2!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0815 - mean_absolute_error: 0.2021
11. set (Subject 19, M11) being trained for epoch 2!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.0524 - mean_absolute_error: 0.1802
12. set (Subject 20, M12) being trained for epoch 2!
Epoch 1/1
108/108 [==============================] - 45s 421ms/step - loss: 0.0453 - mean_absolute_error: 0.1433
13. set (Subject 2, F02) being trained for epoch 2!
Epoch 1/1
99/99 [==============================] - 42s 423ms/step - loss: 0.1030 - mean_absolute_error: 0.2407
14. set (Subject 23, M13) being trained for epoch 2!
Epoch 1/1
111/111 [==============================] - 47s 421ms/step - loss: 0.0884 - mean_absolute_error: 0.2204
15. set (Subject 12, M06) being trained for epoch 2!
Epoch 1/1
144/144 [==============================] - 60s 420ms/step - loss: 0.1090 - mean_absolute_error: 0.2770
16. set (Subject 17, M10) being trained for epoch 2!
Epoch 1/1
76/76 [==============================] - 32s 420ms/step - loss: 0.1785 - mean_absolute_error: 0.3265
17. set (Subject 15, F03) being trained for epoch 2!
Epoch 1/1
128/128 [==============================] - 54s 422ms/step - loss: 0.1416 - mean_absolute_error: 0.2927
18. set (Subject 16, M09) being trained for epoch 2!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.1006 - mean_absolute_error: 0.2364
19. set (Subject 10, M04) being trained for epoch 2!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0780 - mean_absolute_error: 0.2229
20. set (Subject 13, M07) being trained for epoch 2!
Epoch 1/1
94/94 [==============================] - 40s 421ms/step - loss: 0.0528 - mean_absolute_error: 0.1761
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 05:04:01.660601
1. set (Subject 16, M09) being trained for epoch 3!
Epoch 1/1
180/180 [==============================] - 75s 419ms/step - loss: 0.0567 - mean_absolute_error: 0.1745
2. set (Subject 13, M07) being trained for epoch 3!
Epoch 1/1
94/94 [==============================] - 40s 423ms/step - loss: 0.0513 - mean_absolute_error: 0.1641
3. set (Subject 19, M11) being trained for epoch 3!
Epoch 1/1
98/98 [==============================] - 41s 419ms/step - loss: 0.0430 - mean_absolute_error: 0.1625
4. set (Subject 12, M06) being trained for epoch 3!
Epoch 1/1
144/144 [==============================] - 61s 421ms/step - loss: 0.0728 - mean_absolute_error: 0.1979
5. set (Subject 11, M05) being trained for epoch 3!
Epoch 1/1
112/112 [==============================] - 47s 421ms/step - loss: 0.0472 - mean_absolute_error: 0.1496
6. set (Subject 10, M04) being trained for epoch 3!
Epoch 1/1
142/142 [==============================] - 60s 422ms/step - loss: 0.0701 - mean_absolute_error: 0.1908
7. set (Subject 15, F03) being trained for epoch 3!
Epoch 1/1
128/128 [==============================] - 54s 421ms/step - loss: 0.0633 - mean_absolute_error: 0.1720
8. set (Subject 20, M12) being trained for epoch 3!
Epoch 1/1
108/108 [==============================] - 46s 422ms/step - loss: 0.0412 - mean_absolute_error: 0.1346
9. set (Subject 22, M01) being trained for epoch 3!
Epoch 1/1
130/130 [==============================] - 55s 421ms/step - loss: 0.0314 - mean_absolute_error: 0.1107
10. set (Subject 6, F06) being trained for epoch 3!
Epoch 1/1
106/106 [==============================] - 45s 420ms/step - loss: 0.0777 - mean_absolute_error: 0.1834
11. set (Subject 14, M08) being trained for epoch 3!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1146 - mean_absolute_error: 0.2673
12. set (Subject 4, F04) being trained for epoch 3!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0917 - mean_absolute_error: 0.2322
13. set (Subject 23, M13) being trained for epoch 3!
Epoch 1/1
111/111 [==============================] - 47s 421ms/step - loss: 0.0721 - mean_absolute_error: 0.1943
14. set (Subject 8, M02) being trained for epoch 3!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0796 - mean_absolute_error: 0.2114
15. set (Subject 7, M01) being trained for epoch 3!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0852 - mean_absolute_error: 0.2197
16. set (Subject 17, M10) being trained for epoch 3!
Epoch 1/1
76/76 [==============================] - 32s 420ms/step - loss: 0.0295 - mean_absolute_error: 0.1141
17. set (Subject 2, F02) being trained for epoch 3!
Epoch 1/1
99/99 [==============================] - 42s 421ms/step - loss: 0.1090 - mean_absolute_error: 0.2443
18. set (Subject 3, F03) being trained for epoch 3!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0770 - mean_absolute_error: 0.2074
19. set (Subject 5, F05) being trained for epoch 3!
Epoch 1/1
186/186 [==============================] - 79s 422ms/step - loss: 0.0813 - mean_absolute_error: 0.1996
20. set (Subject 1, F01) being trained for epoch 3!
Epoch 1/1
97/97 [==============================] - 41s 420ms/step - loss: 0.1025 - mean_absolute_error: 0.2297
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 05:24:08.557698
1. set (Subject 3, F03) being trained for epoch 4!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0767 - mean_absolute_error: 0.2037
2. set (Subject 1, F01) being trained for epoch 4!
Epoch 1/1
97/97 [==============================] - 41s 419ms/step - loss: 0.1026 - mean_absolute_error: 0.2325
3. set (Subject 14, M08) being trained for epoch 4!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1225 - mean_absolute_error: 0.2794
4. set (Subject 7, M01) being trained for epoch 4!
Epoch 1/1
146/146 [==============================] - 62s 421ms/step - loss: 0.0826 - mean_absolute_error: 0.2144
5. set (Subject 10, M04) being trained for epoch 4!
Epoch 1/1
142/142 [==============================] - 60s 422ms/step - loss: 0.0630 - mean_absolute_error: 0.1787
6. set (Subject 5, F05) being trained for epoch 4!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0778 - mean_absolute_error: 0.1971
7. set (Subject 2, F02) being trained for epoch 4!
Epoch 1/1
99/99 [==============================] - 42s 420ms/step - loss: 0.0907 - mean_absolute_error: 0.2274
8. set (Subject 4, F04) being trained for epoch 4!
Epoch 1/1
146/146 [==============================] - 61s 419ms/step - loss: 0.0885 - mean_absolute_error: 0.2227
9. set (Subject 11, M05) being trained for epoch 4!
Epoch 1/1
112/112 [==============================] - 47s 419ms/step - loss: 0.0498 - mean_absolute_error: 0.1566
10. set (Subject 22, M01) being trained for epoch 4!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0373 - mean_absolute_error: 0.1281
11. set (Subject 15, F03) being trained for epoch 4!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.0733 - mean_absolute_error: 0.1938
12. set (Subject 16, M09) being trained for epoch 4!
Epoch 1/1
180/180 [==============================] - 76s 423ms/step - loss: 0.0625 - mean_absolute_error: 0.1793
13. set (Subject 8, M02) being trained for epoch 4!
Epoch 1/1
152/152 [==============================] - 64s 421ms/step - loss: 0.0741 - mean_absolute_error: 0.2007
14. set (Subject 13, M07) being trained for epoch 4!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0393 - mean_absolute_error: 0.1479
15. set (Subject 19, M11) being trained for epoch 4!
Epoch 1/1
98/98 [==============================] - 41s 417ms/step - loss: 0.0473 - mean_absolute_error: 0.1717
16. set (Subject 17, M10) being trained for epoch 4!
Epoch 1/1
76/76 [==============================] - 32s 422ms/step - loss: 0.0318 - mean_absolute_error: 0.1218
17. set (Subject 23, M13) being trained for epoch 4!
Epoch 1/1
111/111 [==============================] - 47s 420ms/step - loss: 0.0733 - mean_absolute_error: 0.1984
18. set (Subject 12, M06) being trained for epoch 4!
Epoch 1/1
144/144 [==============================] - 60s 419ms/step - loss: 0.0600 - mean_absolute_error: 0.1784
19. set (Subject 6, F06) being trained for epoch 4!
Epoch 1/1
106/106 [==============================] - 44s 418ms/step - loss: 0.0848 - mean_absolute_error: 0.1939
20. set (Subject 20, M12) being trained for epoch 4!
Epoch 1/1
108/108 [==============================] - 45s 420ms/step - loss: 0.0421 - mean_absolute_error: 0.1373
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 05:44:14.889901
1. set (Subject 12, M06) being trained for epoch 5!
Epoch 1/1
144/144 [==============================] - 60s 417ms/step - loss: 0.0600 - mean_absolute_error: 0.1780
2. set (Subject 20, M12) being trained for epoch 5!
Epoch 1/1
108/108 [==============================] - 46s 423ms/step - loss: 0.0431 - mean_absolute_error: 0.1407
3. set (Subject 15, F03) being trained for epoch 5!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.0672 - mean_absolute_error: 0.1824
4. set (Subject 19, M11) being trained for epoch 5!
Epoch 1/1
98/98 [==============================] - 41s 420ms/step - loss: 0.0449 - mean_absolute_error: 0.1637
5. set (Subject 5, F05) being trained for epoch 5!
Epoch 1/1
186/186 [==============================] - 78s 422ms/step - loss: 0.0846 - mean_absolute_error: 0.2073
6. set (Subject 6, F06) being trained for epoch 5!
Epoch 1/1
106/106 [==============================] - 44s 418ms/step - loss: 0.0837 - mean_absolute_error: 0.1921
7. set (Subject 23, M13) being trained for epoch 5!
Epoch 1/1
111/111 [==============================] - 47s 420ms/step - loss: 0.0717 - mean_absolute_error: 0.1953
8. set (Subject 16, M09) being trained for epoch 5!
Epoch 1/1
180/180 [==============================] - 76s 422ms/step - loss: 0.0573 - mean_absolute_error: 0.1667
9. set (Subject 10, M04) being trained for epoch 5!
Epoch 1/1
142/142 [==============================] - 60s 424ms/step - loss: 0.0675 - mean_absolute_error: 0.1866
10. set (Subject 11, M05) being trained for epoch 5!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0442 - mean_absolute_error: 0.1375
11. set (Subject 2, F02) being trained for epoch 5!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.1077 - mean_absolute_error: 0.2448
12. set (Subject 3, F03) being trained for epoch 5!
Epoch 1/1
143/143 [==============================] - 60s 421ms/step - loss: 0.0787 - mean_absolute_error: 0.2104
13. set (Subject 13, M07) being trained for epoch 5!
Epoch 1/1
94/94 [==============================] - 40s 420ms/step - loss: 0.0399 - mean_absolute_error: 0.1429
14. set (Subject 1, F01) being trained for epoch 5!
Epoch 1/1
97/97 [==============================] - 41s 419ms/step - loss: 0.1031 - mean_absolute_error: 0.2301
15. set (Subject 14, M08) being trained for epoch 5!
Epoch 1/1
157/157 [==============================] - 66s 419ms/step - loss: 0.1206 - mean_absolute_error: 0.2760
16. set (Subject 17, M10) being trained for epoch 5!
Epoch 1/1
76/76 [==============================] - 32s 423ms/step - loss: 0.0319 - mean_absolute_error: 0.1186
17. set (Subject 8, M02) being trained for epoch 5!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0740 - mean_absolute_error: 0.2010
18. set (Subject 7, M01) being trained for epoch 5!
Epoch 1/1
146/146 [==============================] - 62s 421ms/step - loss: 0.0825 - mean_absolute_error: 0.2159
19. set (Subject 22, M01) being trained for epoch 5!
Epoch 1/1
130/130 [==============================] - 55s 422ms/step - loss: 0.0335 - mean_absolute_error: 0.1161
20. set (Subject 4, F04) being trained for epoch 5!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0880 - mean_absolute_error: 0.2264
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 06:04:21.777849
1. set (Subject 7, M01) being trained for epoch 6!
Epoch 1/1
146/146 [==============================] - 61s 419ms/step - loss: 0.0832 - mean_absolute_error: 0.2165
2. set (Subject 4, F04) being trained for epoch 6!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0859 - mean_absolute_error: 0.2232
3. set (Subject 2, F02) being trained for epoch 6!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.0974 - mean_absolute_error: 0.2326
4. set (Subject 14, M08) being trained for epoch 6!
Epoch 1/1
157/157 [==============================] - 66s 419ms/step - loss: 0.1234 - mean_absolute_error: 0.2794
5. set (Subject 6, F06) being trained for epoch 6!
Epoch 1/1
106/106 [==============================] - 44s 417ms/step - loss: 0.0889 - mean_absolute_error: 0.2013
6. set (Subject 22, M01) being trained for epoch 6!
Epoch 1/1
130/130 [==============================] - 55s 421ms/step - loss: 0.0342 - mean_absolute_error: 0.1174
7. set (Subject 8, M02) being trained for epoch 6!
Epoch 1/1
152/152 [==============================] - 64s 421ms/step - loss: 0.0730 - mean_absolute_error: 0.1993
8. set (Subject 3, F03) being trained for epoch 6!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0770 - mean_absolute_error: 0.2104
9. set (Subject 5, F05) being trained for epoch 6!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0800 - mean_absolute_error: 0.1975
10. set (Subject 10, M04) being trained for epoch 6!
Epoch 1/1
142/142 [==============================] - 60s 423ms/step - loss: 0.0624 - mean_absolute_error: 0.1783
11. set (Subject 23, M13) being trained for epoch 6!
Epoch 1/1
111/111 [==============================] - 47s 421ms/step - loss: 0.0759 - mean_absolute_error: 0.2063
12. set (Subject 12, M06) being trained for epoch 6!
Epoch 1/1
144/144 [==============================] - 61s 420ms/step - loss: 0.0553 - mean_absolute_error: 0.1726
13. set (Subject 1, F01) being trained for epoch 6!
Epoch 1/1
97/97 [==============================] - 41s 421ms/step - loss: 0.0995 - mean_absolute_error: 0.2262
14. set (Subject 20, M12) being trained for epoch 6!
Epoch 1/1
108/108 [==============================] - 46s 422ms/step - loss: 0.0475 - mean_absolute_error: 0.1534
15. set (Subject 15, F03) being trained for epoch 6!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.0735 - mean_absolute_error: 0.1945
16. set (Subject 17, M10) being trained for epoch 6!
Epoch 1/1
76/76 [==============================] - 32s 422ms/step - loss: 0.0336 - mean_absolute_error: 0.1240
17. set (Subject 13, M07) being trained for epoch 6!
Epoch 1/1
94/94 [==============================] - 40s 421ms/step - loss: 0.0394 - mean_absolute_error: 0.1450
18. set (Subject 19, M11) being trained for epoch 6!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.0493 - mean_absolute_error: 0.1760
19. set (Subject 11, M05) being trained for epoch 6!
Epoch 1/1
112/112 [==============================] - 47s 420ms/step - loss: 0.0463 - mean_absolute_error: 0.1425
20. set (Subject 16, M09) being trained for epoch 6!
Epoch 1/1
180/180 [==============================] - 76s 420ms/step - loss: 0.0598 - mean_absolute_error: 0.1739
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 06:24:28.291078
1. set (Subject 19, M11) being trained for epoch 7!
Epoch 1/1
98/98 [==============================] - 41s 417ms/step - loss: 0.0441 - mean_absolute_error: 0.1617
2. set (Subject 16, M09) being trained for epoch 7!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0564 - mean_absolute_error: 0.1663
3. set (Subject 23, M13) being trained for epoch 7!
Epoch 1/1
111/111 [==============================] - 47s 420ms/step - loss: 0.0713 - mean_absolute_error: 0.1925
4. set (Subject 15, F03) being trained for epoch 7!
Epoch 1/1
128/128 [==============================] - 54s 422ms/step - loss: 0.0611 - mean_absolute_error: 0.1663
5. set (Subject 22, M01) being trained for epoch 7!
Epoch 1/1
130/130 [==============================] - 54s 418ms/step - loss: 0.0305 - mean_absolute_error: 0.1094
6. set (Subject 11, M05) being trained for epoch 7!
Epoch 1/1
112/112 [==============================] - 47s 419ms/step - loss: 0.0450 - mean_absolute_error: 0.1386
7. set (Subject 13, M07) being trained for epoch 7!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0466 - mean_absolute_error: 0.1562
8. set (Subject 12, M06) being trained for epoch 7!
Epoch 1/1
144/144 [==============================] - 60s 419ms/step - loss: 0.0649 - mean_absolute_error: 0.1846
9. set (Subject 6, F06) being trained for epoch 7!
Epoch 1/1
106/106 [==============================] - 44s 419ms/step - loss: 0.0807 - mean_absolute_error: 0.1870
10. set (Subject 5, F05) being trained for epoch 7!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0846 - mean_absolute_error: 0.2059
11. set (Subject 8, M02) being trained for epoch 7!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0750 - mean_absolute_error: 0.2015
12. set (Subject 7, M01) being trained for epoch 7!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0834 - mean_absolute_error: 0.2175
13. set (Subject 20, M12) being trained for epoch 7!
Epoch 1/1
108/108 [==============================] - 45s 421ms/step - loss: 0.0450 - mean_absolute_error: 0.1450
14. set (Subject 4, F04) being trained for epoch 7!
Epoch 1/1
146/146 [==============================] - 61s 418ms/step - loss: 0.0897 - mean_absolute_error: 0.2289
15. set (Subject 2, F02) being trained for epoch 7!
Epoch 1/1
99/99 [==============================] - 42s 421ms/step - loss: 0.0983 - mean_absolute_error: 0.2346
16. set (Subject 17, M10) being trained for epoch 7!
Epoch 1/1
76/76 [==============================] - 32s 423ms/step - loss: 0.0355 - mean_absolute_error: 0.1314
17. set (Subject 1, F01) being trained for epoch 7!
Epoch 1/1
97/97 [==============================] - 41s 422ms/step - loss: 0.1026 - mean_absolute_error: 0.2296
18. set (Subject 14, M08) being trained for epoch 7!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1251 - mean_absolute_error: 0.2796
19. set (Subject 10, M04) being trained for epoch 7!
Epoch 1/1
142/142 [==============================] - 60s 422ms/step - loss: 0.0633 - mean_absolute_error: 0.1793
20. set (Subject 3, F03) being trained for epoch 7!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0784 - mean_absolute_error: 0.2099
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 06:44:34.198492
1. set (Subject 14, M08) being trained for epoch 8!
Epoch 1/1
157/157 [==============================] - 66s 418ms/step - loss: 0.1218 - mean_absolute_error: 0.2775
2. set (Subject 3, F03) being trained for epoch 8!
Epoch 1/1
143/143 [==============================] - 60s 423ms/step - loss: 0.0773 - mean_absolute_error: 0.2056
3. set (Subject 8, M02) being trained for epoch 8!
Epoch 1/1
152/152 [==============================] - 64s 421ms/step - loss: 0.0735 - mean_absolute_error: 0.2035
4. set (Subject 2, F02) being trained for epoch 8!
Epoch 1/1
99/99 [==============================] - 42s 423ms/step - loss: 0.0976 - mean_absolute_error: 0.2333
5. set (Subject 11, M05) being trained for epoch 8!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0480 - mean_absolute_error: 0.1513
6. set (Subject 10, M04) being trained for epoch 8!
Epoch 1/1
142/142 [==============================] - 60s 420ms/step - loss: 0.0626 - mean_absolute_error: 0.1785
7. set (Subject 1, F01) being trained for epoch 8!
Epoch 1/1
97/97 [==============================] - 41s 419ms/step - loss: 0.1012 - mean_absolute_error: 0.2274
8. set (Subject 7, M01) being trained for epoch 8!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0831 - mean_absolute_error: 0.2156
9. set (Subject 22, M01) being trained for epoch 8!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0366 - mean_absolute_error: 0.1261
10. set (Subject 6, F06) being trained for epoch 8!
Epoch 1/1
106/106 [==============================] - 44s 420ms/step - loss: 0.0903 - mean_absolute_error: 0.2015
11. set (Subject 13, M07) being trained for epoch 8!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0580 - mean_absolute_error: 0.1718
12. set (Subject 19, M11) being trained for epoch 8!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.3679 - mean_absolute_error: 0.5278
13. set (Subject 4, F04) being trained for epoch 8!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.3223 - mean_absolute_error: 0.5022
14. set (Subject 16, M09) being trained for epoch 8!
Epoch 1/1
180/180 [==============================] - 76s 422ms/step - loss: 0.3616 - mean_absolute_error: 0.5500
15. set (Subject 23, M13) being trained for epoch 8!
Epoch 1/1
111/111 [==============================] - 47s 420ms/step - loss: 0.2965 - mean_absolute_error: 0.4818
16. set (Subject 17, M10) being trained for epoch 8!
Epoch 1/1
76/76 [==============================] - 32s 423ms/step - loss: 0.2395 - mean_absolute_error: 0.4495
17. set (Subject 20, M12) being trained for epoch 8!
Epoch 1/1
108/108 [==============================] - 46s 421ms/step - loss: 0.2027 - mean_absolute_error: 0.4036
18. set (Subject 15, F03) being trained for epoch 8!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.2430 - mean_absolute_error: 0.4288
19. set (Subject 5, F05) being trained for epoch 8!
Epoch 1/1
186/186 [==============================] - 78s 422ms/step - loss: 0.1432 - mean_absolute_error: 0.3265
20. set (Subject 12, M06) being trained for epoch 8!
Epoch 1/1
144/144 [==============================] - 60s 419ms/step - loss: 0.1003 - mean_absolute_error: 0.2678
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 07:04:41.320148
1. set (Subject 15, F03) being trained for epoch 9!
Epoch 1/1
128/128 [==============================] - 54s 418ms/step - loss: 0.1869 - mean_absolute_error: 0.3628
2. set (Subject 12, M06) being trained for epoch 9!
Epoch 1/1
144/144 [==============================] - 61s 420ms/step - loss: 0.0832 - mean_absolute_error: 0.2417
3. set (Subject 13, M07) being trained for epoch 9!
Epoch 1/1
94/94 [==============================] - 40s 421ms/step - loss: 0.0698 - mean_absolute_error: 0.2251
4. set (Subject 23, M13) being trained for epoch 9!
Epoch 1/1
111/111 [==============================] - 46s 419ms/step - loss: 0.1450 - mean_absolute_error: 0.3120
5. set (Subject 10, M04) being trained for epoch 9!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0862 - mean_absolute_error: 0.2368
6. set (Subject 5, F05) being trained for epoch 9!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0894 - mean_absolute_error: 0.2456
7. set (Subject 20, M12) being trained for epoch 9!
Epoch 1/1
108/108 [==============================] - 46s 421ms/step - loss: 0.0867 - mean_absolute_error: 0.2392
8. set (Subject 19, M11) being trained for epoch 9!
Epoch 1/1
98/98 [==============================] - 41s 419ms/step - loss: 0.0873 - mean_absolute_error: 0.2315
9. set (Subject 11, M05) being trained for epoch 9!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0739 - mean_absolute_error: 0.2109
10. set (Subject 22, M01) being trained for epoch 9!
Epoch 1/1
130/130 [==============================] - 55s 423ms/step - loss: 0.0624 - mean_absolute_error: 0.1966
11. set (Subject 1, F01) being trained for epoch 9!
Epoch 1/1
97/97 [==============================] - 41s 418ms/step - loss: 0.1016 - mean_absolute_error: 0.2389
12. set (Subject 14, M08) being trained for epoch 9!
Epoch 1/1
157/157 [==============================] - 66s 419ms/step - loss: 0.1469 - mean_absolute_error: 0.3131
13. set (Subject 16, M09) being trained for epoch 9!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0872 - mean_absolute_error: 0.2256
14. set (Subject 3, F03) being trained for epoch 9!
Epoch 1/1
143/143 [==============================] - 60s 422ms/step - loss: 0.0829 - mean_absolute_error: 0.2309
15. set (Subject 8, M02) being trained for epoch 9!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0665 - mean_absolute_error: 0.1851
16. set (Subject 17, M10) being trained for epoch 9!
Epoch 1/1
76/76 [==============================] - 32s 421ms/step - loss: 0.0464 - mean_absolute_error: 0.1611
17. set (Subject 4, F04) being trained for epoch 9!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0859 - mean_absolute_error: 0.2222
18. set (Subject 2, F02) being trained for epoch 9!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.0859 - mean_absolute_error: 0.2222
19. set (Subject 6, F06) being trained for epoch 9!
Epoch 1/1
106/106 [==============================] - 44s 419ms/step - loss: 0.1023 - mean_absolute_error: 0.2226
20. set (Subject 7, M01) being trained for epoch 9!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0828 - mean_absolute_error: 0.2155
Epoch 9 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 07:24:47.652919
1. set (Subject 2, F02) being trained for epoch 10!
Epoch 1/1
99/99 [==============================] - 41s 419ms/step - loss: 0.0863 - mean_absolute_error: 0.2225
2. set (Subject 7, M01) being trained for epoch 10!
Epoch 1/1
146/146 [==============================] - 62s 422ms/step - loss: 0.0829 - mean_absolute_error: 0.2140
3. set (Subject 1, F01) being trained for epoch 10!
Epoch 1/1
97/97 [==============================] - 41s 421ms/step - loss: 0.0996 - mean_absolute_error: 0.2251
4. set (Subject 8, M02) being trained for epoch 10!
Epoch 1/1
152/152 [==============================] - 64s 421ms/step - loss: 0.0676 - mean_absolute_error: 0.1875
5. set (Subject 5, F05) being trained for epoch 10!
Epoch 1/1
186/186 [==============================] - 79s 423ms/step - loss: 0.0754 - mean_absolute_error: 0.2007
6. set (Subject 6, F06) being trained for epoch 10!
Epoch 1/1
106/106 [==============================] - 44s 419ms/step - loss: 0.1055 - mean_absolute_error: 0.2288
7. set (Subject 4, F04) being trained for epoch 10!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0937 - mean_absolute_error: 0.2267
8. set (Subject 14, M08) being trained for epoch 10!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1284 - mean_absolute_error: 0.2872
9. set (Subject 10, M04) being trained for epoch 10!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0623 - mean_absolute_error: 0.1778
10. set (Subject 11, M05) being trained for epoch 10!
Epoch 1/1
112/112 [==============================] - 47s 421ms/step - loss: 0.0503 - mean_absolute_error: 0.1538
11. set (Subject 20, M12) being trained for epoch 10!
Epoch 1/1
108/108 [==============================] - 46s 422ms/step - loss: 0.0469 - mean_absolute_error: 0.1552
12. set (Subject 15, F03) being trained for epoch 10!
Epoch 1/1
128/128 [==============================] - 54s 419ms/step - loss: 0.0729 - mean_absolute_error: 0.1950
13. set (Subject 3, F03) being trained for epoch 10!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0770 - mean_absolute_error: 0.2102
14. set (Subject 12, M06) being trained for epoch 10!
Epoch 1/1
144/144 [==============================] - 60s 417ms/step - loss: 0.0580 - mean_absolute_error: 0.1758
15. set (Subject 13, M07) being trained for epoch 10!
Epoch 1/1
94/94 [==============================] - 39s 419ms/step - loss: 0.0385 - mean_absolute_error: 0.1431
16. set (Subject 17, M10) being trained for epoch 10!
Epoch 1/1
76/76 [==============================] - 32s 419ms/step - loss: 0.0359 - mean_absolute_error: 0.1344
17. set (Subject 16, M09) being trained for epoch 10!
Epoch 1/1
180/180 [==============================] - 76s 420ms/step - loss: 0.0639 - mean_absolute_error: 0.1836
18. set (Subject 23, M13) being trained for epoch 10!
Epoch 1/1
111/111 [==============================] - 47s 422ms/step - loss: 0.0736 - mean_absolute_error: 0.1994
19. set (Subject 22, M01) being trained for epoch 10!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0326 - mean_absolute_error: 0.1134
20. set (Subject 19, M11) being trained for epoch 10!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.0452 - mean_absolute_error: 0.1663
Epoch 10 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 07:44:54.537999
1. set (Subject 23, M13) being trained for epoch 11!
Epoch 1/1
111/111 [==============================] - 46s 418ms/step - loss: 0.0724 - mean_absolute_error: 0.1957
2. set (Subject 19, M11) being trained for epoch 11!
Epoch 1/1
98/98 [==============================] - 41s 419ms/step - loss: 0.0437 - mean_absolute_error: 0.1617
3. set (Subject 20, M12) being trained for epoch 11!
Epoch 1/1
108/108 [==============================] - 46s 424ms/step - loss: 0.0411 - mean_absolute_error: 0.1334
4. set (Subject 13, M07) being trained for epoch 11!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0435 - mean_absolute_error: 0.1529
5. set (Subject 6, F06) being trained for epoch 11!
Epoch 1/1
106/106 [==============================] - 44s 419ms/step - loss: 0.0806 - mean_absolute_error: 0.1875
6. set (Subject 22, M01) being trained for epoch 11!
Epoch 1/1
130/130 [==============================] - 55s 422ms/step - loss: 0.0314 - mean_absolute_error: 0.1098
7. set (Subject 16, M09) being trained for epoch 11!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0551 - mean_absolute_error: 0.1621
8. set (Subject 15, F03) being trained for epoch 11!
Epoch 1/1
128/128 [==============================] - 54s 421ms/step - loss: 0.0607 - mean_absolute_error: 0.1650
9. set (Subject 5, F05) being trained for epoch 11!
Epoch 1/1
186/186 [==============================] - 78s 422ms/step - loss: 0.0914 - mean_absolute_error: 0.2142
10. set (Subject 10, M04) being trained for epoch 11!
Epoch 1/1
142/142 [==============================] - 60s 420ms/step - loss: 0.0676 - mean_absolute_error: 0.1868
11. set (Subject 4, F04) being trained for epoch 11!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0905 - mean_absolute_error: 0.2298
12. set (Subject 2, F02) being trained for epoch 11!
Epoch 1/1
99/99 [==============================] - 42s 421ms/step - loss: 0.1049 - mean_absolute_error: 0.2401
13. set (Subject 12, M06) being trained for epoch 11!
Epoch 1/1
144/144 [==============================] - 61s 420ms/step - loss: 0.0577 - mean_absolute_error: 0.1759
14. set (Subject 7, M01) being trained for epoch 11!
Epoch 1/1
146/146 [==============================] - 62s 421ms/step - loss: 0.0822 - mean_absolute_error: 0.2143
15. set (Subject 1, F01) being trained for epoch 11!
Epoch 1/1
97/97 [==============================] - 41s 420ms/step - loss: 0.1015 - mean_absolute_error: 0.2282
16. set (Subject 17, M10) being trained for epoch 11!
Epoch 1/1
76/76 [==============================] - 32s 421ms/step - loss: 0.0363 - mean_absolute_error: 0.1310
17. set (Subject 3, F03) being trained for epoch 11!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0775 - mean_absolute_error: 0.2075
18. set (Subject 8, M02) being trained for epoch 11!
Epoch 1/1
152/152 [==============================] - 64s 422ms/step - loss: 0.0718 - mean_absolute_error: 0.1987
19. set (Subject 11, M05) being trained for epoch 11!
Epoch 1/1
112/112 [==============================] - 47s 420ms/step - loss: 0.0482 - mean_absolute_error: 0.1504
20. set (Subject 14, M08) being trained for epoch 11!
Epoch 1/1
157/157 [==============================] - 66s 421ms/step - loss: 0.1218 - mean_absolute_error: 0.2768
Epoch 11 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 08:05:01.933075
1. set (Subject 8, M02) being trained for epoch 12!
Epoch 1/1
152/152 [==============================] - 63s 416ms/step - loss: 0.0715 - mean_absolute_error: 0.1960
2. set (Subject 14, M08) being trained for epoch 12!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1205 - mean_absolute_error: 0.2750
3. set (Subject 4, F04) being trained for epoch 12!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0863 - mean_absolute_error: 0.2252
4. set (Subject 1, F01) being trained for epoch 12!
Epoch 1/1
97/97 [==============================] - 41s 419ms/step - loss: 0.1051 - mean_absolute_error: 0.2291
5. set (Subject 22, M01) being trained for epoch 12!
Epoch 1/1
130/130 [==============================] - 55s 421ms/step - loss: 0.0344 - mean_absolute_error: 0.1194
6. set (Subject 11, M05) being trained for epoch 12!
Epoch 1/1
112/112 [==============================] - 47s 419ms/step - loss: 0.0464 - mean_absolute_error: 0.1434
7. set (Subject 3, F03) being trained for epoch 12!
Epoch 1/1
143/143 [==============================] - 60s 422ms/step - loss: 0.0772 - mean_absolute_error: 0.2105
8. set (Subject 2, F02) being trained for epoch 12!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.0998 - mean_absolute_error: 0.2353
9. set (Subject 6, F06) being trained for epoch 12!
Epoch 1/1
106/106 [==============================] - 44s 419ms/step - loss: 0.0890 - mean_absolute_error: 0.2031
10. set (Subject 5, F05) being trained for epoch 12!
Epoch 1/1
186/186 [==============================] - 78s 422ms/step - loss: 0.0798 - mean_absolute_error: 0.1978
11. set (Subject 16, M09) being trained for epoch 12!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0650 - mean_absolute_error: 0.1845
12. set (Subject 23, M13) being trained for epoch 12!
Epoch 1/1
111/111 [==============================] - 47s 423ms/step - loss: 0.0725 - mean_absolute_error: 0.1981
13. set (Subject 7, M01) being trained for epoch 12!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0834 - mean_absolute_error: 0.2153
14. set (Subject 19, M11) being trained for epoch 12!
Epoch 1/1
98/98 [==============================] - 41s 419ms/step - loss: 0.0487 - mean_absolute_error: 0.1753
15. set (Subject 20, M12) being trained for epoch 12!
Epoch 1/1
108/108 [==============================] - 46s 421ms/step - loss: 0.0424 - mean_absolute_error: 0.1386
16. set (Subject 17, M10) being trained for epoch 12!
Epoch 1/1
76/76 [==============================] - 32s 422ms/step - loss: 0.0304 - mean_absolute_error: 0.1153
17. set (Subject 12, M06) being trained for epoch 12!
Epoch 1/1
144/144 [==============================] - 60s 417ms/step - loss: 0.0607 - mean_absolute_error: 0.1789
18. set (Subject 13, M07) being trained for epoch 12!
Epoch 1/1
94/94 [==============================] - 40s 421ms/step - loss: 0.0403 - mean_absolute_error: 0.1471
19. set (Subject 10, M04) being trained for epoch 12!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0636 - mean_absolute_error: 0.1795
20. set (Subject 15, F03) being trained for epoch 12!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.0698 - mean_absolute_error: 0.1872
Epoch 12 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 08:25:08.318562
1. set (Subject 13, M07) being trained for epoch 13!
Epoch 1/1
94/94 [==============================] - 39s 417ms/step - loss: 0.0401 - mean_absolute_error: 0.1462
2. set (Subject 15, F03) being trained for epoch 13!
Epoch 1/1
128/128 [==============================] - 54s 422ms/step - loss: 0.0681 - mean_absolute_error: 0.1833
3. set (Subject 16, M09) being trained for epoch 13!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0584 - mean_absolute_error: 0.1703
4. set (Subject 20, M12) being trained for epoch 13!
Epoch 1/1
108/108 [==============================] - 46s 422ms/step - loss: 0.0411 - mean_absolute_error: 0.1324
5. set (Subject 11, M05) being trained for epoch 13!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0445 - mean_absolute_error: 0.1374
6. set (Subject 10, M04) being trained for epoch 13!
Epoch 1/1
142/142 [==============================] - 60s 422ms/step - loss: 0.0672 - mean_absolute_error: 0.1861
7. set (Subject 12, M06) being trained for epoch 13!
Epoch 1/1
144/144 [==============================] - 60s 419ms/step - loss: 0.0610 - mean_absolute_error: 0.1803
8. set (Subject 23, M13) being trained for epoch 13!
Epoch 1/1
111/111 [==============================] - 47s 421ms/step - loss: 0.0720 - mean_absolute_error: 0.1968
9. set (Subject 22, M01) being trained for epoch 13!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0317 - mean_absolute_error: 0.1100
10. set (Subject 6, F06) being trained for epoch 13!
Epoch 1/1
106/106 [==============================] - 45s 421ms/step - loss: 0.0819 - mean_absolute_error: 0.1887
11. set (Subject 3, F03) being trained for epoch 13!
Epoch 1/1
143/143 [==============================] - 60s 421ms/step - loss: 0.0798 - mean_absolute_error: 0.2126
12. set (Subject 8, M02) being trained for epoch 13!
Epoch 1/1
152/152 [==============================] - 64s 421ms/step - loss: 0.0766 - mean_absolute_error: 0.2067
13. set (Subject 19, M11) being trained for epoch 13!
Epoch 1/1
98/98 [==============================] - 41s 419ms/step - loss: 0.0471 - mean_absolute_error: 0.1702
14. set (Subject 14, M08) being trained for epoch 13!
Epoch 1/1
157/157 [==============================] - 66s 419ms/step - loss: 0.1168 - mean_absolute_error: 0.2705
15. set (Subject 4, F04) being trained for epoch 13!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0880 - mean_absolute_error: 0.2278
16. set (Subject 17, M10) being trained for epoch 13!
Epoch 1/1
76/76 [==============================] - 32s 421ms/step - loss: 0.0296 - mean_absolute_error: 0.1160
17. set (Subject 7, M01) being trained for epoch 13!
Epoch 1/1
146/146 [==============================] - 62s 422ms/step - loss: 0.0849 - mean_absolute_error: 0.2190
18. set (Subject 1, F01) being trained for epoch 13!
Epoch 1/1
97/97 [==============================] - 41s 418ms/step - loss: 0.1078 - mean_absolute_error: 0.2323
19. set (Subject 5, F05) being trained for epoch 13!
Epoch 1/1
186/186 [==============================] - 79s 423ms/step - loss: 0.0815 - mean_absolute_error: 0.2009
20. set (Subject 2, F02) being trained for epoch 13!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.0962 - mean_absolute_error: 0.2325
Epoch 13 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 08:45:15.262168
1. set (Subject 1, F01) being trained for epoch 14!
Epoch 1/1
97/97 [==============================] - 40s 414ms/step - loss: 0.0999 - mean_absolute_error: 0.2266
2. set (Subject 2, F02) being trained for epoch 14!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.0897 - mean_absolute_error: 0.2264
3. set (Subject 3, F03) being trained for epoch 14!
Epoch 1/1
143/143 [==============================] - 60s 423ms/step - loss: 0.0783 - mean_absolute_error: 0.2081
4. set (Subject 4, F04) being trained for epoch 14!
Epoch 1/1
146/146 [==============================] - 62s 422ms/step - loss: 0.0874 - mean_absolute_error: 0.2219
5. set (Subject 10, M04) being trained for epoch 14!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0622 - mean_absolute_error: 0.1794
6. set (Subject 5, F05) being trained for epoch 14!
Epoch 1/1
186/186 [==============================] - 79s 422ms/step - loss: 0.0754 - mean_absolute_error: 0.1962
7. set (Subject 7, M01) being trained for epoch 14!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0822 - mean_absolute_error: 0.2115
8. set (Subject 8, M02) being trained for epoch 14!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0686 - mean_absolute_error: 0.1905
9. set (Subject 11, M05) being trained for epoch 14!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0509 - mean_absolute_error: 0.1561
10. set (Subject 22, M01) being trained for epoch 14!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0383 - mean_absolute_error: 0.1312
11. set (Subject 12, M06) being trained for epoch 14!
Epoch 1/1
144/144 [==============================] - 60s 420ms/step - loss: 0.0538 - mean_absolute_error: 0.1705
12. set (Subject 13, M07) being trained for epoch 14!
Epoch 1/1
94/94 [==============================] - 39s 419ms/step - loss: 0.0376 - mean_absolute_error: 0.1463
13. set (Subject 14, M08) being trained for epoch 14!
Epoch 1/1
157/157 [==============================] - 66s 421ms/step - loss: 0.1265 - mean_absolute_error: 0.2846
14. set (Subject 15, F03) being trained for epoch 14!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.0731 - mean_absolute_error: 0.1941
15. set (Subject 16, M09) being trained for epoch 14!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0620 - mean_absolute_error: 0.1785
16. set (Subject 17, M10) being trained for epoch 14!
Epoch 1/1
76/76 [==============================] - 32s 420ms/step - loss: 0.0307 - mean_absolute_error: 0.1165
17. set (Subject 19, M11) being trained for epoch 14!
Epoch 1/1
98/98 [==============================] - 41s 416ms/step - loss: 0.0455 - mean_absolute_error: 0.1672
18. set (Subject 20, M12) being trained for epoch 14!
Epoch 1/1
108/108 [==============================] - 45s 420ms/step - loss: 0.0415 - mean_absolute_error: 0.1352
19. set (Subject 6, F06) being trained for epoch 14!
Epoch 1/1
106/106 [==============================] - 45s 421ms/step - loss: 0.0805 - mean_absolute_error: 0.1873
20. set (Subject 23, M13) being trained for epoch 14!
Epoch 1/1
111/111 [==============================] - 47s 421ms/step - loss: 0.0716 - mean_absolute_error: 0.1937
Epoch 14 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 09:05:21.595584
1. set (Subject 20, M12) being trained for epoch 15!
Epoch 1/1
108/108 [==============================] - 45s 420ms/step - loss: 0.0404 - mean_absolute_error: 0.1306
2. set (Subject 23, M13) being trained for epoch 15!
Epoch 1/1
111/111 [==============================] - 47s 422ms/step - loss: 0.0712 - mean_absolute_error: 0.1926
3. set (Subject 12, M06) being trained for epoch 15!
Epoch 1/1
144/144 [==============================] - 60s 419ms/step - loss: 0.0647 - mean_absolute_error: 0.1847
4. set (Subject 16, M09) being trained for epoch 15!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0569 - mean_absolute_error: 0.1655
5. set (Subject 5, F05) being trained for epoch 15!
Epoch 1/1
186/186 [==============================] - 78s 421ms/step - loss: 0.0858 - mean_absolute_error: 0.2071
6. set (Subject 6, F06) being trained for epoch 15!
Epoch 1/1
106/106 [==============================] - 45s 421ms/step - loss: 0.0820 - mean_absolute_error: 0.1893
7. set (Subject 19, M11) being trained for epoch 15!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.0470 - mean_absolute_error: 0.1677
8. set (Subject 13, M07) being trained for epoch 15!
Epoch 1/1
94/94 [==============================] - 40s 421ms/step - loss: 0.0438 - mean_absolute_error: 0.1516
9. set (Subject 10, M04) being trained for epoch 15!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0665 - mean_absolute_error: 0.1845
10. set (Subject 11, M05) being trained for epoch 15!
Epoch 1/1
112/112 [==============================] - 47s 418ms/step - loss: 0.0448 - mean_absolute_error: 0.1395
11. set (Subject 7, M01) being trained for epoch 15!
Epoch 1/1
146/146 [==============================] - 62s 421ms/step - loss: 0.0847 - mean_absolute_error: 0.2193
12. set (Subject 1, F01) being trained for epoch 15!
Epoch 1/1
97/97 [==============================] - 41s 420ms/step - loss: 0.1042 - mean_absolute_error: 0.2302
13. set (Subject 15, F03) being trained for epoch 15!
Epoch 1/1
128/128 [==============================] - 54s 421ms/step - loss: 0.0685 - mean_absolute_error: 0.1848
14. set (Subject 2, F02) being trained for epoch 15!
Epoch 1/1
99/99 [==============================] - 42s 420ms/step - loss: 0.1040 - mean_absolute_error: 0.2411
15. set (Subject 3, F03) being trained for epoch 15!
Epoch 1/1
143/143 [==============================] - 60s 421ms/step - loss: 0.0785 - mean_absolute_error: 0.2092
16. set (Subject 17, M10) being trained for epoch 15!
Epoch 1/1
76/76 [==============================] - 32s 420ms/step - loss: 0.0330 - mean_absolute_error: 0.1241
17. set (Subject 14, M08) being trained for epoch 15!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1192 - mean_absolute_error: 0.2742
18. set (Subject 4, F04) being trained for epoch 15!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0881 - mean_absolute_error: 0.2268
19. set (Subject 22, M01) being trained for epoch 15!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0331 - mean_absolute_error: 0.1158
20. set (Subject 8, M02) being trained for epoch 15!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0751 - mean_absolute_error: 0.2039
Epoch 15 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 09:25:27.808724
1. set (Subject 4, F04) being trained for epoch 16!
Epoch 1/1
146/146 [==============================] - 61s 419ms/step - loss: 0.0867 - mean_absolute_error: 0.2249
2. set (Subject 8, M02) being trained for epoch 16!
Epoch 1/1
152/152 [==============================] - 64s 420ms/step - loss: 0.0715 - mean_absolute_error: 0.1977
3. set (Subject 7, M01) being trained for epoch 16!
Epoch 1/1
146/146 [==============================] - 62s 422ms/step - loss: 0.0823 - mean_absolute_error: 0.2167
4. set (Subject 3, F03) being trained for epoch 16!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0764 - mean_absolute_error: 0.2086
5. set (Subject 6, F06) being trained for epoch 16!
Epoch 1/1
106/106 [==============================] - 44s 418ms/step - loss: 0.0890 - mean_absolute_error: 0.2034
6. set (Subject 22, M01) being trained for epoch 16!
Epoch 1/1
130/130 [==============================] - 55s 421ms/step - loss: 0.0348 - mean_absolute_error: 0.1206
7. set (Subject 14, M08) being trained for epoch 16!
Epoch 1/1
157/157 [==============================] - 66s 419ms/step - loss: 0.1183 - mean_absolute_error: 0.2723
8. set (Subject 1, F01) being trained for epoch 16!
Epoch 1/1
97/97 [==============================] - 41s 420ms/step - loss: 0.1078 - mean_absolute_error: 0.2325
9. set (Subject 5, F05) being trained for epoch 16!
Epoch 1/1
186/186 [==============================] - 78s 422ms/step - loss: 0.0816 - mean_absolute_error: 0.2006
10. set (Subject 10, M04) being trained for epoch 16!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0633 - mean_absolute_error: 0.1791
11. set (Subject 19, M11) being trained for epoch 16!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.0505 - mean_absolute_error: 0.1799
12. set (Subject 20, M12) being trained for epoch 16!
Epoch 1/1
108/108 [==============================] - 46s 421ms/step - loss: 0.0435 - mean_absolute_error: 0.1435
13. set (Subject 2, F02) being trained for epoch 16!
Epoch 1/1
99/99 [==============================] - 42s 421ms/step - loss: 0.1004 - mean_absolute_error: 0.2378
14. set (Subject 23, M13) being trained for epoch 16!
Epoch 1/1
111/111 [==============================] - 47s 419ms/step - loss: 0.0752 - mean_absolute_error: 0.2042
15. set (Subject 12, M06) being trained for epoch 16!
Epoch 1/1
144/144 [==============================] - 61s 421ms/step - loss: 0.0561 - mean_absolute_error: 0.1730
16. set (Subject 17, M10) being trained for epoch 16!
Epoch 1/1
76/76 [==============================] - 32s 419ms/step - loss: 0.0357 - mean_absolute_error: 0.1300
17. set (Subject 15, F03) being trained for epoch 16!
Epoch 1/1
128/128 [==============================] - 54s 420ms/step - loss: 0.0711 - mean_absolute_error: 0.1896
18. set (Subject 16, M09) being trained for epoch 16!
Epoch 1/1
180/180 [==============================] - 76s 422ms/step - loss: 0.0607 - mean_absolute_error: 0.1749
19. set (Subject 11, M05) being trained for epoch 16!
Epoch 1/1
112/112 [==============================] - 47s 420ms/step - loss: 0.0448 - mean_absolute_error: 0.1398
20. set (Subject 13, M07) being trained for epoch 16!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0416 - mean_absolute_error: 0.1480
Epoch 16 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 09:45:34.065162
1. set (Subject 16, M09) being trained for epoch 17!
Epoch 1/1
180/180 [==============================] - 75s 419ms/step - loss: 0.0585 - mean_absolute_error: 0.1702
2. set (Subject 13, M07) being trained for epoch 17!
Epoch 1/1
94/94 [==============================] - 39s 420ms/step - loss: 0.0432 - mean_absolute_error: 0.1493
3. set (Subject 19, M11) being trained for epoch 17!
Epoch 1/1
98/98 [==============================] - 41s 420ms/step - loss: 0.0459 - mean_absolute_error: 0.1657
4. set (Subject 12, M06) being trained for epoch 17!
Epoch 1/1
144/144 [==============================] - 61s 421ms/step - loss: 0.0630 - mean_absolute_error: 0.1820
5. set (Subject 22, M01) being trained for epoch 17!
Epoch 1/1
130/130 [==============================] - 55s 420ms/step - loss: 0.0321 - mean_absolute_error: 0.1108
6. set (Subject 11, M05) being trained for epoch 17!
Epoch 1/1
112/112 [==============================] - 47s 420ms/step - loss: 0.0448 - mean_absolute_error: 0.1386
7. set (Subject 15, F03) being trained for epoch 17!
Epoch 1/1
128/128 [==============================] - 54s 422ms/step - loss: 0.0652 - mean_absolute_error: 0.1772
8. set (Subject 20, M12) being trained for epoch 17!
Epoch 1/1
108/108 [==============================] - 46s 422ms/step - loss: 0.0407 - mean_absolute_error: 0.1314
9. set (Subject 6, F06) being trained for epoch 17!
Epoch 1/1
106/106 [==============================] - 44s 418ms/step - loss: 0.0795 - mean_absolute_error: 0.1849
10. set (Subject 5, F05) being trained for epoch 17!
Epoch 1/1
186/186 [==============================] - 78s 420ms/step - loss: 0.0873 - mean_absolute_error: 0.2104
11. set (Subject 14, M08) being trained for epoch 17!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1168 - mean_absolute_error: 0.2709
12. set (Subject 4, F04) being trained for epoch 17!
Epoch 1/1
146/146 [==============================] - 61s 420ms/step - loss: 0.0906 - mean_absolute_error: 0.2303
13. set (Subject 23, M13) being trained for epoch 17!
Epoch 1/1
111/111 [==============================] - 47s 420ms/step - loss: 0.0717 - mean_absolute_error: 0.1947
14. set (Subject 8, M02) being trained for epoch 17!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0762 - mean_absolute_error: 0.2052
15. set (Subject 7, M01) being trained for epoch 17!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0834 - mean_absolute_error: 0.2177
16. set (Subject 17, M10) being trained for epoch 17!
Epoch 1/1
76/76 [==============================] - 32s 422ms/step - loss: 0.0312 - mean_absolute_error: 0.1182
17. set (Subject 2, F02) being trained for epoch 17!
Epoch 1/1
99/99 [==============================] - 42s 422ms/step - loss: 0.1032 - mean_absolute_error: 0.2393
18. set (Subject 3, F03) being trained for epoch 17!
Epoch 1/1
143/143 [==============================] - 60s 421ms/step - loss: 0.0771 - mean_absolute_error: 0.2068
19. set (Subject 10, M04) being trained for epoch 17!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0633 - mean_absolute_error: 0.1807
20. set (Subject 1, F01) being trained for epoch 17!
Epoch 1/1
97/97 [==============================] - 41s 420ms/step - loss: 0.1022 - mean_absolute_error: 0.2290
Epoch 17 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 10:05:40.337440
1. set (Subject 3, F03) being trained for epoch 18!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0771 - mean_absolute_error: 0.2059
2. set (Subject 1, F01) being trained for epoch 18!
Epoch 1/1
97/97 [==============================] - 41s 421ms/step - loss: 0.1022 - mean_absolute_error: 0.2313
3. set (Subject 14, M08) being trained for epoch 18!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1232 - mean_absolute_error: 0.2800
4. set (Subject 7, M01) being trained for epoch 18!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0824 - mean_absolute_error: 0.2138
5. set (Subject 11, M05) being trained for epoch 18!
Epoch 1/1
112/112 [==============================] - 47s 417ms/step - loss: 0.0466 - mean_absolute_error: 0.1470
6. set (Subject 10, M04) being trained for epoch 18!
Epoch 1/1
142/142 [==============================] - 60s 420ms/step - loss: 0.0628 - mean_absolute_error: 0.1780
7. set (Subject 2, F02) being trained for epoch 18!
Epoch 1/1
99/99 [==============================] - 42s 421ms/step - loss: 0.0949 - mean_absolute_error: 0.2321
8. set (Subject 4, F04) being trained for epoch 18!
Epoch 1/1
146/146 [==============================] - 61s 419ms/step - loss: 0.0879 - mean_absolute_error: 0.2235
9. set (Subject 22, M01) being trained for epoch 18!
Epoch 1/1
130/130 [==============================] - 55s 421ms/step - loss: 0.0365 - mean_absolute_error: 0.1268
10. set (Subject 6, F06) being trained for epoch 18!
Epoch 1/1
106/106 [==============================] - 44s 418ms/step - loss: 0.0903 - mean_absolute_error: 0.2025
11. set (Subject 15, F03) being trained for epoch 18!
Epoch 1/1
128/128 [==============================] - 54s 418ms/step - loss: 0.0695 - mean_absolute_error: 0.1868
12. set (Subject 16, M09) being trained for epoch 18!
Epoch 1/1
180/180 [==============================] - 76s 420ms/step - loss: 0.0598 - mean_absolute_error: 0.1734
13. set (Subject 8, M02) being trained for epoch 18!
Epoch 1/1
152/152 [==============================] - 64s 420ms/step - loss: 0.0757 - mean_absolute_error: 0.2041
14. set (Subject 13, M07) being trained for epoch 18!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0403 - mean_absolute_error: 0.1485
15. set (Subject 19, M11) being trained for epoch 18!
Epoch 1/1
98/98 [==============================] - 41s 418ms/step - loss: 0.0458 - mean_absolute_error: 0.1677
16. set (Subject 17, M10) being trained for epoch 18!
Epoch 1/1
76/76 [==============================] - 32s 421ms/step - loss: 0.0307 - mean_absolute_error: 0.1187
17. set (Subject 23, M13) being trained for epoch 18!
Epoch 1/1
111/111 [==============================] - 46s 419ms/step - loss: 0.0730 - mean_absolute_error: 0.1972
18. set (Subject 12, M06) being trained for epoch 18!
Epoch 1/1
144/144 [==============================] - 60s 418ms/step - loss: 0.0618 - mean_absolute_error: 0.1806
19. set (Subject 5, F05) being trained for epoch 18!
Epoch 1/1
186/186 [==============================] - 79s 423ms/step - loss: 0.0814 - mean_absolute_error: 0.2016
20. set (Subject 20, M12) being trained for epoch 18!
Epoch 1/1
108/108 [==============================] - 46s 422ms/step - loss: 0.0442 - mean_absolute_error: 0.1446
Epoch 18 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 10:25:45.774783
1. set (Subject 12, M06) being trained for epoch 19!
Epoch 1/1
144/144 [==============================] - 60s 417ms/step - loss: 0.0568 - mean_absolute_error: 0.1738
2. set (Subject 20, M12) being trained for epoch 19!
Epoch 1/1
108/108 [==============================] - 46s 423ms/step - loss: 0.0446 - mean_absolute_error: 0.1454
3. set (Subject 15, F03) being trained for epoch 19!
Epoch 1/1
128/128 [==============================] - 54s 421ms/step - loss: 0.0702 - mean_absolute_error: 0.1882
4. set (Subject 19, M11) being trained for epoch 19!
Epoch 1/1
98/98 [==============================] - 41s 419ms/step - loss: 0.0472 - mean_absolute_error: 0.1700
5. set (Subject 10, M04) being trained for epoch 19!
Epoch 1/1
142/142 [==============================] - 59s 418ms/step - loss: 0.0648 - mean_absolute_error: 0.1820
6. set (Subject 5, F05) being trained for epoch 19!
Epoch 1/1
186/186 [==============================] - 78s 422ms/step - loss: 0.0807 - mean_absolute_error: 0.2011
7. set (Subject 23, M13) being trained for epoch 19!
Epoch 1/1
111/111 [==============================] - 47s 421ms/step - loss: 0.0735 - mean_absolute_error: 0.2009
8. set (Subject 16, M09) being trained for epoch 19!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0616 - mean_absolute_error: 0.1761
9. set (Subject 11, M05) being trained for epoch 19!
Epoch 1/1
112/112 [==============================] - 47s 420ms/step - loss: 0.0456 - mean_absolute_error: 0.1420
10. set (Subject 22, M01) being trained for epoch 19!
Epoch 1/1
130/130 [==============================] - 55s 421ms/step - loss: 0.0315 - mean_absolute_error: 0.1092
11. set (Subject 2, F02) being trained for epoch 19!
Epoch 1/1
99/99 [==============================] - 42s 420ms/step - loss: 0.1061 - mean_absolute_error: 0.2431
12. set (Subject 3, F03) being trained for epoch 19!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0789 - mean_absolute_error: 0.2092
13. set (Subject 13, M07) being trained for epoch 19!
Epoch 1/1
94/94 [==============================] - 40s 422ms/step - loss: 0.0399 - mean_absolute_error: 0.1430
14. set (Subject 1, F01) being trained for epoch 19!
Epoch 1/1
97/97 [==============================] - 41s 420ms/step - loss: 0.1027 - mean_absolute_error: 0.2302
15. set (Subject 14, M08) being trained for epoch 19!
Epoch 1/1
157/157 [==============================] - 66s 419ms/step - loss: 0.1215 - mean_absolute_error: 0.2777
16. set (Subject 17, M10) being trained for epoch 19!
Epoch 1/1
76/76 [==============================] - 32s 423ms/step - loss: 0.0321 - mean_absolute_error: 0.1199
17. set (Subject 8, M02) being trained for epoch 19!
Epoch 1/1
152/152 [==============================] - 64s 419ms/step - loss: 0.0738 - mean_absolute_error: 0.2006
18. set (Subject 7, M01) being trained for epoch 19!
Epoch 1/1
146/146 [==============================] - 61s 421ms/step - loss: 0.0826 - mean_absolute_error: 0.2162
19. set (Subject 6, F06) being trained for epoch 19!
Epoch 1/1
106/106 [==============================] - 45s 420ms/step - loss: 0.0862 - mean_absolute_error: 0.1959
20. set (Subject 4, F04) being trained for epoch 19!
Epoch 1/1
146/146 [==============================] - 62s 421ms/step - loss: 0.0884 - mean_absolute_error: 0.2274
Epoch 19 completed!
All frames and annotations from 20 datasets have been read by 2019-01-20 10:45:52.534411
1. set (Subject 7, M01) being trained for epoch 20!
Epoch 1/1
146/146 [==============================] - 61s 419ms/step - loss: 0.0828 - mean_absolute_error: 0.2164
2. set (Subject 4, F04) being trained for epoch 20!
Epoch 1/1
146/146 [==============================] - 62s 423ms/step - loss: 0.0864 - mean_absolute_error: 0.2240
3. set (Subject 2, F02) being trained for epoch 20!
Epoch 1/1
99/99 [==============================] - 42s 420ms/step - loss: 0.0980 - mean_absolute_error: 0.2333
4. set (Subject 14, M08) being trained for epoch 20!
Epoch 1/1
157/157 [==============================] - 66s 420ms/step - loss: 0.1227 - mean_absolute_error: 0.2785
5. set (Subject 5, F05) being trained for epoch 20!
Epoch 1/1
186/186 [==============================] - 79s 423ms/step - loss: 0.0797 - mean_absolute_error: 0.1979
6. set (Subject 6, F06) being trained for epoch 20!
Epoch 1/1
106/106 [==============================] - 44s 419ms/step - loss: 0.0902 - mean_absolute_error: 0.2039
7. set (Subject 8, M02) being trained for epoch 20!
Epoch 1/1
152/152 [==============================] - 64s 420ms/step - loss: 0.0709 - mean_absolute_error: 0.1960
8. set (Subject 3, F03) being trained for epoch 20!
Epoch 1/1
143/143 [==============================] - 60s 420ms/step - loss: 0.0771 - mean_absolute_error: 0.2100
9. set (Subject 10, M04) being trained for epoch 20!
Epoch 1/1
142/142 [==============================] - 60s 421ms/step - loss: 0.0629 - mean_absolute_error: 0.1794
10. set (Subject 11, M05) being trained for epoch 20!
Epoch 1/1
112/112 [==============================] - 47s 421ms/step - loss: 0.0479 - mean_absolute_error: 0.1503
11. set (Subject 23, M13) being trained for epoch 20!
Epoch 1/1
111/111 [==============================] - 46s 418ms/step - loss: 0.0753 - mean_absolute_error: 0.2042
12. set (Subject 12, M06) being trained for epoch 20!
Epoch 1/1
144/144 [==============================] - 60s 419ms/step - loss: 0.0566 - mean_absolute_error: 0.1741
13. set (Subject 1, F01) being trained for epoch 20!
Epoch 1/1
97/97 [==============================] - 41s 419ms/step - loss: 0.1003 - mean_absolute_error: 0.2266
14. set (Subject 20, M12) being trained for epoch 20!
Epoch 1/1
108/108 [==============================] - 45s 420ms/step - loss: 0.0465 - mean_absolute_error: 0.1511
15. set (Subject 15, F03) being trained for epoch 20!
Epoch 1/1
128/128 [==============================] - 54s 419ms/step - loss: 0.0724 - mean_absolute_error: 0.1926
16. set (Subject 17, M10) being trained for epoch 20!
Epoch 1/1
76/76 [==============================] - 32s 419ms/step - loss: 0.0333 - mean_absolute_error: 0.1229
17. set (Subject 13, M07) being trained for epoch 20!
Epoch 1/1
94/94 [==============================] - 40s 421ms/step - loss: 0.0397 - mean_absolute_error: 0.1455
18. set (Subject 19, M11) being trained for epoch 20!
Epoch 1/1
98/98 [==============================] - 41s 420ms/step - loss: 0.0485 - mean_absolute_error: 0.1740
19. set (Subject 22, M01) being trained for epoch 20!
Epoch 1/1
130/130 [==============================] - 55s 422ms/step - loss: 0.0327 - mean_absolute_error: 0.1132
20. set (Subject 16, M09) being trained for epoch 20!
Epoch 1/1
180/180 [==============================] - 76s 421ms/step - loss: 0.0588 - mean_absolute_error: 0.1714
Epoch 20 completed!
Exp2019-01-20_04-23-27.h5 has been saved.
The subjects are trained: [(7, 'M01'), (4, 'F04'), (2, 'F02'), (14, 'M08'), (5, 'F05'), (6, 'F06'), (8, 'M02'), (3, 'F03
'), (10, 'M04'), (11, 'M05'), (23, 'M13'), (12, 'M06'), (1, 'F01'), (20, 'M12'), (15, 'F03'), (17, 'M10'), (13, 'M07'),
(19, 'M11'), (22, 'M01'), (16, 'M09')]
Evaluating model VGG16_seqLen16_lstm10_output3_inEpochs1_outEpochs20_AdamOpt_lr-0.000100__2019-01-20_04-23-27
The subjects will be tested: [(9, 'M03'), (18, 'F05'), (21, 'F02'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-01-20 11:05:55.709299
For the Subject 9 (M03):
217/217 [==============================] - 54s 251ms/step
        The absolute mean error on Pitch angle estimation: 18.53 Degree
        The absolute mean error on Yaw angle estimation: 26.39 Degree
        The absolute mean error on Roll angle estimation: 8.39 Degree
For the Subject 18 (F05):
150/150 [==============================] - 38s 254ms/step
        The absolute mean error on Pitch angle estimation: 21.75 Degree
        The absolute mean error on Yaw angle estimation: 20.85 Degree
        The absolute mean error on Roll angle estimation: 11.38 Degree
For the Subject 21 (F02):
155/155 [==============================] - 39s 253ms/step
        The absolute mean error on Pitch angle estimation: 22.68 Degree
        The absolute mean error on Yaw angle estimation: 16.16 Degree
        The absolute mean error on Roll angle estimation: 16.54 Degree
For the Subject 24 (M14):
119/119 [==============================] - 30s 254ms/step
        The absolute mean error on Pitch angle estimation: 18.50 Degree
        The absolute mean error on Yaw angle estimation: 11.64 Degree
        The absolute mean error on Roll angle estimation: 5.45 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 20.36 Degree
        The absolute mean error on Yaw angle estimations: 18.76 Degree
        The absolute mean error on Roll angle estimations: 10.44 Degree
subject9_Exp2019-01-20_04-23-27.png has been saved by 2019-01-20 11:09:03.077748.
subject18_Exp2019-01-20_04-23-27.png has been saved by 2019-01-20 11:09:03.272954.
subject21_Exp2019-01-20_04-23-27.png has been saved by 2019-01-20 11:09:03.471265.
subject24_Exp2019-01-20_04-23-27.png has been saved by 2019-01-20 11:09:03.656507.
Model Exp2019-01-20_04-23-27 has been evaluated successfully.
Model Exp2019-01-20_04-23-27 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$
