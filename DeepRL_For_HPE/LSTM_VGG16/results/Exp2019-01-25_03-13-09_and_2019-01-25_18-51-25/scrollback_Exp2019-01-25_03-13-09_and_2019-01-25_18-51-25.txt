36
2019-01-24 02:37:30.360217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c913900 of size 1536
2019-01-24 02:37:30.360222: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c913f00 of size 1536
2019-01-24 02:37:30.360227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c914500 of size 1536
2019-01-24 02:37:30.360232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c914b00 of size 1536
2019-01-24 02:37:30.360237: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c915100 of size 1536
2019-01-24 02:37:30.360242: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c915700 of size 1536
2019-01-24 02:37:30.360248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c915d00 of size 1536
2019-01-24 02:37:30.360253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c916300 of size 1536
2019-01-24 02:37:30.360258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c916900 of size 1536
2019-01-24 02:37:30.360263: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c916f00 of size 1536
2019-01-24 02:37:30.360268: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c917500 of size 1536
2019-01-24 02:37:30.360273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c917b00 of size 1536
2019-01-24 02:37:30.360278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918100 of size 1536
2019-01-24 02:37:30.360283: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918700 of size 1536
2019-01-24 02:37:30.360288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918d00 of size 256
2019-01-24 02:37:30.360294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918e00 of size 1536
2019-01-24 02:37:30.360299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919400 of size 256
2019-01-24 02:37:30.360304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919500 of size 256
2019-01-24 02:37:30.360309: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919600 of size 1536
2019-01-24 02:37:30.360314: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919c00 of size 2816
2019-01-24 02:37:30.360319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91a700 of size 256
2019-01-24 02:37:30.360324: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91a800 of size 1536
2019-01-24 02:37:30.360330: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ae00 of size 2816
2019-01-24 02:37:30.360335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91b900 of size 256
2019-01-24 02:37:30.360340: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ba00 of size 1536
2019-01-24 02:37:30.360345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c000 of size 256
2019-01-24 02:37:30.360350: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c100 of size 256
2019-01-24 02:37:30.360356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c200 of size 1536
2019-01-24 02:37:30.360361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c800 of size 256
2019-01-24 02:37:30.360366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c900 of size 1536
2019-01-24 02:37:30.360371: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91cf00 of size 2816
2019-01-24 02:37:30.360377: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91da00 of size 256
2019-01-24 02:37:30.360382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91db00 of size 256
2019-01-24 02:37:30.360387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91dc00 of size 1536
2019-01-24 02:37:30.360392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91e200 of size 256
2019-01-24 02:37:30.360397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91e300 of size 256
2019-01-24 02:37:30.360402: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91e400 of size 1536
2019-01-24 02:37:30.360408: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ea00 of size 256
2019-01-24 02:37:30.360413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91eb00 of size 256
2019-01-24 02:37:30.360418: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ec00 of size 1536
2019-01-24 02:37:30.360423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91f200 of size 2816
2019-01-24 02:37:30.360428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91fd00 of size 256
2019-01-24 02:37:30.360433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91fe00 of size 1536
2019-01-24 02:37:30.360438: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920400 of size 256
2019-01-24 02:37:30.360443: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920500 of size 256
2019-01-24 02:37:30.360449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920600 of size 1536
2019-01-24 02:37:30.360454: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920c00 of size 2816
2019-01-24 02:37:30.360459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c921700 of size 256
2019-01-24 02:37:30.360464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c921800 of size 1536
2019-01-24 02:37:30.360469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c921e00 of size 2816
2019-01-24 02:37:30.360474: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c922900 of size 256
2019-01-24 02:37:30.360479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c922a00 of size 1536
2019-01-24 02:37:30.360484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923000 of size 256
2019-01-24 02:37:30.360490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923100 of size 256
2019-01-24 02:37:30.360495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923200 of size 1536
2019-01-24 02:37:30.360500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923800 of size 256
2019-01-24 02:37:30.360505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923900 of size 1536
2019-01-24 02:37:30.368849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923f00 of size 2816
2019-01-24 02:37:30.368860: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c924a00 of size 256
2019-01-24 02:37:30.368865: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c924b00 of size 256
2019-01-24 02:37:30.368869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c924c00 of size 1536
2019-01-24 02:37:30.368873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925200 of size 256
2019-01-24 02:37:30.368877: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925300 of size 256
2019-01-24 02:37:30.368881: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925400 of size 1536
2019-01-24 02:37:30.368885: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925a00 of size 256
2019-01-24 02:37:30.368890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925b00 of size 1536
2019-01-24 02:37:30.368894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c926100 of size 2816
2019-01-24 02:37:30.368898: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c926c00 of size 256
2019-01-24 02:37:30.368902: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c926d00 of size 1536
2019-01-24 02:37:30.368906: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927300 of size 256
2019-01-24 02:37:30.368910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927400 of size 256
2019-01-24 02:37:30.368914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927500 of size 1536
2019-01-24 02:37:30.368918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927b00 of size 2816
2019-01-24 02:37:30.368922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c928600 of size 256
2019-01-24 02:37:30.368927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c928700 of size 1536
2019-01-24 02:37:30.368931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c928d00 of size 2816
2019-01-24 02:37:30.368935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c929800 of size 256
2019-01-24 02:37:30.368939: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c929900 of size 1536
2019-01-24 02:37:30.368943: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c929f00 of size 256
2019-01-24 02:37:30.368947: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a000 of size 256
2019-01-24 02:37:30.368951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a100 of size 1536
2019-01-24 02:37:30.368955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a700 of size 256
2019-01-24 02:37:30.368959: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a800 of size 1536
2019-01-24 02:37:30.368963: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ae00 of size 2816
2019-01-24 02:37:30.368967: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92b900 of size 256
2019-01-24 02:37:30.368970: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ba00 of size 256
2019-01-24 02:37:30.368975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92bb00 of size 1536
2019-01-24 02:37:30.368979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c100 of size 256
2019-01-24 02:37:30.368983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c200 of size 256
2019-01-24 02:37:30.368987: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c300 of size 1536
2019-01-24 02:37:30.368991: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c900 of size 256
2019-01-24 02:37:30.368995: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ca00 of size 1536
2019-01-24 02:37:30.368999: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92d000 of size 2816
2019-01-24 02:37:30.369003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92db00 of size 256
2019-01-24 02:37:30.369007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92dc00 of size 1536
2019-01-24 02:37:30.369012: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92e200 of size 256
2019-01-24 02:37:30.369016: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92e300 of size 256
2019-01-24 02:37:30.369020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92e400 of size 1536
2019-01-24 02:37:30.369024: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ea00 of size 2816
2019-01-24 02:37:30.369028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92f500 of size 256
2019-01-24 02:37:30.369032: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92f600 of size 1536
2019-01-24 02:37:30.369036: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92fc00 of size 2816
2019-01-24 02:37:30.369041: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930700 of size 256
2019-01-24 02:37:30.369045: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930800 of size 1536
2019-01-24 02:37:30.369049: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930e00 of size 256
2019-01-24 02:37:30.369053: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930f00 of size 256
2019-01-24 02:37:30.369057: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931000 of size 1536
2019-01-24 02:37:30.369061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931600 of size 256
2019-01-24 02:37:30.369065: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931700 of size 1536
2019-01-24 02:37:30.369069: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931d00 of size 2816
2019-01-24 02:37:30.369073: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c932800 of size 256
2019-01-24 02:37:30.369077: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c932900 of size 256
2019-01-24 02:37:30.369081: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c932a00 of size 1536
2019-01-24 02:37:30.369085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933000 of size 256
2019-01-24 02:37:30.369089: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933100 of size 256
2019-01-24 02:37:30.369093: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933200 of size 1536
2019-01-24 02:37:30.369098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933800 of size 23040
0
2019-01-24 02:37:30.369102: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c96bc00 of size 23040
0
2019-01-24 02:37:30.369106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a4000 of size 256
2019-01-24 02:37:30.369110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a4100 of size 1536
2019-01-24 02:37:30.369114: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a4700 of size 2816
2019-01-24 02:37:30.369118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5200 of size 256
2019-01-24 02:37:30.369122: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5300 of size 1536
2019-01-24 02:37:30.369126: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5900 of size 256
2019-01-24 02:37:30.369130: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5a00 of size 256
2019-01-24 02:37:30.369134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5b00 of size 1536
2019-01-24 02:37:30.369138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a6100 of size 2816
2019-01-24 02:37:30.369142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a6c00 of size 256
2019-01-24 02:37:30.369146: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a6d00 of size 1536
2019-01-24 02:37:30.369150: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a7300 of size 2816
2019-01-24 02:37:30.369154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a7e00 of size 256
2019-01-24 02:37:30.369159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a7f00 of size 1536
2019-01-24 02:37:30.369163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8500 of size 256
2019-01-24 02:37:30.369167: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8600 of size 256
2019-01-24 02:37:30.369171: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8700 of size 1536
2019-01-24 02:37:30.369175: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8d00 of size 256
2019-01-24 02:37:30.369179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8e00 of size 1536
2019-01-24 02:37:30.369183: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a9400 of size 2816
2019-01-24 02:37:30.369187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a9f00 of size 256
2019-01-24 02:37:30.369191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa000 of size 256
2019-01-24 02:37:30.369195: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa100 of size 1536
2019-01-24 02:37:30.369199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa700 of size 256
2019-01-24 02:37:30.369203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa800 of size 256
2019-01-24 02:37:30.369207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa900 of size 1536
2019-01-24 02:37:30.369211: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aaf00 of size 256
2019-01-24 02:37:30.369215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ab000 of size 1536
2019-01-24 02:37:30.369219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ab600 of size 2816
2019-01-24 02:37:30.369223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac100 of size 256
2019-01-24 02:37:30.369227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac200 of size 1536
2019-01-24 02:37:30.369232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac800 of size 256
2019-01-24 02:37:30.369236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac900 of size 256
2019-01-24 02:37:30.369240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aca00 of size 1536
2019-01-24 02:37:30.369244: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ad000 of size 2816
2019-01-24 02:37:30.369248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9adb00 of size 256
2019-01-24 02:37:30.369252: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9adc00 of size 1536
2019-01-24 02:37:30.369256: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ae200 of size 2816
2019-01-24 02:37:30.369260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aed00 of size 256
2019-01-24 02:37:30.369265: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aee00 of size 2048
2019-01-24 02:37:30.369269: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9af600 of size 2048
2019-01-24 02:37:30.369273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9afe00 of size 1536
2019-01-24 02:37:30.369276: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0400 of size 256
2019-01-24 02:37:30.369281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0500 of size 256
2019-01-24 02:37:30.369285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0600 of size 1536
2019-01-24 02:37:30.369288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0c00 of size 256
2019-01-24 02:37:30.369292: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0d00 of size 1536
2019-01-24 02:37:30.369296: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b1300 of size 2816
2019-01-24 02:37:30.369300: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b1e00 of size 256
2019-01-24 02:37:30.369304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b1f00 of size 256
2019-01-24 02:37:30.369308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2000 of size 1536
2019-01-24 02:37:30.369312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2600 of size 256
2019-01-24 02:37:30.369316: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2700 of size 256
2019-01-24 02:37:30.369320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2800 of size 1536
2019-01-24 02:37:30.369324: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2e00 of size 256
2019-01-24 02:37:30.369328: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2f00 of size 1536
2019-01-24 02:37:30.369332: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b3500 of size 2816
2019-01-24 02:37:30.369336: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4000 of size 256
2019-01-24 02:37:30.369340: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4100 of size 1536
2019-01-24 02:37:30.369344: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4700 of size 256
2019-01-24 02:37:30.369348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4800 of size 256
2019-01-24 02:37:30.369352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4900 of size 1536
2019-01-24 02:37:30.369356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4f00 of size 2816
2019-01-24 02:37:30.369360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b5a00 of size 256
2019-01-24 02:37:30.369364: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b5b00 of size 1536
2019-01-24 02:37:30.369368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b6100 of size 2816
2019-01-24 02:37:30.369372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b6c00 of size 256
2019-01-24 02:37:30.369376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b6d00 of size 1536
2019-01-24 02:37:30.369380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b7300 of size 1536
2019-01-24 02:37:30.369384: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b7900 of size 57600
2019-01-24 02:37:30.369388: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9c5a00 of size 57600
2019-01-24 02:37:30.369392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9d3b00 of size 57600
2019-01-24 02:37:30.369396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9e1c00 of size 57600
2019-01-24 02:37:30.369400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9efd00 of size 512
2019-01-24 02:37:30.369404: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9eff00 of size 512
2019-01-24 02:37:30.369408: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0100 of size 512
2019-01-24 02:37:30.369412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0300 of size 512
2019-01-24 02:37:30.369416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0500 of size 256
2019-01-24 02:37:30.369420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0600 of size 256
2019-01-24 02:37:30.369425: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0700 of size 256
2019-01-24 02:37:30.369429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0800 of size 256
2019-01-24 02:37:30.369432: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0900 of size 256
2019-01-24 02:37:30.369436: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0a00 of size 256
2019-01-24 02:37:30.369440: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0b00 of size 256
2019-01-24 02:37:30.369444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0c00 of size 256
2019-01-24 02:37:30.369448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0d00 of size 256
2019-01-24 02:37:30.369452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0e00 of size 256
2019-01-24 02:37:30.369456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0f00 of size 256
2019-01-24 02:37:30.369460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1000 of size 256
2019-01-24 02:37:30.369464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1100 of size 256
2019-01-24 02:37:30.369468: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1200 of size 256
2019-01-24 02:37:30.369472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1300 of size 256
2019-01-24 02:37:30.369476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1400 of size 256
2019-01-24 02:37:30.369480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1500 of size 256
2019-01-24 02:37:30.369484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1600 of size 256
2019-01-24 02:37:30.369488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1700 of size 256
2019-01-24 02:37:30.369492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1800 of size 256
2019-01-24 02:37:30.369496: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1900 of size 256
2019-01-24 02:37:30.369500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1a00 of size 256
2019-01-24 02:37:30.369504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1b00 of size 256
2019-01-24 02:37:30.369508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1c00 of size 256
2019-01-24 02:37:30.369512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1d00 of size 256
2019-01-24 02:37:30.369516: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1e00 of size 256
2019-01-24 02:37:30.369520: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1f00 of size 256
2019-01-24 02:37:30.369523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2000 of size 256
2019-01-24 02:37:30.369527: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2100 of size 256
2019-01-24 02:37:30.369531: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2200 of size 256
2019-01-24 02:37:30.369535: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2300 of size 256
2019-01-24 02:37:30.369539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2400 of size 256
2019-01-24 02:37:30.369543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2500 of size 256
2019-01-24 02:37:30.369547: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2600 of size 256
2019-01-24 02:37:30.369551: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2700 of size 256
2019-01-24 02:37:30.369555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2800 of size 256
2019-01-24 02:37:30.369559: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2900 of size 256
2019-01-24 02:37:30.369563: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2a00 of size 256
2019-01-24 02:37:30.377406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2b00 of size 768
2019-01-24 02:37:30.377411: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1c9f2e00 of size 256
2019-01-24 02:37:30.377414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2f00 of size 256
2019-01-24 02:37:30.377417: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f3000 of size 256
2019-01-24 02:37:30.377420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1c9f3100 of size 1792
2019-01-24 02:37:30.377423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f3800 of size 256
2019-01-24 02:37:30.377426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1c9f3900 of size 1792
2019-01-24 02:37:30.377429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f4000 of size 57600
2019-01-24 02:37:30.377433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca02100 of size 10828
8
2019-01-24 02:37:30.377436: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1c800 of size 2816
2019-01-24 02:37:30.377439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1d300 of size 1536
2019-01-24 02:37:30.377443: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1d900 of size 1536
2019-01-24 02:37:30.377446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1df00 of size 1536
2019-01-24 02:37:30.377449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1e500 of size 1536
2019-01-24 02:37:30.377453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1eb00 of size 1536
2019-01-24 02:37:30.377456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1f100 of size 1536
2019-01-24 02:37:30.377459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1f700 of size 1536
2019-01-24 02:37:30.377462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1fd00 of size 1536
2019-01-24 02:37:30.377466: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca20300 of size 1536
2019-01-24 02:37:30.377469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca20900 of size 1536
2019-01-24 02:37:30.377472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca20f00 of size 1536
2019-01-24 02:37:30.377476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca21500 of size 1536
2019-01-24 02:37:30.377479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca21b00 of size 1536
2019-01-24 02:37:30.377482: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca22100 of size 1536
2019-01-24 02:37:30.377485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca22700 of size 1536
2019-01-24 02:37:30.377489: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca22d00 of size 1536
2019-01-24 02:37:30.377492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca23300 of size 1536
2019-01-24 02:37:30.377496: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca23900 of size 1536
2019-01-24 02:37:30.377499: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca23f00 of size 1536
2019-01-24 02:37:30.377503: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca24500 of size 1536
2019-01-24 02:37:30.377506: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca24b00 of size 1536
2019-01-24 02:37:30.377510: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca25100 of size 1536
2019-01-24 02:37:30.377513: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca25700 of size 1536
2019-01-24 02:37:30.377516: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca25d00 of size 1536
2019-01-24 02:37:30.377520: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca26300 of size 1536
2019-01-24 02:37:30.377523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca26900 of size 1536
2019-01-24 02:37:30.377527: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca26f00 of size 1536
2019-01-24 02:37:30.377530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca27500 of size 1536
2019-01-24 02:37:30.377534: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca27b00 of size 1536
2019-01-24 02:37:30.377537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca28100 of size 1536
2019-01-24 02:37:30.377541: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca28700 of size 1536
2019-01-24 02:37:30.377544: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca28d00 of size 1536
2019-01-24 02:37:30.377548: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca29300 of size 1536
2019-01-24 02:37:30.377551: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca29900 of size 1536
2019-01-24 02:37:30.377555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca29f00 of size 1536
2019-01-24 02:37:30.377558: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2a500 of size 1536
2019-01-24 02:37:30.377562: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2ab00 of size 1536
2019-01-24 02:37:30.377565: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2b100 of size 1536
2019-01-24 02:37:30.377568: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2b700 of size 1536
2019-01-24 02:37:30.377572: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2bd00 of size 1536
2019-01-24 02:37:30.377575: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2c300 of size 1536
2019-01-24 02:37:30.377579: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2c900 of size 1536
2019-01-24 02:37:30.377582: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2cf00 of size 1536
2019-01-24 02:37:30.377586: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2d500 of size 1536
2019-01-24 02:37:30.377589: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2db00 of size 1536
2019-01-24 02:37:30.377592: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2e100 of size 1536
2019-01-24 02:37:30.377596: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2e700 of size 1536
2019-01-24 02:37:30.377599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2ed00 of size 1536
2019-01-24 02:37:30.377603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2f300 of size 1536
2019-01-24 02:37:30.377606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2f900 of size 1536
2019-01-24 02:37:30.377609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2ff00 of size 1536
2019-01-24 02:37:30.377613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca30500 of size 1536
2019-01-24 02:37:30.377616: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca30b00 of size 1536
2019-01-24 02:37:30.377620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca31100 of size 1536
2019-01-24 02:37:30.377623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca31700 of size 1536
2019-01-24 02:37:30.377626: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca31d00 of size 1536
2019-01-24 02:37:30.377630: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca32300 of size 1536
2019-01-24 02:37:30.377633: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca32900 of size 1536
2019-01-24 02:37:30.377637: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca32f00 of size 1536
2019-01-24 02:37:30.377640: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca33500 of size 1536
2019-01-24 02:37:30.377643: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca33b00 of size 1536
2019-01-24 02:37:30.377647: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca34100 of size 1536
2019-01-24 02:37:30.377650: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca34700 of size 1536
2019-01-24 02:37:30.377654: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca34d00 of size 1536
2019-01-24 02:37:30.377657: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca35300 of size 1536
2019-01-24 02:37:30.377660: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca35900 of size 1536
2019-01-24 02:37:30.377664: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca35f00 of size 1536
2019-01-24 02:37:30.377667: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca36500 of size 1536
2019-01-24 02:37:30.377671: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca36b00 of size 1536
2019-01-24 02:37:30.377674: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca37100 of size 1536
2019-01-24 02:37:30.377678: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca37700 of size 1536
2019-01-24 02:37:30.377684: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca37d00 of size 1536
2019-01-24 02:37:30.377688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca38300 of size 1536
2019-01-24 02:37:30.377691: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca38900 of size 1536
2019-01-24 02:37:30.377695: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca38f00 of size 1536
2019-01-24 02:37:30.377698: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca39500 of size 1536
2019-01-24 02:37:30.377702: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca39b00 of size 1536
2019-01-24 02:37:30.377705: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3a100 of size 1536
2019-01-24 02:37:30.377709: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3a700 of size 1536
2019-01-24 02:37:30.377712: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3ad00 of size 1536
2019-01-24 02:37:30.377715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3b300 of size 1536
2019-01-24 02:37:30.377719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3b900 of size 1536
2019-01-24 02:37:30.377722: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3bf00 of size 1536
2019-01-24 02:37:30.377726: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3c500 of size 1536
2019-01-24 02:37:30.377729: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3cb00 of size 1536
2019-01-24 02:37:30.377733: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3d100 of size 1536
2019-01-24 02:37:30.377736: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3d700 of size 1536
2019-01-24 02:37:30.377739: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3dd00 of size 1536
2019-01-24 02:37:30.377743: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3e300 of size 1536
2019-01-24 02:37:30.377746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3e900 of size 1536
2019-01-24 02:37:30.377750: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3ef00 of size 1536
2019-01-24 02:37:30.377753: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3f500 of size 1536
2019-01-24 02:37:30.377756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3fb00 of size 1536
2019-01-24 02:37:30.377760: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca40100 of size 1536
2019-01-24 02:37:30.377763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca40700 of size 1536
2019-01-24 02:37:30.377767: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca40d00 of size 1536
2019-01-24 02:37:30.377770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca41300 of size 1536
2019-01-24 02:37:30.377774: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca41900 of size 1536
2019-01-24 02:37:30.377777: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca41f00 of size 1536
2019-01-24 02:37:30.377781: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca42500 of size 1536
2019-01-24 02:37:30.377784: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca42b00 of size 1536
2019-01-24 02:37:30.377788: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca43100 of size 1536
2019-01-24 02:37:30.377791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca43700 of size 1536
2019-01-24 02:37:30.377794: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca43d00 of size 1536
2019-01-24 02:37:30.377798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca44300 of size 1536
2019-01-24 02:37:30.377801: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca44900 of size 1536
2019-01-24 02:37:30.377805: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca44f00 of size 1536
2019-01-24 02:37:30.377808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca45500 of size 1536
2019-01-24 02:37:30.377812: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca45b00 of size 1536
2019-01-24 02:37:30.377815: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca46100 of size 1536
2019-01-24 02:37:30.377818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca46700 of size 1536
2019-01-24 02:37:30.377822: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca46d00 of size 1536
2019-01-24 02:37:30.377825: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca47300 of size 1536
2019-01-24 02:37:30.377829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca47900 of size 1536
2019-01-24 02:37:30.377832: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca47f00 of size 1536
2019-01-24 02:37:30.377836: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca48500 of size 1536
2019-01-24 02:37:30.377839: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca48b00 of size 1536
2019-01-24 02:37:30.377842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca49100 of size 1536
2019-01-24 02:37:30.377846: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca49700 of size 1536
2019-01-24 02:37:30.377849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca49d00 of size 1536
2019-01-24 02:37:30.377853: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4a300 of size 1536
2019-01-24 02:37:30.377856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4a900 of size 1536
2019-01-24 02:37:30.377859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4af00 of size 1536
2019-01-24 02:37:30.377863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4b500 of size 1536
2019-01-24 02:37:30.377866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4bb00 of size 1536
2019-01-24 02:37:30.377870: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4c100 of size 1536
2019-01-24 02:37:30.377873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4c700 of size 1536
2019-01-24 02:37:30.377877: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4cd00 of size 1536
2019-01-24 02:37:30.377880: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4d300 of size 1536
2019-01-24 02:37:30.377883: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4d900 of size 1536
2019-01-24 02:37:30.377887: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4df00 of size 1536
2019-01-24 02:37:30.377890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4e500 of size 1536
2019-01-24 02:37:30.377894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4eb00 of size 1536
2019-01-24 02:37:30.377897: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4f100 of size 1536
2019-01-24 02:37:30.377901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4f700 of size 1536
2019-01-24 02:37:30.377904: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4fd00 of size 1536
2019-01-24 02:37:30.377907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca50300 of size 1536
2019-01-24 02:37:30.377911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca50900 of size 1536
2019-01-24 02:37:30.377914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca50f00 of size 1536
2019-01-24 02:37:30.377918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca51500 of size 1536
2019-01-24 02:37:30.377921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca51b00 of size 1536
2019-01-24 02:37:30.377925: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca52100 of size 1536
2019-01-24 02:37:30.377928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca52700 of size 1536
2019-01-24 02:37:30.377931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca52d00 of size 1536
2019-01-24 02:37:30.377935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca53300 of size 1536
2019-01-24 02:37:30.377938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca53900 of size 1536
2019-01-24 02:37:30.377942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca53f00 of size 1536
2019-01-24 02:37:30.377945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca54500 of size 1536
2019-01-24 02:37:30.377949: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca54b00 of size 1536
2019-01-24 02:37:30.377952: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca55100 of size 1536
2019-01-24 02:37:30.377955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca55700 of size 1536
2019-01-24 02:37:30.377959: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca55d00 of size 1536
2019-01-24 02:37:30.377962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca56300 of size 1536
2019-01-24 02:37:30.377966: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca56900 of size 1536
2019-01-24 02:37:30.377969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca56f00 of size 1536
2019-01-24 02:37:30.377973: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca57500 of size 1536
2019-01-24 02:37:30.377976: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca57b00 of size 1536
2019-01-24 02:37:30.377979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca58100 of size 1536
2019-01-24 02:37:30.377983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca58700 of size 1536
2019-01-24 02:37:30.377986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca58d00 of size 1536
2019-01-24 02:37:30.377990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca59300 of size 1536
2019-01-24 02:37:30.377993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca59900 of size 1536
2019-01-24 02:37:30.377997: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca59f00 of size 1536
2019-01-24 02:37:30.378000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5a500 of size 1536
2019-01-24 02:37:30.378003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5ab00 of size 1536
2019-01-24 02:37:30.378007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5b100 of size 1536
2019-01-24 02:37:30.384231: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5b700 of size 1536
2019-01-24 02:37:30.384238: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5bd00 of size 1536
2019-01-24 02:37:30.384241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5c300 of size 1536
2019-01-24 02:37:30.384244: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5c900 of size 1536
2019-01-24 02:37:30.384247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5cf00 of size 1536
2019-01-24 02:37:30.384251: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5d500 of size 1536
2019-01-24 02:37:30.384255: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5db00 of size 1536
2019-01-24 02:37:30.384258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5e100 of size 1536
2019-01-24 02:37:30.384261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5e700 of size 1536
2019-01-24 02:37:30.384265: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5ed00 of size 1536
2019-01-24 02:37:30.384267: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5f300 of size 1536
2019-01-24 02:37:30.384271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5f900 of size 1536
2019-01-24 02:37:30.384274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5ff00 of size 1536
2019-01-24 02:37:30.384277: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca60500 of size 1536
2019-01-24 02:37:30.384281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca60b00 of size 1536
2019-01-24 02:37:30.384284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca61100 of size 1536
2019-01-24 02:37:30.384287: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca61700 of size 1536
2019-01-24 02:37:30.384290: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca61d00 of size 1536
2019-01-24 02:37:30.384293: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca62300 of size 1536
2019-01-24 02:37:30.384297: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca62900 of size 1536
2019-01-24 02:37:30.384300: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca62f00 of size 1536
2019-01-24 02:37:30.384304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca63500 of size 1536
2019-01-24 02:37:30.384307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca63b00 of size 1536
2019-01-24 02:37:30.384310: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca64100 of size 1536
2019-01-24 02:37:30.384314: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca64700 of size 1536
2019-01-24 02:37:30.384317: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca64d00 of size 1536
2019-01-24 02:37:30.384321: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca65300 of size 1536
2019-01-24 02:37:30.384324: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca65900 of size 1536
2019-01-24 02:37:30.384328: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca65f00 of size 1536
2019-01-24 02:37:30.384331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca66500 of size 1536
2019-01-24 02:37:30.384335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca66b00 of size 1536
2019-01-24 02:37:30.384338: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca67100 of size 1536
2019-01-24 02:37:30.384342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca67700 of size 1536
2019-01-24 02:37:30.384345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca67d00 of size 1536
2019-01-24 02:37:30.384348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca68300 of size 1536
2019-01-24 02:37:30.384352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca68900 of size 1536
2019-01-24 02:37:30.384355: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca68f00 of size 1536
2019-01-24 02:37:30.384359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca69500 of size 1536
2019-01-24 02:37:30.384362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca69b00 of size 1536
2019-01-24 02:37:30.384366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6a100 of size 1536
2019-01-24 02:37:30.384369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6a700 of size 1536
2019-01-24 02:37:30.384373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6ad00 of size 1536
2019-01-24 02:37:30.384376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6b300 of size 1536
2019-01-24 02:37:30.384380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6b900 of size 1536
2019-01-24 02:37:30.384383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6bf00 of size 1536
2019-01-24 02:37:30.384387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6c500 of size 1536
2019-01-24 02:37:30.384390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6cb00 of size 1536
2019-01-24 02:37:30.384393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6d100 of size 1536
2019-01-24 02:37:30.384397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6d700 of size 1536
2019-01-24 02:37:30.384400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6dd00 of size 1536
2019-01-24 02:37:30.384404: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6e300 of size 1536
2019-01-24 02:37:30.384407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6e900 of size 1536
2019-01-24 02:37:30.384411: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6ef00 of size 1536
2019-01-24 02:37:30.384414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6f500 of size 1536
2019-01-24 02:37:30.384417: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6fb00 of size 1536
2019-01-24 02:37:30.384421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca70100 of size 1536
2019-01-24 02:37:30.384424: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca70700 of size 1536
2019-01-24 02:37:30.384428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca70d00 of size 1536
2019-01-24 02:37:30.384431: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca71300 of size 1536
2019-01-24 02:37:30.384434: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca71900 of size 1536
2019-01-24 02:37:30.384438: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca71f00 of size 1536
2019-01-24 02:37:30.384441: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca72500 of size 1536
2019-01-24 02:37:30.384445: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca72b00 of size 1536
2019-01-24 02:37:30.384448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca73100 of size 1536
2019-01-24 02:37:30.384452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca73700 of size 1536
2019-01-24 02:37:30.384455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca73d00 of size 1536
2019-01-24 02:37:30.384458: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca74300 of size 1536
2019-01-24 02:37:30.384462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca74900 of size 1536
2019-01-24 02:37:30.384465: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca74f00 of size 1536
2019-01-24 02:37:30.384469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca75500 of size 1536
2019-01-24 02:37:30.384472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca75b00 of size 1536
2019-01-24 02:37:30.384476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca76100 of size 1536
2019-01-24 02:37:30.384479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca76700 of size 1536
2019-01-24 02:37:30.384483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca76d00 of size 1536
2019-01-24 02:37:30.384486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca77300 of size 1536
2019-01-24 02:37:30.384489: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca77900 of size 1536
2019-01-24 02:37:30.384493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca77f00 of size 1536
2019-01-24 02:37:30.384496: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca78500 of size 1536
2019-01-24 02:37:30.384500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca78b00 of size 1536
2019-01-24 02:37:30.384503: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca79100 of size 1536
2019-01-24 02:37:30.384506: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca79700 of size 1536
2019-01-24 02:37:30.384510: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca79d00 of size 1536
2019-01-24 02:37:30.384513: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7a300 of size 1536
2019-01-24 02:37:30.384517: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7a900 of size 1536
2019-01-24 02:37:30.384520: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7af00 of size 1536
2019-01-24 02:37:30.384524: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7b500 of size 1536
2019-01-24 02:37:30.384527: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7bb00 of size 1536
2019-01-24 02:37:30.384530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7c100 of size 1536
2019-01-24 02:37:30.384534: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7c700 of size 1536
2019-01-24 02:37:30.384537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7cd00 of size 1536
2019-01-24 02:37:30.384541: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7d300 of size 1536
2019-01-24 02:37:30.384544: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7d900 of size 1536
2019-01-24 02:37:30.384548: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7df00 of size 1536
2019-01-24 02:37:30.384551: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7e500 of size 1536
2019-01-24 02:37:30.384554: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7eb00 of size 1536
2019-01-24 02:37:30.384558: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7f100 of size 1536
2019-01-24 02:37:30.384561: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7f700 of size 1536
2019-01-24 02:37:30.384565: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7fd00 of size 1536
2019-01-24 02:37:30.384568: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca80300 of size 1536
2019-01-24 02:37:30.384571: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca80900 of size 1536
2019-01-24 02:37:30.384575: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca80f00 of size 1536
2019-01-24 02:37:30.384578: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca81500 of size 1536
2019-01-24 02:37:30.384582: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca81b00 of size 1536
2019-01-24 02:37:30.384585: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca82100 of size 1536
2019-01-24 02:37:30.384589: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca82700 of size 1536
2019-01-24 02:37:30.384592: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca82d00 of size 1536
2019-01-24 02:37:30.384596: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca83300 of size 1536
2019-01-24 02:37:30.384599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca83900 of size 1536
2019-01-24 02:37:30.384603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca83f00 of size 1536
2019-01-24 02:37:30.384606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca84500 of size 1536
2019-01-24 02:37:30.384609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca84b00 of size 1536
2019-01-24 02:37:30.384613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca85100 of size 1536
2019-01-24 02:37:30.384616: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca85700 of size 1536
2019-01-24 02:37:30.384620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca85d00 of size 1536
2019-01-24 02:37:30.384623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca86300 of size 1536
2019-01-24 02:37:30.384626: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca86900 of size 1536
2019-01-24 02:37:30.384630: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca86f00 of size 1536
2019-01-24 02:37:30.384633: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca87500 of size 1536
2019-01-24 02:37:30.384637: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca87b00 of size 1536
2019-01-24 02:37:30.384640: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca88100 of size 1536
2019-01-24 02:37:30.384644: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca88700 of size 1536
2019-01-24 02:37:30.384647: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca88d00 of size 1536
2019-01-24 02:37:30.384650: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca89300 of size 1536
2019-01-24 02:37:30.384654: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca89900 of size 1536
2019-01-24 02:37:30.384657: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca89f00 of size 1536
2019-01-24 02:37:30.384661: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8a500 of size 1536
2019-01-24 02:37:30.384664: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8ab00 of size 1536
2019-01-24 02:37:30.384667: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8b100 of size 1536
2019-01-24 02:37:30.384671: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8b700 of size 1536
2019-01-24 02:37:30.384674: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8bd00 of size 1536
2019-01-24 02:37:30.384678: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8c300 of size 1536
2019-01-24 02:37:30.384681: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8c900 of size 1536
2019-01-24 02:37:30.384684: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8cf00 of size 1536
2019-01-24 02:37:30.384688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8d500 of size 1536
2019-01-24 02:37:30.384691: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8db00 of size 1536
2019-01-24 02:37:30.384695: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8e100 of size 1536
2019-01-24 02:37:30.384698: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8e700 of size 1536
2019-01-24 02:37:30.384702: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8ed00 of size 1536
2019-01-24 02:37:30.384705: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8f300 of size 1536
2019-01-24 02:37:30.384708: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8f900 of size 1536
2019-01-24 02:37:30.384712: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8ff00 of size 1536
2019-01-24 02:37:30.384715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca90500 of size 1536
2019-01-24 02:37:30.384719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca90b00 of size 1536
2019-01-24 02:37:30.384724: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca91100 of size 1536
2019-01-24 02:37:30.384728: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca91700 of size 1536
2019-01-24 02:37:30.384732: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca91d00 of size 1536
2019-01-24 02:37:30.384735: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca92300 of size 1536
2019-01-24 02:37:30.384739: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca92900 of size 1536
2019-01-24 02:37:30.384742: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca92f00 of size 1536
2019-01-24 02:37:30.384746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca93500 of size 1536
2019-01-24 02:37:30.384749: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca93b00 of size 1536
2019-01-24 02:37:30.384753: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca94100 of size 1536
2019-01-24 02:37:30.384756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca94700 of size 1536
2019-01-24 02:37:30.384760: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca94d00 of size 1536
2019-01-24 02:37:30.384763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca95300 of size 1536
2019-01-24 02:37:30.384766: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca95900 of size 1536
2019-01-24 02:37:30.384770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca95f00 of size 1536
2019-01-24 02:37:30.384773: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca96500 of size 1536
2019-01-24 02:37:30.384777: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca96b00 of size 1536
2019-01-24 02:37:30.384780: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca97100 of size 1536
2019-01-24 02:37:30.384784: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca97700 of size 1536
2019-01-24 02:37:30.384787: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca97d00 of size 1536
2019-01-24 02:37:30.384791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca98300 of size 1536
2019-01-24 02:37:30.384794: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca98900 of size 1536
2019-01-24 02:37:30.384798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca98f00 of size 1536
2019-01-24 02:37:30.384801: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca99500 of size 1536
2019-01-24 02:37:30.384804: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca99b00 of size 1536
2019-01-24 02:37:30.384808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9a100 of size 1536
2019-01-24 02:37:30.384811: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9a700 of size 1536
2019-01-24 02:37:30.384815: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9ad00 of size 1536
2019-01-24 02:37:30.384818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9b300 of size 1536
2019-01-24 02:37:30.384822: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9b900 of size 1536
2019-01-24 02:37:30.384825: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9bf00 of size 1536
2019-01-24 02:37:30.384829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9c500 of size 1536
2019-01-24 02:37:30.384832: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9cb00 of size 1536
2019-01-24 02:37:30.384835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9d100 of size 1536
2019-01-24 02:37:30.393273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9d700 of size 1536
2019-01-24 02:37:30.393279: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9dd00 of size 1536
2019-01-24 02:37:30.393283: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9e300 of size 1536
2019-01-24 02:37:30.393285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9e900 of size 1536
2019-01-24 02:37:30.393288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9ef00 of size 1536
2019-01-24 02:37:30.393291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9f500 of size 1536
2019-01-24 02:37:30.393295: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9fb00 of size 1536
2019-01-24 02:37:30.393299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa0100 of size 1536
2019-01-24 02:37:30.393302: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa0700 of size 1536
2019-01-24 02:37:30.393306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa0d00 of size 1536
2019-01-24 02:37:30.393310: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa1300 of size 1536
2019-01-24 02:37:30.393313: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa1900 of size 1536
2019-01-24 02:37:30.393317: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa1f00 of size 1536
2019-01-24 02:37:30.393320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa2500 of size 1536
2019-01-24 02:37:30.393324: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa2b00 of size 1536
2019-01-24 02:37:30.393327: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa3100 of size 1536
2019-01-24 02:37:30.393331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa3700 of size 1536
2019-01-24 02:37:30.393334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa3d00 of size 1536
2019-01-24 02:37:30.393338: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa4300 of size 1536
2019-01-24 02:37:30.393341: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa4900 of size 1536
2019-01-24 02:37:30.393345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa4f00 of size 1536
2019-01-24 02:37:30.393348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa5500 of size 1536
2019-01-24 02:37:30.393352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa5b00 of size 1536
2019-01-24 02:37:30.393355: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa6100 of size 1536
2019-01-24 02:37:30.393359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa6700 of size 1536
2019-01-24 02:37:30.393362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa6d00 of size 1536
2019-01-24 02:37:30.393366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa7300 of size 1536
2019-01-24 02:37:30.393369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa7900 of size 1536
2019-01-24 02:37:30.393373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa7f00 of size 1536
2019-01-24 02:37:30.393377: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa8500 of size 1536
2019-01-24 02:37:30.393380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa8b00 of size 1536
2019-01-24 02:37:30.393384: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa9100 of size 1536
2019-01-24 02:37:30.393388: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa9700 of size 1536
2019-01-24 02:37:30.393391: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa9d00 of size 1536
2019-01-24 02:37:30.393395: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaa300 of size 1536
2019-01-24 02:37:30.393398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaa900 of size 1536
2019-01-24 02:37:30.393402: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaaf00 of size 1536
2019-01-24 02:37:30.393405: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caab500 of size 1536
2019-01-24 02:37:30.393409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caabb00 of size 1536
2019-01-24 02:37:30.393412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caac100 of size 1536
2019-01-24 02:37:30.393416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caac700 of size 1536
2019-01-24 02:37:30.393419: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caacd00 of size 1536
2019-01-24 02:37:30.393423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caad300 of size 1536
2019-01-24 02:37:30.393426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caad900 of size 1536
2019-01-24 02:37:30.393430: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caadf00 of size 1536
2019-01-24 02:37:30.393433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caae500 of size 1536
2019-01-24 02:37:30.393437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaeb00 of size 1536
2019-01-24 02:37:30.393440: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaf100 of size 1536
2019-01-24 02:37:30.393444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaf700 of size 1536
2019-01-24 02:37:30.393447: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caafd00 of size 2816
2019-01-24 02:37:30.393451: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab0800 of size 256
2019-01-24 02:37:30.393454: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab0900 of size 1536
2019-01-24 02:37:30.393458: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab0f00 of size 256
2019-01-24 02:37:30.393461: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab1000 of size 2816
2019-01-24 02:37:30.393465: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab1b00 of size 256
2019-01-24 02:37:30.393468: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab1c00 of size 1536
2019-01-24 02:37:30.393472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab2200 of size 1536
2019-01-24 02:37:30.393475: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab2800 of size 1536
2019-01-24 02:37:30.393479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab2e00 of size 2816
2019-01-24 02:37:30.393482: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab3900 of size 1536
2019-01-24 02:37:30.393485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab3f00 of size 1536
2019-01-24 02:37:30.393489: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4500 of size 256
2019-01-24 02:37:30.393492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4600 of size 256
2019-01-24 02:37:30.393496: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4700 of size 1536
2019-01-24 02:37:30.393499: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4d00 of size 256
2019-01-24 02:37:30.393504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4e00 of size 33792
2019-01-24 02:37:30.393508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cabd200 of size 33792
2019-01-24 02:37:30.393511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cac5600 of size 33792
2019-01-24 02:37:30.393515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cacda00 of size 33792
2019-01-24 02:37:30.393518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cad5e00 of size 33792
2019-01-24 02:37:30.393522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cade200 of size 33792
2019-01-24 02:37:30.393525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cae6600 of size 33792
2019-01-24 02:37:30.393529: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caeea00 of size 33792
2019-01-24 02:37:30.393532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caf6e00 of size 33792
2019-01-24 02:37:30.393536: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caff200 of size 33792
2019-01-24 02:37:30.393539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb07600 of size 33792
2019-01-24 02:37:30.393543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb0fa00 of size 33792
2019-01-24 02:37:30.393546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb17e00 of size 33792
2019-01-24 02:37:30.393549: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb20200 of size 33792
2019-01-24 02:37:30.393553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb28600 of size 33792
2019-01-24 02:37:30.393557: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb30a00 of size 33792
2019-01-24 02:37:30.393560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb38e00 of size 33792
2019-01-24 02:37:30.393563: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb41200 of size 33792
2019-01-24 02:37:30.393567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb49600 of size 33792
2019-01-24 02:37:30.393570: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb51a00 of size 33792
2019-01-24 02:37:30.393574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb59e00 of size 33792
2019-01-24 02:37:30.393577: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb62200 of size 33792
2019-01-24 02:37:30.393581: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb6a600 of size 33792
2019-01-24 02:37:30.393584: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb72a00 of size 33792
2019-01-24 02:37:30.393588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb7ae00 of size 33792
2019-01-24 02:37:30.393591: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb83200 of size 33792
2019-01-24 02:37:30.393595: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb8b600 of size 33792
2019-01-24 02:37:30.393599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb93a00 of size 48537
6
2019-01-24 02:37:30.393602: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cc0a200 of size 45158
4
2019-01-24 02:37:30.393606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cc78600 of size 45158
4
2019-01-24 02:37:30.393609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cce6a00 of size 45158
4
2019-01-24 02:37:30.393613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cd54e00 of size 45158
4
2019-01-24 02:37:30.393617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cdc3200 of size 45158
4
2019-01-24 02:37:30.393620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ce31600 of size 45158
4
2019-01-24 02:37:30.393623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ce9fa00 of size 45158
4
2019-01-24 02:37:30.393627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cf0de00 of size 45158
4
2019-01-24 02:37:30.393630: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cf7c200 of size 45158
4
2019-01-24 02:37:30.393634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cfea600 of size 45158
4
2019-01-24 02:37:30.393637: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d058a00 of size 45158
4
2019-01-24 02:37:30.393641: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d0c6e00 of size 45158
4
2019-01-24 02:37:30.393644: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d135200 of size 45158
4
2019-01-24 02:37:30.393648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d1a3600 of size 45158
4
2019-01-24 02:37:30.393651: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d211a00 of size 45158
4
2019-01-24 02:37:30.393655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d27fe00 of size 45158
4
2019-01-24 02:37:30.393658: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d2ee200 of size 45158
4
2019-01-24 02:37:30.393662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d35c600 of size 45158
4
2019-01-24 02:37:30.393665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d3caa00 of size 45158
4
2019-01-24 02:37:30.393669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d438e00 of size 45158
4
2019-01-24 02:37:30.393672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d4a7200 of size 45158
4
2019-01-24 02:37:30.393676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d515600 of size 45158
4
2019-01-24 02:37:30.393679: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d583a00 of size 45158
4
2019-01-24 02:37:30.393686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d5f1e00 of size 45158
4
2019-01-24 02:37:30.393690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d660200 of size 45158
4
2019-01-24 02:37:30.393693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d6ce600 of size 45158
4
2019-01-24 02:37:30.393697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d73ca00 of size 45158
4
2019-01-24 02:37:30.393700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d7aae00 of size 45158
4
2019-01-24 02:37:30.393704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d819200 of size 45158
4
2019-01-24 02:37:30.393707: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d887600 of size 45158
4
2019-01-24 02:37:30.393711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d8f5a00 of size 45158
4
2019-01-24 02:37:30.393714: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d963e00 of size 45158
4
2019-01-24 02:37:30.393718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d9d2200 of size 45158
4
2019-01-24 02:37:30.393721: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1da40600 of size 45158
4
2019-01-24 02:37:30.393724: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1daaea00 of size 45158
4
2019-01-24 02:37:30.393728: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1db1ce00 of size 45158
4
2019-01-24 02:37:30.393731: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1db8b200 of size 45158
4
2019-01-24 02:37:30.393735: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dbf9600 of size 45158
4
2019-01-24 02:37:30.393738: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dc67a00 of size 45158
4
2019-01-24 02:37:30.393742: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dcd5e00 of size 45158
4
2019-01-24 02:37:30.393745: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dd44200 of size 45158
4
2019-01-24 02:37:30.393749: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ddb2600 of size 45158
4
2019-01-24 02:37:30.393752: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1de20a00 of size 45158
4
2019-01-24 02:37:30.393756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1de8ee00 of size 45158
4
2019-01-24 02:37:30.393759: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1defd200 of size 45158
4
2019-01-24 02:37:30.393763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1df6b600 of size 45158
4
2019-01-24 02:37:30.393766: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dfd9a00 of size 45158
4
2019-01-24 02:37:30.393769: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e047e00 of size 45158
4
2019-01-24 02:37:30.393773: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e0b6200 of size 45158
4
2019-01-24 02:37:30.393776: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e124600 of size 45158
4
2019-01-24 02:37:30.393780: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e192a00 of size 45158
4
2019-01-24 02:37:30.393783: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e200e00 of size 45158
4
2019-01-24 02:37:30.393787: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e26f200 of size 45158
4
2019-01-24 02:37:30.393790: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e2dd600 of size 45158
4
2019-01-24 02:37:30.393794: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e34ba00 of size 45158
4
2019-01-24 02:37:30.393797: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e3b9e00 of size 45158
4
2019-01-24 02:37:30.393801: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e428200 of size 45158
4
2019-01-24 02:37:30.393804: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e496600 of size 45158
4
2019-01-24 02:37:30.393807: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e504a00 of size 45158
4
2019-01-24 02:37:30.393811: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e572e00 of size 45158
4
2019-01-24 02:37:30.393814: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e5e1200 of size 45158
4
2019-01-24 02:37:30.393818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e64f600 of size 45158
4
2019-01-24 02:37:30.393821: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e6bda00 of size 45158
4
2019-01-24 02:37:30.393825: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e72be00 of size 45158
4
2019-01-24 02:37:30.393828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e79a200 of size 45158
4
2019-01-24 02:37:30.393832: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e808600 of size 45158
4
2019-01-24 02:37:30.393835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e876a00 of size 45158
4
2019-01-24 02:37:30.393839: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e8e4e00 of size 45158
4
2019-01-24 02:37:30.393842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e953200 of size 45158
4
2019-01-24 02:37:30.393846: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c1600 of size 1536
2019-01-24 02:37:30.393849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c1c00 of size 1536
2019-01-24 02:37:30.393852: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c2200 of size 1536
2019-01-24 02:37:30.393856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c2800 of size 1536
2019-01-24 02:37:30.393860: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c2e00 of size 512
2019-01-24 02:37:30.393863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c3000 of size 512
2019-01-24 02:37:30.393867: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c3200 of size 1536
2019-01-24 02:37:30.393870: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c3800 of size 2816
2019-01-24 02:37:30.393873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c4300 of size 1536
2019-01-24 02:37:30.393877: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c4900 of size 1536
2019-01-24 02:37:30.393880: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c4f00 of size 1536
2019-01-24 02:37:30.393884: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c5500 of size 2816
2019-01-24 02:37:30.393887: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6000 of size 1536
2019-01-24 02:37:30.393891: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6600 of size 256
2019-01-24 02:37:30.401323: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6700 of size 1536
2019-01-24 02:37:30.401327: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6d00 of size 2816
2019-01-24 02:37:30.401330: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c7800 of size 256
2019-01-24 02:37:30.401333: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c7900 of size 2816
2019-01-24 02:37:30.401336: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c8400 of size 2816
2019-01-24 02:37:30.401339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c8f00 of size 256
2019-01-24 02:37:30.401342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c9000 of size 1536
2019-01-24 02:37:30.401345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c9600 of size 1536
2019-01-24 02:37:30.401348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c9c00 of size 2816
2019-01-24 02:37:30.401350: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ca700 of size 1536
2019-01-24 02:37:30.401354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cad00 of size 1536
2019-01-24 02:37:30.401358: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cb300 of size 1536
2019-01-24 02:37:30.401361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cb900 of size 256
2019-01-24 02:37:30.401365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cba00 of size 256
2019-01-24 02:37:30.401368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cbb00 of size 2816
2019-01-24 02:37:30.401371: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cc600 of size 1536
2019-01-24 02:37:30.401375: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ccc00 of size 256
2019-01-24 02:37:30.401378: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ccd00 of size 2816
2019-01-24 02:37:30.401381: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cd800 of size 2816
2019-01-24 02:37:30.401385: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ce300 of size 1536
2019-01-24 02:37:30.401388: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ce900 of size 1536
2019-01-24 02:37:30.401392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cef00 of size 1536
2019-01-24 02:37:30.401395: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cf500 of size 1536
2019-01-24 02:37:30.401399: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cfb00 of size 1536
2019-01-24 02:37:30.401402: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d0100 of size 256
2019-01-24 02:37:30.401406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d0200 of size 1536
2019-01-24 02:37:30.401409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d0800 of size 2816
2019-01-24 02:37:30.401413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d1300 of size 256
2019-01-24 02:37:30.401416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d1400 of size 2816
2019-01-24 02:37:30.401420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d1f00 of size 2816
2019-01-24 02:37:30.401423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d2a00 of size 2816
2019-01-24 02:37:30.401427: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d3500 of size 1536
2019-01-24 02:37:30.401431: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d3b00 of size 1536
2019-01-24 02:37:30.401434: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d4100 of size 2816
2019-01-24 02:37:30.401438: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d4c00 of size 1536
2019-01-24 02:37:30.401441: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d5200 of size 2816
2019-01-24 02:37:30.401445: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d5d00 of size 1536
2019-01-24 02:37:30.401448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d6300 of size 1536
2019-01-24 02:37:30.401452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d6900 of size 2816
2019-01-24 02:37:30.401455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7400 of size 256
2019-01-24 02:37:30.401459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7500 of size 1536
2019-01-24 02:37:30.401462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7b00 of size 256
2019-01-24 02:37:30.401466: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7c00 of size 2816
2019-01-24 02:37:30.401469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d8700 of size 256
2019-01-24 02:37:30.401473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d8800 of size 2816
2019-01-24 02:37:30.401477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d9300 of size 2816
2019-01-24 02:37:30.401480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d9e00 of size 1536
2019-01-24 02:37:30.401483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9da400 of size 1536
2019-01-24 02:37:30.401487: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9daa00 of size 1536
2019-01-24 02:37:30.401490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9db000 of size 256
2019-01-24 02:37:30.401494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9db100 of size 1536
2019-01-24 02:37:30.401497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9db700 of size 1536
2019-01-24 02:37:30.401501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dbd00 of size 256
2019-01-24 02:37:30.401504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dbe00 of size 1536
2019-01-24 02:37:30.401508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dc400 of size 256
2019-01-24 02:37:30.401511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dc500 of size 256
2019-01-24 02:37:30.401515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dc600 of size 2816
2019-01-24 02:37:30.401518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dd100 of size 1536
2019-01-24 02:37:30.401522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dd700 of size 2816
2019-01-24 02:37:30.401525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9de200 of size 1536
2019-01-24 02:37:30.401529: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9de800 of size 1536
2019-01-24 02:37:30.401532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dee00 of size 2816
2019-01-24 02:37:30.401536: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9df900 of size 1536
2019-01-24 02:37:30.401539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dff00 of size 1536
2019-01-24 02:37:30.401543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0500 of size 256
2019-01-24 02:37:30.401546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0600 of size 1536
2019-01-24 02:37:30.401550: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0c00 of size 256
2019-01-24 02:37:30.401553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0d00 of size 2816
2019-01-24 02:37:30.401557: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e1800 of size 256
2019-01-24 02:37:30.401561: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e1900 of size 2816
2019-01-24 02:37:30.401564: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e2400 of size 2816
2019-01-24 02:37:30.401568: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e2f00 of size 1536
2019-01-24 02:37:30.401571: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e3500 of size 1536
2019-01-24 02:37:30.401575: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e3b00 of size 1536
2019-01-24 02:37:30.401578: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e4100 of size 2816
2019-01-24 02:37:30.401582: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e4c00 of size 1536
2019-01-24 02:37:30.401585: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e5200 of size 1536
2019-01-24 02:37:30.401589: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e5800 of size 256
2019-01-24 02:37:30.401592: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e5900 of size 2816
2019-01-24 02:37:30.401596: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e6400 of size 1536
2019-01-24 02:37:30.401599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e6a00 of size 2816
2019-01-24 02:37:30.401603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7500 of size 256
2019-01-24 02:37:30.401606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7600 of size 256
2019-01-24 02:37:30.401610: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7700 of size 1536
2019-01-24 02:37:30.401613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7d00 of size 2816
2019-01-24 02:37:30.401617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e8800 of size 1536
2019-01-24 02:37:30.401620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e8e00 of size 2816
2019-01-24 02:37:30.401623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e9900 of size 1536
2019-01-24 02:37:30.401627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e9f00 of size 1536
2019-01-24 02:37:30.401631: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ea500 of size 256
2019-01-24 02:37:30.401634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ea600 of size 1536
2019-01-24 02:37:30.401638: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eac00 of size 256
2019-01-24 02:37:30.401641: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ead00 of size 1536
2019-01-24 02:37:30.401645: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eb300 of size 256
2019-01-24 02:37:30.401648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eb400 of size 1536
2019-01-24 02:37:30.401652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eba00 of size 1536
2019-01-24 02:37:30.401655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ec000 of size 1536
2019-01-24 02:37:30.401659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ec600 of size 1536
2019-01-24 02:37:30.401662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ecc00 of size 1536
2019-01-24 02:37:30.401666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ed200 of size 256
2019-01-24 02:37:30.401669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ed300 of size 1536
2019-01-24 02:37:30.401673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ed900 of size 2816
2019-01-24 02:37:30.401676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ee400 of size 256
2019-01-24 02:37:30.401682: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ee500 of size 2816
2019-01-24 02:37:30.401686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ef000 of size 1536
2019-01-24 02:37:30.401690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ef600 of size 2816
2019-01-24 02:37:30.401693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f0100 of size 1536
2019-01-24 02:37:30.401697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f0700 of size 1536
2019-01-24 02:37:30.401700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f0d00 of size 1536
2019-01-24 02:37:30.401704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f1300 of size 2816
2019-01-24 02:37:30.401707: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f1e00 of size 1536
2019-01-24 02:37:30.401711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f2400 of size 256
2019-01-24 02:37:30.401714: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f2500 of size 1536
2019-01-24 02:37:30.401718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f2b00 of size 2816
2019-01-24 02:37:30.401721: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f3600 of size 256
2019-01-24 02:37:30.401725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f3700 of size 2816
2019-01-24 02:37:30.401728: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f4200 of size 256
2019-01-24 02:37:30.401732: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f4300 of size 2816
2019-01-24 02:37:30.401735: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f4e00 of size 1536
2019-01-24 02:37:30.401738: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f5400 of size 1536
2019-01-24 02:37:30.401742: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f5a00 of size 2816
2019-01-24 02:37:30.401745: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f6500 of size 1536
2019-01-24 02:37:30.401748: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f6b00 of size 256
2019-01-24 02:37:30.401752: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f6c00 of size 1536
2019-01-24 02:37:30.401755: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7200 of size 1536
2019-01-24 02:37:30.401759: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7800 of size 256
2019-01-24 02:37:30.401762: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7900 of size 256
2019-01-24 02:37:30.401766: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7a00 of size 1536
2019-01-24 02:37:30.401769: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f8000 of size 256
2019-01-24 02:37:30.401773: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f8100 of size 2816
2019-01-24 02:37:30.401776: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f8c00 of size 2816
2019-01-24 02:37:30.401779: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f9700 of size 1536
2019-01-24 02:37:30.401783: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f9d00 of size 1536
2019-01-24 02:37:30.401786: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fa300 of size 2816
2019-01-24 02:37:30.401790: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fae00 of size 1536
2019-01-24 02:37:30.401793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fb400 of size 2816
2019-01-24 02:37:30.401797: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fbf00 of size 1536
2019-01-24 02:37:30.401800: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fc500 of size 1536
2019-01-24 02:37:30.401804: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fcb00 of size 2816
2019-01-24 02:37:30.401807: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fd600 of size 256
2019-01-24 02:37:30.401811: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fd700 of size 1536
2019-01-24 02:37:30.401814: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fdd00 of size 256
2019-01-24 02:37:30.401817: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fde00 of size 2816
2019-01-24 02:37:30.401821: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fe900 of size 2816
2019-01-24 02:37:30.401824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ff400 of size 2816
2019-01-24 02:37:30.401828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fff00 of size 2816
2019-01-24 02:37:30.401831: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea00a00 of size 1536
2019-01-24 02:37:30.401835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea01000 of size 2816
2019-01-24 02:37:30.401838: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea01b00 of size 1536
2019-01-24 02:37:30.401842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02100 of size 1536
2019-01-24 02:37:30.401845: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02700 of size 256
2019-01-24 02:37:30.401849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02800 of size 1536
2019-01-24 02:37:30.401852: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02e00 of size 1536
2019-01-24 02:37:30.401855: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea03400 of size 256
2019-01-24 02:37:30.401859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea03500 of size 2816
2019-01-24 02:37:30.401862: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea04000 of size 1536
2019-01-24 02:37:30.401866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea04600 of size 2816
2019-01-24 02:37:30.401869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05100 of size 256
2019-01-24 02:37:30.401873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05200 of size 256
2019-01-24 02:37:30.401876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05300 of size 1536
2019-01-24 02:37:30.401880: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05900 of size 256
2019-01-24 02:37:30.401883: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05a00 of size 1536
2019-01-24 02:37:30.401887: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea06000 of size 1536
2019-01-24 02:37:30.401890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea06600 of size 1536
2019-01-24 02:37:30.401894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea06c00 of size 1536
2019-01-24 02:37:30.401897: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea07200 of size 256
2019-01-24 02:37:30.401901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea07300 of size 2816
2019-01-24 02:37:30.401904: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea07e00 of size 1536
2019-01-24 02:37:30.401907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea08400 of size 256
2019-01-24 02:37:30.401911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea08500 of size 2816
2019-01-24 02:37:30.401914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea09000 of size 2816
2019-01-24 02:37:30.401918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea09b00 of size 2816
2019-01-24 02:37:30.401921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0a600 of size 256
2019-01-24 02:37:30.401925: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0a700 of size 1536
2019-01-24 02:37:30.401928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0ad00 of size 2816
2019-01-24 02:37:30.401932: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0b800 of size 1536
2019-01-24 02:37:30.409471: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0be00 of size 1536
2019-01-24 02:37:30.409475: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0c400 of size 1536
2019-01-24 02:37:30.409478: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0ca00 of size 2816
2019-01-24 02:37:30.409480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0d500 of size 1536
2019-01-24 02:37:30.409483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0db00 of size 256
2019-01-24 02:37:30.409486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0dc00 of size 256
2019-01-24 02:37:30.409489: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0dd00 of size 1536
2019-01-24 02:37:30.409492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0e300 of size 256
2019-01-24 02:37:30.409495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0e400 of size 256
2019-01-24 02:37:30.409499: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0e500 of size 2816
2019-01-24 02:37:30.409502: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0f000 of size 256
2019-01-24 02:37:30.409506: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0f100 of size 1536
2019-01-24 02:37:30.409509: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0f700 of size 1536
2019-01-24 02:37:30.409513: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0fd00 of size 1536
2019-01-24 02:37:30.409516: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea10300 of size 1536
2019-01-24 02:37:30.409520: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea10900 of size 1536
2019-01-24 02:37:30.409523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea10f00 of size 256
2019-01-24 02:37:30.409527: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea11000 of size 1536
2019-01-24 02:37:30.409530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea11600 of size 256
2019-01-24 02:37:30.409534: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea11700 of size 2816
2019-01-24 02:37:30.409537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea12200 of size 1536
2019-01-24 02:37:30.409541: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea12800 of size 1536
2019-01-24 02:37:30.409544: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea12e00 of size 1536
2019-01-24 02:37:30.409548: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea13400 of size 1536
2019-01-24 02:37:30.409551: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea13a00 of size 2816
2019-01-24 02:37:30.409555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea14500 of size 1536
2019-01-24 02:37:30.409558: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea14b00 of size 256
2019-01-24 02:37:30.409562: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea14c00 of size 1536
2019-01-24 02:37:30.409565: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea15200 of size 16640
2019-01-24 02:37:30.409569: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea19300 of size 54190
08
2019-01-24 02:37:30.409573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ef44300 of size 27095
04
2019-01-24 02:37:30.409576: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1f1d9b00 of size 72253
44
2019-01-24 02:37:30.409580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1f8bdb00 of size 10838
016
2019-01-24 02:37:30.409584: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb20313b00 of size 93671
4240
2019-01-24 02:37:30.409588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb58065b00 of size 23417
8560
2019-01-24 02:37:30.409591: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb65fba300 of size 23417
8560
2019-01-24 02:37:30.409595: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb73f0eb00 of size 23417
8560
2019-01-24 02:37:30.409599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb81e63300 of size 23417
8560
2019-01-24 02:37:30.409602: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb8fdb7b00 of size 93671
4240
2019-01-24 02:37:30.409606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xbc7b09b00 of size 93671
4240
2019-01-24 02:37:30.409609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xbff85bb00 of size 93671
4240
2019-01-24 02:37:30.409613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc375adb00 of size 15611
904
2019-01-24 02:37:30.409617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38491300 of size 512
2019-01-24 02:37:30.409620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc38491500 of size 78059
52
2019-01-24 02:37:30.409624: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38c03100 of size 512
2019-01-24 02:37:30.409627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38c03300 of size 512
2019-01-24 02:37:30.409631: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38c03500 of size 512
2019-01-24 02:37:30.409634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc38c03700 of size 39040
00
2019-01-24 02:37:30.409638: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38fbc900 of size 512
2019-01-24 02:37:30.409641: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc38fbcb00 of size 11721
216
2019-01-24 02:37:30.409645: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc39aea500 of size 512
2019-01-24 02:37:30.409648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc39aea700 of size 58641
92
2019-01-24 02:37:30.409652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3a082200 of size 512
2019-01-24 02:37:30.409655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3a082400 of size 11720
704
2019-01-24 02:37:30.409659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3abafc00 of size 512
2019-01-24 02:37:30.409662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3abafe00 of size 11720
704
2019-01-24 02:37:30.409666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3b6dd600 of size 512
2019-01-24 02:37:30.409670: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3b6dd800 of size 11720
704
2019-01-24 02:37:30.409673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3c20b000 of size 512
2019-01-24 02:37:30.409677: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3c20b200 of size 58641
92
2019-01-24 02:37:30.409682: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3c7a2d00 of size 512
2019-01-24 02:37:30.409686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3c7a2f00 of size 11720
704
2019-01-24 02:37:30.409690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3d2d0700 of size 512
2019-01-24 02:37:30.409693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3d2d0900 of size 11720
704
2019-01-24 02:37:30.409697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3ddfe100 of size 512
2019-01-24 02:37:30.409701: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3ddfe300 of size 58641
92
2019-01-24 02:37:30.409704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e395e00 of size 512
2019-01-24 02:37:30.409708: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e396000 of size 7680
2019-01-24 02:37:30.409711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e397e00 of size 512
2019-01-24 02:37:30.409715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e398000 of size 7680
2019-01-24 02:37:30.409719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e399e00 of size 512
2019-01-24 02:37:30.409722: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e39a000 of size 7680
2019-01-24 02:37:30.409726: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e39be00 of size 512
2019-01-24 02:37:30.409729: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e39c000 of size 7680
2019-01-24 02:37:30.409733: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e39de00 of size 512
2019-01-24 02:37:30.409736: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e39e000 of size 7680
2019-01-24 02:37:30.409740: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e39fe00 of size 512
2019-01-24 02:37:30.409743: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a0000 of size 2048
2019-01-24 02:37:30.409747: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e3a0800 of size 512
2019-01-24 02:37:30.409750: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a0a00 of size 2048
2019-01-24 02:37:30.409754: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e3a1200 of size 3072
2019-01-24 02:37:30.409757: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a1e00 of size 512
2019-01-24 02:37:30.409761: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a2000 of size 512
2019-01-24 02:37:30.409765: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e3a2200 of size 46836
3776
2019-01-24 02:37:30.409768: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc5a24cc00 of size 23417
8560
2019-01-24 02:37:30.409772: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc681a1400 of size 23417
8560
2019-01-24 02:37:30.409775: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc760f5c00 of size 26130
9696
2019-01-24 02:37:30.409779: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc85a2a100 of size 93671
4240
2019-01-24 02:37:30.409783: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xcbd77c100 of size 93671
4240
2019-01-24 02:37:30.409786: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xcf54ce100 of size 93671
4240
2019-01-24 02:37:30.409790: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xd2d220100 of size 93671
4240
2019-01-24 02:37:30.409793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xd64f72100 of size 90480
7680
2019-01-24 02:37:30.409797: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by s
ize:
2019-01-24 02:37:30.409805: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1274 Chunks of size 256 totalling
318.5KiB
2019-01-24 02:37:30.409810: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 135 Chunks of size 512 totalling 6
7.5KiB
2019-01-24 02:37:30.409814: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 579 Chunks of size 768 totalling 4
34.2KiB
2019-01-24 02:37:30.409818: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 1280 totalling 3.
8KiB
2019-01-24 02:37:30.409822: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 681 Chunks of size 1536 totalling
1021.5KiB
2019-01-24 02:37:30.409826: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 2048 totalling 18
.0KiB
2019-01-24 02:37:30.409830: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 675 Chunks of size 2816 totalling
1.81MiB
2019-01-24 02:37:30.409834: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 3072 totalling 6.
0KiB
2019-01-24 02:37:30.409838: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 4352 totalling 8.
5KiB
2019-01-24 02:37:30.409842: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 37 Chunks of size 6144 totalling 2
22.0KiB
2019-01-24 02:37:30.409846: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 7168 totalling 35
.0KiB
2019-01-24 02:37:30.409850: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 8448 totalling 41
.2KiB
2019-01-24 02:37:30.409854: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 10496 totalling 1
0.2KiB
2019-01-24 02:37:30.409858: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 11520 totalling 1
1.2KiB
2019-01-24 02:37:30.409862: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 39 Chunks of size 12288 totalling
468.0KiB
2019-01-24 02:37:30.409866: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 6 Chunks of size 16128 totalling 9
4.5KiB
2019-01-24 02:37:30.409870: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 16640 totalling 6
5.0KiB
2019-01-24 02:37:30.409874: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 24 Chunks of size 16896 totalling
396.0KiB
2019-01-24 02:37:30.409878: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 18944 totalling 5
5.5KiB
2019-01-24 02:37:30.409883: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 38 Chunks of size 24320 totalling
902.5KiB
2019-01-24 02:37:30.409886: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 28416 totalling 2
22.0KiB
2019-01-24 02:37:30.409890: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 32000 totalling 3
1.2KiB
2019-01-24 02:37:30.409894: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 27 Chunks of size 33792 totalling
891.0KiB
2019-01-24 02:37:30.409898: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 36864 totalling 3
6.0KiB
2019-01-24 02:37:30.409902: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 47104 totalling 4
6.0KiB
2019-01-24 02:37:30.409906: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 56576 totalling 2
21.0KiB
2019-01-24 02:37:30.409911: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 57600 totalling 5
06.2KiB
2019-01-24 02:37:30.409915: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 66048 totalling 1
93.5KiB
2019-01-24 02:37:30.409919: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 28 Chunks of size 67328 totalling
1.80MiB
2019-01-24 02:37:30.409923: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 108288 totalling
105.8KiB
2019-01-24 02:37:30.409927: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 60 Chunks of size 112896 totalling
 6.46MiB
2019-01-24 02:37:30.409931: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 129792 totalling
126.8KiB
2019-01-24 02:37:30.409935: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 131840 totalling
515.0KiB
2019-01-24 02:37:30.409939: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 225792 totalling
441.0KiB
2019-01-24 02:37:30.409942: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 230400 totalling
1.54MiB
2019-01-24 02:37:30.409947: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 69 Chunks of size 451584 totalling
 29.72MiB
2019-01-24 02:37:30.409951: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 485376 totalling
474.0KiB
2019-01-24 02:37:30.409954: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 12 Chunks of size 677376 totalling
 7.75MiB
2019-01-24 02:37:30.409958: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1354752 totalling
 1.29MiB
2019-01-24 02:37:30.409962: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 71 Chunks of size 1806336 totallin
g 122.31MiB
2019-01-24 02:37:30.409966: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 2032128 totalling
 1.94MiB
2019-01-24 02:37:30.409970: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 11 Chunks of size 2709504 totallin
g 28.42MiB
2019-01-24 02:37:30.409974: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 3316480 totalling
 3.16MiB
2019-01-24 02:37:30.409978: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5419008 totalling
 5.17MiB
2019-01-24 02:37:30.409982: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5435648 totalling
 5.18MiB
2019-01-24 02:37:30.409986: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 7225344 totalling
 13.78MiB
2019-01-24 02:37:30.409990: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 10838016 totallin
g 93.02MiB
2019-01-24 02:37:30.409994: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 6 Chunks of size 234178560 totalli
ng 1.31GiB
2019-01-24 02:37:30.409998: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 936714240 totalli
ng 6.98GiB
2019-01-24 02:37:30.410001: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 8.61Gi
B
2019-01-24 02:37:30.410007: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats:
Limit:                 11015644775
InUse:                  9246031360
MaxInUse:              10301485312
NumAllocs:                    9509
MaxAllocSize:           2236809216

2019-01-24 02:37:30.410137: W tensorflow/core/common_runtime/bfc_allocator.cc:279] **********************************
*************____*****_***********************************________
2019-01-24 02:37:30.410151: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at strided_slice_op.cc:
247 : Resource exhausted: OOM when allocating tensor with shape[487872,480] and type float on /job:localhost/replica:
0/task:0/device:GPU:0 by allocator GPU_0_bfc
2019-01-24 02:37:40.410419: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of m
emory trying to allocate 893.32MiB.  Current allocation summary follows.
2019-01-24 02:37:40.410614: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (256):   Total Chunks: 1275, C
hunks in use: 1274. 318.8KiB allocated for chunks. 318.5KiB in use in bin. 19.6KiB client-requested in use in bin.
2019-01-24 02:37:40.410664: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (512):   Total Chunks: 714, Ch
unks in use: 713. 501.8KiB allocated for chunks. 501.2KiB in use in bin. 427.4KiB client-requested in use in bin.
2019-01-24 02:37:40.410703: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1024):  Total Chunks: 686, Ch
unks in use: 684. 1.00MiB allocated for chunks. 1.00MiB in use in bin. 896.8KiB client-requested in use in bin.
2019-01-24 02:37:40.410739: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2048):  Total Chunks: 687, Ch
unks in use: 687. 1.84MiB allocated for chunks. 1.84MiB in use in bin. 1.75MiB client-requested in use in bin.
2019-01-24 02:37:40.410778: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4096):  Total Chunks: 49, Chu
nks in use: 44. 303.0KiB allocated for chunks. 265.5KiB in use in bin. 259.4KiB client-requested in use in bin.
2019-01-24 02:37:40.410816: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8192):  Total Chunks: 52, Chu
nks in use: 52. 625.2KiB allocated for chunks. 625.2KiB in use in bin. 600.4KiB client-requested in use in bin.
2019-01-24 02:37:40.410850: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16384):         Total Chunks:
 78, Chunks in use: 78. 1.63MiB allocated for chunks. 1.63MiB in use in bin. 1.60MiB client-requested in use in bin.
2019-01-24 02:37:40.410885: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (32768):         Total Chunks:
 40, Chunks in use: 40. 1.55MiB allocated for chunks. 1.55MiB in use in bin. 1.50MiB client-requested in use in bin.
2019-01-24 02:37:40.410919: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (65536):         Total Chunks:
 93, Chunks in use: 93. 8.67MiB allocated for chunks. 8.67MiB in use in bin. 8.56MiB client-requested in use in bin.
2019-01-24 02:37:40.410953: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (131072):        Total Chunks:
 14, Chunks in use: 14. 2.69MiB allocated for chunks. 2.69MiB in use in bin. 2.69MiB client-requested in use in bin.
2019-01-24 02:37:40.410988: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (262144):        Total Chunks:
 71, Chunks in use: 71. 30.45MiB allocated for chunks. 30.45MiB in use in bin. 30.16MiB client-requested in use in bi
n.
2019-01-24 02:37:40.411021: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (524288):        Total Chunks:
 12, Chunks in use: 12. 7.75MiB allocated for chunks. 7.75MiB in use in bin. 7.54MiB client-requested in use in bin.
2019-01-24 02:37:40.411057: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (1048576):       Total Chunks:
 73, Chunks in use: 73. 125.54MiB allocated for chunks. 125.54MiB in use in bin. 124.89MiB client-requested in use in
 bin.
2019-01-24 02:37:40.411092: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (2097152):       Total Chunks:
 14, Chunks in use: 12. 37.34MiB allocated for chunks. 31.59MiB in use in bin. 30.15MiB client-requested in use in bi
n.
2019-01-24 02:37:40.411127: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (4194304):       Total Chunks:
 9, Chunks in use: 4. 54.53MiB allocated for chunks. 24.13MiB in use in bin. 24.12MiB client-requested in use in bin.
2019-01-24 02:37:40.411163: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (8388608):       Total Chunks:
 17, Chunks in use: 9. 185.31MiB allocated for chunks. 93.02MiB in use in bin. 93.02MiB client-requested in use in bi
n.
2019-01-24 02:37:40.411195: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (16777216):      Total Chunks:
 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-01-24 02:37:40.411226: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (33554432):      Total Chunks:
 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-01-24 02:37:40.411256: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (67108864):      Total Chunks:
 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2019-01-24 02:37:40.411293: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (134217728):     Total Chunks:
 6, Chunks in use: 5. 1.33GiB allocated for chunks. 1.09GiB in use in bin. 1.09GiB client-requested in use in bin.
2019-01-24 02:37:40.411322: I tensorflow/core/common_runtime/bfc_allocator.cc:630] Bin (268435456):     Total Chunks:
 10, Chunks in use: 8. 8.48GiB allocated for chunks. 6.98GiB in use in bin. 6.98GiB client-requested in use in bin.
2019-01-24 02:37:40.411348: I tensorflow/core/common_runtime/bfc_allocator.cc:646] Bin for 893.32MiB was 256.00MiB, C
hunk State:
2019-01-24 02:37:40.411386: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 670.00MiB | Requested Size
: 480B | in_use: 0, prev:   Size: 512B | Requested Size: 480B | in_use: 1, next:   Size: 223.33MiB | Requested Size:
223.33MiB | in_use: 1
2019-01-24 02:37:40.411415: I tensorflow/core/common_runtime/bfc_allocator.cc:652]   Size: 862.89MiB | Requested Size
: 480B | in_use: 0, prev:   Size: 893.32MiB | Requested Size: 893.32MiB | in_use: 1
2019-01-24 02:37:40.411436: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500000 of size 1280
2019-01-24 02:37:40.411454: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500500 of size 256
2019-01-24 02:37:40.411473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500600 of size 512
2019-01-24 02:37:40.411492: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500800 of size 512
2019-01-24 02:37:40.411507: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500a00 of size 512
2019-01-24 02:37:40.411525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500c00 of size 256
2019-01-24 02:37:40.411543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500d00 of size 256
2019-01-24 02:37:40.411561: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500e00 of size 256
2019-01-24 02:37:40.411579: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a500f00 of size 256
2019-01-24 02:37:40.411597: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501000 of size 256
2019-01-24 02:37:40.411615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501100 of size 256
2019-01-24 02:37:40.411633: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501200 of size 256
2019-01-24 02:37:40.411651: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501300 of size 256
2019-01-24 02:37:40.411669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501400 of size 256
2019-01-24 02:37:40.411687: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501500 of size 256
2019-01-24 02:37:40.411705: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501600 of size 256
2019-01-24 02:37:40.411723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501700 of size 256
2019-01-24 02:37:40.411741: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501800 of size 256
2019-01-24 02:37:40.411759: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501900 of size 256
2019-01-24 02:37:40.411777: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501a00 of size 256
2019-01-24 02:37:40.411795: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501b00 of size 256
2019-01-24 02:37:40.411813: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501c00 of size 256
2019-01-24 02:37:40.411831: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501d00 of size 256
2019-01-24 02:37:40.411849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a501e00 of size 512
2019-01-24 02:37:40.411867: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502000 of size 512
2019-01-24 02:37:40.411885: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502200 of size 256
2019-01-24 02:37:40.411903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502300 of size 256
2019-01-24 02:37:40.411921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502400 of size 256
2019-01-24 02:37:40.411938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502500 of size 256
2019-01-24 02:37:40.411956: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502600 of size 256
2019-01-24 02:37:40.411974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502700 of size 256
2019-01-24 02:37:40.411992: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502800 of size 256
2019-01-24 02:37:40.412010: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502900 of size 256
2019-01-24 02:37:40.412028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502a00 of size 256
2019-01-24 02:37:40.412047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502b00 of size 768
2019-01-24 02:37:40.412065: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a502e00 of size 1280
2019-01-24 02:37:40.412084: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a503300 of size 512
2019-01-24 02:37:40.412102: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a503500 of size 512
2019-01-24 02:37:40.412120: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a503700 of size 512
2019-01-24 02:37:40.412138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a503900 of size 512
2019-01-24 02:37:40.412157: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a503b00 of size 10496
2019-01-24 02:37:40.412176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a506400 of size 2816
2019-01-24 02:37:40.412194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a506f00 of size 2816
2019-01-24 02:37:40.412212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a507a00 of size 256
2019-01-24 02:37:40.412230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a507b00 of size 256
2019-01-24 02:37:40.412248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a507c00 of size 256
2019-01-24 02:37:40.412266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a507d00 of size 256
2019-01-24 02:37:40.412284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a507e00 of size 256
2019-01-24 02:37:40.412302: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a507f00 of size 256
2019-01-24 02:37:40.412320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508000 of size 256
2019-01-24 02:37:40.412338: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508100 of size 256
2019-01-24 02:37:40.412356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508200 of size 256
2019-01-24 02:37:40.412374: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508300 of size 256
2019-01-24 02:37:40.412392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508400 of size 256
2019-01-24 02:37:40.412410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508500 of size 256
2019-01-24 02:37:40.412428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508600 of size 256
2019-01-24 02:37:40.412446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508700 of size 256
2019-01-24 02:37:40.412464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508800 of size 256
2019-01-24 02:37:40.412482: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508900 of size 256
2019-01-24 02:37:40.412500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508a00 of size 256
2019-01-24 02:37:40.412517: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508b00 of size 256
2019-01-24 02:37:40.412537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a508c00 of size 1536
2019-01-24 02:37:40.412555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509200 of size 1536
2019-01-24 02:37:40.412573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509800 of size 256
2019-01-24 02:37:40.412591: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509900 of size 256
2019-01-24 02:37:40.412609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509a00 of size 256
2019-01-24 02:37:40.412627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509b00 of size 256
2019-01-24 02:37:40.412645: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509c00 of size 256
2019-01-24 02:37:40.412663: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509d00 of size 256
2019-01-24 02:37:40.412681: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509e00 of size 256
2019-01-24 02:37:40.412699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a509f00 of size 256
2019-01-24 02:37:40.412717: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a50a000 of size 256
2019-01-24 02:37:40.412735: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a50a100 of size 256
2019-01-24 02:37:40.412755: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a50a200 of size 16640
2019-01-24 02:37:40.412773: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a50e300 of size 16640
2019-01-24 02:37:40.412791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a512400 of size 16640
2019-01-24 02:37:40.412818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0a516500 of size 54356
48
2019-01-24 02:37:40.412842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0aa45600 of size 3072
2019-01-24 02:37:40.412861: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0aa46200 of size 67328
2019-01-24 02:37:40.412880: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0aa56900 of size 22579
2
2019-01-24 02:37:40.412900: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0aa8db00 of size 18063
36
2019-01-24 02:37:40.412919: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0ac46b00 of size 33164
80
2019-01-24 02:37:40.412938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af70600 of size 2816
2019-01-24 02:37:40.412957: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af71100 of size 2816
2019-01-24 02:37:40.412975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af71c00 of size 2816
2019-01-24 02:37:40.412993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af72700 of size 2816
2019-01-24 02:37:40.413012: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af73200 of size 2816
2019-01-24 02:37:40.413030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af73d00 of size 2816
2019-01-24 02:37:40.413047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af74800 of size 2816
2019-01-24 02:37:40.413066: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af75300 of size 2816
2019-01-24 02:37:40.413085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af75e00 of size 2816
2019-01-24 02:37:40.413103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af76900 of size 2816
2019-01-24 02:37:40.413121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af77400 of size 3072
2019-01-24 02:37:40.413139: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af78000 of size 1536
2019-01-24 02:37:40.413157: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af78600 of size 1536
2019-01-24 02:37:40.413176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af78c00 of size 2816
2019-01-24 02:37:40.413194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af79700 of size 2816
2019-01-24 02:37:40.413212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7a200 of size 2816
2019-01-24 02:37:40.413230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7ad00 of size 2816
2019-01-24 02:37:40.413247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7b800 of size 2816
2019-01-24 02:37:40.413265: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7c300 of size 2816
2019-01-24 02:37:40.413283: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7ce00 of size 2816
2019-01-24 02:37:40.413301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7d900 of size 2816
2019-01-24 02:37:40.413319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7e400 of size 2816
2019-01-24 02:37:40.413337: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7ef00 of size 2816
2019-01-24 02:37:40.413355: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af7fa00 of size 67328
2019-01-24 02:37:40.413374: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0af90100 of size 67328
2019-01-24 02:37:40.413392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0afa0800 of size 67328
2019-01-24 02:37:40.413410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0afb0f00 of size 67328
2019-01-24 02:37:40.413429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0afc1600 of size 67328
2019-01-24 02:37:40.413447: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0afd1d00 of size 67328
2019-01-24 02:37:40.413465: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0afe2400 of size 67328
2019-01-24 02:37:40.413483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0aff2b00 of size 67328
2019-01-24 02:37:40.413501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b003200 of size 67328
2019-01-24 02:37:40.413520: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b013900 of size 67328
2019-01-24 02:37:40.413537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b024000 of size 67328
2019-01-24 02:37:40.413555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b034700 of size 67328
2019-01-24 02:37:40.413574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b044e00 of size 67328
2019-01-24 02:37:40.413592: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b055500 of size 67328
2019-01-24 02:37:40.413610: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b065c00 of size 67328
2019-01-24 02:37:40.413628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b076300 of size 67328
2019-01-24 02:37:40.413647: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b086a00 of size 67328
2019-01-24 02:37:40.413665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b097100 of size 67328
2019-01-24 02:37:40.413709: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b0a7800 of size 67328
2019-01-24 02:37:40.413730: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b0b7f00 of size 67328
2019-01-24 02:37:40.413749: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b0c8600 of size 67328
2019-01-24 02:37:40.413767: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b0d8d00 of size 67328
2019-01-24 02:37:40.413785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b0e9400 of size 67328
2019-01-24 02:37:40.413803: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b0f9b00 of size 67328
2019-01-24 02:37:40.430361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b10a200 of size 67328
2019-01-24 02:37:40.430369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b11a900 of size 67328
2019-01-24 02:37:40.430373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b12b000 of size 67328
2019-01-24 02:37:40.430376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b13b700 of size 16896
2019-01-24 02:37:40.430379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b13f900 of size 6144
2019-01-24 02:37:40.430383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b141100 of size 12288
2019-01-24 02:37:40.430386: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b144100 of size 32000
2019-01-24 02:37:40.430390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14be00 of size 768
2019-01-24 02:37:40.430393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14c100 of size 768
2019-01-24 02:37:40.430396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14c400 of size 768
2019-01-24 02:37:40.430400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14c700 of size 768
2019-01-24 02:37:40.430403: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14ca00 of size 768
2019-01-24 02:37:40.430406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14cd00 of size 768
2019-01-24 02:37:40.430410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b14d000 of size 22579
2
2019-01-24 02:37:40.430413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b184200 of size 20321
28
2019-01-24 02:37:40.430417: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b374400 of size 18063
36
2019-01-24 02:37:40.430420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b52d400 of size 18063
36
2019-01-24 02:37:40.430423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b6e6400 of size 18063
36
2019-01-24 02:37:40.430427: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0b89f400 of size 18063
36
2019-01-24 02:37:40.430430: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0ba58400 of size 18063
36
2019-01-24 02:37:40.430434: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0bc11400 of size 18063
36
2019-01-24 02:37:40.430437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0bdca400 of size 18063
36
2019-01-24 02:37:40.430441: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0bf83400 of size 18063
36
2019-01-24 02:37:40.430444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0c13c400 of size 18063
36
2019-01-24 02:37:40.430448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0c2f5400 of size 18063
36
2019-01-24 02:37:40.430451: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0c4ae400 of size 18063
36
2019-01-24 02:37:40.430455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0c667400 of size 18063
36
2019-01-24 02:37:40.430458: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0c820400 of size 18063
36
2019-01-24 02:37:40.430462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0c9d9400 of size 18063
36
2019-01-24 02:37:40.430465: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0cb92400 of size 18063
36
2019-01-24 02:37:40.430469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0cd4b400 of size 18063
36
2019-01-24 02:37:40.430472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0cf04400 of size 18063
36
2019-01-24 02:37:40.430476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0d0bd400 of size 18063
36
2019-01-24 02:37:40.430479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0d276400 of size 18063
36
2019-01-24 02:37:40.430483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0d42f400 of size 18063
36
2019-01-24 02:37:40.430486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0d5e8400 of size 18063
36
2019-01-24 02:37:40.430490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0d7a1400 of size 18063
36
2019-01-24 02:37:40.430493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0d95a400 of size 18063
36
2019-01-24 02:37:40.430497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0db13400 of size 18063
36
2019-01-24 02:37:40.430500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0dccc400 of size 18063
36
2019-01-24 02:37:40.430504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0de85400 of size 18063
36
2019-01-24 02:37:40.430507: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0e03e400 of size 18063
36
2019-01-24 02:37:40.430511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0e1f7400 of size 18063
36
2019-01-24 02:37:40.430514: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0e3b0400 of size 18063
36
2019-01-24 02:37:40.430518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0e569400 of size 18063
36
2019-01-24 02:37:40.430521: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0e722400 of size 18063
36
2019-01-24 02:37:40.430525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0e8db400 of size 18063
36
2019-01-24 02:37:40.430528: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0ea94400 of size 18063
36
2019-01-24 02:37:40.430532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0ec4d400 of size 18063
36
2019-01-24 02:37:40.430535: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0ee06400 of size 18063
36
2019-01-24 02:37:40.430539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0efbf400 of size 18063
36
2019-01-24 02:37:40.430542: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0f178400 of size 18063
36
2019-01-24 02:37:40.430546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0f331400 of size 18063
36
2019-01-24 02:37:40.430549: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0f4ea400 of size 18063
36
2019-01-24 02:37:40.430553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0f6a3400 of size 18063
36
2019-01-24 02:37:40.430556: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0f85c400 of size 18063
36
2019-01-24 02:37:40.430560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0fa15400 of size 18063
36
2019-01-24 02:37:40.430563: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0fbce400 of size 18063
36
2019-01-24 02:37:40.430567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0fd87400 of size 18063
36
2019-01-24 02:37:40.430570: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb0ff40400 of size 18063
36
2019-01-24 02:37:40.430574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb100f9400 of size 18063
36
2019-01-24 02:37:40.430577: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb102b2400 of size 18063
36
2019-01-24 02:37:40.430581: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1046b400 of size 18063
36
2019-01-24 02:37:40.430584: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb10624400 of size 18063
36
2019-01-24 02:37:40.430588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb107dd400 of size 18063
36
2019-01-24 02:37:40.430593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb10996400 of size 18063
36
2019-01-24 02:37:40.430598: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb10b4f400 of size 18063
36
2019-01-24 02:37:40.430601: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb10d08400 of size 18063
36
2019-01-24 02:37:40.430605: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb10ec1400 of size 18063
36
2019-01-24 02:37:40.430609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1107a400 of size 18063
36
2019-01-24 02:37:40.430612: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb11233400 of size 18063
36
2019-01-24 02:37:40.430615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb113ec400 of size 18063
36
2019-01-24 02:37:40.430619: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb115a5400 of size 18063
36
2019-01-24 02:37:40.430623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1175e400 of size 18063
36
2019-01-24 02:37:40.430626: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb11917400 of size 18063
36
2019-01-24 02:37:40.430629: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb11ad0400 of size 18063
36
2019-01-24 02:37:40.430633: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb11c89400 of size 18063
36
2019-01-24 02:37:40.430636: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb11e42400 of size 18063
36
2019-01-24 02:37:40.430640: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb11ffb400 of size 18063
36
2019-01-24 02:37:40.430643: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb121b4400 of size 18063
36
2019-01-24 02:37:40.430647: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1236d400 of size 18063
36
2019-01-24 02:37:40.430650: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12526400 of size 18063
36
2019-01-24 02:37:40.430654: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb126df400 of size 18063
36
2019-01-24 02:37:40.430658: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12898400 of size 11289
6
2019-01-24 02:37:40.430661: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb128b3d00 of size 13184
0
2019-01-24 02:37:40.430665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb128d4000 of size 67737
6
2019-01-24 02:37:40.430669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12979600 of size 23040
0
2019-01-24 02:37:40.430673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129b1a00 of size 23040
0
2019-01-24 02:37:40.430676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129e9e00 of size 768
2019-01-24 02:37:40.430680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ea100 of size 768
2019-01-24 02:37:40.430683: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ea400 of size 256
2019-01-24 02:37:40.430687: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ea500 of size 256
2019-01-24 02:37:40.430690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ea600 of size 768
2019-01-24 02:37:40.430694: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ea900 of size 256
2019-01-24 02:37:40.430697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eaa00 of size 256
2019-01-24 02:37:40.430701: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eab00 of size 768
2019-01-24 02:37:40.430704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eae00 of size 256
2019-01-24 02:37:40.430708: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eaf00 of size 768
2019-01-24 02:37:40.430711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eb200 of size 256
2019-01-24 02:37:40.430715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eb300 of size 768
2019-01-24 02:37:40.430718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eb600 of size 256
2019-01-24 02:37:40.430722: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eb700 of size 256
2019-01-24 02:37:40.430725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eb800 of size 768
2019-01-24 02:37:40.430729: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ebb00 of size 256
2019-01-24 02:37:40.430732: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ebc00 of size 768
2019-01-24 02:37:40.430736: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ebf00 of size 256
2019-01-24 02:37:40.430739: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ec000 of size 768
2019-01-24 02:37:40.430743: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ec300 of size 256
2019-01-24 02:37:40.430746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ec400 of size 256
2019-01-24 02:37:40.430750: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ec500 of size 768
2019-01-24 02:37:40.430753: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ec800 of size 256
2019-01-24 02:37:40.430757: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ec900 of size 768
2019-01-24 02:37:40.430760: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ecc00 of size 256
2019-01-24 02:37:40.430764: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ecd00 of size 256
2019-01-24 02:37:40.430767: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ece00 of size 768
2019-01-24 02:37:40.430771: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ed100 of size 256
2019-01-24 02:37:40.430774: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ed200 of size 256
2019-01-24 02:37:40.430778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ed300 of size 768
2019-01-24 02:37:40.430781: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ed600 of size 256
2019-01-24 02:37:40.430785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ed700 of size 768
2019-01-24 02:37:40.430788: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eda00 of size 256
2019-01-24 02:37:40.430792: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129edb00 of size 768
2019-01-24 02:37:40.430795: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ede00 of size 256
2019-01-24 02:37:40.430798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129edf00 of size 256
2019-01-24 02:37:40.430802: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ee000 of size 768
2019-01-24 02:37:40.430806: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ee300 of size 256
2019-01-24 02:37:40.430809: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ee400 of size 768
2019-01-24 02:37:40.430813: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ee700 of size 256
2019-01-24 02:37:40.430816: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ee800 of size 768
2019-01-24 02:37:40.430819: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eeb00 of size 256
2019-01-24 02:37:40.430823: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eec00 of size 256
2019-01-24 02:37:40.430826: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eed00 of size 768
2019-01-24 02:37:40.430830: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ef000 of size 256
2019-01-24 02:37:40.430833: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ef100 of size 768
2019-01-24 02:37:40.430837: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ef400 of size 256
2019-01-24 02:37:40.430840: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ef500 of size 256
2019-01-24 02:37:40.430844: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ef600 of size 768
2019-01-24 02:37:40.430847: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ef900 of size 256
2019-01-24 02:37:40.430851: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129efa00 of size 256
2019-01-24 02:37:40.430854: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129efb00 of size 768
2019-01-24 02:37:40.430858: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129efe00 of size 256
2019-01-24 02:37:40.430861: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129eff00 of size 768
2019-01-24 02:37:40.430865: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0200 of size 256
2019-01-24 02:37:40.430869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0300 of size 768
2019-01-24 02:37:40.430874: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0600 of size 256
2019-01-24 02:37:40.430879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0700 of size 256
2019-01-24 02:37:40.430884: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0800 of size 768
2019-01-24 02:37:40.430889: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0b00 of size 256
2019-01-24 02:37:40.430894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0c00 of size 768
2019-01-24 02:37:40.430899: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f0f00 of size 256
2019-01-24 02:37:40.430904: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1000 of size 256
2019-01-24 02:37:40.430909: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1100 of size 768
2019-01-24 02:37:40.430913: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1400 of size 256
2019-01-24 02:37:40.430918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1500 of size 256
2019-01-24 02:37:40.430923: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1600 of size 768
2019-01-24 02:37:40.430927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1900 of size 256
2019-01-24 02:37:40.430932: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1a00 of size 768
2019-01-24 02:37:40.430936: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1d00 of size 256
2019-01-24 02:37:40.430941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1e00 of size 256
2019-01-24 02:37:40.430945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f1f00 of size 768
2019-01-24 02:37:40.430950: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2200 of size 256
2019-01-24 02:37:40.430955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2300 of size 256
2019-01-24 02:37:40.430959: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2400 of size 768
2019-01-24 02:37:40.430964: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2700 of size 256
2019-01-24 02:37:40.430968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2800 of size 768
2019-01-24 02:37:40.430973: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2b00 of size 256
2019-01-24 02:37:40.430978: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2c00 of size 768
2019-01-24 02:37:40.430982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f2f00 of size 256
2019-01-24 02:37:40.430987: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3000 of size 256
2019-01-24 02:37:40.430991: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3100 of size 768
2019-01-24 02:37:40.430996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3400 of size 256
2019-01-24 02:37:40.431001: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3500 of size 768
2019-01-24 02:37:40.435879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3800 of size 256
2019-01-24 02:37:40.435888: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3900 of size 768
2019-01-24 02:37:40.435892: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3c00 of size 256
2019-01-24 02:37:40.435895: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3d00 of size 256
2019-01-24 02:37:40.435898: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f3e00 of size 768
2019-01-24 02:37:40.435900: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4100 of size 256
2019-01-24 02:37:40.435903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4200 of size 768
2019-01-24 02:37:40.435907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4500 of size 256
2019-01-24 02:37:40.435911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4600 of size 256
2019-01-24 02:37:40.435914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4700 of size 768
2019-01-24 02:37:40.435917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4a00 of size 256
2019-01-24 02:37:40.435921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4b00 of size 256
2019-01-24 02:37:40.435924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4c00 of size 256
2019-01-24 02:37:40.435927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f4d00 of size 768
2019-01-24 02:37:40.435931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5000 of size 256
2019-01-24 02:37:40.435933: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5100 of size 768
2019-01-24 02:37:40.435937: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5400 of size 256
2019-01-24 02:37:40.435940: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5500 of size 768
2019-01-24 02:37:40.435944: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5800 of size 256
2019-01-24 02:37:40.435947: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5900 of size 256
2019-01-24 02:37:40.435951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5a00 of size 768
2019-01-24 02:37:40.435955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5d00 of size 256
2019-01-24 02:37:40.435958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f5e00 of size 768
2019-01-24 02:37:40.435962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6100 of size 256
2019-01-24 02:37:40.435965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6200 of size 768
2019-01-24 02:37:40.435969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6500 of size 256
2019-01-24 02:37:40.435972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6600 of size 256
2019-01-24 02:37:40.435976: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6700 of size 768
2019-01-24 02:37:40.435979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6a00 of size 256
2019-01-24 02:37:40.435983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6b00 of size 768
2019-01-24 02:37:40.435986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6e00 of size 256
2019-01-24 02:37:40.435990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f6f00 of size 256
2019-01-24 02:37:40.435993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7000 of size 768
2019-01-24 02:37:40.435997: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7300 of size 256
2019-01-24 02:37:40.436000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7400 of size 256
2019-01-24 02:37:40.436004: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7500 of size 768
2019-01-24 02:37:40.436007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7800 of size 256
2019-01-24 02:37:40.436011: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7900 of size 768
2019-01-24 02:37:40.436014: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7c00 of size 256
2019-01-24 02:37:40.436018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f7d00 of size 768
2019-01-24 02:37:40.436021: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8000 of size 256
2019-01-24 02:37:40.436025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8100 of size 256
2019-01-24 02:37:40.436028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8200 of size 768
2019-01-24 02:37:40.436032: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8500 of size 256
2019-01-24 02:37:40.436035: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8600 of size 768
2019-01-24 02:37:40.436038: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8900 of size 256
2019-01-24 02:37:40.436042: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8a00 of size 256
2019-01-24 02:37:40.436045: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8b00 of size 768
2019-01-24 02:37:40.436049: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8e00 of size 256
2019-01-24 02:37:40.436052: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f8f00 of size 256
2019-01-24 02:37:40.436056: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9000 of size 768
2019-01-24 02:37:40.436059: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9300 of size 256
2019-01-24 02:37:40.436063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9400 of size 768
2019-01-24 02:37:40.436066: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9700 of size 256
2019-01-24 02:37:40.436070: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9800 of size 256
2019-01-24 02:37:40.436073: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9900 of size 768
2019-01-24 02:37:40.436077: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9c00 of size 256
2019-01-24 02:37:40.436080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9d00 of size 256
2019-01-24 02:37:40.436083: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129f9e00 of size 768
2019-01-24 02:37:40.436087: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fa100 of size 256
2019-01-24 02:37:40.436090: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fa200 of size 768
2019-01-24 02:37:40.436094: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fa500 of size 256
2019-01-24 02:37:40.436097: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fa600 of size 768
2019-01-24 02:37:40.436101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fa900 of size 256
2019-01-24 02:37:40.436104: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129faa00 of size 256
2019-01-24 02:37:40.436108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fab00 of size 256
2019-01-24 02:37:40.436111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fac00 of size 256
2019-01-24 02:37:40.436115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fad00 of size 256
2019-01-24 02:37:40.436118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fae00 of size 256
2019-01-24 02:37:40.436121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129faf00 of size 256
2019-01-24 02:37:40.436124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb000 of size 256
2019-01-24 02:37:40.436128: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb100 of size 256
2019-01-24 02:37:40.436131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb200 of size 256
2019-01-24 02:37:40.436135: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb300 of size 256
2019-01-24 02:37:40.436138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb400 of size 256
2019-01-24 02:37:40.436142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb500 of size 256
2019-01-24 02:37:40.436145: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb600 of size 256
2019-01-24 02:37:40.436149: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb700 of size 256
2019-01-24 02:37:40.436152: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb800 of size 256
2019-01-24 02:37:40.436156: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fb900 of size 256
2019-01-24 02:37:40.436159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fba00 of size 256
2019-01-24 02:37:40.436163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fbb00 of size 256
2019-01-24 02:37:40.436166: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fbc00 of size 256
2019-01-24 02:37:40.436170: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fbd00 of size 256
2019-01-24 02:37:40.436173: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fbe00 of size 256
2019-01-24 02:37:40.436177: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fbf00 of size 256
2019-01-24 02:37:40.436180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc000 of size 256
2019-01-24 02:37:40.436184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc100 of size 256
2019-01-24 02:37:40.436187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc200 of size 256
2019-01-24 02:37:40.436191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc300 of size 256
2019-01-24 02:37:40.436194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc400 of size 256
2019-01-24 02:37:40.436197: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc500 of size 256
2019-01-24 02:37:40.436201: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc600 of size 256
2019-01-24 02:37:40.436204: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc700 of size 256
2019-01-24 02:37:40.436208: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc800 of size 256
2019-01-24 02:37:40.436211: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fc900 of size 256
2019-01-24 02:37:40.436215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fca00 of size 256
2019-01-24 02:37:40.436218: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fcb00 of size 256
2019-01-24 02:37:40.436222: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fcc00 of size 256
2019-01-24 02:37:40.436225: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fcd00 of size 256
2019-01-24 02:37:40.436229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fce00 of size 256
2019-01-24 02:37:40.436232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fcf00 of size 2816
2019-01-24 02:37:40.436236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fda00 of size 2816
2019-01-24 02:37:40.436239: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129fe500 of size 2816
2019-01-24 02:37:40.436243: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ff000 of size 2816
2019-01-24 02:37:40.436246: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb129ffb00 of size 2816
2019-01-24 02:37:40.436250: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a00600 of size 2816
2019-01-24 02:37:40.436253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a01100 of size 2816
2019-01-24 02:37:40.436257: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a01c00 of size 2816
2019-01-24 02:37:40.436260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a02700 of size 2816
2019-01-24 02:37:40.436264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a03200 of size 2816
2019-01-24 02:37:40.436267: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a03d00 of size 2816
2019-01-24 02:37:40.436271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a04800 of size 2816
2019-01-24 02:37:40.436274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a05300 of size 2816
2019-01-24 02:37:40.436278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a05e00 of size 2816
2019-01-24 02:37:40.436281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a06900 of size 2816
2019-01-24 02:37:40.436285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a07400 of size 2816
2019-01-24 02:37:40.436288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a07f00 of size 2816
2019-01-24 02:37:40.436292: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a08a00 of size 2816
2019-01-24 02:37:40.436295: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a09500 of size 2816
2019-01-24 02:37:40.436299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0a000 of size 2816
2019-01-24 02:37:40.436302: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0ab00 of size 2816
2019-01-24 02:37:40.436306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0b600 of size 2816
2019-01-24 02:37:40.436309: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0c100 of size 2816
2019-01-24 02:37:40.436313: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0cc00 of size 2816
2019-01-24 02:37:40.436316: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0d700 of size 2816
2019-01-24 02:37:40.436320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0e200 of size 2816
2019-01-24 02:37:40.436323: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0ed00 of size 2816
2019-01-24 02:37:40.436327: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a0f800 of size 2816
2019-01-24 02:37:40.436330: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a10300 of size 2816
2019-01-24 02:37:40.436334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a10e00 of size 2816
2019-01-24 02:37:40.436337: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a11900 of size 2816
2019-01-24 02:37:40.436341: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a12400 of size 2816
2019-01-24 02:37:40.436344: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a12f00 of size 2816
2019-01-24 02:37:40.436348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a13a00 of size 2816
2019-01-24 02:37:40.436351: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a14500 of size 2816
2019-01-24 02:37:40.436355: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a15000 of size 2816
2019-01-24 02:37:40.436358: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a15b00 of size 2816
2019-01-24 02:37:40.436362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a16600 of size 2816
2019-01-24 02:37:40.436365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a17100 of size 2816
2019-01-24 02:37:40.436369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a17c00 of size 2816
2019-01-24 02:37:40.436372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a18700 of size 2816
2019-01-24 02:37:40.436376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a19200 of size 2816
2019-01-24 02:37:40.436382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a19d00 of size 2816
2019-01-24 02:37:40.436387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1a800 of size 2816
2019-01-24 02:37:40.436392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1b300 of size 2816
2019-01-24 02:37:40.436397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1be00 of size 2816
2019-01-24 02:37:40.436403: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1c900 of size 2816
2019-01-24 02:37:40.436409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1d400 of size 2816
2019-01-24 02:37:40.436414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1df00 of size 2816
2019-01-24 02:37:40.436420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1ea00 of size 2816
2019-01-24 02:37:40.436423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a1f500 of size 2816
2019-01-24 02:37:40.436427: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a20000 of size 2816
2019-01-24 02:37:40.436430: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a20b00 of size 2816
2019-01-24 02:37:40.436434: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a21600 of size 2816
2019-01-24 02:37:40.436437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a22100 of size 2816
2019-01-24 02:37:40.436441: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a22c00 of size 2816
2019-01-24 02:37:40.436444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a23700 of size 2816
2019-01-24 02:37:40.436448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a24200 of size 2816
2019-01-24 02:37:40.436451: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a24d00 of size 2816
2019-01-24 02:37:40.436455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a25800 of size 2816
2019-01-24 02:37:40.436458: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a26300 of size 2816
2019-01-24 02:37:40.436462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a26e00 of size 2816
2019-01-24 02:37:40.436465: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a27900 of size 2816
2019-01-24 02:37:40.436469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a28400 of size 2816
2019-01-24 02:37:40.436472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a28f00 of size 2816
2019-01-24 02:37:40.436476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a29a00 of size 2816
2019-01-24 02:37:40.436479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2a500 of size 2816
2019-01-24 02:37:40.436483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2b000 of size 2816
2019-01-24 02:37:40.436486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2bb00 of size 2816
2019-01-24 02:37:40.436490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2c600 of size 2816
2019-01-24 02:37:40.436493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2d100 of size 2816
2019-01-24 02:37:40.436497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2dc00 of size 2816
2019-01-24 02:37:40.436500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2e700 of size 2816
2019-01-24 02:37:40.436503: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2f200 of size 2816
2019-01-24 02:37:40.436507: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a2fd00 of size 2816
2019-01-24 02:37:40.446633: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a30800 of size 2816
2019-01-24 02:37:40.446643: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a31300 of size 2816
2019-01-24 02:37:40.446646: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a31e00 of size 2816
2019-01-24 02:37:40.446649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a32900 of size 2816
2019-01-24 02:37:40.446652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a33400 of size 2816
2019-01-24 02:37:40.446655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a33f00 of size 2816
2019-01-24 02:37:40.446659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a34a00 of size 2816
2019-01-24 02:37:40.446662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a35500 of size 2816
2019-01-24 02:37:40.446666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a36000 of size 2816
2019-01-24 02:37:40.446669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a36b00 of size 2816
2019-01-24 02:37:40.446672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a37600 of size 256
2019-01-24 02:37:40.446676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a37700 of size 2816
2019-01-24 02:37:40.446679: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a38200 of size 2816
2019-01-24 02:37:40.446682: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a38d00 of size 256
2019-01-24 02:37:40.446686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a38e00 of size 256
2019-01-24 02:37:40.446689: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a38f00 of size 2816
2019-01-24 02:37:40.446692: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a39a00 of size 256
2019-01-24 02:37:40.446696: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a39b00 of size 256
2019-01-24 02:37:40.446699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a39c00 of size 256
2019-01-24 02:37:40.446702: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a39d00 of size 2816
2019-01-24 02:37:40.446705: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3a800 of size 256
2019-01-24 02:37:40.446709: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3a900 of size 2816
2019-01-24 02:37:40.446712: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3b400 of size 2816
2019-01-24 02:37:40.446716: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3bf00 of size 256
2019-01-24 02:37:40.446719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3c000 of size 2816
2019-01-24 02:37:40.446723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3cb00 of size 256
2019-01-24 02:37:40.446726: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3cc00 of size 256
2019-01-24 02:37:40.446730: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3cd00 of size 2816
2019-01-24 02:37:40.446733: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3d800 of size 256
2019-01-24 02:37:40.446737: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3d900 of size 256
2019-01-24 02:37:40.446740: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3da00 of size 256
2019-01-24 02:37:40.446744: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3db00 of size 2816
2019-01-24 02:37:40.446747: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3e600 of size 256
2019-01-24 02:37:40.446751: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3e700 of size 256
2019-01-24 02:37:40.446754: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3e800 of size 256
2019-01-24 02:37:40.446758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3e900 of size 256
2019-01-24 02:37:40.446761: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3ea00 of size 256
2019-01-24 02:37:40.446765: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3eb00 of size 2816
2019-01-24 02:37:40.446768: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3f600 of size 256
2019-01-24 02:37:40.446772: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3f700 of size 256
2019-01-24 02:37:40.446775: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3f800 of size 256
2019-01-24 02:37:40.446779: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a3f900 of size 2816
2019-01-24 02:37:40.446782: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a40400 of size 256
2019-01-24 02:37:40.446786: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a40500 of size 2816
2019-01-24 02:37:40.446789: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a41000 of size 256
2019-01-24 02:37:40.446793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a41100 of size 256
2019-01-24 02:37:40.446799: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a41200 of size 256
2019-01-24 02:37:40.446802: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a41300 of size 256
2019-01-24 02:37:40.446806: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a41400 of size 2816
2019-01-24 02:37:40.446809: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a41f00 of size 256
2019-01-24 02:37:40.446812: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a42000 of size 256
2019-01-24 02:37:40.446816: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a42100 of size 256
2019-01-24 02:37:40.446819: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a42200 of size 256
2019-01-24 02:37:40.446823: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a42300 of size 256
2019-01-24 02:37:40.446826: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a42400 of size 2816
2019-01-24 02:37:40.446830: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a42f00 of size 256
2019-01-24 02:37:40.446833: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a43000 of size 256
2019-01-24 02:37:40.446837: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a43100 of size 256
2019-01-24 02:37:40.446840: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a43200 of size 2816
2019-01-24 02:37:40.446844: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a43d00 of size 256
2019-01-24 02:37:40.446847: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a43e00 of size 2816
2019-01-24 02:37:40.446851: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a44900 of size 256
2019-01-24 02:37:40.446854: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a44a00 of size 256
2019-01-24 02:37:40.446858: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a44b00 of size 256
2019-01-24 02:37:40.446861: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a44c00 of size 256
2019-01-24 02:37:40.446865: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a44d00 of size 256
2019-01-24 02:37:40.446868: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a44e00 of size 2816
2019-01-24 02:37:40.446872: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a45900 of size 256
2019-01-24 02:37:40.446875: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a45a00 of size 256
2019-01-24 02:37:40.446879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a45b00 of size 256
2019-01-24 02:37:40.446882: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a45c00 of size 256
2019-01-24 02:37:40.446886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a45d00 of size 256
2019-01-24 02:37:40.446889: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a45e00 of size 2816
2019-01-24 02:37:40.446893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a46900 of size 256
2019-01-24 02:37:40.446896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a46a00 of size 256
2019-01-24 02:37:40.446899: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a46b00 of size 256
2019-01-24 02:37:40.446903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a46c00 of size 2816
2019-01-24 02:37:40.446906: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a47700 of size 256
2019-01-24 02:37:40.446910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a47800 of size 2816
2019-01-24 02:37:40.446913: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a48300 of size 256
2019-01-24 02:37:40.446917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a48400 of size 256
2019-01-24 02:37:40.446920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a48500 of size 256
2019-01-24 02:37:40.446924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a48600 of size 256
2019-01-24 02:37:40.446927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a48700 of size 2816
2019-01-24 02:37:40.446931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a49200 of size 256
2019-01-24 02:37:40.446934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a49300 of size 256
2019-01-24 02:37:40.446938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a49400 of size 256
2019-01-24 02:37:40.446941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a49500 of size 256
2019-01-24 02:37:40.446944: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a49600 of size 256
2019-01-24 02:37:40.446948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a49700 of size 2816
2019-01-24 02:37:40.446951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4a200 of size 256
2019-01-24 02:37:40.446955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4a300 of size 256
2019-01-24 02:37:40.446958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4a400 of size 256
2019-01-24 02:37:40.446962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4a500 of size 2816
2019-01-24 02:37:40.446965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4b000 of size 256
2019-01-24 02:37:40.446969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4b100 of size 2816
2019-01-24 02:37:40.446972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4bc00 of size 256
2019-01-24 02:37:40.446976: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4bd00 of size 256
2019-01-24 02:37:40.446979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4be00 of size 256
2019-01-24 02:37:40.446982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4bf00 of size 256
2019-01-24 02:37:40.446986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4c000 of size 2816
2019-01-24 02:37:40.446989: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4cb00 of size 256
2019-01-24 02:37:40.446993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4cc00 of size 256
2019-01-24 02:37:40.446996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4cd00 of size 256
2019-01-24 02:37:40.447000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4ce00 of size 256
2019-01-24 02:37:40.447003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4cf00 of size 256
2019-01-24 02:37:40.447006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4d000 of size 2816
2019-01-24 02:37:40.447010: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4db00 of size 256
2019-01-24 02:37:40.447013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4dc00 of size 256
2019-01-24 02:37:40.447016: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4dd00 of size 256
2019-01-24 02:37:40.447020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4de00 of size 2816
2019-01-24 02:37:40.447023: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4e900 of size 256
2019-01-24 02:37:40.447027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4ea00 of size 2816
2019-01-24 02:37:40.447030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4f500 of size 256
2019-01-24 02:37:40.447034: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4f600 of size 256
2019-01-24 02:37:40.447037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4f700 of size 256
2019-01-24 02:37:40.447041: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4f800 of size 256
2019-01-24 02:37:40.447044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a4f900 of size 2816
2019-01-24 02:37:40.447047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a50400 of size 256
2019-01-24 02:37:40.447051: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a50500 of size 256
2019-01-24 02:37:40.447054: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a50600 of size 256
2019-01-24 02:37:40.447058: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a50700 of size 256
2019-01-24 02:37:40.447061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a50800 of size 256
2019-01-24 02:37:40.447065: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a50900 of size 2816
2019-01-24 02:37:40.447068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a51400 of size 768
2019-01-24 02:37:40.447072: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a51700 of size 768
2019-01-24 02:37:40.447075: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a51a00 of size 768
2019-01-24 02:37:40.447078: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a51d00 of size 768
2019-01-24 02:37:40.447082: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a52000 of size 768
2019-01-24 02:37:40.447085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a52300 of size 768
2019-01-24 02:37:40.447089: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a52600 of size 2816
2019-01-24 02:37:40.447092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a53100 of size 16896
2019-01-24 02:37:40.447096: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a57300 of size 16896
2019-01-24 02:37:40.447099: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a5b500 of size 16896
2019-01-24 02:37:40.447103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a5f700 of size 16896
2019-01-24 02:37:40.447106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a63900 of size 16896
2019-01-24 02:37:40.447110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a67b00 of size 16896
2019-01-24 02:37:40.447113: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a6bd00 of size 16896
2019-01-24 02:37:40.447117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a6ff00 of size 16896
2019-01-24 02:37:40.447120: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a74100 of size 16896
2019-01-24 02:37:40.447123: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a78300 of size 16896
2019-01-24 02:37:40.447127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a7c500 of size 16896
2019-01-24 02:37:40.447130: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a80700 of size 16896
2019-01-24 02:37:40.447134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a84900 of size 16896
2019-01-24 02:37:40.447137: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a88b00 of size 16896
2019-01-24 02:37:40.447141: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a8cd00 of size 16896
2019-01-24 02:37:40.447144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a90f00 of size 16896
2019-01-24 02:37:40.447147: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a95100 of size 16896
2019-01-24 02:37:40.447151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a99300 of size 16896
2019-01-24 02:37:40.447154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12a9d500 of size 16896
2019-01-24 02:37:40.447158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12aa1700 of size 16896
2019-01-24 02:37:40.447161: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12aa5900 of size 16896
2019-01-24 02:37:40.447165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12aa9b00 of size 16896
2019-01-24 02:37:40.447168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12aadd00 of size 16896
2019-01-24 02:37:40.447172: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12ab1f00 of size 12979
2
2019-01-24 02:37:40.447176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12ad1a00 of size 11289
6
2019-01-24 02:37:40.447179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12aed300 of size 11289
6
2019-01-24 02:37:40.447183: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12b08c00 of size 11289
6
2019-01-24 02:37:40.447186: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12b24500 of size 11289
6
2019-01-24 02:37:40.447190: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12b3fe00 of size 11289
6
2019-01-24 02:37:40.447193: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12b5b700 of size 11289
6
2019-01-24 02:37:40.447197: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12b77000 of size 11289
6
2019-01-24 02:37:40.447200: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12b92900 of size 11289
6
2019-01-24 02:37:40.447204: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12bae200 of size 11289
6
2019-01-24 02:37:40.447207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12bc9b00 of size 11289
6
2019-01-24 02:37:40.447211: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12be5400 of size 11289
6
2019-01-24 02:37:40.447214: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12c00d00 of size 11289
6
2019-01-24 02:37:40.447217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12c1c600 of size 11289
6
2019-01-24 02:37:40.447221: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12c37f00 of size 11289
6
2019-01-24 02:37:40.447224: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12c53800 of size 11289
6
2019-01-24 02:37:40.447228: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12c6f100 of size 11289
6
2019-01-24 02:37:40.447231: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12c8aa00 of size 11289
6
2019-01-24 02:37:40.447235: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12ca6300 of size 11289
6
2019-01-24 02:37:40.447238: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12cc1c00 of size 11289
6
2019-01-24 02:37:40.447241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12cdd500 of size 11289
6
2019-01-24 02:37:40.447245: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12cf8e00 of size 11289
6
2019-01-24 02:37:40.452488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12d14700 of size 11289
6
2019-01-24 02:37:40.452497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12d30000 of size 11289
6
2019-01-24 02:37:40.452501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12d4b900 of size 11289
6
2019-01-24 02:37:40.452505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12d67200 of size 11289
6
2019-01-24 02:37:40.452508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12d82b00 of size 11289
6
2019-01-24 02:37:40.452512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12d9e400 of size 11289
6
2019-01-24 02:37:40.452515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12db9d00 of size 11289
6
2019-01-24 02:37:40.452519: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12dd5600 of size 11289
6
2019-01-24 02:37:40.452523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12df0f00 of size 11289
6
2019-01-24 02:37:40.452526: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12e0c800 of size 11289
6
2019-01-24 02:37:40.452530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12e28100 of size 11289
6
2019-01-24 02:37:40.452533: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12e43a00 of size 11289
6
2019-01-24 02:37:40.452537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12e5f300 of size 11289
6
2019-01-24 02:37:40.452540: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12e7ac00 of size 11289
6
2019-01-24 02:37:40.452544: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12e96500 of size 11289
6
2019-01-24 02:37:40.452547: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12eb1e00 of size 11289
6
2019-01-24 02:37:40.452551: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12ecd700 of size 11289
6
2019-01-24 02:37:40.452555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12ee9000 of size 11289
6
2019-01-24 02:37:40.452559: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12f04900 of size 11289
6
2019-01-24 02:37:40.452562: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12f20200 of size 11289
6
2019-01-24 02:37:40.452566: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12f3bb00 of size 11289
6
2019-01-24 02:37:40.452569: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12f57400 of size 11289
6
2019-01-24 02:37:40.452573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12f72d00 of size 11289
6
2019-01-24 02:37:40.452576: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12f8e600 of size 11289
6
2019-01-24 02:37:40.452579: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12fa9f00 of size 11289
6
2019-01-24 02:37:40.452583: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12fc5800 of size 11289
6
2019-01-24 02:37:40.452586: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12fe1100 of size 11289
6
2019-01-24 02:37:40.452590: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb12ffca00 of size 11289
6
2019-01-24 02:37:40.452593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13018300 of size 11289
6
2019-01-24 02:37:40.452597: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13033c00 of size 11289
6
2019-01-24 02:37:40.452600: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1304f500 of size 11289
6
2019-01-24 02:37:40.452603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1306ae00 of size 11289
6
2019-01-24 02:37:40.452607: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13086700 of size 11289
6
2019-01-24 02:37:40.452610: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb130a2000 of size 11289
6
2019-01-24 02:37:40.452614: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb130bd900 of size 11289
6
2019-01-24 02:37:40.452617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb130d9200 of size 11289
6
2019-01-24 02:37:40.452621: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb130f4b00 of size 11289
6
2019-01-24 02:37:40.452624: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13110400 of size 11289
6
2019-01-24 02:37:40.452628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312bd00 of size 768
2019-01-24 02:37:40.452631: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312c000 of size 768
2019-01-24 02:37:40.452635: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312c300 of size 2816
2019-01-24 02:37:40.452638: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312ce00 of size 768
2019-01-24 02:37:40.452642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312d100 of size 768
2019-01-24 02:37:40.452645: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312d400 of size 768
2019-01-24 02:37:40.452649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312d700 of size 2816
2019-01-24 02:37:40.452652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312e200 of size 768
2019-01-24 02:37:40.452656: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312e500 of size 2816
2019-01-24 02:37:40.452659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312f000 of size 2816
2019-01-24 02:37:40.452662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1312fb00 of size 2816
2019-01-24 02:37:40.452666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13130600 of size 768
2019-01-24 02:37:40.452669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13130900 of size 2816
2019-01-24 02:37:40.452673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13131400 of size 768
2019-01-24 02:37:40.452676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13131700 of size 768
2019-01-24 02:37:40.452680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13131a00 of size 2816
2019-01-24 02:37:40.452683: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13132500 of size 768
2019-01-24 02:37:40.452686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13132800 of size 768
2019-01-24 02:37:40.452690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13132b00 of size 768
2019-01-24 02:37:40.452693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13132e00 of size 6144
2019-01-24 02:37:40.452697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13134600 of size 6144
2019-01-24 02:37:40.452700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13135e00 of size 6144
2019-01-24 02:37:40.452704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13137600 of size 6144
2019-01-24 02:37:40.452707: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13138e00 of size 6144
2019-01-24 02:37:40.452711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1313a600 of size 6144
2019-01-24 02:37:40.452714: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1313be00 of size 6144
2019-01-24 02:37:40.452718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1313d600 of size 6144
2019-01-24 02:37:40.452721: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1313ee00 of size 6144
2019-01-24 02:37:40.452724: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13140600 of size 6144
2019-01-24 02:37:40.452728: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13141e00 of size 6144
2019-01-24 02:37:40.452731: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13143600 of size 6144
2019-01-24 02:37:40.452735: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13144e00 of size 6144
2019-01-24 02:37:40.452738: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13146600 of size 6144
2019-01-24 02:37:40.452742: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13147e00 of size 6144
2019-01-24 02:37:40.452745: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13149600 of size 6144
2019-01-24 02:37:40.452749: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1314ae00 of size 6144
2019-01-24 02:37:40.452752: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1314c600 of size 6144
2019-01-24 02:37:40.452756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1314de00 of size 6144
2019-01-24 02:37:40.452759: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1314f600 of size 6144
2019-01-24 02:37:40.452762: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13150e00 of size 6144
2019-01-24 02:37:40.452766: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13152600 of size 6144
2019-01-24 02:37:40.452769: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13153e00 of size 6144
2019-01-24 02:37:40.452773: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13155600 of size 6144
2019-01-24 02:37:40.452776: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13156e00 of size 6144
2019-01-24 02:37:40.452780: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13158600 of size 6144
2019-01-24 02:37:40.452783: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13159e00 of size 6144
2019-01-24 02:37:40.452787: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1315b600 of size 6144
2019-01-24 02:37:40.452790: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1315ce00 of size 6144
2019-01-24 02:37:40.452794: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1315e600 of size 6144
2019-01-24 02:37:40.452797: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1315fe00 of size 6144
2019-01-24 02:37:40.452801: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13161600 of size 6144
2019-01-24 02:37:40.452804: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13162e00 of size 6144
2019-01-24 02:37:40.452808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13164600 of size 6144
2019-01-24 02:37:40.452811: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13165e00 of size 6144
2019-01-24 02:37:40.452814: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13167600 of size 6144
2019-01-24 02:37:40.452818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13168e00 of size 2816
2019-01-24 02:37:40.452821: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13169900 of size 768
2019-01-24 02:37:40.452825: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13169c00 of size 768
2019-01-24 02:37:40.452828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13169f00 of size 768
2019-01-24 02:37:40.452832: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316a200 of size 768
2019-01-24 02:37:40.452835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316a500 of size 768
2019-01-24 02:37:40.452839: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316a800 of size 768
2019-01-24 02:37:40.452842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316ab00 of size 2816
2019-01-24 02:37:40.452846: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316b600 of size 2816
2019-01-24 02:37:40.452849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316c100 of size 768
2019-01-24 02:37:40.452853: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316c400 of size 768
2019-01-24 02:37:40.452856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316c700 of size 768
2019-01-24 02:37:40.452860: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316ca00 of size 2816
2019-01-24 02:37:40.452863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316d500 of size 768
2019-01-24 02:37:40.452867: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316d800 of size 2816
2019-01-24 02:37:40.452870: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316e300 of size 768
2019-01-24 02:37:40.452874: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316e600 of size 2816
2019-01-24 02:37:40.452877: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316f100 of size 768
2019-01-24 02:37:40.452881: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316f400 of size 2816
2019-01-24 02:37:40.452884: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1316ff00 of size 2816
2019-01-24 02:37:40.452888: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13170a00 of size 768
2019-01-24 02:37:40.452891: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13170d00 of size 768
2019-01-24 02:37:40.452895: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13171000 of size 768
2019-01-24 02:37:40.452898: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13171300 of size 768
2019-01-24 02:37:40.452902: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13171600 of size 2816
2019-01-24 02:37:40.452905: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13172100 of size 768
2019-01-24 02:37:40.452908: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13172400 of size 768
2019-01-24 02:37:40.452912: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13172700 of size 2816
2019-01-24 02:37:40.452915: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13173200 of size 13184
0
2019-01-24 02:37:40.452919: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13193500 of size 13184
0
2019-01-24 02:37:40.452922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131b3800 of size 13184
0
2019-01-24 02:37:40.452926: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131d3b00 of size 56576
2019-01-24 02:37:40.452930: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e1800 of size 512
2019-01-24 02:37:40.452934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e1a00 of size 256
2019-01-24 02:37:40.452937: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e1b00 of size 512
2019-01-24 02:37:40.452941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e1d00 of size 256
2019-01-24 02:37:40.452944: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e1e00 of size 256
2019-01-24 02:37:40.452948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e1f00 of size 512
2019-01-24 02:37:40.452951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2100 of size 256
2019-01-24 02:37:40.452955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2200 of size 256
2019-01-24 02:37:40.452958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2300 of size 512
2019-01-24 02:37:40.452961: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2500 of size 256
2019-01-24 02:37:40.452965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2600 of size 512
2019-01-24 02:37:40.452968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2800 of size 256
2019-01-24 02:37:40.452972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2900 of size 768
2019-01-24 02:37:40.452975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2c00 of size 256
2019-01-24 02:37:40.452979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e2d00 of size 768
2019-01-24 02:37:40.452982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3000 of size 256
2019-01-24 02:37:40.452986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3100 of size 256
2019-01-24 02:37:40.452989: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3200 of size 768
2019-01-24 02:37:40.452993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3500 of size 256
2019-01-24 02:37:40.452996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3600 of size 768
2019-01-24 02:37:40.453000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3900 of size 256
2019-01-24 02:37:40.453003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3a00 of size 768
2019-01-24 02:37:40.453007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3d00 of size 256
2019-01-24 02:37:40.453011: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3e00 of size 256
2019-01-24 02:37:40.453014: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e3f00 of size 768
2019-01-24 02:37:40.453018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4200 of size 256
2019-01-24 02:37:40.453021: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4300 of size 768
2019-01-24 02:37:40.453025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4600 of size 256
2019-01-24 02:37:40.453028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4700 of size 256
2019-01-24 02:37:40.453031: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4800 of size 768
2019-01-24 02:37:40.453035: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4b00 of size 256
2019-01-24 02:37:40.453038: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4c00 of size 256
2019-01-24 02:37:40.453042: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e4d00 of size 768
2019-01-24 02:37:40.453045: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5000 of size 256
2019-01-24 02:37:40.453049: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5100 of size 768
2019-01-24 02:37:40.453052: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5400 of size 256
2019-01-24 02:37:40.453056: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5500 of size 768
2019-01-24 02:37:40.453059: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5800 of size 256
2019-01-24 02:37:40.453063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5900 of size 256
2019-01-24 02:37:40.453066: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5a00 of size 768
2019-01-24 02:37:40.453070: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5d00 of size 256
2019-01-24 02:37:40.453073: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e5e00 of size 768
2019-01-24 02:37:40.453077: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6100 of size 256
2019-01-24 02:37:40.453080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6200 of size 768
2019-01-24 02:37:40.453084: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6500 of size 256
2019-01-24 02:37:40.453087: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6600 of size 256
2019-01-24 02:37:40.453091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6700 of size 768
2019-01-24 02:37:40.453094: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6a00 of size 256
2019-01-24 02:37:40.453097: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6b00 of size 768
2019-01-24 02:37:40.453101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6e00 of size 256
2019-01-24 02:37:40.453104: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e6f00 of size 256
2019-01-24 02:37:40.453108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7000 of size 768
2019-01-24 02:37:40.453111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7300 of size 256
2019-01-24 02:37:40.453115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7400 of size 256
2019-01-24 02:37:40.453118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7500 of size 768
2019-01-24 02:37:40.460446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7800 of size 256
2019-01-24 02:37:40.460455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7900 of size 768
2019-01-24 02:37:40.460458: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7c00 of size 256
2019-01-24 02:37:40.460461: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e7d00 of size 768
2019-01-24 02:37:40.460464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8000 of size 256
2019-01-24 02:37:40.460467: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8100 of size 256
2019-01-24 02:37:40.460470: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8200 of size 768
2019-01-24 02:37:40.460473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8500 of size 256
2019-01-24 02:37:40.460477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8600 of size 768
2019-01-24 02:37:40.460480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8900 of size 256
2019-01-24 02:37:40.460483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8a00 of size 768
2019-01-24 02:37:40.460487: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8d00 of size 256
2019-01-24 02:37:40.460490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8e00 of size 256
2019-01-24 02:37:40.460494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e8f00 of size 768
2019-01-24 02:37:40.460497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9200 of size 256
2019-01-24 02:37:40.460501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9300 of size 768
2019-01-24 02:37:40.460504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9600 of size 256
2019-01-24 02:37:40.460508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9700 of size 256
2019-01-24 02:37:40.460511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9800 of size 768
2019-01-24 02:37:40.460515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9b00 of size 256
2019-01-24 02:37:40.460518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9c00 of size 256
2019-01-24 02:37:40.460522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131e9d00 of size 768
2019-01-24 02:37:40.460525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ea000 of size 256
2019-01-24 02:37:40.460529: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ea100 of size 768
2019-01-24 02:37:40.460532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ea400 of size 256
2019-01-24 02:37:40.460536: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ea500 of size 768
2019-01-24 02:37:40.460539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ea800 of size 256
2019-01-24 02:37:40.460543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ea900 of size 256
2019-01-24 02:37:40.460546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eaa00 of size 768
2019-01-24 02:37:40.460550: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ead00 of size 256
2019-01-24 02:37:40.460553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eae00 of size 768
2019-01-24 02:37:40.460557: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eb100 of size 256
2019-01-24 02:37:40.460560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eb200 of size 768
2019-01-24 02:37:40.460564: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eb500 of size 256
2019-01-24 02:37:40.460567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eb600 of size 256
2019-01-24 02:37:40.460571: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eb700 of size 768
2019-01-24 02:37:40.460574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eba00 of size 256
2019-01-24 02:37:40.460578: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ebb00 of size 768
2019-01-24 02:37:40.460581: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ebe00 of size 256
2019-01-24 02:37:40.460585: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ebf00 of size 256
2019-01-24 02:37:40.460588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ec000 of size 768
2019-01-24 02:37:40.460592: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ec300 of size 256
2019-01-24 02:37:40.460595: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ec400 of size 256
2019-01-24 02:37:40.460599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ec500 of size 2048
2019-01-24 02:37:40.460602: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ecd00 of size 768
2019-01-24 02:37:40.460606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ed000 of size 256
2019-01-24 02:37:40.460609: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ed100 of size 768
2019-01-24 02:37:40.460613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ed400 of size 256
2019-01-24 02:37:40.460616: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ed500 of size 768
2019-01-24 02:37:40.460620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ed800 of size 256
2019-01-24 02:37:40.460623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ed900 of size 256
2019-01-24 02:37:40.460627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eda00 of size 768
2019-01-24 02:37:40.460630: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131edd00 of size 256
2019-01-24 02:37:40.460634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ede00 of size 768
2019-01-24 02:37:40.460637: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ee100 of size 256
2019-01-24 02:37:40.460641: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ee200 of size 768
2019-01-24 02:37:40.460644: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ee500 of size 256
2019-01-24 02:37:40.460648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ee600 of size 256
2019-01-24 02:37:40.460651: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ee700 of size 768
2019-01-24 02:37:40.460654: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eea00 of size 256
2019-01-24 02:37:40.460658: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eeb00 of size 768
2019-01-24 02:37:40.460661: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eee00 of size 256
2019-01-24 02:37:40.460665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131eef00 of size 256
2019-01-24 02:37:40.460668: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ef000 of size 768
2019-01-24 02:37:40.460672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ef300 of size 256
2019-01-24 02:37:40.460675: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ef400 of size 256
2019-01-24 02:37:40.460679: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ef500 of size 768
2019-01-24 02:37:40.460682: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ef800 of size 256
2019-01-24 02:37:40.460686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ef900 of size 768
2019-01-24 02:37:40.460689: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131efc00 of size 256
2019-01-24 02:37:40.460693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131efd00 of size 768
2019-01-24 02:37:40.460696: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0000 of size 256
2019-01-24 02:37:40.460700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0100 of size 256
2019-01-24 02:37:40.460703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0200 of size 768
2019-01-24 02:37:40.460707: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0500 of size 256
2019-01-24 02:37:40.460710: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0600 of size 768
2019-01-24 02:37:40.460713: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0900 of size 256
2019-01-24 02:37:40.460717: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0a00 of size 256
2019-01-24 02:37:40.460720: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0b00 of size 256
2019-01-24 02:37:40.460724: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0c00 of size 256
2019-01-24 02:37:40.460727: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0d00 of size 256
2019-01-24 02:37:40.460731: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0e00 of size 256
2019-01-24 02:37:40.460734: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f0f00 of size 256
2019-01-24 02:37:40.460738: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1000 of size 768
2019-01-24 02:37:40.460741: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1300 of size 256
2019-01-24 02:37:40.460744: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1400 of size 256
2019-01-24 02:37:40.460747: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1500 of size 768
2019-01-24 02:37:40.460751: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1800 of size 256
2019-01-24 02:37:40.460754: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1900 of size 768
2019-01-24 02:37:40.460758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1c00 of size 256
2019-01-24 02:37:40.460761: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1d00 of size 256
2019-01-24 02:37:40.460764: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f1e00 of size 768
2019-01-24 02:37:40.460768: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2100 of size 256
2019-01-24 02:37:40.460771: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2200 of size 256
2019-01-24 02:37:40.460775: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2300 of size 768
2019-01-24 02:37:40.460778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2600 of size 256
2019-01-24 02:37:40.460781: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2700 of size 768
2019-01-24 02:37:40.460785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2a00 of size 256
2019-01-24 02:37:40.460788: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2b00 of size 768
2019-01-24 02:37:40.460792: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2e00 of size 256
2019-01-24 02:37:40.460795: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f2f00 of size 256
2019-01-24 02:37:40.460798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3000 of size 768
2019-01-24 02:37:40.460802: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3300 of size 256
2019-01-24 02:37:40.460805: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3400 of size 768
2019-01-24 02:37:40.460809: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3700 of size 256
2019-01-24 02:37:40.460812: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3800 of size 768
2019-01-24 02:37:40.460816: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3b00 of size 256
2019-01-24 02:37:40.460819: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3c00 of size 256
2019-01-24 02:37:40.460822: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3d00 of size 256
2019-01-24 02:37:40.460826: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f3e00 of size 768
2019-01-24 02:37:40.460829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f4100 of size 2816
2019-01-24 02:37:40.460833: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f4c00 of size 2816
2019-01-24 02:37:40.460836: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f5700 of size 2816
2019-01-24 02:37:40.460840: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f6200 of size 2816
2019-01-24 02:37:40.460843: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f6d00 of size 2816
2019-01-24 02:37:40.460846: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f7800 of size 2816
2019-01-24 02:37:40.460850: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f8300 of size 2816
2019-01-24 02:37:40.460853: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f8e00 of size 2816
2019-01-24 02:37:40.460859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131f9900 of size 2816
2019-01-24 02:37:40.460863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131fa400 of size 2816
2019-01-24 02:37:40.460866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131faf00 of size 2816
2019-01-24 02:37:40.460870: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131fba00 of size 2816
2019-01-24 02:37:40.460873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131fc500 of size 2816
2019-01-24 02:37:40.460877: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131fd000 of size 2816
2019-01-24 02:37:40.460880: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131fdb00 of size 2816
2019-01-24 02:37:40.460884: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131fe600 of size 2816
2019-01-24 02:37:40.460887: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ff100 of size 2816
2019-01-24 02:37:40.460891: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb131ffc00 of size 2816
2019-01-24 02:37:40.460894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13200700 of size 2816
2019-01-24 02:37:40.460897: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13201200 of size 2816
2019-01-24 02:37:40.460901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13201d00 of size 2816
2019-01-24 02:37:40.460904: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13202800 of size 2816
2019-01-24 02:37:40.460908: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13203300 of size 2816
2019-01-24 02:37:40.460911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13203e00 of size 2816
2019-01-24 02:37:40.460915: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13204900 of size 2816
2019-01-24 02:37:40.460918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13205400 of size 2816
2019-01-24 02:37:40.460922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13205f00 of size 2816
2019-01-24 02:37:40.460925: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13206a00 of size 2816
2019-01-24 02:37:40.460929: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13207500 of size 2816
2019-01-24 02:37:40.460932: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13208000 of size 2816
2019-01-24 02:37:40.460935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13208b00 of size 2816
2019-01-24 02:37:40.460939: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13209600 of size 2816
2019-01-24 02:37:40.460942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320a100 of size 2816
2019-01-24 02:37:40.460946: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320ac00 of size 2816
2019-01-24 02:37:40.460949: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320b700 of size 2816
2019-01-24 02:37:40.460953: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320c200 of size 2816
2019-01-24 02:37:40.460956: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320cd00 of size 2816
2019-01-24 02:37:40.460960: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320d800 of size 2816
2019-01-24 02:37:40.460963: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320e300 of size 2816
2019-01-24 02:37:40.460967: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320ee00 of size 2816
2019-01-24 02:37:40.460970: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1320f900 of size 2816
2019-01-24 02:37:40.460973: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13210400 of size 2816
2019-01-24 02:37:40.460977: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13210f00 of size 2816
2019-01-24 02:37:40.460980: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13211a00 of size 2816
2019-01-24 02:37:40.460983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13212500 of size 2816
2019-01-24 02:37:40.460987: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13213000 of size 2816
2019-01-24 02:37:40.460990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13213b00 of size 2816
2019-01-24 02:37:40.460994: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13214600 of size 2816
2019-01-24 02:37:40.460997: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13215100 of size 2816
2019-01-24 02:37:40.461001: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13215c00 of size 2816
2019-01-24 02:37:40.461004: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13216700 of size 2816
2019-01-24 02:37:40.461008: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13217200 of size 2816
2019-01-24 02:37:40.461011: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13217d00 of size 2816
2019-01-24 02:37:40.461015: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13218800 of size 66048
2019-01-24 02:37:40.461018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13228a00 of size 66048
2019-01-24 02:37:40.461022: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13238c00 of size 66048
2019-01-24 02:37:40.461026: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13248e00 of size 18944
2019-01-24 02:37:40.461029: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1324d800 of size 47104
2019-01-24 02:37:40.461033: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13259000 of size 2816
2019-01-24 02:37:40.461036: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13259b00 of size 2816
2019-01-24 02:37:40.461040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325a600 of size 2816
2019-01-24 02:37:40.461043: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325b100 of size 2816
2019-01-24 02:37:40.461047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325bc00 of size 2816
2019-01-24 02:37:40.461050: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325c700 of size 2816
2019-01-24 02:37:40.461054: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325d200 of size 2816
2019-01-24 02:37:40.461057: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325dd00 of size 2816
2019-01-24 02:37:40.473194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325e800 of size 2816
2019-01-24 02:37:40.473203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325f300 of size 2816
2019-01-24 02:37:40.473206: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1325fe00 of size 2816
2019-01-24 02:37:40.473209: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13260900 of size 2816
2019-01-24 02:37:40.473212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13261400 of size 2816
2019-01-24 02:37:40.473215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13261f00 of size 2816
2019-01-24 02:37:40.473218: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13262a00 of size 2816
2019-01-24 02:37:40.473221: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13263500 of size 2816
2019-01-24 02:37:40.473224: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13264000 of size 2816
2019-01-24 02:37:40.473227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13264b00 of size 2816
2019-01-24 02:37:40.473229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13265600 of size 2816
2019-01-24 02:37:40.473232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13266100 of size 2816
2019-01-24 02:37:40.473235: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13266c00 of size 2816
2019-01-24 02:37:40.473238: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13267700 of size 12288
2019-01-24 02:37:40.473241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1326a700 of size 12288
2019-01-24 02:37:40.473245: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1326d700 of size 12288
2019-01-24 02:37:40.473249: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13270700 of size 12288
2019-01-24 02:37:40.473252: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13273700 of size 12288
2019-01-24 02:37:40.473256: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13276700 of size 12288
2019-01-24 02:37:40.473259: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13279700 of size 12288
2019-01-24 02:37:40.473263: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1327c700 of size 12288
2019-01-24 02:37:40.473266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1327f700 of size 12288
2019-01-24 02:37:40.473270: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13282700 of size 12288
2019-01-24 02:37:40.473274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13285700 of size 12288
2019-01-24 02:37:40.473277: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13288700 of size 12288
2019-01-24 02:37:40.473280: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1328b700 of size 12288
2019-01-24 02:37:40.473284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1328e700 of size 12288
2019-01-24 02:37:40.473287: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13291700 of size 12288
2019-01-24 02:37:40.473291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13294700 of size 12288
2019-01-24 02:37:40.473294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13297700 of size 12288
2019-01-24 02:37:40.473297: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1329a700 of size 12288
2019-01-24 02:37:40.473301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1329d700 of size 12288
2019-01-24 02:37:40.473304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132a0700 of size 12288
2019-01-24 02:37:40.473308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132a3700 of size 12288
2019-01-24 02:37:40.473311: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132a6700 of size 12288
2019-01-24 02:37:40.473315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132a9700 of size 12288
2019-01-24 02:37:40.473318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132ac700 of size 12288
2019-01-24 02:37:40.473322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132af700 of size 12288
2019-01-24 02:37:40.473325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132b2700 of size 12288
2019-01-24 02:37:40.473329: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132b5700 of size 12288
2019-01-24 02:37:40.473333: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132b8700 of size 12288
2019-01-24 02:37:40.473335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132bb700 of size 12288
2019-01-24 02:37:40.473339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132be700 of size 12288
2019-01-24 02:37:40.473342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132c1700 of size 12288
2019-01-24 02:37:40.473346: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132c4700 of size 12288
2019-01-24 02:37:40.473349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132c7700 of size 12288
2019-01-24 02:37:40.473353: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132ca700 of size 12288
2019-01-24 02:37:40.473356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132cd700 of size 12288
2019-01-24 02:37:40.473360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132d0700 of size 12288
2019-01-24 02:37:40.473363: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132d3700 of size 12288
2019-01-24 02:37:40.473367: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132d6700 of size 12288
2019-01-24 02:37:40.473370: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132d9700 of size 2816
2019-01-24 02:37:40.473374: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132da200 of size 2816
2019-01-24 02:37:40.473377: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132dad00 of size 2816
2019-01-24 02:37:40.473381: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132db800 of size 2816
2019-01-24 02:37:40.473384: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132dc300 of size 2816
2019-01-24 02:37:40.473388: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132dce00 of size 2816
2019-01-24 02:37:40.473391: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132dd900 of size 2816
2019-01-24 02:37:40.473395: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132de400 of size 2816
2019-01-24 02:37:40.473398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132def00 of size 2816
2019-01-24 02:37:40.473402: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb132dfa00 of size 18063
36
2019-01-24 02:37:40.473405: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13498a00 of size 18063
36
2019-01-24 02:37:40.473409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13651a00 of size 2816
2019-01-24 02:37:40.473412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13652500 of size 2816
2019-01-24 02:37:40.473416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13653000 of size 2816
2019-01-24 02:37:40.473419: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13653b00 of size 2816
2019-01-24 02:37:40.473422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13654600 of size 2816
2019-01-24 02:37:40.473426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13655100 of size 2816
2019-01-24 02:37:40.473429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13655c00 of size 2816
2019-01-24 02:37:40.473433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13656700 of size 2816
2019-01-24 02:37:40.473436: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13657200 of size 2816
2019-01-24 02:37:40.473440: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13657d00 of size 2816
2019-01-24 02:37:40.473443: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13658800 of size 2816
2019-01-24 02:37:40.473446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13659300 of size 2816
2019-01-24 02:37:40.473450: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13659e00 of size 2816
2019-01-24 02:37:40.473453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365a900 of size 2816
2019-01-24 02:37:40.473457: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365b400 of size 2816
2019-01-24 02:37:40.473460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365bf00 of size 2816
2019-01-24 02:37:40.473464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365ca00 of size 2816
2019-01-24 02:37:40.473467: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365d500 of size 2816
2019-01-24 02:37:40.473470: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365e000 of size 2816
2019-01-24 02:37:40.473474: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365eb00 of size 2816
2019-01-24 02:37:40.473477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365f600 of size 768
2019-01-24 02:37:40.473481: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365f900 of size 768
2019-01-24 02:37:40.473484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365fc00 of size 768
2019-01-24 02:37:40.473488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1365ff00 of size 768
2019-01-24 02:37:40.473491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13660200 of size 768
2019-01-24 02:37:40.473495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13660500 of size 2816
2019-01-24 02:37:40.473498: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13661000 of size 768
2019-01-24 02:37:40.473501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13661300 of size 2816
2019-01-24 02:37:40.473505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13661e00 of size 768
2019-01-24 02:37:40.473508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13662100 of size 768
2019-01-24 02:37:40.473512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13662400 of size 768
2019-01-24 02:37:40.473515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13662700 of size 2816
2019-01-24 02:37:40.473519: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13663200 of size 768
2019-01-24 02:37:40.473522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13663500 of size 768
2019-01-24 02:37:40.473526: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13663800 of size 768
2019-01-24 02:37:40.473529: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13663b00 of size 2816
2019-01-24 02:37:40.473532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13664600 of size 2816
2019-01-24 02:37:40.473536: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13665100 of size 768
2019-01-24 02:37:40.473539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13665400 of size 768
2019-01-24 02:37:40.473543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13665700 of size 768
2019-01-24 02:37:40.473546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13665a00 of size 2816
2019-01-24 02:37:40.473550: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13666500 of size 768
2019-01-24 02:37:40.473553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13666800 of size 768
2019-01-24 02:37:40.473556: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13666b00 of size 2816
2019-01-24 02:37:40.473560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13667600 of size 768
2019-01-24 02:37:40.473563: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13667900 of size 2816
2019-01-24 02:37:40.473567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13668400 of size 2816
2019-01-24 02:37:40.473570: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13668f00 of size 2816
2019-01-24 02:37:40.473574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13669a00 of size 768
2019-01-24 02:37:40.473577: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13669d00 of size 768
2019-01-24 02:37:40.473580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366a000 of size 2816
2019-01-24 02:37:40.473583: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366ab00 of size 768
2019-01-24 02:37:40.473587: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366ae00 of size 768
2019-01-24 02:37:40.473590: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366b100 of size 2816
2019-01-24 02:37:40.473594: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366bc00 of size 768
2019-01-24 02:37:40.473597: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366bf00 of size 768
2019-01-24 02:37:40.473601: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366c200 of size 2816
2019-01-24 02:37:40.473604: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366cd00 of size 768
2019-01-24 02:37:40.473607: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366d000 of size 768
2019-01-24 02:37:40.473611: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366d300 of size 768
2019-01-24 02:37:40.473614: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366d600 of size 768
2019-01-24 02:37:40.473618: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366d900 of size 768
2019-01-24 02:37:40.473621: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366dc00 of size 2816
2019-01-24 02:37:40.473625: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366e700 of size 768
2019-01-24 02:37:40.473628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366ea00 of size 2816
2019-01-24 02:37:40.473631: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366f500 of size 768
2019-01-24 02:37:40.473635: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1366f800 of size 2816
2019-01-24 02:37:40.473638: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13670300 of size 768
2019-01-24 02:37:40.473642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13670600 of size 768
2019-01-24 02:37:40.473645: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13670900 of size 768
2019-01-24 02:37:40.473649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13670c00 of size 2816
2019-01-24 02:37:40.473652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13671700 of size 768
2019-01-24 02:37:40.473656: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13671a00 of size 768
2019-01-24 02:37:40.473659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13671d00 of size 2816
2019-01-24 02:37:40.473662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13672800 of size 2816
2019-01-24 02:37:40.473666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13673300 of size 768
2019-01-24 02:37:40.473669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13673600 of size 768
2019-01-24 02:37:40.473673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13673900 of size 2816
2019-01-24 02:37:40.473676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13674400 of size 768
2019-01-24 02:37:40.473684: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13674700 of size 768
2019-01-24 02:37:40.473688: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13674a00 of size 768
2019-01-24 02:37:40.473691: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13674d00 of size 768
2019-01-24 02:37:40.473695: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13675000 of size 768
2019-01-24 02:37:40.473698: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13675300 of size 768
2019-01-24 02:37:40.473701: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13675600 of size 768
2019-01-24 02:37:40.473705: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13675900 of size 768
2019-01-24 02:37:40.473708: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13675c00 of size 768
2019-01-24 02:37:40.473712: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13675f00 of size 2816
2019-01-24 02:37:40.473715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13676a00 of size 768
2019-01-24 02:37:40.473719: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13676d00 of size 768
2019-01-24 02:37:40.473722: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13677000 of size 768
2019-01-24 02:37:40.473725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13677300 of size 2816
2019-01-24 02:37:40.473729: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13677e00 of size 768
2019-01-24 02:37:40.473732: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13678100 of size 2816
2019-01-24 02:37:40.473736: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13678c00 of size 768
2019-01-24 02:37:40.473739: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13678f00 of size 768
2019-01-24 02:37:40.473743: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13679200 of size 2816
2019-01-24 02:37:40.473746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13679d00 of size 768
2019-01-24 02:37:40.473750: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367a000 of size 2816
2019-01-24 02:37:40.473753: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367ab00 of size 2816
2019-01-24 02:37:40.473756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367b600 of size 2816
2019-01-24 02:37:40.473760: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367c100 of size 2816
2019-01-24 02:37:40.473763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367cc00 of size 768
2019-01-24 02:37:40.473767: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367cf00 of size 768
2019-01-24 02:37:40.473770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367d200 of size 768
2019-01-24 02:37:40.473774: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367d500 of size 768
2019-01-24 02:37:40.473777: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367d800 of size 768
2019-01-24 02:37:40.473780: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367db00 of size 2816
2019-01-24 02:37:40.473784: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367e600 of size 768
2019-01-24 02:37:40.473787: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367e900 of size 2816
2019-01-24 02:37:40.473791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367f400 of size 768
2019-01-24 02:37:40.473794: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1367f700 of size 2816
2019-01-24 02:37:40.473798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13680200 of size 768
2019-01-24 02:37:40.473801: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13680500 of size 768
2019-01-24 02:37:40.478979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13680800 of size 768
2019-01-24 02:37:40.478988: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13680b00 of size 768
2019-01-24 02:37:40.478991: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13680e00 of size 768
2019-01-24 02:37:40.478995: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13681100 of size 2816
2019-01-24 02:37:40.478999: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13681c00 of size 2816
2019-01-24 02:37:40.479002: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13682700 of size 768
2019-01-24 02:37:40.479005: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13682a00 of size 768
2019-01-24 02:37:40.479009: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13682d00 of size 768
2019-01-24 02:37:40.479012: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13683000 of size 2816
2019-01-24 02:37:40.479015: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13683b00 of size 768
2019-01-24 02:37:40.479018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13683e00 of size 2816
2019-01-24 02:37:40.479022: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13684900 of size 768
2019-01-24 02:37:40.479025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13684c00 of size 2816
2019-01-24 02:37:40.479028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13685700 of size 768
2019-01-24 02:37:40.479031: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13685a00 of size 2816
2019-01-24 02:37:40.479034: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13686500 of size 2816
2019-01-24 02:37:40.479037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13687000 of size 768
2019-01-24 02:37:40.479041: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13687300 of size 768
2019-01-24 02:37:40.479044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13687600 of size 768
2019-01-24 02:37:40.479048: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13687900 of size 768
2019-01-24 02:37:40.479051: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13687c00 of size 2816
2019-01-24 02:37:40.479055: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13688700 of size 768
2019-01-24 02:37:40.479058: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13688a00 of size 768
2019-01-24 02:37:40.479061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13688d00 of size 2816
2019-01-24 02:37:40.479065: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13689800 of size 768
2019-01-24 02:37:40.479068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13689b00 of size 2816
2019-01-24 02:37:40.479072: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368a600 of size 768
2019-01-24 02:37:40.479075: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368a900 of size 768
2019-01-24 02:37:40.479079: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368ac00 of size 768
2019-01-24 02:37:40.479082: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368af00 of size 768
2019-01-24 02:37:40.479086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368b200 of size 768
2019-01-24 02:37:40.479089: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368b500 of size 2816
2019-01-24 02:37:40.479093: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368c000 of size 768
2019-01-24 02:37:40.479096: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368c300 of size 2816
2019-01-24 02:37:40.479100: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368ce00 of size 768
2019-01-24 02:37:40.479103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368d100 of size 768
2019-01-24 02:37:40.479107: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368d400 of size 768
2019-01-24 02:37:40.479110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368d700 of size 2816
2019-01-24 02:37:40.479113: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368e200 of size 768
2019-01-24 02:37:40.479117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368e500 of size 2816
2019-01-24 02:37:40.479120: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368f000 of size 768
2019-01-24 02:37:40.479124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368f300 of size 2816
2019-01-24 02:37:40.479127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1368fe00 of size 2816
2019-01-24 02:37:40.479131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13690900 of size 768
2019-01-24 02:37:40.479134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13690c00 of size 768
2019-01-24 02:37:40.479138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13690f00 of size 2816
2019-01-24 02:37:40.479141: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13691a00 of size 768
2019-01-24 02:37:40.479144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13691d00 of size 768
2019-01-24 02:37:40.479148: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13692000 of size 768
2019-01-24 02:37:40.479151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13692300 of size 768
2019-01-24 02:37:40.479155: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13692600 of size 2816
2019-01-24 02:37:40.479158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13693100 of size 2816
2019-01-24 02:37:40.479161: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13693c00 of size 768
2019-01-24 02:37:40.479165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13693f00 of size 768
2019-01-24 02:37:40.479168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13694200 of size 768
2019-01-24 02:37:40.479172: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13694500 of size 768
2019-01-24 02:37:40.479175: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13694800 of size 768
2019-01-24 02:37:40.479179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13694b00 of size 2816
2019-01-24 02:37:40.479182: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13695600 of size 768
2019-01-24 02:37:40.479185: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13695900 of size 2816
2019-01-24 02:37:40.479189: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13696400 of size 768
2019-01-24 02:37:40.479192: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13696700 of size 768
2019-01-24 02:37:40.479196: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13696a00 of size 768
2019-01-24 02:37:40.479199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13696d00 of size 768
2019-01-24 02:37:40.479202: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13697000 of size 768
2019-01-24 02:37:40.479206: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13697300 of size 2816
2019-01-24 02:37:40.479209: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13697e00 of size 768
2019-01-24 02:37:40.479213: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13698100 of size 2816
2019-01-24 02:37:40.479216: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13698c00 of size 768
2019-01-24 02:37:40.479219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13698f00 of size 2816
2019-01-24 02:37:40.479223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13699a00 of size 768
2019-01-24 02:37:40.479226: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13699d00 of size 768
2019-01-24 02:37:40.479230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369a000 of size 2816
2019-01-24 02:37:40.479233: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369ab00 of size 768
2019-01-24 02:37:40.479236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369ae00 of size 768
2019-01-24 02:37:40.479240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369b100 of size 2816
2019-01-24 02:37:40.479243: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369bc00 of size 2816
2019-01-24 02:37:40.479247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369c700 of size 2816
2019-01-24 02:37:40.479250: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369d200 of size 2816
2019-01-24 02:37:40.479254: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369dd00 of size 768
2019-01-24 02:37:40.479257: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369e000 of size 768
2019-01-24 02:37:40.479260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369e300 of size 2816
2019-01-24 02:37:40.479264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369ee00 of size 768
2019-01-24 02:37:40.479267: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369f100 of size 768
2019-01-24 02:37:40.479271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369f400 of size 768
2019-01-24 02:37:40.479274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1369f700 of size 2816
2019-01-24 02:37:40.479278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a0200 of size 768
2019-01-24 02:37:40.479281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a0500 of size 2816
2019-01-24 02:37:40.479284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a1000 of size 768
2019-01-24 02:37:40.479288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a1300 of size 768
2019-01-24 02:37:40.479291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a1600 of size 768
2019-01-24 02:37:40.479294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a1900 of size 768
2019-01-24 02:37:40.479297: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a1c00 of size 768
2019-01-24 02:37:40.479301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a1f00 of size 768
2019-01-24 02:37:40.479304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a2200 of size 2816
2019-01-24 02:37:40.479308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a2d00 of size 2816
2019-01-24 02:37:40.479311: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a3800 of size 2816
2019-01-24 02:37:40.479315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a4300 of size 768
2019-01-24 02:37:40.479318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a4600 of size 768
2019-01-24 02:37:40.479322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a4900 of size 2816
2019-01-24 02:37:40.479325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a5400 of size 768
2019-01-24 02:37:40.479329: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a5700 of size 768
2019-01-24 02:37:40.479332: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a5a00 of size 768
2019-01-24 02:37:40.479335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a5d00 of size 2816
2019-01-24 02:37:40.479339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a6800 of size 768
2019-01-24 02:37:40.479342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a6b00 of size 2816
2019-01-24 02:37:40.479346: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a7600 of size 768
2019-01-24 02:37:40.479349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a7900 of size 2816
2019-01-24 02:37:40.479353: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a8400 of size 768
2019-01-24 02:37:40.479356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a8700 of size 768
2019-01-24 02:37:40.479360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a8a00 of size 2816
2019-01-24 02:37:40.479363: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a9500 of size 768
2019-01-24 02:37:40.479366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a9800 of size 768
2019-01-24 02:37:40.479370: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a9b00 of size 768
2019-01-24 02:37:40.479373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb136a9e00 of size 67737
6
2019-01-24 02:37:40.479377: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1374f400 of size 67737
6
2019-01-24 02:37:40.479381: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb137f4a00 of size 67737
6
2019-01-24 02:37:40.479384: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1389a000 of size 67737
6
2019-01-24 02:37:40.479388: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1393f600 of size 67737
6
2019-01-24 02:37:40.479391: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb139e4c00 of size 67737
6
2019-01-24 02:37:40.479395: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13a8a200 of size 67737
6
2019-01-24 02:37:40.479398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13b2f800 of size 67737
6
2019-01-24 02:37:40.479401: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13bd4e00 of size 67737
6
2019-01-24 02:37:40.479405: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13c7a400 of size 67737
6
2019-01-24 02:37:40.479408: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13d1fa00 of size 67737
6
2019-01-24 02:37:40.479412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc5000 of size 768
2019-01-24 02:37:40.479415: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc5300 of size 768
2019-01-24 02:37:40.479419: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc5600 of size 768
2019-01-24 02:37:40.479422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc5900 of size 2816
2019-01-24 02:37:40.479426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc6400 of size 768
2019-01-24 02:37:40.479429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc6700 of size 768
2019-01-24 02:37:40.479432: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc6a00 of size 768
2019-01-24 02:37:40.479436: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc6d00 of size 768
2019-01-24 02:37:40.479442: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc7000 of size 768
2019-01-24 02:37:40.479445: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc7300 of size 2816
2019-01-24 02:37:40.479449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc7e00 of size 768
2019-01-24 02:37:40.479452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc8100 of size 768
2019-01-24 02:37:40.479456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc8400 of size 768
2019-01-24 02:37:40.479459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc8700 of size 2816
2019-01-24 02:37:40.479463: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc9200 of size 768
2019-01-24 02:37:40.479466: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dc9500 of size 2816
2019-01-24 02:37:40.479469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dca000 of size 2816
2019-01-24 02:37:40.479473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcab00 of size 2816
2019-01-24 02:37:40.479476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcb600 of size 768
2019-01-24 02:37:40.479480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcb900 of size 768
2019-01-24 02:37:40.479483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcbc00 of size 768
2019-01-24 02:37:40.479487: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcbf00 of size 768
2019-01-24 02:37:40.479490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcc200 of size 768
2019-01-24 02:37:40.479494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcc500 of size 2816
2019-01-24 02:37:40.479497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcd000 of size 768
2019-01-24 02:37:40.479500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcd300 of size 2816
2019-01-24 02:37:40.479504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcde00 of size 768
2019-01-24 02:37:40.479507: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dce100 of size 768
2019-01-24 02:37:40.479511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dce400 of size 768
2019-01-24 02:37:40.479514: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dce700 of size 768
2019-01-24 02:37:40.479517: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcea00 of size 768
2019-01-24 02:37:40.479521: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dced00 of size 768
2019-01-24 02:37:40.479524: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcf000 of size 2816
2019-01-24 02:37:40.479527: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dcfb00 of size 2816
2019-01-24 02:37:40.479531: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd0600 of size 768
2019-01-24 02:37:40.479534: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd0900 of size 768
2019-01-24 02:37:40.479538: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd0c00 of size 768
2019-01-24 02:37:40.479541: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd0f00 of size 2816
2019-01-24 02:37:40.479545: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd1a00 of size 768
2019-01-24 02:37:40.479548: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd1d00 of size 768
2019-01-24 02:37:40.479552: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd2000 of size 2816
2019-01-24 02:37:40.479555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd2b00 of size 768
2019-01-24 02:37:40.479558: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd2e00 of size 2816
2019-01-24 02:37:40.479562: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd3900 of size 2816
2019-01-24 02:37:40.479565: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd4400 of size 2816
2019-01-24 02:37:40.479569: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd4f00 of size 768
2019-01-24 02:37:40.479572: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd5200 of size 768
2019-01-24 02:37:40.479576: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd5500 of size 2816
2019-01-24 02:37:40.479579: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd6000 of size 768
2019-01-24 02:37:40.479583: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd6300 of size 768
2019-01-24 02:37:40.479586: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd6600 of size 2816
2019-01-24 02:37:40.479590: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd7100 of size 768
2019-01-24 02:37:40.479593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd7400 of size 768
2019-01-24 02:37:40.479597: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd7700 of size 2816
2019-01-24 02:37:40.479600: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd8200 of size 768
2019-01-24 02:37:40.479603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd8500 of size 768
2019-01-24 02:37:40.479607: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd8800 of size 768
2019-01-24 02:37:40.479610: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd8b00 of size 768
2019-01-24 02:37:40.479614: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd8e00 of size 768
2019-01-24 02:37:40.485878: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd9100 of size 2816
2019-01-24 02:37:40.485888: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd9c00 of size 768
2019-01-24 02:37:40.485893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dd9f00 of size 2816
2019-01-24 02:37:40.485898: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddaa00 of size 768
2019-01-24 02:37:40.485901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddad00 of size 2816
2019-01-24 02:37:40.485905: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddb800 of size 768
2019-01-24 02:37:40.485908: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddbb00 of size 768
2019-01-24 02:37:40.485911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddbe00 of size 768
2019-01-24 02:37:40.485914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddc100 of size 2816
2019-01-24 02:37:40.485918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddcc00 of size 768
2019-01-24 02:37:40.485921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddcf00 of size 768
2019-01-24 02:37:40.485925: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddd200 of size 2816
2019-01-24 02:37:40.485928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dddd00 of size 2816
2019-01-24 02:37:40.485931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dde800 of size 2816
2019-01-24 02:37:40.485935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddf300 of size 768
2019-01-24 02:37:40.485938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddf600 of size 768
2019-01-24 02:37:40.485942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ddf900 of size 2816
2019-01-24 02:37:40.485945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de0400 of size 768
2019-01-24 02:37:40.485949: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de0700 of size 768
2019-01-24 02:37:40.485952: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de0a00 of size 768
2019-01-24 02:37:40.485955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de0d00 of size 768
2019-01-24 02:37:40.485959: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de1000 of size 768
2019-01-24 02:37:40.485962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de1300 of size 768
2019-01-24 02:37:40.485966: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de1600 of size 768
2019-01-24 02:37:40.485969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de1900 of size 768
2019-01-24 02:37:40.485973: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de1c00 of size 768
2019-01-24 02:37:40.485976: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de1f00 of size 768
2019-01-24 02:37:40.485980: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de2200 of size 2816
2019-01-24 02:37:40.485983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de2d00 of size 2816
2019-01-24 02:37:40.485987: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de3800 of size 768
2019-01-24 02:37:40.485990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de3b00 of size 768
2019-01-24 02:37:40.485994: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de3e00 of size 2816
2019-01-24 02:37:40.485997: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de4900 of size 768
2019-01-24 02:37:40.486001: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de4c00 of size 768
2019-01-24 02:37:40.486004: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de4f00 of size 768
2019-01-24 02:37:40.486007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de5200 of size 2816
2019-01-24 02:37:40.486011: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de5d00 of size 768
2019-01-24 02:37:40.486014: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de6000 of size 2816
2019-01-24 02:37:40.486018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de6b00 of size 768
2019-01-24 02:37:40.486021: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de6e00 of size 2816
2019-01-24 02:37:40.486025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de7900 of size 2816
2019-01-24 02:37:40.486028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de8400 of size 2816
2019-01-24 02:37:40.486032: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de8f00 of size 2816
2019-01-24 02:37:40.486035: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13de9a00 of size 2816
2019-01-24 02:37:40.486039: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dea500 of size 2816
2019-01-24 02:37:40.486042: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13deb000 of size 2816
2019-01-24 02:37:40.486046: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13debb00 of size 2816
2019-01-24 02:37:40.486049: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dec600 of size 2816
2019-01-24 02:37:40.486053: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13ded100 of size 2816
2019-01-24 02:37:40.486056: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dedc00 of size 2816
2019-01-24 02:37:40.486059: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dee700 of size 2816
2019-01-24 02:37:40.486063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13def200 of size 2816
2019-01-24 02:37:40.486066: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13defd00 of size 2816
2019-01-24 02:37:40.486070: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df0800 of size 2816
2019-01-24 02:37:40.486073: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df1300 of size 2816
2019-01-24 02:37:40.486077: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df1e00 of size 2816
2019-01-24 02:37:40.486080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df2900 of size 2816
2019-01-24 02:37:40.486083: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df3400 of size 2816
2019-01-24 02:37:40.486087: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df3f00 of size 2816
2019-01-24 02:37:40.486090: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df4a00 of size 2816
2019-01-24 02:37:40.486094: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df5500 of size 2816
2019-01-24 02:37:40.486097: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df6000 of size 2816
2019-01-24 02:37:40.486101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df6b00 of size 2816
2019-01-24 02:37:40.486104: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df7600 of size 2816
2019-01-24 02:37:40.486108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df8100 of size 2816
2019-01-24 02:37:40.486111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df8c00 of size 2816
2019-01-24 02:37:40.486114: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13df9700 of size 2816
2019-01-24 02:37:40.486118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfa200 of size 2816
2019-01-24 02:37:40.486121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfad00 of size 2816
2019-01-24 02:37:40.486125: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfb800 of size 2816
2019-01-24 02:37:40.486128: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfc300 of size 2816
2019-01-24 02:37:40.486132: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfce00 of size 2816
2019-01-24 02:37:40.486135: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfd900 of size 2816
2019-01-24 02:37:40.486139: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfe400 of size 2816
2019-01-24 02:37:40.486142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dfef00 of size 2816
2019-01-24 02:37:40.486145: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13dffa00 of size 2816
2019-01-24 02:37:40.486149: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e00500 of size 2816
2019-01-24 02:37:40.486152: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e01000 of size 2816
2019-01-24 02:37:40.486156: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e01b00 of size 2816
2019-01-24 02:37:40.486159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e02600 of size 2816
2019-01-24 02:37:40.486163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e03100 of size 2816
2019-01-24 02:37:40.486166: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e03c00 of size 2816
2019-01-24 02:37:40.486169: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e04700 of size 2816
2019-01-24 02:37:40.486173: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e05200 of size 2816
2019-01-24 02:37:40.486176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e05d00 of size 2816
2019-01-24 02:37:40.486180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb13e06800 of size 27095
04
2019-01-24 02:37:40.486184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1409c000 of size 27095
04
2019-01-24 02:37:40.486187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb14331800 of size 27095
04
2019-01-24 02:37:40.486191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb145c7000 of size 27095
04
2019-01-24 02:37:40.486194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1485c800 of size 27095
04
2019-01-24 02:37:40.486198: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb14af2000 of size 27095
04
2019-01-24 02:37:40.486201: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb14d87800 of size 27095
04
2019-01-24 02:37:40.486205: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1501d000 of size 27095
04
2019-01-24 02:37:40.486208: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb152b2800 of size 27095
04
2019-01-24 02:37:40.486212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15548000 of size 27095
04
2019-01-24 02:37:40.486215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb157dd800 of size 57600
2019-01-24 02:37:40.486219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb157eb900 of size 57600
2019-01-24 02:37:40.486223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb157f9a00 of size 23040
0
2019-01-24 02:37:40.486226: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15831e00 of size 23040
0
2019-01-24 02:37:40.486230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1586a200 of size 2048
2019-01-24 02:37:40.486233: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1586aa00 of size 2048
2019-01-24 02:37:40.486237: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1586b200 of size 21294
08
2019-01-24 02:37:40.486240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a73000 of size 2816
2019-01-24 02:37:40.486244: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a73b00 of size 2816
2019-01-24 02:37:40.486247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a74600 of size 2816
2019-01-24 02:37:40.486251: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a75100 of size 2816
2019-01-24 02:37:40.486254: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a75c00 of size 2816
2019-01-24 02:37:40.486258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a76700 of size 2816
2019-01-24 02:37:40.486261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a77200 of size 2816
2019-01-24 02:37:40.486264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a77d00 of size 2816
2019-01-24 02:37:40.486268: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a78800 of size 2816
2019-01-24 02:37:40.486271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a79300 of size 2816
2019-01-24 02:37:40.486275: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a79e00 of size 2816
2019-01-24 02:37:40.486278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7a900 of size 2816
2019-01-24 02:37:40.486282: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7b400 of size 2816
2019-01-24 02:37:40.486285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7bf00 of size 2816
2019-01-24 02:37:40.486289: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7ca00 of size 2816
2019-01-24 02:37:40.486292: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7d500 of size 2816
2019-01-24 02:37:40.486295: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7e000 of size 2816
2019-01-24 02:37:40.486299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7eb00 of size 2816
2019-01-24 02:37:40.486302: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a7f600 of size 2816
2019-01-24 02:37:40.486306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a80100 of size 2816
2019-01-24 02:37:40.486309: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a80c00 of size 2816
2019-01-24 02:37:40.486313: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a81700 of size 2816
2019-01-24 02:37:40.486316: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a82200 of size 2816
2019-01-24 02:37:40.486320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a82d00 of size 2816
2019-01-24 02:37:40.486323: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a83800 of size 2816
2019-01-24 02:37:40.486326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a84300 of size 2816
2019-01-24 02:37:40.486330: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a84e00 of size 2816
2019-01-24 02:37:40.486333: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a85900 of size 2816
2019-01-24 02:37:40.486337: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a86400 of size 2816
2019-01-24 02:37:40.486340: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a86f00 of size 2816
2019-01-24 02:37:40.486344: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a87a00 of size 2816
2019-01-24 02:37:40.486347: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a88500 of size 2816
2019-01-24 02:37:40.486351: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a89000 of size 2816
2019-01-24 02:37:40.486354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a89b00 of size 2816
2019-01-24 02:37:40.486357: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8a600 of size 2816
2019-01-24 02:37:40.486361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8b100 of size 2816
2019-01-24 02:37:40.486364: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8bc00 of size 768
2019-01-24 02:37:40.486368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8bf00 of size 768
2019-01-24 02:37:40.486371: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8c200 of size 2816
2019-01-24 02:37:40.486375: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8cd00 of size 768
2019-01-24 02:37:40.486378: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8d000 of size 768
2019-01-24 02:37:40.486382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8d300 of size 768
2019-01-24 02:37:40.486385: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a8d600 of size 24320
2019-01-24 02:37:40.486389: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a93500 of size 24320
2019-01-24 02:37:40.486392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a99400 of size 24320
2019-01-24 02:37:40.486396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15a9f300 of size 24320
2019-01-24 02:37:40.486399: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15aa5200 of size 24320
2019-01-24 02:37:40.486403: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15aab100 of size 24320
2019-01-24 02:37:40.486406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ab1000 of size 24320
2019-01-24 02:37:40.486410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ab6f00 of size 24320
2019-01-24 02:37:40.486413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15abce00 of size 24320
2019-01-24 02:37:40.486417: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ac2d00 of size 24320
2019-01-24 02:37:40.486420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ac8c00 of size 24320
2019-01-24 02:37:40.486424: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15aceb00 of size 24320
2019-01-24 02:37:40.486427: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ad4a00 of size 24320
2019-01-24 02:37:40.486431: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ada900 of size 24320
2019-01-24 02:37:40.486434: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ae0800 of size 24320
2019-01-24 02:37:40.486438: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15ae6700 of size 24320
2019-01-24 02:37:40.486441: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15aec600 of size 24320
2019-01-24 02:37:40.486445: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15af2500 of size 24320
2019-01-24 02:37:40.486448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15af8400 of size 24320
2019-01-24 02:37:40.486451: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15afe300 of size 24320
2019-01-24 02:37:40.486455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b04200 of size 24320
2019-01-24 02:37:40.486458: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b0a100 of size 24320
2019-01-24 02:37:40.486462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b10000 of size 24320
2019-01-24 02:37:40.486465: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b15f00 of size 24320
2019-01-24 02:37:40.486469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b1be00 of size 24320
2019-01-24 02:37:40.486472: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b21d00 of size 24320
2019-01-24 02:37:40.486476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b27c00 of size 24320
2019-01-24 02:37:40.486479: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b2db00 of size 24320
2019-01-24 02:37:40.486483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b33a00 of size 24320
2019-01-24 02:37:40.486486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b39900 of size 24320
2019-01-24 02:37:40.486490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b3f800 of size 24320
2019-01-24 02:37:40.486493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b45700 of size 24320
2019-01-24 02:37:40.496088: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b4b600 of size 24320
2019-01-24 02:37:40.496096: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b51500 of size 24320
2019-01-24 02:37:40.496100: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b57400 of size 24320
2019-01-24 02:37:40.496103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b5d300 of size 24320
2019-01-24 02:37:40.496106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b63200 of size 24320
2019-01-24 02:37:40.496108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b69100 of size 24320
2019-01-24 02:37:40.496111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b6f000 of size 768
2019-01-24 02:37:40.496115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b6f300 of size 768
2019-01-24 02:37:40.496119: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b6f600 of size 768
2019-01-24 02:37:40.496121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b6f900 of size 768
2019-01-24 02:37:40.496125: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b6fc00 of size 768
2019-01-24 02:37:40.496128: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b6ff00 of size 768
2019-01-24 02:37:40.496132: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b70200 of size 2816
2019-01-24 02:37:40.496135: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b70d00 of size 768
2019-01-24 02:37:40.496138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b71000 of size 2816
2019-01-24 02:37:40.496142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b71b00 of size 768
2019-01-24 02:37:40.496145: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b71e00 of size 768
2019-01-24 02:37:40.496149: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b72100 of size 2816
2019-01-24 02:37:40.496152: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b72c00 of size 768
2019-01-24 02:37:40.496156: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b72f00 of size 768
2019-01-24 02:37:40.496159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b73200 of size 2816
2019-01-24 02:37:40.496163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b73d00 of size 768
2019-01-24 02:37:40.496167: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b74000 of size 2816
2019-01-24 02:37:40.496170: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b74b00 of size 2816
2019-01-24 02:37:40.496174: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b75600 of size 2816
2019-01-24 02:37:40.496177: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b76100 of size 2816
2019-01-24 02:37:40.496180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b76c00 of size 768
2019-01-24 02:37:40.496184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b76f00 of size 768
2019-01-24 02:37:40.496187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b77200 of size 768
2019-01-24 02:37:40.496191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b77500 of size 768
2019-01-24 02:37:40.496194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b77800 of size 2816
2019-01-24 02:37:40.496198: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b78300 of size 768
2019-01-24 02:37:40.496201: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b78600 of size 2816
2019-01-24 02:37:40.496205: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b79100 of size 768
2019-01-24 02:37:40.496208: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b79400 of size 2816
2019-01-24 02:37:40.496212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b79f00 of size 768
2019-01-24 02:37:40.496215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7a200 of size 768
2019-01-24 02:37:40.496218: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7a500 of size 768
2019-01-24 02:37:40.496222: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7a800 of size 768
2019-01-24 02:37:40.496225: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7ab00 of size 768
2019-01-24 02:37:40.496229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7ae00 of size 768
2019-01-24 02:37:40.496232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7b100 of size 2816
2019-01-24 02:37:40.496236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7bc00 of size 2816
2019-01-24 02:37:40.496239: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7c700 of size 2816
2019-01-24 02:37:40.496243: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7d200 of size 768
2019-01-24 02:37:40.496246: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7d500 of size 2816
2019-01-24 02:37:40.496250: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7e000 of size 768
2019-01-24 02:37:40.496253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7e300 of size 768
2019-01-24 02:37:40.496257: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7e600 of size 768
2019-01-24 02:37:40.496260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7e900 of size 2816
2019-01-24 02:37:40.496264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7f400 of size 768
2019-01-24 02:37:40.496267: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7f700 of size 768
2019-01-24 02:37:40.496271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b7fa00 of size 2816
2019-01-24 02:37:40.496274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b80500 of size 2816
2019-01-24 02:37:40.496277: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b81000 of size 2816
2019-01-24 02:37:40.496281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b81b00 of size 768
2019-01-24 02:37:40.496284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b81e00 of size 768
2019-01-24 02:37:40.496288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b82100 of size 2816
2019-01-24 02:37:40.496291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b82c00 of size 768
2019-01-24 02:37:40.496295: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b82f00 of size 768
2019-01-24 02:37:40.496298: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b83200 of size 768
2019-01-24 02:37:40.496301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b83500 of size 768
2019-01-24 02:37:40.496305: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b83800 of size 2816
2019-01-24 02:37:40.496308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b84300 of size 768
2019-01-24 02:37:40.496312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b84600 of size 768
2019-01-24 02:37:40.496315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b84900 of size 768
2019-01-24 02:37:40.496318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b84c00 of size 768
2019-01-24 02:37:40.496322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b84f00 of size 768
2019-01-24 02:37:40.496325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b85200 of size 768
2019-01-24 02:37:40.496329: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b85500 of size 2816
2019-01-24 02:37:40.496332: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b86000 of size 2816
2019-01-24 02:37:40.496336: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b86b00 of size 2816
2019-01-24 02:37:40.496339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b87600 of size 768
2019-01-24 02:37:40.496342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b87900 of size 768
2019-01-24 02:37:40.496346: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b87c00 of size 2816
2019-01-24 02:37:40.496349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b88700 of size 768
2019-01-24 02:37:40.496353: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b88a00 of size 768
2019-01-24 02:37:40.496356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b88d00 of size 768
2019-01-24 02:37:40.496359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b89000 of size 2816
2019-01-24 02:37:40.496363: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b89b00 of size 768
2019-01-24 02:37:40.496366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b89e00 of size 2816
2019-01-24 02:37:40.496370: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8a900 of size 2816
2019-01-24 02:37:40.496373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8b400 of size 768
2019-01-24 02:37:40.496377: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8b700 of size 768
2019-01-24 02:37:40.496380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8ba00 of size 768
2019-01-24 02:37:40.496383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8bd00 of size 768
2019-01-24 02:37:40.496387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8c000 of size 768
2019-01-24 02:37:40.496390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8c300 of size 768
2019-01-24 02:37:40.496394: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb15b8c600 of size 72253
44
2019-01-24 02:37:40.496398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16270600 of size 28800
0
2019-01-24 02:37:40.496401: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb162b6b00 of size 23040
0
2019-01-24 02:37:40.496405: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb162eef00 of size 23040
0
2019-01-24 02:37:40.496409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb16327300 of size 64765
44
2019-01-24 02:37:40.496412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16954600 of size 2816
2019-01-24 02:37:40.496416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16955100 of size 768
2019-01-24 02:37:40.496419: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16955400 of size 2816
2019-01-24 02:37:40.496423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16955f00 of size 768
2019-01-24 02:37:40.496426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16956200 of size 768
2019-01-24 02:37:40.496429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16956500 of size 2816
2019-01-24 02:37:40.496433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16957000 of size 768
2019-01-24 02:37:40.496437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16957300 of size 768
2019-01-24 02:37:40.496440: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16957600 of size 2816
2019-01-24 02:37:40.496443: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16958100 of size 768
2019-01-24 02:37:40.496446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16958400 of size 2816
2019-01-24 02:37:40.496450: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16958f00 of size 2816
2019-01-24 02:37:40.496453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16959a00 of size 2816
2019-01-24 02:37:40.496457: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695a500 of size 768
2019-01-24 02:37:40.496460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695a800 of size 768
2019-01-24 02:37:40.496464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695ab00 of size 768
2019-01-24 02:37:40.496467: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695ae00 of size 768
2019-01-24 02:37:40.496471: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695b100 of size 2816
2019-01-24 02:37:40.496474: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695bc00 of size 768
2019-01-24 02:37:40.496478: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695bf00 of size 2816
2019-01-24 02:37:40.496481: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695ca00 of size 768
2019-01-24 02:37:40.496484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695cd00 of size 768
2019-01-24 02:37:40.496488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695d000 of size 768
2019-01-24 02:37:40.496491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695d300 of size 2816
2019-01-24 02:37:40.496495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695de00 of size 768
2019-01-24 02:37:40.496498: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695e100 of size 768
2019-01-24 02:37:40.496501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695e400 of size 768
2019-01-24 02:37:40.496505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695e700 of size 768
2019-01-24 02:37:40.496508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695ea00 of size 2816
2019-01-24 02:37:40.496512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695f500 of size 768
2019-01-24 02:37:40.496515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695f800 of size 768
2019-01-24 02:37:40.496519: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695fb00 of size 768
2019-01-24 02:37:40.496522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1695fe00 of size 768
2019-01-24 02:37:40.496526: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16960100 of size 2816
2019-01-24 02:37:40.496529: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16960c00 of size 768
2019-01-24 02:37:40.496532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16960f00 of size 768
2019-01-24 02:37:40.496536: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16961200 of size 2816
2019-01-24 02:37:40.496539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16961d00 of size 2816
2019-01-24 02:37:40.496543: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16962800 of size 2816
2019-01-24 02:37:40.496546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16963300 of size 2816
2019-01-24 02:37:40.496550: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16963e00 of size 768
2019-01-24 02:37:40.496553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16964100 of size 768
2019-01-24 02:37:40.496557: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16964400 of size 2816
2019-01-24 02:37:40.496560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16964f00 of size 768
2019-01-24 02:37:40.496564: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16965200 of size 768
2019-01-24 02:37:40.496567: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16965500 of size 768
2019-01-24 02:37:40.496570: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16965800 of size 2816
2019-01-24 02:37:40.496574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16966300 of size 768
2019-01-24 02:37:40.496577: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16966600 of size 2816
2019-01-24 02:37:40.496581: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16967100 of size 2816
2019-01-24 02:37:40.496584: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16967c00 of size 768
2019-01-24 02:37:40.496588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16967f00 of size 768
2019-01-24 02:37:40.496591: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16968200 of size 768
2019-01-24 02:37:40.496594: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16968500 of size 768
2019-01-24 02:37:40.496598: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16968800 of size 768
2019-01-24 02:37:40.496601: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16968b00 of size 768
2019-01-24 02:37:40.496605: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16968e00 of size 768
2019-01-24 02:37:40.496608: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16969100 of size 768
2019-01-24 02:37:40.496612: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16969400 of size 2816
2019-01-24 02:37:40.496615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16969f00 of size 768
2019-01-24 02:37:40.496618: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696a200 of size 768
2019-01-24 02:37:40.496622: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696a500 of size 768
2019-01-24 02:37:40.496625: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696a800 of size 2816
2019-01-24 02:37:40.496629: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696b300 of size 768
2019-01-24 02:37:40.496632: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696b600 of size 2816
2019-01-24 02:37:40.496636: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c100 of size 256
2019-01-24 02:37:40.496639: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c200 of size 256
2019-01-24 02:37:40.496643: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c300 of size 256
2019-01-24 02:37:40.496646: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c400 of size 256
2019-01-24 02:37:40.496649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c500 of size 256
2019-01-24 02:37:40.496653: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c600 of size 256
2019-01-24 02:37:40.496656: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c700 of size 256
2019-01-24 02:37:40.496660: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c800 of size 256
2019-01-24 02:37:40.496663: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696c900 of size 256
2019-01-24 02:37:40.496667: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ca00 of size 256
2019-01-24 02:37:40.496670: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696cb00 of size 256
2019-01-24 02:37:40.496673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696cc00 of size 256
2019-01-24 02:37:40.496676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696cd00 of size 256
2019-01-24 02:37:40.496679: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ce00 of size 256
2019-01-24 02:37:40.496683: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696cf00 of size 256
2019-01-24 02:37:40.496686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d000 of size 256
2019-01-24 02:37:40.496690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d100 of size 256
2019-01-24 02:37:40.496693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d200 of size 256
2019-01-24 02:37:40.496697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d300 of size 256
2019-01-24 02:37:40.496700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d400 of size 256
2019-01-24 02:37:40.496703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d500 of size 256
2019-01-24 02:37:40.496707: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d600 of size 256
2019-01-24 02:37:40.496710: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d700 of size 256
2019-01-24 02:37:40.496713: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d800 of size 256
2019-01-24 02:37:40.496717: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696d900 of size 256
2019-01-24 02:37:40.496720: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696da00 of size 256
2019-01-24 02:37:40.505097: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696db00 of size 256
2019-01-24 02:37:40.505105: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696dc00 of size 256
2019-01-24 02:37:40.505108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696dd00 of size 256
2019-01-24 02:37:40.505111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696de00 of size 256
2019-01-24 02:37:40.505114: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696df00 of size 256
2019-01-24 02:37:40.505117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e000 of size 256
2019-01-24 02:37:40.505121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e100 of size 256
2019-01-24 02:37:40.505124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e200 of size 256
2019-01-24 02:37:40.505127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e300 of size 256
2019-01-24 02:37:40.505131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e400 of size 256
2019-01-24 02:37:40.505133: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e500 of size 256
2019-01-24 02:37:40.505137: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e600 of size 256
2019-01-24 02:37:40.505140: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e700 of size 256
2019-01-24 02:37:40.505144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e800 of size 256
2019-01-24 02:37:40.505147: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696e900 of size 256
2019-01-24 02:37:40.505150: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ea00 of size 256
2019-01-24 02:37:40.505154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696eb00 of size 256
2019-01-24 02:37:40.505157: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ec00 of size 256
2019-01-24 02:37:40.505161: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ed00 of size 256
2019-01-24 02:37:40.505164: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ee00 of size 256
2019-01-24 02:37:40.505167: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ef00 of size 256
2019-01-24 02:37:40.505171: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f000 of size 256
2019-01-24 02:37:40.505174: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f100 of size 256
2019-01-24 02:37:40.505178: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f200 of size 256
2019-01-24 02:37:40.505181: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f300 of size 256
2019-01-24 02:37:40.505185: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f400 of size 256
2019-01-24 02:37:40.505188: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f500 of size 256
2019-01-24 02:37:40.505192: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f600 of size 256
2019-01-24 02:37:40.505195: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f700 of size 256
2019-01-24 02:37:40.505199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f800 of size 256
2019-01-24 02:37:40.505202: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696f900 of size 256
2019-01-24 02:37:40.505205: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696fa00 of size 256
2019-01-24 02:37:40.505209: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696fb00 of size 256
2019-01-24 02:37:40.505212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696fc00 of size 256
2019-01-24 02:37:40.505216: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696fd00 of size 256
2019-01-24 02:37:40.505219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696fe00 of size 256
2019-01-24 02:37:40.505223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1696ff00 of size 256
2019-01-24 02:37:40.505226: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970000 of size 256
2019-01-24 02:37:40.505229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970100 of size 256
2019-01-24 02:37:40.505233: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970200 of size 256
2019-01-24 02:37:40.505236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970300 of size 256
2019-01-24 02:37:40.505240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970400 of size 256
2019-01-24 02:37:40.505243: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970500 of size 256
2019-01-24 02:37:40.505246: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970600 of size 256
2019-01-24 02:37:40.505250: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970700 of size 256
2019-01-24 02:37:40.505253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970800 of size 256
2019-01-24 02:37:40.505257: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970900 of size 256
2019-01-24 02:37:40.505260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970a00 of size 256
2019-01-24 02:37:40.505264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970b00 of size 256
2019-01-24 02:37:40.505267: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970c00 of size 256
2019-01-24 02:37:40.505270: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970d00 of size 256
2019-01-24 02:37:40.505274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970e00 of size 256
2019-01-24 02:37:40.505277: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16970f00 of size 256
2019-01-24 02:37:40.505281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971000 of size 256
2019-01-24 02:37:40.505284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971100 of size 256
2019-01-24 02:37:40.505287: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971200 of size 256
2019-01-24 02:37:40.505291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971300 of size 256
2019-01-24 02:37:40.505294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971400 of size 256
2019-01-24 02:37:40.505298: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971500 of size 256
2019-01-24 02:37:40.505301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971600 of size 256
2019-01-24 02:37:40.505305: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971700 of size 256
2019-01-24 02:37:40.505308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971800 of size 256
2019-01-24 02:37:40.505312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971900 of size 256
2019-01-24 02:37:40.505315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971a00 of size 256
2019-01-24 02:37:40.505318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971b00 of size 256
2019-01-24 02:37:40.505321: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971c00 of size 256
2019-01-24 02:37:40.505325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971d00 of size 256
2019-01-24 02:37:40.505328: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971e00 of size 256
2019-01-24 02:37:40.505332: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16971f00 of size 256
2019-01-24 02:37:40.505335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972000 of size 256
2019-01-24 02:37:40.505339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972100 of size 256
2019-01-24 02:37:40.505342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972200 of size 256
2019-01-24 02:37:40.505345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972300 of size 256
2019-01-24 02:37:40.505349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972400 of size 256
2019-01-24 02:37:40.505352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972500 of size 256
2019-01-24 02:37:40.505356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972600 of size 256
2019-01-24 02:37:40.505359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972700 of size 256
2019-01-24 02:37:40.505362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972800 of size 256
2019-01-24 02:37:40.505365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972900 of size 256
2019-01-24 02:37:40.505369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972a00 of size 256
2019-01-24 02:37:40.505372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972b00 of size 256
2019-01-24 02:37:40.505376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972c00 of size 256
2019-01-24 02:37:40.505379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972d00 of size 256
2019-01-24 02:37:40.505382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972e00 of size 256
2019-01-24 02:37:40.505386: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16972f00 of size 256
2019-01-24 02:37:40.505389: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973000 of size 256
2019-01-24 02:37:40.505393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973100 of size 256
2019-01-24 02:37:40.505396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973200 of size 256
2019-01-24 02:37:40.505400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973300 of size 256
2019-01-24 02:37:40.505403: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973400 of size 256
2019-01-24 02:37:40.505406: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973500 of size 256
2019-01-24 02:37:40.505410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973600 of size 256
2019-01-24 02:37:40.505413: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973700 of size 256
2019-01-24 02:37:40.505416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973800 of size 256
2019-01-24 02:37:40.505420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973900 of size 256
2019-01-24 02:37:40.505423: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973a00 of size 256
2019-01-24 02:37:40.505427: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973b00 of size 256
2019-01-24 02:37:40.505430: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973c00 of size 256
2019-01-24 02:37:40.505433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973d00 of size 256
2019-01-24 02:37:40.505437: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973e00 of size 256
2019-01-24 02:37:40.505440: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16973f00 of size 256
2019-01-24 02:37:40.505444: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974000 of size 256
2019-01-24 02:37:40.505447: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974100 of size 256
2019-01-24 02:37:40.505451: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974200 of size 256
2019-01-24 02:37:40.505454: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974300 of size 256
2019-01-24 02:37:40.505457: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974400 of size 256
2019-01-24 02:37:40.505461: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974500 of size 256
2019-01-24 02:37:40.505464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974600 of size 256
2019-01-24 02:37:40.505468: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974700 of size 256
2019-01-24 02:37:40.505471: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974800 of size 256
2019-01-24 02:37:40.505474: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974900 of size 256
2019-01-24 02:37:40.505478: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974a00 of size 256
2019-01-24 02:37:40.505481: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974b00 of size 256
2019-01-24 02:37:40.505485: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974c00 of size 256
2019-01-24 02:37:40.505488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974d00 of size 256
2019-01-24 02:37:40.505491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974e00 of size 256
2019-01-24 02:37:40.505495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16974f00 of size 256
2019-01-24 02:37:40.505498: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975000 of size 256
2019-01-24 02:37:40.505501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975100 of size 256
2019-01-24 02:37:40.505505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975200 of size 256
2019-01-24 02:37:40.505508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975300 of size 256
2019-01-24 02:37:40.505512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975400 of size 256
2019-01-24 02:37:40.505515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975500 of size 256
2019-01-24 02:37:40.505518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975600 of size 256
2019-01-24 02:37:40.505522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975700 of size 256
2019-01-24 02:37:40.505525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975800 of size 256
2019-01-24 02:37:40.505529: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975900 of size 256
2019-01-24 02:37:40.505532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975a00 of size 256
2019-01-24 02:37:40.505535: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975b00 of size 256
2019-01-24 02:37:40.505539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975c00 of size 256
2019-01-24 02:37:40.505542: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975d00 of size 256
2019-01-24 02:37:40.505546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975e00 of size 256
2019-01-24 02:37:40.505549: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16975f00 of size 256
2019-01-24 02:37:40.505555: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976000 of size 256
2019-01-24 02:37:40.505558: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976100 of size 256
2019-01-24 02:37:40.505562: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976200 of size 256
2019-01-24 02:37:40.505565: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976300 of size 256
2019-01-24 02:37:40.505569: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976400 of size 256
2019-01-24 02:37:40.505572: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976500 of size 256
2019-01-24 02:37:40.505575: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976600 of size 256
2019-01-24 02:37:40.505579: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976700 of size 256
2019-01-24 02:37:40.505582: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976800 of size 256
2019-01-24 02:37:40.505586: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976900 of size 256
2019-01-24 02:37:40.505589: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976a00 of size 256
2019-01-24 02:37:40.505593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976b00 of size 256
2019-01-24 02:37:40.505596: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976c00 of size 256
2019-01-24 02:37:40.505599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976d00 of size 256
2019-01-24 02:37:40.505603: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976e00 of size 256
2019-01-24 02:37:40.505606: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16976f00 of size 256
2019-01-24 02:37:40.505610: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977000 of size 256
2019-01-24 02:37:40.505613: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977100 of size 256
2019-01-24 02:37:40.505617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977200 of size 256
2019-01-24 02:37:40.505620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977300 of size 256
2019-01-24 02:37:40.505623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977400 of size 256
2019-01-24 02:37:40.505627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977500 of size 256
2019-01-24 02:37:40.505630: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977600 of size 256
2019-01-24 02:37:40.505634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977700 of size 256
2019-01-24 02:37:40.505637: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977800 of size 256
2019-01-24 02:37:40.505640: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977900 of size 256
2019-01-24 02:37:40.505644: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977a00 of size 256
2019-01-24 02:37:40.505647: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977b00 of size 256
2019-01-24 02:37:40.505651: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977c00 of size 256
2019-01-24 02:37:40.505654: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977d00 of size 256
2019-01-24 02:37:40.505658: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977e00 of size 256
2019-01-24 02:37:40.505661: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16977f00 of size 256
2019-01-24 02:37:40.505664: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978000 of size 256
2019-01-24 02:37:40.505668: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978100 of size 256
2019-01-24 02:37:40.505671: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978200 of size 256
2019-01-24 02:37:40.505675: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978300 of size 256
2019-01-24 02:37:40.505678: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978400 of size 256
2019-01-24 02:37:40.505686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978500 of size 256
2019-01-24 02:37:40.505689: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978600 of size 256
2019-01-24 02:37:40.505693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978700 of size 256
2019-01-24 02:37:40.505696: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978800 of size 256
2019-01-24 02:37:40.505700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978900 of size 256
2019-01-24 02:37:40.505703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978a00 of size 256
2019-01-24 02:37:40.513392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978b00 of size 256
2019-01-24 02:37:40.513418: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978c00 of size 256
2019-01-24 02:37:40.513422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978d00 of size 256
2019-01-24 02:37:40.513425: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978e00 of size 256
2019-01-24 02:37:40.513429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16978f00 of size 256
2019-01-24 02:37:40.513432: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979000 of size 256
2019-01-24 02:37:40.513435: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979100 of size 256
2019-01-24 02:37:40.513439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979200 of size 256
2019-01-24 02:37:40.513442: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979300 of size 256
2019-01-24 02:37:40.513445: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979400 of size 256
2019-01-24 02:37:40.513448: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979500 of size 256
2019-01-24 02:37:40.513452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979600 of size 256
2019-01-24 02:37:40.513455: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979700 of size 256
2019-01-24 02:37:40.513459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979800 of size 256
2019-01-24 02:37:40.513462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979900 of size 256
2019-01-24 02:37:40.513466: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979a00 of size 256
2019-01-24 02:37:40.513469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979b00 of size 256
2019-01-24 02:37:40.513473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979c00 of size 256
2019-01-24 02:37:40.513476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979d00 of size 256
2019-01-24 02:37:40.513480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979e00 of size 256
2019-01-24 02:37:40.513483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16979f00 of size 256
2019-01-24 02:37:40.513486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a000 of size 256
2019-01-24 02:37:40.513490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a100 of size 256
2019-01-24 02:37:40.513493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a200 of size 256
2019-01-24 02:37:40.513497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a300 of size 256
2019-01-24 02:37:40.513500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a400 of size 256
2019-01-24 02:37:40.513504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a500 of size 256
2019-01-24 02:37:40.513507: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a600 of size 256
2019-01-24 02:37:40.513511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a700 of size 256
2019-01-24 02:37:40.513514: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a800 of size 256
2019-01-24 02:37:40.513517: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697a900 of size 256
2019-01-24 02:37:40.513521: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697aa00 of size 256
2019-01-24 02:37:40.513524: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ab00 of size 256
2019-01-24 02:37:40.513528: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ac00 of size 256
2019-01-24 02:37:40.513531: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ad00 of size 256
2019-01-24 02:37:40.513535: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ae00 of size 256
2019-01-24 02:37:40.513538: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697af00 of size 256
2019-01-24 02:37:40.513542: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b000 of size 256
2019-01-24 02:37:40.513545: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b100 of size 256
2019-01-24 02:37:40.513549: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b200 of size 256
2019-01-24 02:37:40.513552: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b300 of size 256
2019-01-24 02:37:40.513556: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b400 of size 256
2019-01-24 02:37:40.513559: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b500 of size 256
2019-01-24 02:37:40.513562: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b600 of size 256
2019-01-24 02:37:40.513566: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b700 of size 256
2019-01-24 02:37:40.513569: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b800 of size 256
2019-01-24 02:37:40.513573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697b900 of size 256
2019-01-24 02:37:40.513576: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ba00 of size 256
2019-01-24 02:37:40.513580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697bb00 of size 256
2019-01-24 02:37:40.513583: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697bc00 of size 256
2019-01-24 02:37:40.513587: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697bd00 of size 256
2019-01-24 02:37:40.513590: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697be00 of size 256
2019-01-24 02:37:40.513593: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697bf00 of size 256
2019-01-24 02:37:40.513597: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c000 of size 256
2019-01-24 02:37:40.513600: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c100 of size 256
2019-01-24 02:37:40.513604: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c200 of size 256
2019-01-24 02:37:40.513607: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c300 of size 256
2019-01-24 02:37:40.513610: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c400 of size 256
2019-01-24 02:37:40.513614: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c500 of size 256
2019-01-24 02:37:40.513617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c600 of size 256
2019-01-24 02:37:40.513621: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c700 of size 256
2019-01-24 02:37:40.513624: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c800 of size 256
2019-01-24 02:37:40.513628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697c900 of size 256
2019-01-24 02:37:40.513631: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ca00 of size 256
2019-01-24 02:37:40.513634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697cb00 of size 256
2019-01-24 02:37:40.513638: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697cc00 of size 256
2019-01-24 02:37:40.513641: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697cd00 of size 256
2019-01-24 02:37:40.513645: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ce00 of size 256
2019-01-24 02:37:40.513648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697cf00 of size 256
2019-01-24 02:37:40.513652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d000 of size 256
2019-01-24 02:37:40.513655: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d100 of size 256
2019-01-24 02:37:40.513658: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d200 of size 256
2019-01-24 02:37:40.513662: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d300 of size 256
2019-01-24 02:37:40.513665: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d400 of size 256
2019-01-24 02:37:40.513669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d500 of size 256
2019-01-24 02:37:40.513672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d600 of size 256
2019-01-24 02:37:40.513675: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d700 of size 256
2019-01-24 02:37:40.513679: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d800 of size 256
2019-01-24 02:37:40.513686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697d900 of size 256
2019-01-24 02:37:40.513690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697da00 of size 256
2019-01-24 02:37:40.513693: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697db00 of size 256
2019-01-24 02:37:40.513697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697dc00 of size 256
2019-01-24 02:37:40.513700: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697dd00 of size 256
2019-01-24 02:37:40.513703: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697de00 of size 256
2019-01-24 02:37:40.513707: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697df00 of size 256
2019-01-24 02:37:40.513710: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e000 of size 256
2019-01-24 02:37:40.513714: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e100 of size 256
2019-01-24 02:37:40.513717: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e200 of size 256
2019-01-24 02:37:40.513720: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e300 of size 256
2019-01-24 02:37:40.513724: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e400 of size 256
2019-01-24 02:37:40.513727: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e500 of size 256
2019-01-24 02:37:40.513731: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e600 of size 256
2019-01-24 02:37:40.513734: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e700 of size 256
2019-01-24 02:37:40.513737: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e800 of size 256
2019-01-24 02:37:40.513741: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697e900 of size 256
2019-01-24 02:37:40.513744: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ea00 of size 256
2019-01-24 02:37:40.513748: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697eb00 of size 256
2019-01-24 02:37:40.513751: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ec00 of size 256
2019-01-24 02:37:40.513755: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ed00 of size 256
2019-01-24 02:37:40.513758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ee00 of size 256
2019-01-24 02:37:40.513761: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ef00 of size 256
2019-01-24 02:37:40.513764: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f000 of size 256
2019-01-24 02:37:40.513768: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f100 of size 256
2019-01-24 02:37:40.513771: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f200 of size 256
2019-01-24 02:37:40.513775: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f300 of size 256
2019-01-24 02:37:40.513778: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f400 of size 256
2019-01-24 02:37:40.513781: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f500 of size 256
2019-01-24 02:37:40.513785: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f600 of size 256
2019-01-24 02:37:40.513788: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f700 of size 256
2019-01-24 02:37:40.513792: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f800 of size 256
2019-01-24 02:37:40.513795: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697f900 of size 256
2019-01-24 02:37:40.513798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697fa00 of size 256
2019-01-24 02:37:40.513802: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697fb00 of size 256
2019-01-24 02:37:40.513805: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697fc00 of size 256
2019-01-24 02:37:40.513808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697fd00 of size 256
2019-01-24 02:37:40.513812: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697fe00 of size 256
2019-01-24 02:37:40.513815: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1697ff00 of size 256
2019-01-24 02:37:40.513818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980000 of size 256
2019-01-24 02:37:40.513821: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980100 of size 256
2019-01-24 02:37:40.513825: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980200 of size 256
2019-01-24 02:37:40.513828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980300 of size 256
2019-01-24 02:37:40.513832: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980400 of size 256
2019-01-24 02:37:40.513835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980500 of size 256
2019-01-24 02:37:40.513838: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980600 of size 256
2019-01-24 02:37:40.513842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980700 of size 256
2019-01-24 02:37:40.513845: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980800 of size 256
2019-01-24 02:37:40.513849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980900 of size 256
2019-01-24 02:37:40.513852: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980a00 of size 256
2019-01-24 02:37:40.513856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980b00 of size 256
2019-01-24 02:37:40.513859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980c00 of size 256
2019-01-24 02:37:40.513862: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980d00 of size 256
2019-01-24 02:37:40.513866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980e00 of size 256
2019-01-24 02:37:40.513869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16980f00 of size 256
2019-01-24 02:37:40.513873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981000 of size 256
2019-01-24 02:37:40.513876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981100 of size 256
2019-01-24 02:37:40.513879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981200 of size 256
2019-01-24 02:37:40.513883: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981300 of size 256
2019-01-24 02:37:40.513886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981400 of size 256
2019-01-24 02:37:40.513890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981500 of size 256
2019-01-24 02:37:40.513893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981600 of size 256
2019-01-24 02:37:40.513897: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981700 of size 256
2019-01-24 02:37:40.513900: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981800 of size 256
2019-01-24 02:37:40.513903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981900 of size 256
2019-01-24 02:37:40.513907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981a00 of size 256
2019-01-24 02:37:40.513910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981b00 of size 256
2019-01-24 02:37:40.513914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981c00 of size 256
2019-01-24 02:37:40.513917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981d00 of size 256
2019-01-24 02:37:40.513920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981e00 of size 256
2019-01-24 02:37:40.513924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16981f00 of size 256
2019-01-24 02:37:40.513927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982000 of size 256
2019-01-24 02:37:40.513931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982100 of size 256
2019-01-24 02:37:40.513934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982200 of size 256
2019-01-24 02:37:40.513938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982300 of size 256
2019-01-24 02:37:40.513941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982400 of size 256
2019-01-24 02:37:40.513944: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982500 of size 256
2019-01-24 02:37:40.513948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982600 of size 256
2019-01-24 02:37:40.513951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982700 of size 256
2019-01-24 02:37:40.513955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982800 of size 256
2019-01-24 02:37:40.513958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982900 of size 256
2019-01-24 02:37:40.513962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982a00 of size 256
2019-01-24 02:37:40.513965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982b00 of size 256
2019-01-24 02:37:40.513968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982c00 of size 256
2019-01-24 02:37:40.513972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982d00 of size 256
2019-01-24 02:37:40.513975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982e00 of size 256
2019-01-24 02:37:40.513979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16982f00 of size 256
2019-01-24 02:37:40.513982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983000 of size 256
2019-01-24 02:37:40.513985: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983100 of size 256
2019-01-24 02:37:40.513989: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983200 of size 256
2019-01-24 02:37:40.513992: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983300 of size 256
2019-01-24 02:37:40.513996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983400 of size 256
2019-01-24 02:37:40.513999: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983500 of size 256
2019-01-24 02:37:40.514003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983600 of size 256
2019-01-24 02:37:40.522307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983700 of size 256
2019-01-24 02:37:40.522316: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983800 of size 256
2019-01-24 02:37:40.522319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983900 of size 256
2019-01-24 02:37:40.522322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983a00 of size 256
2019-01-24 02:37:40.522325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983b00 of size 256
2019-01-24 02:37:40.522328: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983c00 of size 256
2019-01-24 02:37:40.522331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983d00 of size 256
2019-01-24 02:37:40.522335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983e00 of size 256
2019-01-24 02:37:40.522339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16983f00 of size 16128
2019-01-24 02:37:40.522342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16987e00 of size 16128
2019-01-24 02:37:40.522345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1698bd00 of size 16128
2019-01-24 02:37:40.522348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1698fc00 of size 16128
2019-01-24 02:37:40.522352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16993b00 of size 16128
2019-01-24 02:37:40.522354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16997a00 of size 16128
2019-01-24 02:37:40.522358: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699b900 of size 256
2019-01-24 02:37:40.522361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699ba00 of size 256
2019-01-24 02:37:40.522365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699bb00 of size 256
2019-01-24 02:37:40.522368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699bc00 of size 2816
2019-01-24 02:37:40.522372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699c700 of size 256
2019-01-24 02:37:40.522375: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699c800 of size 256
2019-01-24 02:37:40.522379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699c900 of size 256
2019-01-24 02:37:40.522382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699ca00 of size 2816
2019-01-24 02:37:40.522386: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699d500 of size 256
2019-01-24 02:37:40.522389: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699d600 of size 256
2019-01-24 02:37:40.522393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699d700 of size 256
2019-01-24 02:37:40.522396: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699d800 of size 4352
2019-01-24 02:37:40.522400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699e900 of size 4352
2019-01-24 02:37:40.522404: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1699fa00 of size 11520
2019-01-24 02:37:40.522407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169a2700 of size 7168
2019-01-24 02:37:40.522411: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169a4300 of size 7168
2019-01-24 02:37:40.522414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169a5f00 of size 7168
2019-01-24 02:37:40.522418: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169a7b00 of size 7168
2019-01-24 02:37:40.522421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169a9700 of size 7168
2019-01-24 02:37:40.522425: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ab300 of size 256
2019-01-24 02:37:40.522428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ab400 of size 2048
2019-01-24 02:37:40.522432: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169abc00 of size 256
2019-01-24 02:37:40.522435: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169abd00 of size 256
2019-01-24 02:37:40.522439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169abe00 of size 256
2019-01-24 02:37:40.522442: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169abf00 of size 256
2019-01-24 02:37:40.522446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ac000 of size 256
2019-01-24 02:37:40.522449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ac100 of size 256
2019-01-24 02:37:40.522453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ac200 of size 256
2019-01-24 02:37:40.522456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ac300 of size 1536
2019-01-24 02:37:40.522460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ac900 of size 256
2019-01-24 02:37:40.522463: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169aca00 of size 256
2019-01-24 02:37:40.522467: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169acb00 of size 256
2019-01-24 02:37:40.522470: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169acc00 of size 768
2019-01-24 02:37:40.522473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169acf00 of size 256
2019-01-24 02:37:40.522477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ad000 of size 256
2019-01-24 02:37:40.522480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ad100 of size 256
2019-01-24 02:37:40.522484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ad200 of size 256
2019-01-24 02:37:40.522487: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ad300 of size 2816
2019-01-24 02:37:40.522491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ade00 of size 256
2019-01-24 02:37:40.522494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169adf00 of size 256
2019-01-24 02:37:40.522497: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ae000 of size 256
2019-01-24 02:37:40.522501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ae100 of size 256
2019-01-24 02:37:40.522504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ae200 of size 2816
2019-01-24 02:37:40.522508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169aed00 of size 256
2019-01-24 02:37:40.522511: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169aee00 of size 2816
2019-01-24 02:37:40.522515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169af900 of size 256
2019-01-24 02:37:40.522518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169afa00 of size 256
2019-01-24 02:37:40.522522: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169afb00 of size 256
2019-01-24 02:37:40.522525: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169afc00 of size 256
2019-01-24 02:37:40.522528: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169afd00 of size 256
2019-01-24 02:37:40.522532: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169afe00 of size 256
2019-01-24 02:37:40.522535: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169aff00 of size 2816
2019-01-24 02:37:40.522539: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169b0a00 of size 256
2019-01-24 02:37:40.522542: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169b0b00 of size 256
2019-01-24 02:37:40.522546: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169b0c00 of size 2816
2019-01-24 02:37:40.522549: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169b1700 of size 18944
2019-01-24 02:37:40.522553: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169b6100 of size 18944
2019-01-24 02:37:40.522556: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bab00 of size 256
2019-01-24 02:37:40.522560: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bac00 of size 256
2019-01-24 02:37:40.522563: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bad00 of size 256
2019-01-24 02:37:40.522566: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bae00 of size 256
2019-01-24 02:37:40.522570: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169baf00 of size 256
2019-01-24 02:37:40.522573: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bb000 of size 256
2019-01-24 02:37:40.522576: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bb100 of size 2816
2019-01-24 02:37:40.522580: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bbc00 of size 256
2019-01-24 02:37:40.522583: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bbd00 of size 256
2019-01-24 02:37:40.522587: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bbe00 of size 8448
2019-01-24 02:37:40.522590: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169bdf00 of size 8448
2019-01-24 02:37:40.522594: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0000 of size 256
2019-01-24 02:37:40.522597: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0100 of size 256
2019-01-24 02:37:40.522601: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0200 of size 256
2019-01-24 02:37:40.522604: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0300 of size 256
2019-01-24 02:37:40.522608: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0400 of size 256
2019-01-24 02:37:40.522611: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0500 of size 256
2019-01-24 02:37:40.522615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0600 of size 256
2019-01-24 02:37:40.522618: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0700 of size 256
2019-01-24 02:37:40.522621: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0800 of size 256
2019-01-24 02:37:40.522625: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0900 of size 256
2019-01-24 02:37:40.522628: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0a00 of size 256
2019-01-24 02:37:40.522632: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0b00 of size 256
2019-01-24 02:37:40.522635: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c0c00 of size 2816
2019-01-24 02:37:40.522639: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1700 of size 256
2019-01-24 02:37:40.522642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1800 of size 256
2019-01-24 02:37:40.522646: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1900 of size 256
2019-01-24 02:37:40.522649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1a00 of size 256
2019-01-24 02:37:40.522652: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1b00 of size 256
2019-01-24 02:37:40.522656: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1c00 of size 256
2019-01-24 02:37:40.522659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1d00 of size 256
2019-01-24 02:37:40.522663: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1e00 of size 256
2019-01-24 02:37:40.522666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c1f00 of size 256
2019-01-24 02:37:40.522670: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2000 of size 256
2019-01-24 02:37:40.522673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2100 of size 256
2019-01-24 02:37:40.522677: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2200 of size 256
2019-01-24 02:37:40.522680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2300 of size 256
2019-01-24 02:37:40.522684: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2400 of size 256
2019-01-24 02:37:40.522687: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2500 of size 256
2019-01-24 02:37:40.522690: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2600 of size 256
2019-01-24 02:37:40.522694: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2700 of size 256
2019-01-24 02:37:40.522697: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2800 of size 256
2019-01-24 02:37:40.522701: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c2900 of size 2048
2019-01-24 02:37:40.522704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c3100 of size 1536
2019-01-24 02:37:40.522708: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c3700 of size 2816
2019-01-24 02:37:40.522711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4200 of size 256
2019-01-24 02:37:40.522715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4300 of size 512
2019-01-24 02:37:40.522718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4500 of size 256
2019-01-24 02:37:40.522722: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4600 of size 256
2019-01-24 02:37:40.522725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4700 of size 256
2019-01-24 02:37:40.522729: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4800 of size 256
2019-01-24 02:37:40.522732: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4900 of size 256
2019-01-24 02:37:40.522736: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4a00 of size 256
2019-01-24 02:37:40.522739: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4b00 of size 256
2019-01-24 02:37:40.522743: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4c00 of size 256
2019-01-24 02:37:40.522746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4d00 of size 256
2019-01-24 02:37:40.522750: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4e00 of size 256
2019-01-24 02:37:40.522753: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c4f00 of size 2816
2019-01-24 02:37:40.522757: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c5a00 of size 256
2019-01-24 02:37:40.522760: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c5b00 of size 256
2019-01-24 02:37:40.522763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c5c00 of size 256
2019-01-24 02:37:40.522767: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c5d00 of size 256
2019-01-24 02:37:40.522770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c5e00 of size 256
2019-01-24 02:37:40.522774: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c5f00 of size 2816
2019-01-24 02:37:40.522777: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c6a00 of size 256
2019-01-24 02:37:40.522781: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c6b00 of size 256
2019-01-24 02:37:40.522784: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c6c00 of size 256
2019-01-24 02:37:40.522788: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c6d00 of size 256
2019-01-24 02:37:40.522791: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c6e00 of size 256
2019-01-24 02:37:40.522795: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c6f00 of size 256
2019-01-24 02:37:40.522798: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7000 of size 256
2019-01-24 02:37:40.522801: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7100 of size 256
2019-01-24 02:37:40.522804: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7200 of size 256
2019-01-24 02:37:40.522808: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7300 of size 256
2019-01-24 02:37:40.522811: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7400 of size 256
2019-01-24 02:37:40.522815: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7500 of size 256
2019-01-24 02:37:40.522818: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7600 of size 256
2019-01-24 02:37:40.522822: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7700 of size 256
2019-01-24 02:37:40.522825: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7800 of size 512
2019-01-24 02:37:40.522829: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7a00 of size 256
2019-01-24 02:37:40.522832: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7b00 of size 256
2019-01-24 02:37:40.522835: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7c00 of size 512
2019-01-24 02:37:40.522839: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7e00 of size 256
2019-01-24 02:37:40.522842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c7f00 of size 1280
2019-01-24 02:37:40.522846: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8400 of size 256
2019-01-24 02:37:40.522849: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8500 of size 256
2019-01-24 02:37:40.522853: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8600 of size 256
2019-01-24 02:37:40.522856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8700 of size 256
2019-01-24 02:37:40.522859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8800 of size 256
2019-01-24 02:37:40.522863: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8900 of size 256
2019-01-24 02:37:40.522866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8a00 of size 256
2019-01-24 02:37:40.522870: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8b00 of size 256
2019-01-24 02:37:40.522873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c8c00 of size 2816
2019-01-24 02:37:40.522877: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9700 of size 256
2019-01-24 02:37:40.522880: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9800 of size 256
2019-01-24 02:37:40.522884: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9900 of size 256
2019-01-24 02:37:40.522887: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9a00 of size 256
2019-01-24 02:37:40.522890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9b00 of size 256
2019-01-24 02:37:40.522894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9c00 of size 256
2019-01-24 02:37:40.522897: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169c9d00 of size 2816
2019-01-24 02:37:40.522901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ca800 of size 256
2019-01-24 02:37:40.522904: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ca900 of size 256
2019-01-24 02:37:40.522908: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169caa00 of size 256
2019-01-24 02:37:40.522911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cab00 of size 256
2019-01-24 02:37:40.522914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cac00 of size 512
2019-01-24 02:37:40.528081: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cae00 of size 512
2019-01-24 02:37:40.528089: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cb000 of size 512
2019-01-24 02:37:40.528092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cb200 of size 512
2019-01-24 02:37:40.528095: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cb400 of size 512
2019-01-24 02:37:40.528098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cb600 of size 512
2019-01-24 02:37:40.528101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cb800 of size 512
2019-01-24 02:37:40.528104: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cba00 of size 512
2019-01-24 02:37:40.528108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cbc00 of size 512
2019-01-24 02:37:40.528111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cbe00 of size 512
2019-01-24 02:37:40.528114: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cc000 of size 512
2019-01-24 02:37:40.528117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cc200 of size 512
2019-01-24 02:37:40.528121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cc400 of size 512
2019-01-24 02:37:40.528124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cc600 of size 512
2019-01-24 02:37:40.528127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cc800 of size 512
2019-01-24 02:37:40.528131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cca00 of size 512
2019-01-24 02:37:40.528134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ccc00 of size 512
2019-01-24 02:37:40.528138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cce00 of size 512
2019-01-24 02:37:40.528141: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cd000 of size 512
2019-01-24 02:37:40.528144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cd200 of size 512
2019-01-24 02:37:40.528148: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cd400 of size 512
2019-01-24 02:37:40.528151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cd600 of size 512
2019-01-24 02:37:40.528155: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cd800 of size 512
2019-01-24 02:37:40.528158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cda00 of size 512
2019-01-24 02:37:40.528162: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cdc00 of size 512
2019-01-24 02:37:40.528165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cde00 of size 512
2019-01-24 02:37:40.528168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ce000 of size 512
2019-01-24 02:37:40.528172: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ce200 of size 512
2019-01-24 02:37:40.528175: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ce400 of size 512
2019-01-24 02:37:40.528179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ce600 of size 512
2019-01-24 02:37:40.528182: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ce800 of size 512
2019-01-24 02:37:40.528186: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cea00 of size 512
2019-01-24 02:37:40.528189: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cec00 of size 512
2019-01-24 02:37:40.528192: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cee00 of size 512
2019-01-24 02:37:40.528196: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cf000 of size 512
2019-01-24 02:37:40.528199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cf200 of size 512
2019-01-24 02:37:40.528203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cf400 of size 512
2019-01-24 02:37:40.528206: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cf600 of size 512
2019-01-24 02:37:40.528210: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cf800 of size 512
2019-01-24 02:37:40.528213: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cfa00 of size 512
2019-01-24 02:37:40.528217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cfc00 of size 512
2019-01-24 02:37:40.528220: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169cfe00 of size 512
2019-01-24 02:37:40.528223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0000 of size 512
2019-01-24 02:37:40.528227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0200 of size 512
2019-01-24 02:37:40.528230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0400 of size 512
2019-01-24 02:37:40.528234: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0600 of size 512
2019-01-24 02:37:40.528237: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0800 of size 512
2019-01-24 02:37:40.528240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0a00 of size 512
2019-01-24 02:37:40.528244: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0c00 of size 512
2019-01-24 02:37:40.528247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d0e00 of size 512
2019-01-24 02:37:40.528251: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d1000 of size 512
2019-01-24 02:37:40.528254: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d1200 of size 2816
2019-01-24 02:37:40.528258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d1d00 of size 512
2019-01-24 02:37:40.528261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d1f00 of size 512
2019-01-24 02:37:40.528264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d2100 of size 256
2019-01-24 02:37:40.528268: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d2200 of size 512
2019-01-24 02:37:40.528271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d2400 of size 256
2019-01-24 02:37:40.528275: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169d2500 of size 56576
2019-01-24 02:37:40.528278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169e0200 of size 56576
2019-01-24 02:37:40.528282: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169edf00 of size 56576
2019-01-24 02:37:40.528285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fbc00 of size 512
2019-01-24 02:37:40.528289: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fbe00 of size 2816
2019-01-24 02:37:40.528292: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fc900 of size 512
2019-01-24 02:37:40.528295: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fcb00 of size 512
2019-01-24 02:37:40.528299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fcd00 of size 512
2019-01-24 02:37:40.528302: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fcf00 of size 512
2019-01-24 02:37:40.528306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fd100 of size 256
2019-01-24 02:37:40.528309: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fd200 of size 512
2019-01-24 02:37:40.528312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fd400 of size 256
2019-01-24 02:37:40.528316: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169fd500 of size 8448
2019-01-24 02:37:40.528319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb169ff600 of size 8448
2019-01-24 02:37:40.528323: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a01700 of size 8448
2019-01-24 02:37:40.528326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a03800 of size 36864
2019-01-24 02:37:40.528330: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a0c800 of size 28416
2019-01-24 02:37:40.528334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a13700 of size 28416
2019-01-24 02:37:40.528337: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a1a600 of size 28416
2019-01-24 02:37:40.528341: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a21500 of size 28416
2019-01-24 02:37:40.528344: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a28400 of size 28416
2019-01-24 02:37:40.528347: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a2f300 of size 28416
2019-01-24 02:37:40.528351: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a36200 of size 28416
2019-01-24 02:37:40.528354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a3d100 of size 28416
2019-01-24 02:37:40.528358: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44000 of size 256
2019-01-24 02:37:40.528361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44100 of size 256
2019-01-24 02:37:40.528365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44200 of size 256
2019-01-24 02:37:40.528368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44300 of size 256
2019-01-24 02:37:40.528372: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44400 of size 256
2019-01-24 02:37:40.528375: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44500 of size 256
2019-01-24 02:37:40.528378: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44600 of size 256
2019-01-24 02:37:40.528382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44700 of size 256
2019-01-24 02:37:40.528385: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44800 of size 256
2019-01-24 02:37:40.528388: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44900 of size 256
2019-01-24 02:37:40.528392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44a00 of size 256
2019-01-24 02:37:40.528395: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44b00 of size 256
2019-01-24 02:37:40.528399: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44c00 of size 256
2019-01-24 02:37:40.528402: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44d00 of size 256
2019-01-24 02:37:40.528405: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44e00 of size 256
2019-01-24 02:37:40.528409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a44f00 of size 256
2019-01-24 02:37:40.528412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45000 of size 256
2019-01-24 02:37:40.528416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45100 of size 256
2019-01-24 02:37:40.528419: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45200 of size 256
2019-01-24 02:37:40.528422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45300 of size 256
2019-01-24 02:37:40.528426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45400 of size 256
2019-01-24 02:37:40.528429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45500 of size 256
2019-01-24 02:37:40.528432: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45600 of size 256
2019-01-24 02:37:40.528435: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45700 of size 256
2019-01-24 02:37:40.528439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45800 of size 256
2019-01-24 02:37:40.528442: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45900 of size 256
2019-01-24 02:37:40.528446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45a00 of size 256
2019-01-24 02:37:40.528449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45b00 of size 256
2019-01-24 02:37:40.528453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45c00 of size 256
2019-01-24 02:37:40.528456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45d00 of size 256
2019-01-24 02:37:40.528459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45e00 of size 256
2019-01-24 02:37:40.528463: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a45f00 of size 256
2019-01-24 02:37:40.528466: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46000 of size 256
2019-01-24 02:37:40.528469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46100 of size 256
2019-01-24 02:37:40.528473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46200 of size 256
2019-01-24 02:37:40.528476: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46300 of size 256
2019-01-24 02:37:40.528480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46400 of size 256
2019-01-24 02:37:40.528483: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46500 of size 256
2019-01-24 02:37:40.528486: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46600 of size 256
2019-01-24 02:37:40.528490: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46700 of size 256
2019-01-24 02:37:40.528493: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46800 of size 256
2019-01-24 02:37:40.528496: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46900 of size 256
2019-01-24 02:37:40.528500: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46a00 of size 256
2019-01-24 02:37:40.528503: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46b00 of size 256
2019-01-24 02:37:40.528507: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46c00 of size 256
2019-01-24 02:37:40.528510: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46d00 of size 512
2019-01-24 02:37:40.528513: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a46f00 of size 256
2019-01-24 02:37:40.528517: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47000 of size 256
2019-01-24 02:37:40.528520: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47100 of size 512
2019-01-24 02:37:40.528523: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47300 of size 256
2019-01-24 02:37:40.528527: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47400 of size 512
2019-01-24 02:37:40.528530: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47600 of size 256
2019-01-24 02:37:40.528534: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47700 of size 256
2019-01-24 02:37:40.528537: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47800 of size 512
2019-01-24 02:37:40.528540: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47a00 of size 256
2019-01-24 02:37:40.528544: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47b00 of size 256
2019-01-24 02:37:40.528547: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47c00 of size 512
2019-01-24 02:37:40.528551: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47e00 of size 256
2019-01-24 02:37:40.528554: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a47f00 of size 512
2019-01-24 02:37:40.528557: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48100 of size 256
2019-01-24 02:37:40.528561: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48200 of size 512
2019-01-24 02:37:40.528564: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48400 of size 256
2019-01-24 02:37:40.528568: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48500 of size 256
2019-01-24 02:37:40.528571: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48600 of size 512
2019-01-24 02:37:40.528574: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48800 of size 256
2019-01-24 02:37:40.528578: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48900 of size 512
2019-01-24 02:37:40.528581: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48b00 of size 256
2019-01-24 02:37:40.528585: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48c00 of size 512
2019-01-24 02:37:40.528588: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48e00 of size 256
2019-01-24 02:37:40.528591: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a48f00 of size 256
2019-01-24 02:37:40.528595: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49000 of size 512
2019-01-24 02:37:40.528598: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49200 of size 256
2019-01-24 02:37:40.528602: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49300 of size 512
2019-01-24 02:37:40.528605: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49500 of size 256
2019-01-24 02:37:40.528608: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49600 of size 256
2019-01-24 02:37:40.528612: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49700 of size 512
2019-01-24 02:37:40.528615: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49900 of size 256
2019-01-24 02:37:40.528619: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49a00 of size 256
2019-01-24 02:37:40.528622: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49b00 of size 512
2019-01-24 02:37:40.528625: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49d00 of size 256
2019-01-24 02:37:40.528629: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a49e00 of size 512
2019-01-24 02:37:40.528632: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a000 of size 256
2019-01-24 02:37:40.528636: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a100 of size 512
2019-01-24 02:37:40.528639: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a300 of size 256
2019-01-24 02:37:40.528642: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a400 of size 256
2019-01-24 02:37:40.528646: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a500 of size 512
2019-01-24 02:37:40.528649: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a700 of size 256
2019-01-24 02:37:40.528653: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4a800 of size 512
2019-01-24 02:37:40.528656: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4aa00 of size 256
2019-01-24 02:37:40.528659: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4ab00 of size 512
2019-01-24 02:37:40.528663: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4ad00 of size 256
2019-01-24 02:37:40.528666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4ae00 of size 256
2019-01-24 02:37:40.528670: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4af00 of size 512
2019-01-24 02:37:40.528673: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4b100 of size 2816
2019-01-24 02:37:40.528677: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4bc00 of size 512
2019-01-24 02:37:40.528680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4be00 of size 512
2019-01-24 02:37:40.534833: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4c000 of size 512
2019-01-24 02:37:40.534842: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4c200 of size 512
2019-01-24 02:37:40.534846: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4c400 of size 2816
2019-01-24 02:37:40.534850: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4cf00 of size 256
2019-01-24 02:37:40.534853: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4d000 of size 512
2019-01-24 02:37:40.534856: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4d200 of size 256
2019-01-24 02:37:40.534859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4d300 of size 256
2019-01-24 02:37:40.534862: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4d400 of size 512
2019-01-24 02:37:40.534866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4d600 of size 512
2019-01-24 02:37:40.534869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4d800 of size 512
2019-01-24 02:37:40.534872: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4da00 of size 512
2019-01-24 02:37:40.534876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4dc00 of size 512
2019-01-24 02:37:40.534879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4de00 of size 256
2019-01-24 02:37:40.534882: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4df00 of size 256
2019-01-24 02:37:40.534886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4e000 of size 2816
2019-01-24 02:37:40.534889: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4eb00 of size 512
2019-01-24 02:37:40.534893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4ed00 of size 256
2019-01-24 02:37:40.534896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4ee00 of size 2816
2019-01-24 02:37:40.534900: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a4f900 of size 2816
2019-01-24 02:37:40.534903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a50400 of size 768
2019-01-24 02:37:40.534907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a50700 of size 768
2019-01-24 02:37:40.534910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a50a00 of size 2816
2019-01-24 02:37:40.534914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a51500 of size 768
2019-01-24 02:37:40.534917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a51800 of size 768
2019-01-24 02:37:40.534920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a51b00 of size 768
2019-01-24 02:37:40.534924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a51e00 of size 2816
2019-01-24 02:37:40.534927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a52900 of size 256
2019-01-24 02:37:40.534931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a52a00 of size 768
2019-01-24 02:37:40.534934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a52d00 of size 256
2019-01-24 02:37:40.534938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a52e00 of size 2816
2019-01-24 02:37:40.534941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a53900 of size 2816
2019-01-24 02:37:40.534945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a54400 of size 256
2019-01-24 02:37:40.534948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a54500 of size 2816
2019-01-24 02:37:40.534952: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a55000 of size 2816
2019-01-24 02:37:40.534955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a55b00 of size 768
2019-01-24 02:37:40.534958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a55e00 of size 768
2019-01-24 02:37:40.534962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a56100 of size 768
2019-01-24 02:37:40.534965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a56400 of size 256
2019-01-24 02:37:40.534969: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a56500 of size 768
2019-01-24 02:37:40.534972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a56800 of size 2816
2019-01-24 02:37:40.534976: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a57300 of size 768
2019-01-24 02:37:40.534979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a57600 of size 256
2019-01-24 02:37:40.534982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a57700 of size 768
2019-01-24 02:37:40.534986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a57a00 of size 2816
2019-01-24 02:37:40.534989: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a58500 of size 256
2019-01-24 02:37:40.534993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a58600 of size 256
2019-01-24 02:37:40.534996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a58700 of size 768
2019-01-24 02:37:40.535000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a58a00 of size 768
2019-01-24 02:37:40.535003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a58d00 of size 768
2019-01-24 02:37:40.535006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a59000 of size 768
2019-01-24 02:37:40.535010: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a59300 of size 768
2019-01-24 02:37:40.535013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a59600 of size 256
2019-01-24 02:37:40.535017: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a59700 of size 768
2019-01-24 02:37:40.535020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a59a00 of size 256
2019-01-24 02:37:40.535023: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a59b00 of size 2816
2019-01-24 02:37:40.535027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5a600 of size 2816
2019-01-24 02:37:40.535030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5b100 of size 768
2019-01-24 02:37:40.535034: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5b400 of size 256
2019-01-24 02:37:40.535037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5b500 of size 768
2019-01-24 02:37:40.535040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5b800 of size 768
2019-01-24 02:37:40.535044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5bb00 of size 2816
2019-01-24 02:37:40.535047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5c600 of size 768
2019-01-24 02:37:40.535051: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5c900 of size 768
2019-01-24 02:37:40.535054: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5cc00 of size 256
2019-01-24 02:37:40.535057: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5cd00 of size 2816
2019-01-24 02:37:40.535061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5d800 of size 768
2019-01-24 02:37:40.535064: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5db00 of size 256
2019-01-24 02:37:40.535068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5dc00 of size 256
2019-01-24 02:37:40.535071: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5dd00 of size 2816
2019-01-24 02:37:40.535074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5e800 of size 2816
2019-01-24 02:37:40.535078: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5f300 of size 768
2019-01-24 02:37:40.535081: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5f600 of size 256
2019-01-24 02:37:40.535085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5f700 of size 768
2019-01-24 02:37:40.535088: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5fa00 of size 768
2019-01-24 02:37:40.535091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a5fd00 of size 768
2019-01-24 02:37:40.535095: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a60000 of size 2816
2019-01-24 02:37:40.535098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a60b00 of size 768
2019-01-24 02:37:40.535102: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a60e00 of size 256
2019-01-24 02:37:40.535105: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a60f00 of size 768
2019-01-24 02:37:40.535109: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a61200 of size 256
2019-01-24 02:37:40.535112: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a61300 of size 256
2019-01-24 02:37:40.535115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a61400 of size 2816
2019-01-24 02:37:40.535119: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a61f00 of size 768
2019-01-24 02:37:40.535122: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a62200 of size 768
2019-01-24 02:37:40.535126: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a62500 of size 768
2019-01-24 02:37:40.535129: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a62800 of size 768
2019-01-24 02:37:40.535133: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a62b00 of size 768
2019-01-24 02:37:40.535136: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a62e00 of size 256
2019-01-24 02:37:40.535139: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a62f00 of size 768
2019-01-24 02:37:40.535143: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a63200 of size 256
2019-01-24 02:37:40.535146: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a63300 of size 2816
2019-01-24 02:37:40.535150: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a63e00 of size 768
2019-01-24 02:37:40.535153: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a64100 of size 2816
2019-01-24 02:37:40.535157: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a64c00 of size 768
2019-01-24 02:37:40.535160: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a64f00 of size 768
2019-01-24 02:37:40.535163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a65200 of size 768
2019-01-24 02:37:40.535167: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a65500 of size 2816
2019-01-24 02:37:40.535170: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a66000 of size 768
2019-01-24 02:37:40.535174: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a66300 of size 256
2019-01-24 02:37:40.535177: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a66400 of size 256
2019-01-24 02:37:40.535180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a66500 of size 768
2019-01-24 02:37:40.535184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a66800 of size 2816
2019-01-24 02:37:40.535187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a67300 of size 256
2019-01-24 02:37:40.535191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a67400 of size 2816
2019-01-24 02:37:40.535194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a67f00 of size 2816
2019-01-24 02:37:40.535198: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a68a00 of size 256
2019-01-24 02:37:40.535201: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a68b00 of size 768
2019-01-24 02:37:40.535204: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a68e00 of size 768
2019-01-24 02:37:40.535208: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a69100 of size 2816
2019-01-24 02:37:40.535211: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a69c00 of size 768
2019-01-24 02:37:40.535215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a69f00 of size 768
2019-01-24 02:37:40.535218: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6a200 of size 768
2019-01-24 02:37:40.535222: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6a500 of size 256
2019-01-24 02:37:40.535225: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6a600 of size 256
2019-01-24 02:37:40.535228: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6a700 of size 2816
2019-01-24 02:37:40.535232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6b200 of size 768
2019-01-24 02:37:40.535234: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6b500 of size 256
2019-01-24 02:37:40.535238: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6b600 of size 2816
2019-01-24 02:37:40.535241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6c100 of size 768
2019-01-24 02:37:40.535245: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6c400 of size 768
2019-01-24 02:37:40.535248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6c700 of size 2816
2019-01-24 02:37:40.535252: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6d200 of size 768
2019-01-24 02:37:40.535255: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6d500 of size 768
2019-01-24 02:37:40.535258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6d800 of size 768
2019-01-24 02:37:40.535262: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6db00 of size 2816
2019-01-24 02:37:40.535265: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6e600 of size 256
2019-01-24 02:37:40.535269: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6e700 of size 768
2019-01-24 02:37:40.535272: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6ea00 of size 256
2019-01-24 02:37:40.535275: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6eb00 of size 2816
2019-01-24 02:37:40.535279: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a6f600 of size 2816
2019-01-24 02:37:40.535282: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a70100 of size 2816
2019-01-24 02:37:40.535286: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a70c00 of size 2816
2019-01-24 02:37:40.535289: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a71700 of size 768
2019-01-24 02:37:40.535293: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a71a00 of size 768
2019-01-24 02:37:40.535296: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a71d00 of size 768
2019-01-24 02:37:40.535299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a72000 of size 256
2019-01-24 02:37:40.535303: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a72100 of size 768
2019-01-24 02:37:40.535306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a72400 of size 2816
2019-01-24 02:37:40.535310: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a72f00 of size 768
2019-01-24 02:37:40.535313: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a73200 of size 256
2019-01-24 02:37:40.535317: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a73300 of size 2816
2019-01-24 02:37:40.535320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a73e00 of size 768
2019-01-24 02:37:40.535324: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a74100 of size 256
2019-01-24 02:37:40.535327: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a74200 of size 256
2019-01-24 02:37:40.535331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb16a74300 of size 10838
016
2019-01-24 02:37:40.535334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb174ca300 of size 10838
016
2019-01-24 02:37:40.535338: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb17f20300 of size 10838
016
2019-01-24 02:37:40.535341: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb18976300 of size 10838
016
2019-01-24 02:37:40.535345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb193cc300 of size 10838
016
2019-01-24 02:37:40.535348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb19e22300 of size 10838
016
2019-01-24 02:37:40.535352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1a878300 of size 10838
016
2019-01-24 02:37:40.535355: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1b2ce300 of size 10838
016
2019-01-24 02:37:40.535359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1bd24300 of size 10838
016
2019-01-24 02:37:40.535362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77a300 of size 768
2019-01-24 02:37:40.535366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77a600 of size 768
2019-01-24 02:37:40.535369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77a900 of size 768
2019-01-24 02:37:40.535373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77ac00 of size 2816
2019-01-24 02:37:40.535376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77b700 of size 768
2019-01-24 02:37:40.535379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77ba00 of size 768
2019-01-24 02:37:40.535383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77bd00 of size 256
2019-01-24 02:37:40.535386: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77be00 of size 2816
2019-01-24 02:37:40.535390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77c900 of size 768
2019-01-24 02:37:40.535393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77cc00 of size 256
2019-01-24 02:37:40.535397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77cd00 of size 2816
2019-01-24 02:37:40.535400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77d800 of size 2816
2019-01-24 02:37:40.535404: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77e300 of size 256
2019-01-24 02:37:40.535407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77e400 of size 768
2019-01-24 02:37:40.535410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77e700 of size 2816
2019-01-24 02:37:40.535414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77f200 of size 768
2019-01-24 02:37:40.535417: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77f500 of size 768
2019-01-24 02:37:40.535421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77f800 of size 768
2019-01-24 02:37:40.535424: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c77fb00 of size 2816
2019-01-24 02:37:40.535428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c780600 of size 768
2019-01-24 02:37:40.535431: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c780900 of size 256
2019-01-24 02:37:40.535434: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c780a00 of size 768
2019-01-24 02:37:40.535438: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c780d00 of size 256
2019-01-24 02:37:40.543815: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c780e00 of size 256
2019-01-24 02:37:40.543824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c780f00 of size 2816
2019-01-24 02:37:40.543828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c781a00 of size 2816
2019-01-24 02:37:40.543831: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c782500 of size 2816
2019-01-24 02:37:40.543834: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783000 of size 256
2019-01-24 02:37:40.543837: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783100 of size 768
2019-01-24 02:37:40.543840: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783400 of size 768
2019-01-24 02:37:40.543843: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783700 of size 768
2019-01-24 02:37:40.543847: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783a00 of size 256
2019-01-24 02:37:40.543850: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783b00 of size 768
2019-01-24 02:37:40.543854: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c783e00 of size 768
2019-01-24 02:37:40.543857: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784100 of size 256
2019-01-24 02:37:40.543861: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784200 of size 768
2019-01-24 02:37:40.543864: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784500 of size 256
2019-01-24 02:37:40.543867: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784600 of size 768
2019-01-24 02:37:40.543872: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784900 of size 768
2019-01-24 02:37:40.543875: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784c00 of size 768
2019-01-24 02:37:40.543879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c784f00 of size 768
2019-01-24 02:37:40.543882: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c785200 of size 2816
2019-01-24 02:37:40.543885: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c785d00 of size 768
2019-01-24 02:37:40.543889: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c786000 of size 256
2019-01-24 02:37:40.543892: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c786100 of size 768
2019-01-24 02:37:40.543895: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c786400 of size 2816
2019-01-24 02:37:40.543898: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c786f00 of size 256
2019-01-24 02:37:40.543902: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c787000 of size 13547
52
2019-01-24 02:37:40.543906: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d1c00 of size 256
2019-01-24 02:37:40.543909: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d1d00 of size 256
2019-01-24 02:37:40.543913: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d1e00 of size 256
2019-01-24 02:37:40.543916: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d1f00 of size 2816
2019-01-24 02:37:40.543920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d2a00 of size 256
2019-01-24 02:37:40.543923: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d2b00 of size 2816
2019-01-24 02:37:40.543927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d3600 of size 256
2019-01-24 02:37:40.543930: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d3700 of size 256
2019-01-24 02:37:40.543934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d3800 of size 256
2019-01-24 02:37:40.543937: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d3900 of size 256
2019-01-24 02:37:40.543940: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d3a00 of size 2816
2019-01-24 02:37:40.543944: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4500 of size 256
2019-01-24 02:37:40.543947: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4600 of size 256
2019-01-24 02:37:40.543951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4700 of size 256
2019-01-24 02:37:40.543954: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4800 of size 256
2019-01-24 02:37:40.543958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4900 of size 256
2019-01-24 02:37:40.543961: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4a00 of size 256
2019-01-24 02:37:40.543965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d4b00 of size 2816
2019-01-24 02:37:40.543968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d5600 of size 256
2019-01-24 02:37:40.543972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d5700 of size 256
2019-01-24 02:37:40.543975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d5800 of size 256
2019-01-24 02:37:40.543979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d5900 of size 2816
2019-01-24 02:37:40.543982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d6400 of size 256
2019-01-24 02:37:40.543986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d6500 of size 2816
2019-01-24 02:37:40.543989: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d7000 of size 256
2019-01-24 02:37:40.543993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d7100 of size 256
2019-01-24 02:37:40.543996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d7200 of size 256
2019-01-24 02:37:40.543999: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d7300 of size 256
2019-01-24 02:37:40.544003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d7400 of size 2816
2019-01-24 02:37:40.544006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d7f00 of size 256
2019-01-24 02:37:40.544010: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d8000 of size 256
2019-01-24 02:37:40.544013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d8100 of size 256
2019-01-24 02:37:40.544017: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d8200 of size 256
2019-01-24 02:37:40.544020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d8300 of size 1536
2019-01-24 02:37:40.544024: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d8900 of size 256
2019-01-24 02:37:40.544027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d8a00 of size 2816
2019-01-24 02:37:40.544030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d9500 of size 256
2019-01-24 02:37:40.544034: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d9600 of size 256
2019-01-24 02:37:40.544037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d9700 of size 256
2019-01-24 02:37:40.544041: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8d9800 of size 2816
2019-01-24 02:37:40.544044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8da300 of size 256
2019-01-24 02:37:40.544048: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8da400 of size 2816
2019-01-24 02:37:40.544051: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8daf00 of size 256
2019-01-24 02:37:40.544055: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8db000 of size 256
2019-01-24 02:37:40.544058: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8db100 of size 256
2019-01-24 02:37:40.544062: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8db200 of size 256
2019-01-24 02:37:40.544065: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8db300 of size 2816
2019-01-24 02:37:40.544068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dbe00 of size 256
2019-01-24 02:37:40.544072: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dbf00 of size 256
2019-01-24 02:37:40.544075: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dc000 of size 256
2019-01-24 02:37:40.544079: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dc100 of size 256
2019-01-24 02:37:40.544082: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dc200 of size 256
2019-01-24 02:37:40.544086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dc300 of size 2816
2019-01-24 02:37:40.544089: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dce00 of size 256
2019-01-24 02:37:40.544092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dcf00 of size 256
2019-01-24 02:37:40.544096: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dd000 of size 256
2019-01-24 02:37:40.544099: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dd100 of size 2816
2019-01-24 02:37:40.544103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ddc00 of size 256
2019-01-24 02:37:40.544106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ddd00 of size 2816
2019-01-24 02:37:40.544110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8de800 of size 256
2019-01-24 02:37:40.544113: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8de900 of size 256
2019-01-24 02:37:40.544117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dea00 of size 256
2019-01-24 02:37:40.544120: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8deb00 of size 256
2019-01-24 02:37:40.544123: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dec00 of size 256
2019-01-24 02:37:40.544127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ded00 of size 2816
2019-01-24 02:37:40.544130: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8df800 of size 256
2019-01-24 02:37:40.544134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8df900 of size 256
2019-01-24 02:37:40.544137: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dfa00 of size 256
2019-01-24 02:37:40.544141: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dfb00 of size 256
2019-01-24 02:37:40.544144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dfc00 of size 256
2019-01-24 02:37:40.544147: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dfd00 of size 256
2019-01-24 02:37:40.544151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8dfe00 of size 2816
2019-01-24 02:37:40.544154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e0900 of size 768
2019-01-24 02:37:40.544158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e0c00 of size 256
2019-01-24 02:37:40.544161: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e0d00 of size 2816
2019-01-24 02:37:40.544165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e1800 of size 768
2019-01-24 02:37:40.544168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e1b00 of size 256
2019-01-24 02:37:40.544172: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e1c00 of size 768
2019-01-24 02:37:40.544175: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e1f00 of size 256
2019-01-24 02:37:40.544178: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e2000 of size 256
2019-01-24 02:37:40.544182: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e2100 of size 768
2019-01-24 02:37:40.544185: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e2400 of size 256
2019-01-24 02:37:40.544188: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e2500 of size 2816
2019-01-24 02:37:40.544192: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3000 of size 768
2019-01-24 02:37:40.544195: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3300 of size 256
2019-01-24 02:37:40.544199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3400 of size 256
2019-01-24 02:37:40.544202: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3500 of size 768
2019-01-24 02:37:40.544206: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3800 of size 256
2019-01-24 02:37:40.544209: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3900 of size 256
2019-01-24 02:37:40.544212: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3a00 of size 256
2019-01-24 02:37:40.544216: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3b00 of size 768
2019-01-24 02:37:40.544219: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3e00 of size 256
2019-01-24 02:37:40.544223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e3f00 of size 2816
2019-01-24 02:37:40.544226: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e4a00 of size 768
2019-01-24 02:37:40.544229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e4d00 of size 256
2019-01-24 02:37:40.544233: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e4e00 of size 768
2019-01-24 02:37:40.544236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e5100 of size 256
2019-01-24 02:37:40.544240: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e5200 of size 256
2019-01-24 02:37:40.544243: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e5300 of size 2816
2019-01-24 02:37:40.544247: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e5e00 of size 768
2019-01-24 02:37:40.544250: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e6100 of size 256
2019-01-24 02:37:40.544253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e6200 of size 2816
2019-01-24 02:37:40.544257: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e6d00 of size 768
2019-01-24 02:37:40.544260: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7000 of size 256
2019-01-24 02:37:40.544264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7100 of size 768
2019-01-24 02:37:40.544267: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7400 of size 256
2019-01-24 02:37:40.544270: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7500 of size 256
2019-01-24 02:37:40.544274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7600 of size 768
2019-01-24 02:37:40.544277: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7900 of size 256
2019-01-24 02:37:40.544281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e7a00 of size 2816
2019-01-24 02:37:40.544284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8500 of size 768
2019-01-24 02:37:40.544287: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8800 of size 256
2019-01-24 02:37:40.544291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8900 of size 256
2019-01-24 02:37:40.544294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8a00 of size 768
2019-01-24 02:37:40.544298: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8d00 of size 256
2019-01-24 02:37:40.544301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8e00 of size 256
2019-01-24 02:37:40.544304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e8f00 of size 768
2019-01-24 02:37:40.544308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e9200 of size 256
2019-01-24 02:37:40.544311: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e9300 of size 2816
2019-01-24 02:37:40.544315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8e9e00 of size 768
2019-01-24 02:37:40.544318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ea100 of size 256
2019-01-24 02:37:40.544322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ea200 of size 768
2019-01-24 02:37:40.544325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ea500 of size 256
2019-01-24 02:37:40.544328: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ea600 of size 256
2019-01-24 02:37:40.544332: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ea700 of size 2816
2019-01-24 02:37:40.544335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8eb200 of size 768
2019-01-24 02:37:40.544339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8eb500 of size 256
2019-01-24 02:37:40.544342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8eb600 of size 2816
2019-01-24 02:37:40.544345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ec100 of size 768
2019-01-24 02:37:40.544349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ec400 of size 256
2019-01-24 02:37:40.544352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ec500 of size 256
2019-01-24 02:37:40.544356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ec600 of size 768
2019-01-24 02:37:40.544359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ec900 of size 256
2019-01-24 02:37:40.544362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8eca00 of size 256
2019-01-24 02:37:40.544366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ecb00 of size 768
2019-01-24 02:37:40.544369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ece00 of size 256
2019-01-24 02:37:40.544373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ecf00 of size 2816
2019-01-24 02:37:40.544376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8eda00 of size 768
2019-01-24 02:37:40.544379: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8edd00 of size 256
2019-01-24 02:37:40.544383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ede00 of size 256
2019-01-24 02:37:40.544386: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8edf00 of size 768
2019-01-24 02:37:40.544390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ee200 of size 256
2019-01-24 02:37:40.544393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ee300 of size 256
2019-01-24 02:37:40.544397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ee400 of size 768
2019-01-24 02:37:40.544400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ee700 of size 256
2019-01-24 02:37:40.544403: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ee800 of size 2816
2019-01-24 02:37:40.544407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ef300 of size 1536
2019-01-24 02:37:40.544410: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ef900 of size 1536
2019-01-24 02:37:40.544414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8eff00 of size 1536
2019-01-24 02:37:40.544417: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f0500 of size 1536
2019-01-24 02:37:40.544420: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f0b00 of size 1536
2019-01-24 02:37:40.551648: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f1100 of size 1536
2019-01-24 02:37:40.551657: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f1700 of size 1536
2019-01-24 02:37:40.551660: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f1d00 of size 1536
2019-01-24 02:37:40.551663: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f2300 of size 1536
2019-01-24 02:37:40.551666: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f2900 of size 1536
2019-01-24 02:37:40.551669: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f2f00 of size 1536
2019-01-24 02:37:40.551672: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f3500 of size 1536
2019-01-24 02:37:40.551676: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f3b00 of size 1536
2019-01-24 02:37:40.551679: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f4100 of size 1536
2019-01-24 02:37:40.551682: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f4700 of size 1536
2019-01-24 02:37:40.551686: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f4d00 of size 1536
2019-01-24 02:37:40.551689: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f5300 of size 1536
2019-01-24 02:37:40.551692: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f5900 of size 1536
2019-01-24 02:37:40.551696: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f5f00 of size 1536
2019-01-24 02:37:40.551699: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f6500 of size 1536
2019-01-24 02:37:40.551702: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f6b00 of size 1536
2019-01-24 02:37:40.551706: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f7100 of size 1536
2019-01-24 02:37:40.551709: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f7700 of size 1536
2019-01-24 02:37:40.551713: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f7d00 of size 1536
2019-01-24 02:37:40.551716: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f8300 of size 1536
2019-01-24 02:37:40.551720: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f8900 of size 1536
2019-01-24 02:37:40.551723: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f8f00 of size 1536
2019-01-24 02:37:40.551727: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f9500 of size 1536
2019-01-24 02:37:40.551730: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8f9b00 of size 1536
2019-01-24 02:37:40.551734: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fa100 of size 1536
2019-01-24 02:37:40.551737: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fa700 of size 1536
2019-01-24 02:37:40.551741: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fad00 of size 1536
2019-01-24 02:37:40.551744: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fb300 of size 1536
2019-01-24 02:37:40.551748: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fb900 of size 1536
2019-01-24 02:37:40.551751: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fbf00 of size 1536
2019-01-24 02:37:40.551755: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fc500 of size 1536
2019-01-24 02:37:40.551758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fcb00 of size 1536
2019-01-24 02:37:40.551762: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fd100 of size 1536
2019-01-24 02:37:40.551765: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fd700 of size 1536
2019-01-24 02:37:40.551768: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fdd00 of size 1536
2019-01-24 02:37:40.551772: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fe300 of size 1536
2019-01-24 02:37:40.551775: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fe900 of size 1536
2019-01-24 02:37:40.551779: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8fef00 of size 1536
2019-01-24 02:37:40.551782: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ff500 of size 1536
2019-01-24 02:37:40.551786: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c8ffb00 of size 1536
2019-01-24 02:37:40.551789: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c900100 of size 1536
2019-01-24 02:37:40.551793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c900700 of size 1536
2019-01-24 02:37:40.551796: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c900d00 of size 1536
2019-01-24 02:37:40.551800: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c901300 of size 1536
2019-01-24 02:37:40.551803: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c901900 of size 1536
2019-01-24 02:37:40.551807: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c901f00 of size 1536
2019-01-24 02:37:40.551810: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c902500 of size 1536
2019-01-24 02:37:40.551814: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c902b00 of size 1536
2019-01-24 02:37:40.551817: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c903100 of size 1536
2019-01-24 02:37:40.551821: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c903700 of size 1536
2019-01-24 02:37:40.551824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c903d00 of size 1536
2019-01-24 02:37:40.551828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c904300 of size 1536
2019-01-24 02:37:40.551831: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c904900 of size 1536
2019-01-24 02:37:40.551834: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c904f00 of size 1536
2019-01-24 02:37:40.551838: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c905500 of size 1536
2019-01-24 02:37:40.551841: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c905b00 of size 1536
2019-01-24 02:37:40.551845: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c906100 of size 1536
2019-01-24 02:37:40.551848: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c906700 of size 1536
2019-01-24 02:37:40.551852: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c906d00 of size 1536
2019-01-24 02:37:40.551855: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c907300 of size 1536
2019-01-24 02:37:40.551859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c907900 of size 1536
2019-01-24 02:37:40.551862: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c907f00 of size 1536
2019-01-24 02:37:40.551865: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c908500 of size 1536
2019-01-24 02:37:40.551869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c908b00 of size 1536
2019-01-24 02:37:40.551872: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c909100 of size 1536
2019-01-24 02:37:40.551876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c909700 of size 1536
2019-01-24 02:37:40.551879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c909d00 of size 1536
2019-01-24 02:37:40.551883: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90a300 of size 1536
2019-01-24 02:37:40.551886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90a900 of size 1536
2019-01-24 02:37:40.551889: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90af00 of size 1536
2019-01-24 02:37:40.551893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90b500 of size 1536
2019-01-24 02:37:40.551896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90bb00 of size 1536
2019-01-24 02:37:40.551900: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90c100 of size 1536
2019-01-24 02:37:40.551903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90c700 of size 1536
2019-01-24 02:37:40.551907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90cd00 of size 1536
2019-01-24 02:37:40.551910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90d300 of size 1536
2019-01-24 02:37:40.551914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90d900 of size 1536
2019-01-24 02:37:40.551917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90df00 of size 1536
2019-01-24 02:37:40.551920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90e500 of size 1536
2019-01-24 02:37:40.551924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90eb00 of size 1536
2019-01-24 02:37:40.551927: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90f100 of size 1536
2019-01-24 02:37:40.551931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90f700 of size 1536
2019-01-24 02:37:40.551934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c90fd00 of size 1536
2019-01-24 02:37:40.551938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c910300 of size 1536
2019-01-24 02:37:40.551941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c910900 of size 1536
2019-01-24 02:37:40.551945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c910f00 of size 1536
2019-01-24 02:37:40.551948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c911500 of size 1536
2019-01-24 02:37:40.551951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c911b00 of size 1536
2019-01-24 02:37:40.551955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c912100 of size 1536
2019-01-24 02:37:40.551958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c912700 of size 1536
2019-01-24 02:37:40.551962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c912d00 of size 1536
2019-01-24 02:37:40.551965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c913300 of size 1536
2019-01-24 02:37:40.551968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c913900 of size 1536
2019-01-24 02:37:40.551972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c913f00 of size 1536
2019-01-24 02:37:40.551975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c914500 of size 1536
2019-01-24 02:37:40.551979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c914b00 of size 1536
2019-01-24 02:37:40.551983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c915100 of size 1536
2019-01-24 02:37:40.551986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c915700 of size 1536
2019-01-24 02:37:40.551990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c915d00 of size 1536
2019-01-24 02:37:40.551993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c916300 of size 1536
2019-01-24 02:37:40.551996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c916900 of size 1536
2019-01-24 02:37:40.552000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c916f00 of size 1536
2019-01-24 02:37:40.552003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c917500 of size 1536
2019-01-24 02:37:40.552006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c917b00 of size 1536
2019-01-24 02:37:40.552010: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918100 of size 1536
2019-01-24 02:37:40.552013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918700 of size 1536
2019-01-24 02:37:40.552017: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918d00 of size 256
2019-01-24 02:37:40.552020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c918e00 of size 1536
2019-01-24 02:37:40.552023: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919400 of size 256
2019-01-24 02:37:40.552027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919500 of size 256
2019-01-24 02:37:40.552030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919600 of size 1536
2019-01-24 02:37:40.552033: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c919c00 of size 2816
2019-01-24 02:37:40.552037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91a700 of size 256
2019-01-24 02:37:40.552040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91a800 of size 1536
2019-01-24 02:37:40.552043: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ae00 of size 2816
2019-01-24 02:37:40.552046: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91b900 of size 256
2019-01-24 02:37:40.552050: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ba00 of size 1536
2019-01-24 02:37:40.552053: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c000 of size 256
2019-01-24 02:37:40.552057: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c100 of size 256
2019-01-24 02:37:40.552060: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c200 of size 1536
2019-01-24 02:37:40.552063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c800 of size 256
2019-01-24 02:37:40.552067: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91c900 of size 1536
2019-01-24 02:37:40.552070: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91cf00 of size 2816
2019-01-24 02:37:40.552074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91da00 of size 256
2019-01-24 02:37:40.552077: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91db00 of size 256
2019-01-24 02:37:40.552081: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91dc00 of size 1536
2019-01-24 02:37:40.552084: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91e200 of size 256
2019-01-24 02:37:40.552087: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91e300 of size 256
2019-01-24 02:37:40.552091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91e400 of size 1536
2019-01-24 02:37:40.552094: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ea00 of size 256
2019-01-24 02:37:40.552098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91eb00 of size 256
2019-01-24 02:37:40.552101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91ec00 of size 1536
2019-01-24 02:37:40.552104: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91f200 of size 2816
2019-01-24 02:37:40.552108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91fd00 of size 256
2019-01-24 02:37:40.552111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c91fe00 of size 1536
2019-01-24 02:37:40.552115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920400 of size 256
2019-01-24 02:37:40.552118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920500 of size 256
2019-01-24 02:37:40.552122: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920600 of size 1536
2019-01-24 02:37:40.552125: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c920c00 of size 2816
2019-01-24 02:37:40.552128: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c921700 of size 256
2019-01-24 02:37:40.552132: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c921800 of size 1536
2019-01-24 02:37:40.552135: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c921e00 of size 2816
2019-01-24 02:37:40.552139: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c922900 of size 256
2019-01-24 02:37:40.552142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c922a00 of size 1536
2019-01-24 02:37:40.552146: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923000 of size 256
2019-01-24 02:37:40.552149: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923100 of size 256
2019-01-24 02:37:40.552152: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923200 of size 1536
2019-01-24 02:37:40.552156: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923800 of size 256
2019-01-24 02:37:40.552159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923900 of size 1536
2019-01-24 02:37:40.552163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c923f00 of size 2816
2019-01-24 02:37:40.552166: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c924a00 of size 256
2019-01-24 02:37:40.552170: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c924b00 of size 256
2019-01-24 02:37:40.552173: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c924c00 of size 1536
2019-01-24 02:37:40.552176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925200 of size 256
2019-01-24 02:37:40.552180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925300 of size 256
2019-01-24 02:37:40.552183: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925400 of size 1536
2019-01-24 02:37:40.552187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925a00 of size 256
2019-01-24 02:37:40.552190: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c925b00 of size 1536
2019-01-24 02:37:40.552194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c926100 of size 2816
2019-01-24 02:37:40.552197: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c926c00 of size 256
2019-01-24 02:37:40.552201: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c926d00 of size 1536
2019-01-24 02:37:40.552204: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927300 of size 256
2019-01-24 02:37:40.552207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927400 of size 256
2019-01-24 02:37:40.552211: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927500 of size 1536
2019-01-24 02:37:40.552214: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c927b00 of size 2816
2019-01-24 02:37:40.552218: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c928600 of size 256
2019-01-24 02:37:40.552221: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c928700 of size 1536
2019-01-24 02:37:40.552225: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c928d00 of size 2816
2019-01-24 02:37:40.552228: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c929800 of size 256
2019-01-24 02:37:40.552231: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c929900 of size 1536
2019-01-24 02:37:40.552235: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c929f00 of size 256
2019-01-24 02:37:40.552238: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a000 of size 256
2019-01-24 02:37:40.552242: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a100 of size 1536
2019-01-24 02:37:40.552245: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a700 of size 256
2019-01-24 02:37:40.552248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92a800 of size 1536
2019-01-24 02:37:40.552252: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ae00 of size 2816
2019-01-24 02:37:40.561901: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92b900 of size 256
2019-01-24 02:37:40.561910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ba00 of size 256
2019-01-24 02:37:40.561913: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92bb00 of size 1536
2019-01-24 02:37:40.561916: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c100 of size 256
2019-01-24 02:37:40.561919: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c200 of size 256
2019-01-24 02:37:40.561922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c300 of size 1536
2019-01-24 02:37:40.561925: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92c900 of size 256
2019-01-24 02:37:40.561928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ca00 of size 1536
2019-01-24 02:37:40.561931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92d000 of size 2816
2019-01-24 02:37:40.561935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92db00 of size 256
2019-01-24 02:37:40.561938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92dc00 of size 1536
2019-01-24 02:37:40.561941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92e200 of size 256
2019-01-24 02:37:40.561945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92e300 of size 256
2019-01-24 02:37:40.561948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92e400 of size 1536
2019-01-24 02:37:40.561952: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92ea00 of size 2816
2019-01-24 02:37:40.561955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92f500 of size 256
2019-01-24 02:37:40.561958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92f600 of size 1536
2019-01-24 02:37:40.561961: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c92fc00 of size 2816
2019-01-24 02:37:40.561965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930700 of size 256
2019-01-24 02:37:40.561967: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930800 of size 1536
2019-01-24 02:37:40.561971: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930e00 of size 256
2019-01-24 02:37:40.561974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c930f00 of size 256
2019-01-24 02:37:40.561977: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931000 of size 1536
2019-01-24 02:37:40.561980: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931600 of size 256
2019-01-24 02:37:40.561983: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931700 of size 1536
2019-01-24 02:37:40.561986: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c931d00 of size 2816
2019-01-24 02:37:40.561990: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c932800 of size 256
2019-01-24 02:37:40.561993: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c932900 of size 256
2019-01-24 02:37:40.561997: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c932a00 of size 1536
2019-01-24 02:37:40.562000: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933000 of size 256
2019-01-24 02:37:40.562004: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933100 of size 256
2019-01-24 02:37:40.562007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933200 of size 1536
2019-01-24 02:37:40.562011: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c933800 of size 23040
0
2019-01-24 02:37:40.562014: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c96bc00 of size 23040
0
2019-01-24 02:37:40.562018: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a4000 of size 256
2019-01-24 02:37:40.562021: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a4100 of size 1536
2019-01-24 02:37:40.562025: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a4700 of size 2816
2019-01-24 02:37:40.562028: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5200 of size 256
2019-01-24 02:37:40.562032: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5300 of size 1536
2019-01-24 02:37:40.562035: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5900 of size 256
2019-01-24 02:37:40.562039: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5a00 of size 256
2019-01-24 02:37:40.562042: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a5b00 of size 1536
2019-01-24 02:37:40.562046: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a6100 of size 2816
2019-01-24 02:37:40.562049: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a6c00 of size 256
2019-01-24 02:37:40.562053: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a6d00 of size 1536
2019-01-24 02:37:40.562056: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a7300 of size 2816
2019-01-24 02:37:40.562060: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a7e00 of size 256
2019-01-24 02:37:40.562063: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a7f00 of size 1536
2019-01-24 02:37:40.562067: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8500 of size 256
2019-01-24 02:37:40.562070: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8600 of size 256
2019-01-24 02:37:40.562074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8700 of size 1536
2019-01-24 02:37:40.562077: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8d00 of size 256
2019-01-24 02:37:40.562080: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a8e00 of size 1536
2019-01-24 02:37:40.562084: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a9400 of size 2816
2019-01-24 02:37:40.562087: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9a9f00 of size 256
2019-01-24 02:37:40.562091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa000 of size 256
2019-01-24 02:37:40.562094: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa100 of size 1536
2019-01-24 02:37:40.562098: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa700 of size 256
2019-01-24 02:37:40.562101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa800 of size 256
2019-01-24 02:37:40.562104: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aa900 of size 1536
2019-01-24 02:37:40.562108: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aaf00 of size 256
2019-01-24 02:37:40.562111: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ab000 of size 1536
2019-01-24 02:37:40.562115: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ab600 of size 2816
2019-01-24 02:37:40.562118: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac100 of size 256
2019-01-24 02:37:40.562122: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac200 of size 1536
2019-01-24 02:37:40.562125: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac800 of size 256
2019-01-24 02:37:40.562129: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ac900 of size 256
2019-01-24 02:37:40.562132: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aca00 of size 1536
2019-01-24 02:37:40.562135: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ad000 of size 2816
2019-01-24 02:37:40.562139: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9adb00 of size 256
2019-01-24 02:37:40.562142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9adc00 of size 1536
2019-01-24 02:37:40.562146: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9ae200 of size 2816
2019-01-24 02:37:40.562149: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aed00 of size 256
2019-01-24 02:37:40.562153: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9aee00 of size 2048
2019-01-24 02:37:40.562156: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9af600 of size 2048
2019-01-24 02:37:40.562160: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9afe00 of size 1536
2019-01-24 02:37:40.562163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0400 of size 256
2019-01-24 02:37:40.562167: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0500 of size 256
2019-01-24 02:37:40.562170: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0600 of size 1536
2019-01-24 02:37:40.562173: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0c00 of size 256
2019-01-24 02:37:40.562177: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b0d00 of size 1536
2019-01-24 02:37:40.562180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b1300 of size 2816
2019-01-24 02:37:40.562184: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b1e00 of size 256
2019-01-24 02:37:40.562187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b1f00 of size 256
2019-01-24 02:37:40.562191: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2000 of size 1536
2019-01-24 02:37:40.562194: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2600 of size 256
2019-01-24 02:37:40.562198: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2700 of size 256
2019-01-24 02:37:40.562201: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2800 of size 1536
2019-01-24 02:37:40.562205: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2e00 of size 256
2019-01-24 02:37:40.562208: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b2f00 of size 1536
2019-01-24 02:37:40.562211: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b3500 of size 2816
2019-01-24 02:37:40.562215: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4000 of size 256
2019-01-24 02:37:40.562218: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4100 of size 1536
2019-01-24 02:37:40.562222: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4700 of size 256
2019-01-24 02:37:40.562225: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4800 of size 256
2019-01-24 02:37:40.562229: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4900 of size 1536
2019-01-24 02:37:40.562232: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b4f00 of size 2816
2019-01-24 02:37:40.562236: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b5a00 of size 256
2019-01-24 02:37:40.562239: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b5b00 of size 1536
2019-01-24 02:37:40.562243: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b6100 of size 2816
2019-01-24 02:37:40.562246: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b6c00 of size 256
2019-01-24 02:37:40.562250: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b6d00 of size 1536
2019-01-24 02:37:40.562253: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b7300 of size 1536
2019-01-24 02:37:40.562257: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9b7900 of size 57600
2019-01-24 02:37:40.562261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9c5a00 of size 57600
2019-01-24 02:37:40.562264: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9d3b00 of size 57600
2019-01-24 02:37:40.562268: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9e1c00 of size 57600
2019-01-24 02:37:40.562271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9efd00 of size 512
2019-01-24 02:37:40.562274: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9eff00 of size 512
2019-01-24 02:37:40.562278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0100 of size 512
2019-01-24 02:37:40.562281: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0300 of size 512
2019-01-24 02:37:40.562285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0500 of size 256
2019-01-24 02:37:40.562288: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0600 of size 256
2019-01-24 02:37:40.562292: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0700 of size 256
2019-01-24 02:37:40.562295: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0800 of size 256
2019-01-24 02:37:40.562298: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0900 of size 256
2019-01-24 02:37:40.562302: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0a00 of size 256
2019-01-24 02:37:40.562305: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0b00 of size 256
2019-01-24 02:37:40.562309: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0c00 of size 256
2019-01-24 02:37:40.562312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0d00 of size 256
2019-01-24 02:37:40.562315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0e00 of size 256
2019-01-24 02:37:40.562319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f0f00 of size 256
2019-01-24 02:37:40.562322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1000 of size 256
2019-01-24 02:37:40.562326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1100 of size 256
2019-01-24 02:37:40.562329: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1200 of size 256
2019-01-24 02:37:40.562332: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1300 of size 256
2019-01-24 02:37:40.562336: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1400 of size 256
2019-01-24 02:37:40.562339: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1500 of size 256
2019-01-24 02:37:40.562342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1600 of size 256
2019-01-24 02:37:40.562346: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1700 of size 256
2019-01-24 02:37:40.562349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1800 of size 256
2019-01-24 02:37:40.562353: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1900 of size 256
2019-01-24 02:37:40.562356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1a00 of size 256
2019-01-24 02:37:40.562360: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1b00 of size 256
2019-01-24 02:37:40.562363: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1c00 of size 256
2019-01-24 02:37:40.562366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1d00 of size 256
2019-01-24 02:37:40.562370: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1e00 of size 256
2019-01-24 02:37:40.562373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f1f00 of size 256
2019-01-24 02:37:40.562377: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2000 of size 256
2019-01-24 02:37:40.562380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2100 of size 256
2019-01-24 02:37:40.562383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2200 of size 256
2019-01-24 02:37:40.562387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2300 of size 256
2019-01-24 02:37:40.562390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2400 of size 256
2019-01-24 02:37:40.562394: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2500 of size 256
2019-01-24 02:37:40.562397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2600 of size 256
2019-01-24 02:37:40.562400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2700 of size 256
2019-01-24 02:37:40.562404: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2800 of size 256
2019-01-24 02:37:40.562407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2900 of size 256
2019-01-24 02:37:40.562411: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2a00 of size 256
2019-01-24 02:37:40.562414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2b00 of size 768
2019-01-24 02:37:40.562418: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1c9f2e00 of size 256
2019-01-24 02:37:40.562421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f2f00 of size 256
2019-01-24 02:37:40.562425: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f3000 of size 256
2019-01-24 02:37:40.562428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1c9f3100 of size 1792
2019-01-24 02:37:40.562432: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f3800 of size 256
2019-01-24 02:37:40.562435: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xb1c9f3900 of size 1792
2019-01-24 02:37:40.562439: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1c9f4000 of size 57600
2019-01-24 02:37:40.562442: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca02100 of size 10828
8
2019-01-24 02:37:40.562446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1c800 of size 2816
2019-01-24 02:37:40.562449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1d300 of size 1536
2019-01-24 02:37:40.562453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1d900 of size 1536
2019-01-24 02:37:40.562456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1df00 of size 1536
2019-01-24 02:37:40.562460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1e500 of size 1536
2019-01-24 02:37:40.562463: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1eb00 of size 1536
2019-01-24 02:37:40.562467: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1f100 of size 1536
2019-01-24 02:37:40.562470: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1f700 of size 1536
2019-01-24 02:37:40.562473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca1fd00 of size 1536
2019-01-24 02:37:40.562477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca20300 of size 1536
2019-01-24 02:37:40.562480: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca20900 of size 1536
2019-01-24 02:37:40.562484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca20f00 of size 1536
2019-01-24 02:37:40.562487: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca21500 of size 1536
2019-01-24 02:37:40.562491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca21b00 of size 1536
2019-01-24 02:37:40.562494: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca22100 of size 1536
2019-01-24 02:37:40.562498: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca22700 of size 1536
2019-01-24 02:37:40.562501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca22d00 of size 1536
2019-01-24 02:37:40.562504: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca23300 of size 1536
2019-01-24 02:37:40.568599: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca23900 of size 1536
2019-01-24 02:37:40.568607: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca23f00 of size 1536
2019-01-24 02:37:40.568611: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca24500 of size 1536
2019-01-24 02:37:40.568614: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca24b00 of size 1536
2019-01-24 02:37:40.568617: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca25100 of size 1536
2019-01-24 02:37:40.568620: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca25700 of size 1536
2019-01-24 02:37:40.568623: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca25d00 of size 1536
2019-01-24 02:37:40.568627: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca26300 of size 1536
2019-01-24 02:37:40.568631: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca26900 of size 1536
2019-01-24 02:37:40.568634: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca26f00 of size 1536
2019-01-24 02:37:40.568637: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca27500 of size 1536
2019-01-24 02:37:40.568640: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca27b00 of size 1536
2019-01-24 02:37:40.568644: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca28100 of size 1536
2019-01-24 02:37:40.568647: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca28700 of size 1536
2019-01-24 02:37:40.568650: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca28d00 of size 1536
2019-01-24 02:37:40.568654: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca29300 of size 1536
2019-01-24 02:37:40.568656: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca29900 of size 1536
2019-01-24 02:37:40.568660: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca29f00 of size 1536
2019-01-24 02:37:40.568663: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2a500 of size 1536
2019-01-24 02:37:40.568667: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2ab00 of size 1536
2019-01-24 02:37:40.568670: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2b100 of size 1536
2019-01-24 02:37:40.568674: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2b700 of size 1536
2019-01-24 02:37:40.568677: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2bd00 of size 1536
2019-01-24 02:37:40.568680: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2c300 of size 1536
2019-01-24 02:37:40.568684: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2c900 of size 1536
2019-01-24 02:37:40.568687: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2cf00 of size 1536
2019-01-24 02:37:40.568691: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2d500 of size 1536
2019-01-24 02:37:40.568694: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2db00 of size 1536
2019-01-24 02:37:40.568698: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2e100 of size 1536
2019-01-24 02:37:40.568701: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2e700 of size 1536
2019-01-24 02:37:40.568704: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2ed00 of size 1536
2019-01-24 02:37:40.568708: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2f300 of size 1536
2019-01-24 02:37:40.568711: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2f900 of size 1536
2019-01-24 02:37:40.568715: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca2ff00 of size 1536
2019-01-24 02:37:40.568718: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca30500 of size 1536
2019-01-24 02:37:40.568722: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca30b00 of size 1536
2019-01-24 02:37:40.568725: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca31100 of size 1536
2019-01-24 02:37:40.568728: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca31700 of size 1536
2019-01-24 02:37:40.568732: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca31d00 of size 1536
2019-01-24 02:37:40.568735: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca32300 of size 1536
2019-01-24 02:37:40.568739: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca32900 of size 1536
2019-01-24 02:37:40.568742: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca32f00 of size 1536
2019-01-24 02:37:40.568746: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca33500 of size 1536
2019-01-24 02:37:40.568749: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca33b00 of size 1536
2019-01-24 02:37:40.568752: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca34100 of size 1536
2019-01-24 02:37:40.568756: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca34700 of size 1536
2019-01-24 02:37:40.568759: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca34d00 of size 1536
2019-01-24 02:37:40.568763: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca35300 of size 1536
2019-01-24 02:37:40.568766: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca35900 of size 1536
2019-01-24 02:37:40.568769: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca35f00 of size 1536
2019-01-24 02:37:40.568773: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca36500 of size 1536
2019-01-24 02:37:40.568776: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca36b00 of size 1536
2019-01-24 02:37:40.568780: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca37100 of size 1536
2019-01-24 02:37:40.568783: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca37700 of size 1536
2019-01-24 02:37:40.568786: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca37d00 of size 1536
2019-01-24 02:37:40.568790: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca38300 of size 1536
2019-01-24 02:37:40.568793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca38900 of size 1536
2019-01-24 02:37:40.568797: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca38f00 of size 1536
2019-01-24 02:37:40.568800: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca39500 of size 1536
2019-01-24 02:37:40.568803: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca39b00 of size 1536
2019-01-24 02:37:40.568807: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3a100 of size 1536
2019-01-24 02:37:40.568810: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3a700 of size 1536
2019-01-24 02:37:40.568814: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3ad00 of size 1536
2019-01-24 02:37:40.568817: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3b300 of size 1536
2019-01-24 02:37:40.568820: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3b900 of size 1536
2019-01-24 02:37:40.568824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3bf00 of size 1536
2019-01-24 02:37:40.568827: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3c500 of size 1536
2019-01-24 02:37:40.568831: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3cb00 of size 1536
2019-01-24 02:37:40.568834: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3d100 of size 1536
2019-01-24 02:37:40.568837: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3d700 of size 1536
2019-01-24 02:37:40.568841: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3dd00 of size 1536
2019-01-24 02:37:40.568844: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3e300 of size 1536
2019-01-24 02:37:40.568848: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3e900 of size 1536
2019-01-24 02:37:40.568851: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3ef00 of size 1536
2019-01-24 02:37:40.568855: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3f500 of size 1536
2019-01-24 02:37:40.568858: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca3fb00 of size 1536
2019-01-24 02:37:40.568861: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca40100 of size 1536
2019-01-24 02:37:40.568865: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca40700 of size 1536
2019-01-24 02:37:40.568868: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca40d00 of size 1536
2019-01-24 02:37:40.568872: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca41300 of size 1536
2019-01-24 02:37:40.568875: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca41900 of size 1536
2019-01-24 02:37:40.568879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca41f00 of size 1536
2019-01-24 02:37:40.568882: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca42500 of size 1536
2019-01-24 02:37:40.568885: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca42b00 of size 1536
2019-01-24 02:37:40.568889: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca43100 of size 1536
2019-01-24 02:37:40.568892: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca43700 of size 1536
2019-01-24 02:37:40.568896: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca43d00 of size 1536
2019-01-24 02:37:40.568899: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca44300 of size 1536
2019-01-24 02:37:40.568903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca44900 of size 1536
2019-01-24 02:37:40.568906: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca44f00 of size 1536
2019-01-24 02:37:40.568909: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca45500 of size 1536
2019-01-24 02:37:40.568913: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca45b00 of size 1536
2019-01-24 02:37:40.568916: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca46100 of size 1536
2019-01-24 02:37:40.568920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca46700 of size 1536
2019-01-24 02:37:40.568923: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca46d00 of size 1536
2019-01-24 02:37:40.568926: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca47300 of size 1536
2019-01-24 02:37:40.568930: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca47900 of size 1536
2019-01-24 02:37:40.568933: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca47f00 of size 1536
2019-01-24 02:37:40.568937: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca48500 of size 1536
2019-01-24 02:37:40.568940: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca48b00 of size 1536
2019-01-24 02:37:40.568943: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca49100 of size 1536
2019-01-24 02:37:40.568947: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca49700 of size 1536
2019-01-24 02:37:40.568950: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca49d00 of size 1536
2019-01-24 02:37:40.568953: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4a300 of size 1536
2019-01-24 02:37:40.568957: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4a900 of size 1536
2019-01-24 02:37:40.568960: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4af00 of size 1536
2019-01-24 02:37:40.568964: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4b500 of size 1536
2019-01-24 02:37:40.568967: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4bb00 of size 1536
2019-01-24 02:37:40.568971: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4c100 of size 1536
2019-01-24 02:37:40.568974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4c700 of size 1536
2019-01-24 02:37:40.568977: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4cd00 of size 1536
2019-01-24 02:37:40.568981: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4d300 of size 1536
2019-01-24 02:37:40.568984: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4d900 of size 1536
2019-01-24 02:37:40.568988: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4df00 of size 1536
2019-01-24 02:37:40.568992: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4e500 of size 1536
2019-01-24 02:37:40.568996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4eb00 of size 1536
2019-01-24 02:37:40.568999: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4f100 of size 1536
2019-01-24 02:37:40.569003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4f700 of size 1536
2019-01-24 02:37:40.569006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca4fd00 of size 1536
2019-01-24 02:37:40.569009: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca50300 of size 1536
2019-01-24 02:37:40.569013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca50900 of size 1536
2019-01-24 02:37:40.569016: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca50f00 of size 1536
2019-01-24 02:37:40.569020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca51500 of size 1536
2019-01-24 02:37:40.569023: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca51b00 of size 1536
2019-01-24 02:37:40.569027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca52100 of size 1536
2019-01-24 02:37:40.569030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca52700 of size 1536
2019-01-24 02:37:40.569033: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca52d00 of size 1536
2019-01-24 02:37:40.569037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca53300 of size 1536
2019-01-24 02:37:40.569040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca53900 of size 1536
2019-01-24 02:37:40.569044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca53f00 of size 1536
2019-01-24 02:37:40.569047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca54500 of size 1536
2019-01-24 02:37:40.569050: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca54b00 of size 1536
2019-01-24 02:37:40.569054: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca55100 of size 1536
2019-01-24 02:37:40.569057: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca55700 of size 1536
2019-01-24 02:37:40.569061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca55d00 of size 1536
2019-01-24 02:37:40.569064: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca56300 of size 1536
2019-01-24 02:37:40.569068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca56900 of size 1536
2019-01-24 02:37:40.569071: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca56f00 of size 1536
2019-01-24 02:37:40.569074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca57500 of size 1536
2019-01-24 02:37:40.569078: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca57b00 of size 1536
2019-01-24 02:37:40.569081: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca58100 of size 1536
2019-01-24 02:37:40.569085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca58700 of size 1536
2019-01-24 02:37:40.569088: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca58d00 of size 1536
2019-01-24 02:37:40.569092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca59300 of size 1536
2019-01-24 02:37:40.569095: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca59900 of size 1536
2019-01-24 02:37:40.569099: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca59f00 of size 1536
2019-01-24 02:37:40.569102: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5a500 of size 1536
2019-01-24 02:37:40.569106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5ab00 of size 1536
2019-01-24 02:37:40.569109: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5b100 of size 1536
2019-01-24 02:37:40.569112: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5b700 of size 1536
2019-01-24 02:37:40.569116: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5bd00 of size 1536
2019-01-24 02:37:40.569119: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5c300 of size 1536
2019-01-24 02:37:40.569123: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5c900 of size 1536
2019-01-24 02:37:40.569126: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5cf00 of size 1536
2019-01-24 02:37:40.569130: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5d500 of size 1536
2019-01-24 02:37:40.569133: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5db00 of size 1536
2019-01-24 02:37:40.569137: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5e100 of size 1536
2019-01-24 02:37:40.569140: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5e700 of size 1536
2019-01-24 02:37:40.569143: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5ed00 of size 1536
2019-01-24 02:37:40.569147: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5f300 of size 1536
2019-01-24 02:37:40.569150: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5f900 of size 1536
2019-01-24 02:37:40.569154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca5ff00 of size 1536
2019-01-24 02:37:40.569157: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca60500 of size 1536
2019-01-24 02:37:40.569161: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca60b00 of size 1536
2019-01-24 02:37:40.569164: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca61100 of size 1536
2019-01-24 02:37:40.569168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca61700 of size 1536
2019-01-24 02:37:40.569171: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca61d00 of size 1536
2019-01-24 02:37:40.569174: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca62300 of size 1536
2019-01-24 02:37:40.569178: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca62900 of size 1536
2019-01-24 02:37:40.569181: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca62f00 of size 1536
2019-01-24 02:37:40.569185: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca63500 of size 1536
2019-01-24 02:37:40.569188: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca63b00 of size 1536
2019-01-24 02:37:40.569192: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca64100 of size 1536
2019-01-24 02:37:40.569195: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca64700 of size 1536
2019-01-24 02:37:40.569198: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca64d00 of size 1536
2019-01-24 02:37:40.569202: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca65300 of size 1536
2019-01-24 02:37:40.578740: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca65900 of size 1536
2019-01-24 02:37:40.578749: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca65f00 of size 1536
2019-01-24 02:37:40.578752: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca66500 of size 1536
2019-01-24 02:37:40.578755: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca66b00 of size 1536
2019-01-24 02:37:40.578758: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca67100 of size 1536
2019-01-24 02:37:40.578761: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca67700 of size 1536
2019-01-24 02:37:40.578764: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca67d00 of size 1536
2019-01-24 02:37:40.578766: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca68300 of size 1536
2019-01-24 02:37:40.578770: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca68900 of size 1536
2019-01-24 02:37:40.578774: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca68f00 of size 1536
2019-01-24 02:37:40.578777: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca69500 of size 1536
2019-01-24 02:37:40.578780: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca69b00 of size 1536
2019-01-24 02:37:40.578784: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6a100 of size 1536
2019-01-24 02:37:40.578787: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6a700 of size 1536
2019-01-24 02:37:40.578790: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6ad00 of size 1536
2019-01-24 02:37:40.578793: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6b300 of size 1536
2019-01-24 02:37:40.578796: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6b900 of size 1536
2019-01-24 02:37:40.578800: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6bf00 of size 1536
2019-01-24 02:37:40.578803: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6c500 of size 1536
2019-01-24 02:37:40.578807: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6cb00 of size 1536
2019-01-24 02:37:40.578810: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6d100 of size 1536
2019-01-24 02:37:40.578814: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6d700 of size 1536
2019-01-24 02:37:40.578817: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6dd00 of size 1536
2019-01-24 02:37:40.578821: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6e300 of size 1536
2019-01-24 02:37:40.578824: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6e900 of size 1536
2019-01-24 02:37:40.578828: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6ef00 of size 1536
2019-01-24 02:37:40.578831: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6f500 of size 1536
2019-01-24 02:37:40.578834: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca6fb00 of size 1536
2019-01-24 02:37:40.578838: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca70100 of size 1536
2019-01-24 02:37:40.578841: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca70700 of size 1536
2019-01-24 02:37:40.578845: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca70d00 of size 1536
2019-01-24 02:37:40.578848: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca71300 of size 1536
2019-01-24 02:37:40.578852: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca71900 of size 1536
2019-01-24 02:37:40.578855: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca71f00 of size 1536
2019-01-24 02:37:40.578859: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca72500 of size 1536
2019-01-24 02:37:40.578862: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca72b00 of size 1536
2019-01-24 02:37:40.578866: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca73100 of size 1536
2019-01-24 02:37:40.578869: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca73700 of size 1536
2019-01-24 02:37:40.578873: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca73d00 of size 1536
2019-01-24 02:37:40.578876: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca74300 of size 1536
2019-01-24 02:37:40.578879: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca74900 of size 1536
2019-01-24 02:37:40.578883: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca74f00 of size 1536
2019-01-24 02:37:40.578886: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca75500 of size 1536
2019-01-24 02:37:40.578890: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca75b00 of size 1536
2019-01-24 02:37:40.578893: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca76100 of size 1536
2019-01-24 02:37:40.578897: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca76700 of size 1536
2019-01-24 02:37:40.578900: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca76d00 of size 1536
2019-01-24 02:37:40.578903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca77300 of size 1536
2019-01-24 02:37:40.578907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca77900 of size 1536
2019-01-24 02:37:40.578910: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca77f00 of size 1536
2019-01-24 02:37:40.578914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca78500 of size 1536
2019-01-24 02:37:40.578917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca78b00 of size 1536
2019-01-24 02:37:40.578921: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca79100 of size 1536
2019-01-24 02:37:40.578924: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca79700 of size 1536
2019-01-24 02:37:40.578928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca79d00 of size 1536
2019-01-24 02:37:40.578931: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7a300 of size 1536
2019-01-24 02:37:40.578934: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7a900 of size 1536
2019-01-24 02:37:40.578938: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7af00 of size 1536
2019-01-24 02:37:40.578941: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7b500 of size 1536
2019-01-24 02:37:40.578945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7bb00 of size 1536
2019-01-24 02:37:40.578948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7c100 of size 1536
2019-01-24 02:37:40.578951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7c700 of size 1536
2019-01-24 02:37:40.578955: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7cd00 of size 1536
2019-01-24 02:37:40.578958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7d300 of size 1536
2019-01-24 02:37:40.578962: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7d900 of size 1536
2019-01-24 02:37:40.578965: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7df00 of size 1536
2019-01-24 02:37:40.578968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7e500 of size 1536
2019-01-24 02:37:40.578972: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7eb00 of size 1536
2019-01-24 02:37:40.578975: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7f100 of size 1536
2019-01-24 02:37:40.578979: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7f700 of size 1536
2019-01-24 02:37:40.578982: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca7fd00 of size 1536
2019-01-24 02:37:40.578985: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca80300 of size 1536
2019-01-24 02:37:40.578989: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca80900 of size 1536
2019-01-24 02:37:40.578992: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca80f00 of size 1536
2019-01-24 02:37:40.578996: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca81500 of size 1536
2019-01-24 02:37:40.578999: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca81b00 of size 1536
2019-01-24 02:37:40.579003: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca82100 of size 1536
2019-01-24 02:37:40.579006: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca82700 of size 1536
2019-01-24 02:37:40.579009: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca82d00 of size 1536
2019-01-24 02:37:40.579013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca83300 of size 1536
2019-01-24 02:37:40.579016: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca83900 of size 1536
2019-01-24 02:37:40.579020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca83f00 of size 1536
2019-01-24 02:37:40.579023: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca84500 of size 1536
2019-01-24 02:37:40.579027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca84b00 of size 1536
2019-01-24 02:37:40.579030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca85100 of size 1536
2019-01-24 02:37:40.579033: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca85700 of size 1536
2019-01-24 02:37:40.579037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca85d00 of size 1536
2019-01-24 02:37:40.579040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca86300 of size 1536
2019-01-24 02:37:40.579044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca86900 of size 1536
2019-01-24 02:37:40.579047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca86f00 of size 1536
2019-01-24 02:37:40.579050: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca87500 of size 1536
2019-01-24 02:37:40.579054: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca87b00 of size 1536
2019-01-24 02:37:40.579057: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca88100 of size 1536
2019-01-24 02:37:40.579061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca88700 of size 1536
2019-01-24 02:37:40.579064: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca88d00 of size 1536
2019-01-24 02:37:40.579068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca89300 of size 1536
2019-01-24 02:37:40.579071: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca89900 of size 1536
2019-01-24 02:37:40.579074: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca89f00 of size 1536
2019-01-24 02:37:40.579078: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8a500 of size 1536
2019-01-24 02:37:40.579081: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8ab00 of size 1536
2019-01-24 02:37:40.579085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8b100 of size 1536
2019-01-24 02:37:40.579088: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8b700 of size 1536
2019-01-24 02:37:40.579091: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8bd00 of size 1536
2019-01-24 02:37:40.579094: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8c300 of size 1536
2019-01-24 02:37:40.579097: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8c900 of size 1536
2019-01-24 02:37:40.579101: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8cf00 of size 1536
2019-01-24 02:37:40.579103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8d500 of size 1536
2019-01-24 02:37:40.579107: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8db00 of size 1536
2019-01-24 02:37:40.579110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8e100 of size 1536
2019-01-24 02:37:40.579114: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8e700 of size 1536
2019-01-24 02:37:40.579117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8ed00 of size 1536
2019-01-24 02:37:40.579121: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8f300 of size 1536
2019-01-24 02:37:40.579124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8f900 of size 1536
2019-01-24 02:37:40.579128: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca8ff00 of size 1536
2019-01-24 02:37:40.579131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca90500 of size 1536
2019-01-24 02:37:40.579135: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca90b00 of size 1536
2019-01-24 02:37:40.579138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca91100 of size 1536
2019-01-24 02:37:40.579142: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca91700 of size 1536
2019-01-24 02:37:40.579145: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca91d00 of size 1536
2019-01-24 02:37:40.579148: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca92300 of size 1536
2019-01-24 02:37:40.579152: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca92900 of size 1536
2019-01-24 02:37:40.579155: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca92f00 of size 1536
2019-01-24 02:37:40.579159: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca93500 of size 1536
2019-01-24 02:37:40.579162: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca93b00 of size 1536
2019-01-24 02:37:40.579166: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca94100 of size 1536
2019-01-24 02:37:40.579169: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca94700 of size 1536
2019-01-24 02:37:40.579173: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca94d00 of size 1536
2019-01-24 02:37:40.579176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca95300 of size 1536
2019-01-24 02:37:40.579180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca95900 of size 1536
2019-01-24 02:37:40.579183: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca95f00 of size 1536
2019-01-24 02:37:40.579186: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca96500 of size 1536
2019-01-24 02:37:40.579190: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca96b00 of size 1536
2019-01-24 02:37:40.579193: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca97100 of size 1536
2019-01-24 02:37:40.579197: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca97700 of size 1536
2019-01-24 02:37:40.579200: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca97d00 of size 1536
2019-01-24 02:37:40.579204: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca98300 of size 1536
2019-01-24 02:37:40.579207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca98900 of size 1536
2019-01-24 02:37:40.579210: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca98f00 of size 1536
2019-01-24 02:37:40.579214: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca99500 of size 1536
2019-01-24 02:37:40.579217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca99b00 of size 1536
2019-01-24 02:37:40.579221: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9a100 of size 1536
2019-01-24 02:37:40.579224: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9a700 of size 1536
2019-01-24 02:37:40.579228: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9ad00 of size 1536
2019-01-24 02:37:40.579231: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9b300 of size 1536
2019-01-24 02:37:40.579235: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9b900 of size 1536
2019-01-24 02:37:40.579238: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9bf00 of size 1536
2019-01-24 02:37:40.579242: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9c500 of size 1536
2019-01-24 02:37:40.579245: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9cb00 of size 1536
2019-01-24 02:37:40.579249: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9d100 of size 1536
2019-01-24 02:37:40.579252: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9d700 of size 1536
2019-01-24 02:37:40.579255: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9dd00 of size 1536
2019-01-24 02:37:40.579259: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9e300 of size 1536
2019-01-24 02:37:40.579262: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9e900 of size 1536
2019-01-24 02:37:40.579266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9ef00 of size 1536
2019-01-24 02:37:40.579269: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9f500 of size 1536
2019-01-24 02:37:40.579273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ca9fb00 of size 1536
2019-01-24 02:37:40.579276: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa0100 of size 1536
2019-01-24 02:37:40.579280: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa0700 of size 1536
2019-01-24 02:37:40.579283: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa0d00 of size 1536
2019-01-24 02:37:40.579286: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa1300 of size 1536
2019-01-24 02:37:40.579290: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa1900 of size 1536
2019-01-24 02:37:40.579293: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa1f00 of size 1536
2019-01-24 02:37:40.579297: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa2500 of size 1536
2019-01-24 02:37:40.579300: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa2b00 of size 1536
2019-01-24 02:37:40.579304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa3100 of size 1536
2019-01-24 02:37:40.579307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa3700 of size 1536
2019-01-24 02:37:40.579311: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa3d00 of size 1536
2019-01-24 02:37:40.579314: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa4300 of size 1536
2019-01-24 02:37:40.579318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa4900 of size 1536
2019-01-24 02:37:40.579321: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa4f00 of size 1536
2019-01-24 02:37:40.579324: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa5500 of size 1536
2019-01-24 02:37:40.579327: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa5b00 of size 1536
2019-01-24 02:37:40.579331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa6100 of size 1536
2019-01-24 02:37:40.579334: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa6700 of size 1536
2019-01-24 02:37:40.579338: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa6d00 of size 1536
2019-01-24 02:37:40.579341: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa7300 of size 1536
2019-01-24 02:37:40.579344: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa7900 of size 1536
2019-01-24 02:37:40.579348: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa7f00 of size 1536
2019-01-24 02:37:40.579351: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa8500 of size 1536
2019-01-24 02:37:40.579355: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa8b00 of size 1536
2019-01-24 02:37:40.579358: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa9100 of size 1536
2019-01-24 02:37:40.579361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa9700 of size 1536
2019-01-24 02:37:40.579365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caa9d00 of size 1536
2019-01-24 02:37:40.579368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaa300 of size 1536
2019-01-24 02:37:40.584894: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaa900 of size 1536
2019-01-24 02:37:40.584903: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaaf00 of size 1536
2019-01-24 02:37:40.584907: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caab500 of size 1536
2019-01-24 02:37:40.584911: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caabb00 of size 1536
2019-01-24 02:37:40.584914: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caac100 of size 1536
2019-01-24 02:37:40.584918: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caac700 of size 1536
2019-01-24 02:37:40.584922: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caacd00 of size 1536
2019-01-24 02:37:40.584925: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caad300 of size 1536
2019-01-24 02:37:40.584928: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caad900 of size 1536
2019-01-24 02:37:40.584932: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caadf00 of size 1536
2019-01-24 02:37:40.584935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caae500 of size 1536
2019-01-24 02:37:40.584939: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaeb00 of size 1536
2019-01-24 02:37:40.584942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaf100 of size 1536
2019-01-24 02:37:40.584946: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caaf700 of size 1536
2019-01-24 02:37:40.584949: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caafd00 of size 2816
2019-01-24 02:37:40.584953: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab0800 of size 256
2019-01-24 02:37:40.584956: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab0900 of size 1536
2019-01-24 02:37:40.584960: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab0f00 of size 256
2019-01-24 02:37:40.584963: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab1000 of size 2816
2019-01-24 02:37:40.584966: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab1b00 of size 256
2019-01-24 02:37:40.584970: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab1c00 of size 1536
2019-01-24 02:37:40.584974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab2200 of size 1536
2019-01-24 02:37:40.584977: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab2800 of size 1536
2019-01-24 02:37:40.584980: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab2e00 of size 2816
2019-01-24 02:37:40.584984: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab3900 of size 1536
2019-01-24 02:37:40.584987: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab3f00 of size 1536
2019-01-24 02:37:40.584991: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4500 of size 256
2019-01-24 02:37:40.584994: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4600 of size 256
2019-01-24 02:37:40.584998: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4700 of size 1536
2019-01-24 02:37:40.585001: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4d00 of size 256
2019-01-24 02:37:40.585005: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cab4e00 of size 33792
2019-01-24 02:37:40.585009: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cabd200 of size 33792
2019-01-24 02:37:40.585013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cac5600 of size 33792
2019-01-24 02:37:40.585016: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cacda00 of size 33792
2019-01-24 02:37:40.585019: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cad5e00 of size 33792
2019-01-24 02:37:40.585023: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cade200 of size 33792
2019-01-24 02:37:40.585026: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cae6600 of size 33792
2019-01-24 02:37:40.585030: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caeea00 of size 33792
2019-01-24 02:37:40.585033: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caf6e00 of size 33792
2019-01-24 02:37:40.585037: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1caff200 of size 33792
2019-01-24 02:37:40.585040: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb07600 of size 33792
2019-01-24 02:37:40.585044: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb0fa00 of size 33792
2019-01-24 02:37:40.585047: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb17e00 of size 33792
2019-01-24 02:37:40.585051: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb20200 of size 33792
2019-01-24 02:37:40.585054: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb28600 of size 33792
2019-01-24 02:37:40.585058: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb30a00 of size 33792
2019-01-24 02:37:40.585061: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb38e00 of size 33792
2019-01-24 02:37:40.585064: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb41200 of size 33792
2019-01-24 02:37:40.585068: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb49600 of size 33792
2019-01-24 02:37:40.585071: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb51a00 of size 33792
2019-01-24 02:37:40.585075: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb59e00 of size 33792
2019-01-24 02:37:40.585078: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb62200 of size 33792
2019-01-24 02:37:40.585082: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb6a600 of size 33792
2019-01-24 02:37:40.585085: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb72a00 of size 33792
2019-01-24 02:37:40.585089: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb7ae00 of size 33792
2019-01-24 02:37:40.585092: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb83200 of size 33792
2019-01-24 02:37:40.585096: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb8b600 of size 33792
2019-01-24 02:37:40.585099: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cb93a00 of size 48537
6
2019-01-24 02:37:40.585103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cc0a200 of size 45158
4
2019-01-24 02:37:40.585106: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cc78600 of size 45158
4
2019-01-24 02:37:40.585110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cce6a00 of size 45158
4
2019-01-24 02:37:40.585113: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cd54e00 of size 45158
4
2019-01-24 02:37:40.585117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cdc3200 of size 45158
4
2019-01-24 02:37:40.585120: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ce31600 of size 45158
4
2019-01-24 02:37:40.585124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ce9fa00 of size 45158
4
2019-01-24 02:37:40.585127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cf0de00 of size 45158
4
2019-01-24 02:37:40.585131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cf7c200 of size 45158
4
2019-01-24 02:37:40.585134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1cfea600 of size 45158
4
2019-01-24 02:37:40.585137: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d058a00 of size 45158
4
2019-01-24 02:37:40.585141: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d0c6e00 of size 45158
4
2019-01-24 02:37:40.585144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d135200 of size 45158
4
2019-01-24 02:37:40.585148: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d1a3600 of size 45158
4
2019-01-24 02:37:40.585151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d211a00 of size 45158
4
2019-01-24 02:37:40.585155: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d27fe00 of size 45158
4
2019-01-24 02:37:40.585158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d2ee200 of size 45158
4
2019-01-24 02:37:40.585162: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d35c600 of size 45158
4
2019-01-24 02:37:40.585165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d3caa00 of size 45158
4
2019-01-24 02:37:40.585168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d438e00 of size 45158
4
2019-01-24 02:37:40.585172: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d4a7200 of size 45158
4
2019-01-24 02:37:40.585175: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d515600 of size 45158
4
2019-01-24 02:37:40.585179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d583a00 of size 45158
4
2019-01-24 02:37:40.585182: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d5f1e00 of size 45158
4
2019-01-24 02:37:40.585186: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d660200 of size 45158
4
2019-01-24 02:37:40.585189: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d6ce600 of size 45158
4
2019-01-24 02:37:40.585192: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d73ca00 of size 45158
4
2019-01-24 02:37:40.585196: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d7aae00 of size 45158
4
2019-01-24 02:37:40.585199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d819200 of size 45158
4
2019-01-24 02:37:40.585203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d887600 of size 45158
4
2019-01-24 02:37:40.585206: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d8f5a00 of size 45158
4
2019-01-24 02:37:40.585210: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d963e00 of size 45158
4
2019-01-24 02:37:40.585213: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1d9d2200 of size 45158
4
2019-01-24 02:37:40.585217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1da40600 of size 45158
4
2019-01-24 02:37:40.585220: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1daaea00 of size 45158
4
2019-01-24 02:37:40.585223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1db1ce00 of size 45158
4
2019-01-24 02:37:40.585227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1db8b200 of size 45158
4
2019-01-24 02:37:40.585230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dbf9600 of size 45158
4
2019-01-24 02:37:40.585234: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dc67a00 of size 45158
4
2019-01-24 02:37:40.585237: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dcd5e00 of size 45158
4
2019-01-24 02:37:40.585241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dd44200 of size 45158
4
2019-01-24 02:37:40.585244: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ddb2600 of size 45158
4
2019-01-24 02:37:40.585248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1de20a00 of size 45158
4
2019-01-24 02:37:40.585251: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1de8ee00 of size 45158
4
2019-01-24 02:37:40.585254: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1defd200 of size 45158
4
2019-01-24 02:37:40.585258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1df6b600 of size 45158
4
2019-01-24 02:37:40.585261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1dfd9a00 of size 45158
4
2019-01-24 02:37:40.585265: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e047e00 of size 45158
4
2019-01-24 02:37:40.585268: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e0b6200 of size 45158
4
2019-01-24 02:37:40.585271: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e124600 of size 45158
4
2019-01-24 02:37:40.585275: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e192a00 of size 45158
4
2019-01-24 02:37:40.585278: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e200e00 of size 45158
4
2019-01-24 02:37:40.585282: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e26f200 of size 45158
4
2019-01-24 02:37:40.585285: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e2dd600 of size 45158
4
2019-01-24 02:37:40.585289: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e34ba00 of size 45158
4
2019-01-24 02:37:40.585292: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e3b9e00 of size 45158
4
2019-01-24 02:37:40.585296: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e428200 of size 45158
4
2019-01-24 02:37:40.585299: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e496600 of size 45158
4
2019-01-24 02:37:40.585303: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e504a00 of size 45158
4
2019-01-24 02:37:40.585306: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e572e00 of size 45158
4
2019-01-24 02:37:40.585309: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e5e1200 of size 45158
4
2019-01-24 02:37:40.585313: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e64f600 of size 45158
4
2019-01-24 02:37:40.585316: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e6bda00 of size 45158
4
2019-01-24 02:37:40.585320: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e72be00 of size 45158
4
2019-01-24 02:37:40.585323: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e79a200 of size 45158
4
2019-01-24 02:37:40.585326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e808600 of size 45158
4
2019-01-24 02:37:40.585330: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e876a00 of size 45158
4
2019-01-24 02:37:40.585333: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e8e4e00 of size 45158
4
2019-01-24 02:37:40.585337: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e953200 of size 45158
4
2019-01-24 02:37:40.585340: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c1600 of size 1536
2019-01-24 02:37:40.585344: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c1c00 of size 1536
2019-01-24 02:37:40.585347: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c2200 of size 1536
2019-01-24 02:37:40.585351: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c2800 of size 1536
2019-01-24 02:37:40.585354: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c2e00 of size 512
2019-01-24 02:37:40.585358: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c3000 of size 512
2019-01-24 02:37:40.585361: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c3200 of size 1536
2019-01-24 02:37:40.585365: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c3800 of size 2816
2019-01-24 02:37:40.585368: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c4300 of size 1536
2019-01-24 02:37:40.585371: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c4900 of size 1536
2019-01-24 02:37:40.585375: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c4f00 of size 1536
2019-01-24 02:37:40.585378: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c5500 of size 2816
2019-01-24 02:37:40.585382: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6000 of size 1536
2019-01-24 02:37:40.585385: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6600 of size 256
2019-01-24 02:37:40.585389: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6700 of size 1536
2019-01-24 02:37:40.585392: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c6d00 of size 2816
2019-01-24 02:37:40.585395: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c7800 of size 256
2019-01-24 02:37:40.585398: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c7900 of size 2816
2019-01-24 02:37:40.585402: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c8400 of size 2816
2019-01-24 02:37:40.585405: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c8f00 of size 256
2019-01-24 02:37:40.585409: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c9000 of size 1536
2019-01-24 02:37:40.585412: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c9600 of size 1536
2019-01-24 02:37:40.585416: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9c9c00 of size 2816
2019-01-24 02:37:40.585419: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ca700 of size 1536
2019-01-24 02:37:40.585422: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cad00 of size 1536
2019-01-24 02:37:40.585426: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cb300 of size 1536
2019-01-24 02:37:40.585429: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cb900 of size 256
2019-01-24 02:37:40.585433: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cba00 of size 256
2019-01-24 02:37:40.585436: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cbb00 of size 2816
2019-01-24 02:37:40.585440: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cc600 of size 1536
2019-01-24 02:37:40.585443: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ccc00 of size 256
2019-01-24 02:37:40.585446: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ccd00 of size 2816
2019-01-24 02:37:40.585450: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cd800 of size 2816
2019-01-24 02:37:40.585453: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ce300 of size 1536
2019-01-24 02:37:40.585457: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ce900 of size 1536
2019-01-24 02:37:40.585460: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cef00 of size 1536
2019-01-24 02:37:40.585464: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cf500 of size 1536
2019-01-24 02:37:40.585467: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9cfb00 of size 1536
2019-01-24 02:37:40.585471: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d0100 of size 256
2019-01-24 02:37:40.585474: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d0200 of size 1536
2019-01-24 02:37:40.585477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d0800 of size 2816
2019-01-24 02:37:40.585481: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d1300 of size 256
2019-01-24 02:37:40.585484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d1400 of size 2816
2019-01-24 02:37:40.585488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d1f00 of size 2816
2019-01-24 02:37:40.585491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d2a00 of size 2816
2019-01-24 02:37:40.585495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d3500 of size 1536
2019-01-24 02:37:40.585498: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d3b00 of size 1536
2019-01-24 02:37:40.585501: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d4100 of size 2816
2019-01-24 02:37:40.585505: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d4c00 of size 1536
2019-01-24 02:37:40.585508: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d5200 of size 2816
2019-01-24 02:37:40.585512: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d5d00 of size 1536
2019-01-24 02:37:40.585515: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d6300 of size 1536
2019-01-24 02:37:40.585518: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d6900 of size 2816
2019-01-24 02:37:40.591905: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7400 of size 256
2019-01-24 02:37:40.591913: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7500 of size 1536
2019-01-24 02:37:40.591917: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7b00 of size 256
2019-01-24 02:37:40.591920: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d7c00 of size 2816
2019-01-24 02:37:40.591923: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d8700 of size 256
2019-01-24 02:37:40.591926: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d8800 of size 2816
2019-01-24 02:37:40.591929: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d9300 of size 2816
2019-01-24 02:37:40.591932: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9d9e00 of size 1536
2019-01-24 02:37:40.591935: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9da400 of size 1536
2019-01-24 02:37:40.591939: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9daa00 of size 1536
2019-01-24 02:37:40.591942: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9db000 of size 256
2019-01-24 02:37:40.591945: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9db100 of size 1536
2019-01-24 02:37:40.591948: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9db700 of size 1536
2019-01-24 02:37:40.591951: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dbd00 of size 256
2019-01-24 02:37:40.591954: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dbe00 of size 1536
2019-01-24 02:37:40.591958: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dc400 of size 256
2019-01-24 02:37:40.591961: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dc500 of size 256
2019-01-24 02:37:40.591964: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dc600 of size 2816
2019-01-24 02:37:40.591968: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dd100 of size 1536
2019-01-24 02:37:40.591971: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dd700 of size 2816
2019-01-24 02:37:40.591974: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9de200 of size 1536
2019-01-24 02:37:40.591977: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9de800 of size 1536
2019-01-24 02:37:40.591981: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dee00 of size 2816
2019-01-24 02:37:40.591984: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9df900 of size 1536
2019-01-24 02:37:40.591987: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9dff00 of size 1536
2019-01-24 02:37:40.591991: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0500 of size 256
2019-01-24 02:37:40.591994: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0600 of size 1536
2019-01-24 02:37:40.591997: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0c00 of size 256
2019-01-24 02:37:40.592001: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e0d00 of size 2816
2019-01-24 02:37:40.592004: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e1800 of size 256
2019-01-24 02:37:40.592007: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e1900 of size 2816
2019-01-24 02:37:40.592010: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e2400 of size 2816
2019-01-24 02:37:40.592013: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e2f00 of size 1536
2019-01-24 02:37:40.592017: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e3500 of size 1536
2019-01-24 02:37:40.592020: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e3b00 of size 1536
2019-01-24 02:37:40.592024: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e4100 of size 2816
2019-01-24 02:37:40.592027: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e4c00 of size 1536
2019-01-24 02:37:40.592031: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e5200 of size 1536
2019-01-24 02:37:40.592034: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e5800 of size 256
2019-01-24 02:37:40.592038: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e5900 of size 2816
2019-01-24 02:37:40.592041: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e6400 of size 1536
2019-01-24 02:37:40.592045: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e6a00 of size 2816
2019-01-24 02:37:40.592048: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7500 of size 256
2019-01-24 02:37:40.592052: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7600 of size 256
2019-01-24 02:37:40.592055: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7700 of size 1536
2019-01-24 02:37:40.592059: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e7d00 of size 2816
2019-01-24 02:37:40.592062: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e8800 of size 1536
2019-01-24 02:37:40.592065: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e8e00 of size 2816
2019-01-24 02:37:40.592069: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e9900 of size 1536
2019-01-24 02:37:40.592072: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9e9f00 of size 1536
2019-01-24 02:37:40.592076: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ea500 of size 256
2019-01-24 02:37:40.592079: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ea600 of size 1536
2019-01-24 02:37:40.592083: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eac00 of size 256
2019-01-24 02:37:40.592086: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ead00 of size 1536
2019-01-24 02:37:40.592090: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eb300 of size 256
2019-01-24 02:37:40.592093: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eb400 of size 1536
2019-01-24 02:37:40.592096: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9eba00 of size 1536
2019-01-24 02:37:40.592100: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ec000 of size 1536
2019-01-24 02:37:40.592103: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ec600 of size 1536
2019-01-24 02:37:40.592107: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ecc00 of size 1536
2019-01-24 02:37:40.592110: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ed200 of size 256
2019-01-24 02:37:40.592114: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ed300 of size 1536
2019-01-24 02:37:40.592117: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ed900 of size 2816
2019-01-24 02:37:40.592120: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ee400 of size 256
2019-01-24 02:37:40.592124: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ee500 of size 2816
2019-01-24 02:37:40.592127: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ef000 of size 1536
2019-01-24 02:37:40.592131: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ef600 of size 2816
2019-01-24 02:37:40.592134: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f0100 of size 1536
2019-01-24 02:37:40.592138: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f0700 of size 1536
2019-01-24 02:37:40.592141: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f0d00 of size 1536
2019-01-24 02:37:40.592144: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f1300 of size 2816
2019-01-24 02:37:40.592148: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f1e00 of size 1536
2019-01-24 02:37:40.592151: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f2400 of size 256
2019-01-24 02:37:40.592155: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f2500 of size 1536
2019-01-24 02:37:40.592158: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f2b00 of size 2816
2019-01-24 02:37:40.592162: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f3600 of size 256
2019-01-24 02:37:40.592165: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f3700 of size 2816
2019-01-24 02:37:40.592168: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f4200 of size 256
2019-01-24 02:37:40.592172: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f4300 of size 2816
2019-01-24 02:37:40.592175: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f4e00 of size 1536
2019-01-24 02:37:40.592179: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f5400 of size 1536
2019-01-24 02:37:40.592182: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f5a00 of size 2816
2019-01-24 02:37:40.592186: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f6500 of size 1536
2019-01-24 02:37:40.592189: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f6b00 of size 256
2019-01-24 02:37:40.592193: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f6c00 of size 1536
2019-01-24 02:37:40.592196: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7200 of size 1536
2019-01-24 02:37:40.592199: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7800 of size 256
2019-01-24 02:37:40.592203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7900 of size 256
2019-01-24 02:37:40.592206: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f7a00 of size 1536
2019-01-24 02:37:40.592210: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f8000 of size 256
2019-01-24 02:37:40.592213: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f8100 of size 2816
2019-01-24 02:37:40.592217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f8c00 of size 2816
2019-01-24 02:37:40.592220: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f9700 of size 1536
2019-01-24 02:37:40.592223: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9f9d00 of size 1536
2019-01-24 02:37:40.592227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fa300 of size 2816
2019-01-24 02:37:40.592230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fae00 of size 1536
2019-01-24 02:37:40.592234: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fb400 of size 2816
2019-01-24 02:37:40.592237: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fbf00 of size 1536
2019-01-24 02:37:40.592241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fc500 of size 1536
2019-01-24 02:37:40.592244: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fcb00 of size 2816
2019-01-24 02:37:40.592248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fd600 of size 256
2019-01-24 02:37:40.592251: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fd700 of size 1536
2019-01-24 02:37:40.592254: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fdd00 of size 256
2019-01-24 02:37:40.592258: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fde00 of size 2816
2019-01-24 02:37:40.592261: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fe900 of size 2816
2019-01-24 02:37:40.592265: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9ff400 of size 2816
2019-01-24 02:37:40.592268: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1e9fff00 of size 2816
2019-01-24 02:37:40.592272: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea00a00 of size 1536
2019-01-24 02:37:40.592275: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea01000 of size 2816
2019-01-24 02:37:40.592280: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea01b00 of size 1536
2019-01-24 02:37:40.592283: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02100 of size 1536
2019-01-24 02:37:40.592286: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02700 of size 256
2019-01-24 02:37:40.592290: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02800 of size 1536
2019-01-24 02:37:40.592293: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea02e00 of size 1536
2019-01-24 02:37:40.592297: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea03400 of size 256
2019-01-24 02:37:40.592300: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea03500 of size 2816
2019-01-24 02:37:40.592304: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea04000 of size 1536
2019-01-24 02:37:40.592307: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea04600 of size 2816
2019-01-24 02:37:40.592311: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05100 of size 256
2019-01-24 02:37:40.592314: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05200 of size 256
2019-01-24 02:37:40.592318: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05300 of size 1536
2019-01-24 02:37:40.592321: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05900 of size 256
2019-01-24 02:37:40.592325: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea05a00 of size 1536
2019-01-24 02:37:40.592328: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea06000 of size 1536
2019-01-24 02:37:40.592331: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea06600 of size 1536
2019-01-24 02:37:40.592335: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea06c00 of size 1536
2019-01-24 02:37:40.592338: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea07200 of size 256
2019-01-24 02:37:40.592342: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea07300 of size 2816
2019-01-24 02:37:40.592345: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea07e00 of size 1536
2019-01-24 02:37:40.592349: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea08400 of size 256
2019-01-24 02:37:40.592352: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea08500 of size 2816
2019-01-24 02:37:40.592356: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea09000 of size 2816
2019-01-24 02:37:40.592359: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea09b00 of size 2816
2019-01-24 02:37:40.592362: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0a600 of size 256
2019-01-24 02:37:40.592366: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0a700 of size 1536
2019-01-24 02:37:40.592369: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0ad00 of size 2816
2019-01-24 02:37:40.592373: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0b800 of size 1536
2019-01-24 02:37:40.592376: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0be00 of size 1536
2019-01-24 02:37:40.592380: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0c400 of size 1536
2019-01-24 02:37:40.592383: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0ca00 of size 2816
2019-01-24 02:37:40.592387: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0d500 of size 1536
2019-01-24 02:37:40.592390: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0db00 of size 256
2019-01-24 02:37:40.592393: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0dc00 of size 256
2019-01-24 02:37:40.592397: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0dd00 of size 1536
2019-01-24 02:37:40.592400: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0e300 of size 256
2019-01-24 02:37:40.592404: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0e400 of size 256
2019-01-24 02:37:40.592407: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0e500 of size 2816
2019-01-24 02:37:40.592411: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0f000 of size 256
2019-01-24 02:37:40.592414: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0f100 of size 1536
2019-01-24 02:37:40.592418: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0f700 of size 1536
2019-01-24 02:37:40.592421: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea0fd00 of size 1536
2019-01-24 02:37:40.592425: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea10300 of size 1536
2019-01-24 02:37:40.592428: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea10900 of size 1536
2019-01-24 02:37:40.592431: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea10f00 of size 256
2019-01-24 02:37:40.592435: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea11000 of size 1536
2019-01-24 02:37:40.592438: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea11600 of size 256
2019-01-24 02:37:40.592442: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea11700 of size 2816
2019-01-24 02:37:40.592445: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea12200 of size 1536
2019-01-24 02:37:40.592449: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea12800 of size 1536
2019-01-24 02:37:40.592452: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea12e00 of size 1536
2019-01-24 02:37:40.592456: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea13400 of size 1536
2019-01-24 02:37:40.592459: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea13a00 of size 2816
2019-01-24 02:37:40.592462: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea14500 of size 1536
2019-01-24 02:37:40.592466: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea14b00 of size 256
2019-01-24 02:37:40.592469: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea14c00 of size 1536
2019-01-24 02:37:40.592473: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea15200 of size 16640
2019-01-24 02:37:40.592477: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ea19300 of size 54190
08
2019-01-24 02:37:40.592481: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1ef44300 of size 27095
04
2019-01-24 02:37:40.592484: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1f1d9b00 of size 72253
44
2019-01-24 02:37:40.592488: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb1f8bdb00 of size 10838
016
2019-01-24 02:37:40.592491: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb20313b00 of size 93671
4240
2019-01-24 02:37:40.592495: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb58065b00 of size 23417
8560
2019-01-24 02:37:40.592499: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb65fba300 of size 23417
8560
2019-01-24 02:37:40.592502: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb73f0eb00 of size 23417
8560
2019-01-24 02:37:40.592506: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb81e63300 of size 23417
8560
2019-01-24 02:37:40.592509: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xb8fdb7b00 of size 93671
4240
2019-01-24 02:37:40.601154: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xbc7b09b00 of size 93671
4240
2019-01-24 02:37:40.601163: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xbff85bb00 of size 93671
4240
2019-01-24 02:37:40.601166: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc375adb00 of size 15611
904
2019-01-24 02:37:40.601169: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38491300 of size 512
2019-01-24 02:37:40.601173: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc38491500 of size 78059
52
2019-01-24 02:37:40.601176: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38c03100 of size 512
2019-01-24 02:37:40.601180: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38c03300 of size 512
2019-01-24 02:37:40.601183: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38c03500 of size 512
2019-01-24 02:37:40.601187: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc38c03700 of size 39040
00
2019-01-24 02:37:40.601190: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc38fbc900 of size 512
2019-01-24 02:37:40.601193: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc38fbcb00 of size 11721
216
2019-01-24 02:37:40.601197: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc39aea500 of size 512
2019-01-24 02:37:40.601200: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc39aea700 of size 58641
92
2019-01-24 02:37:40.601203: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3a082200 of size 512
2019-01-24 02:37:40.601207: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3a082400 of size 11720
704
2019-01-24 02:37:40.601210: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3abafc00 of size 512
2019-01-24 02:37:40.601213: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3abafe00 of size 11720
704
2019-01-24 02:37:40.601217: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3b6dd600 of size 512
2019-01-24 02:37:40.601220: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3b6dd800 of size 11720
704
2019-01-24 02:37:40.601224: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3c20b000 of size 512
2019-01-24 02:37:40.601227: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3c20b200 of size 58641
92
2019-01-24 02:37:40.601230: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3c7a2d00 of size 512
2019-01-24 02:37:40.601234: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3c7a2f00 of size 11720
704
2019-01-24 02:37:40.601237: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3d2d0700 of size 512
2019-01-24 02:37:40.601241: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3d2d0900 of size 11720
704
2019-01-24 02:37:40.601245: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3ddfe100 of size 512
2019-01-24 02:37:40.601248: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3ddfe300 of size 58641
92
2019-01-24 02:37:40.601252: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e395e00 of size 512
2019-01-24 02:37:40.601255: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e396000 of size 7680
2019-01-24 02:37:40.601259: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e397e00 of size 512
2019-01-24 02:37:40.601262: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e398000 of size 7680
2019-01-24 02:37:40.601266: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e399e00 of size 512
2019-01-24 02:37:40.601270: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e39a000 of size 7680
2019-01-24 02:37:40.601273: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e39be00 of size 512
2019-01-24 02:37:40.601277: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e39c000 of size 7680
2019-01-24 02:37:40.601280: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e39de00 of size 512
2019-01-24 02:37:40.601284: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e39e000 of size 7680
2019-01-24 02:37:40.601287: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e39fe00 of size 512
2019-01-24 02:37:40.601291: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a0000 of size 2048
2019-01-24 02:37:40.601294: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e3a0800 of size 512
2019-01-24 02:37:40.601298: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a0a00 of size 2048
2019-01-24 02:37:40.601301: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a1200 of size 3072
2019-01-24 02:37:40.601305: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc3e3a1e00 of size 512
2019-01-24 02:37:40.601308: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc3e3a2000 of size 70254
2848
2019-01-24 02:37:40.601312: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc681a1400 of size 23417
8560
2019-01-24 02:37:40.601315: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xc760f5c00 of size 26130
9696
2019-01-24 02:37:40.601319: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xc85a2a100 of size 93671
4240
2019-01-24 02:37:40.601322: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xcbd77c100 of size 93671
4240
2019-01-24 02:37:40.601326: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xcf54ce100 of size 93671
4240
2019-01-24 02:37:40.601329: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Chunk at 0xd2d220100 of size 93671
4240
2019-01-24 02:37:40.601333: I tensorflow/core/common_runtime/bfc_allocator.cc:665] Free  at 0xd64f72100 of size 90480
7680
2019-01-24 02:37:40.601336: I tensorflow/core/common_runtime/bfc_allocator.cc:671]      Summary of in-use Chunks by s
ize:
2019-01-24 02:37:40.601344: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1274 Chunks of size 256 totalling
318.5KiB
2019-01-24 02:37:40.601349: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 134 Chunks of size 512 totalling 6
7.0KiB
2019-01-24 02:37:40.601353: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 579 Chunks of size 768 totalling 4
34.2KiB
2019-01-24 02:37:40.601357: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 1280 totalling 3.
8KiB
2019-01-24 02:37:40.601361: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 681 Chunks of size 1536 totalling
1021.5KiB
2019-01-24 02:37:40.601365: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 2048 totalling 18
.0KiB
2019-01-24 02:37:40.601369: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 675 Chunks of size 2816 totalling
1.81MiB
2019-01-24 02:37:40.601373: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 3072 totalling 9.
0KiB
2019-01-24 02:37:40.601377: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 4352 totalling 8.
5KiB
2019-01-24 02:37:40.601381: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 37 Chunks of size 6144 totalling 2
22.0KiB
2019-01-24 02:37:40.601385: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 7168 totalling 35
.0KiB
2019-01-24 02:37:40.601389: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 8448 totalling 41
.2KiB
2019-01-24 02:37:40.601393: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 10496 totalling 1
0.2KiB
2019-01-24 02:37:40.601397: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 11520 totalling 1
1.2KiB
2019-01-24 02:37:40.601401: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 39 Chunks of size 12288 totalling
468.0KiB
2019-01-24 02:37:40.601405: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 6 Chunks of size 16128 totalling 9
4.5KiB
2019-01-24 02:37:40.601409: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 16640 totalling 6
5.0KiB
2019-01-24 02:37:40.601413: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 24 Chunks of size 16896 totalling
396.0KiB
2019-01-24 02:37:40.601417: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 18944 totalling 5
5.5KiB
2019-01-24 02:37:40.601421: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 38 Chunks of size 24320 totalling
902.5KiB
2019-01-24 02:37:40.601425: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 28416 totalling 2
22.0KiB
2019-01-24 02:37:40.601429: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 32000 totalling 3
1.2KiB
2019-01-24 02:37:40.601433: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 27 Chunks of size 33792 totalling
891.0KiB
2019-01-24 02:37:40.601437: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 36864 totalling 3
6.0KiB
2019-01-24 02:37:40.601441: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 47104 totalling 4
6.0KiB
2019-01-24 02:37:40.601445: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 56576 totalling 2
21.0KiB
2019-01-24 02:37:40.601449: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 7 Chunks of size 57600 totalling 3
93.8KiB
2019-01-24 02:37:40.601453: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 3 Chunks of size 66048 totalling 1
93.5KiB
2019-01-24 02:37:40.601457: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 28 Chunks of size 67328 totalling
1.80MiB
2019-01-24 02:37:40.601461: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 108288 totalling
105.8KiB
2019-01-24 02:37:40.601465: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 60 Chunks of size 112896 totalling
 6.46MiB
2019-01-24 02:37:40.601469: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 129792 totalling
126.8KiB
2019-01-24 02:37:40.601473: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 4 Chunks of size 131840 totalling
515.0KiB
2019-01-24 02:37:40.601477: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 225792 totalling
441.0KiB
2019-01-24 02:37:40.601481: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 230400 totalling
1.76MiB
2019-01-24 02:37:40.601485: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 288000 totalling
281.2KiB
2019-01-24 02:37:40.601489: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 69 Chunks of size 451584 totalling
 29.72MiB
2019-01-24 02:37:40.601493: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 485376 totalling
474.0KiB
2019-01-24 02:37:40.601497: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 12 Chunks of size 677376 totalling
 7.75MiB
2019-01-24 02:37:40.601501: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 1354752 totalling
 1.29MiB
2019-01-24 02:37:40.601505: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 71 Chunks of size 1806336 totallin
g 122.31MiB
2019-01-24 02:37:40.601509: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 2032128 totalling
 1.94MiB
2019-01-24 02:37:40.601513: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 11 Chunks of size 2709504 totallin
g 28.42MiB
2019-01-24 02:37:40.601517: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 3316480 totalling
 3.16MiB
2019-01-24 02:37:40.601520: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5419008 totalling
 5.17MiB
2019-01-24 02:37:40.601524: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 1 Chunks of size 5435648 totalling
 5.18MiB
2019-01-24 02:37:40.601528: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 2 Chunks of size 7225344 totalling
 13.78MiB
2019-01-24 02:37:40.601532: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 9 Chunks of size 10838016 totallin
g 93.02MiB
2019-01-24 02:37:40.601536: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 5 Chunks of size 234178560 totalli
ng 1.09GiB
2019-01-24 02:37:40.601540: I tensorflow/core/common_runtime/bfc_allocator.cc:674] 8 Chunks of size 936714240 totalli
ng 6.98GiB
2019-01-24 02:37:40.601544: I tensorflow/core/common_runtime/bfc_allocator.cc:678] Sum Total of in-use chunks: 8.39Gi
B
2019-01-24 02:37:40.601550: I tensorflow/core/common_runtime/bfc_allocator.cc:680] Stats:
Limit:                 11015644775
InUse:                  9012258560
MaxInUse:              10301485312
NumAllocs:                    9512
MaxAllocSize:           2236809216

2019-01-24 02:37:40.601691: W tensorflow/core/common_runtime/bfc_allocator.cc:279] **********************************
*************______***_***********************************________
2019-01-24 02:37:40.601706: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at strided_slice_op.cc:
247 : Resource exhausted: OOM when allocating tensor with shape[487872,480] and type float on /job:localhost/replica:
0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1327, in _do_ca
ll
    return fn(*args)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1312, in _run_f
n
    options, feed_dict, fetch_list, target_list, run_metadata)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1420, in _call_
tf_sessionrun
    status, run_metadata)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py", line 516, in
__exit__
    c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[487872,480] and
 type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[Node: training/Adam/gradients/AddN_5/tmp_var_zeros = ZerosLike[T=DT_FLOAT, _device="/job:localhost/replica
:0/task:0/device:GPU:0"](training/Adam/gradients/lstm_1/strided_slice_2_grad/StridedSliceGrad)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunO
ptions for current allocation info.


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "runCNN_LSTM.py", line 160, in <module>
    main()
  File "runCNN_LSTM.py", line 157, in main
    runCNN_LSTM(record = RECORD)
  File "runCNN_LSTM.py", line 140, in runCNN_LSTM
    batch_size = train_batch_size, in_epochs = in_epochs, stateful = STATEFUL, record = record)
  File "runCNN_LSTM.py", line 44, in trainCNN_LSTM
    in_epochs = in_epochs, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/LSTM_VGG16Helper.py", line 56, in t
rainImageModelForEpochs
    model = trainImageModelOnSets(model, e, trainingSubjects, trainingBiwi, timesteps, output_begin, num_outputs, bat
ch_size, in_epochs, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/LSTM_VGG16Helper.py", line 46, in t
rainImageModelOnSets
    model.fit_generator(data_gen, steps_per_epoch=len(data_gen), epochs=in_epochs, verbose=1)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/models.py", line 1315, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 2230, in fit_generator
    class_weight=class_weight)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 1883, in train_on_batch
    outputs = self.train_function(ins)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py", line 2482, in __call
__
    **self.session_kwargs)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 905, in run
    run_metadata_ptr)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1140, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1321, in _do_ru
n
    run_metadata)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1340, in _do_ca
ll
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[487872,480] and
 type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[Node: training/Adam/gradients/AddN_5/tmp_var_zeros = ZerosLike[T=DT_FLOAT, _device="/job:localhost/replica
:0/task:0/device:GPU:0"](training/Adam/gradients/lstm_1/strided_slice_2_grad/StridedSliceGrad)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunO
ptions for current allocation info.

mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 02:38:31.566689: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 02:38:31.664057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 02:38:31.664370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 02:38:31.664384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 02:38:31.821281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 02:38:31.821304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 02:38:31.821308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 02:38:31.821485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10505 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_02-39-18 has been started to be evaluated.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 331, 331, 3)  0
__________________________________________________________________________________________________
stem_conv1 (Conv2D)             (None, 165, 165, 96) 2592        input_1[0][0]
__________________________________________________________________________________________________
stem_bn1 (BatchNormalization)   (None, 165, 165, 96) 384         stem_conv1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
reduction_conv_1_stem_1 (Conv2D (None, 165, 165, 42) 4032        activation_1[0][0]
__________________________________________________________________________________________________
reduction_bn_1_stem_1 (BatchNor (None, 165, 165, 42) 168         reduction_conv_1_stem_1[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 165, 165, 42) 0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 83, 83, 42)   2814        activation_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_st (None, 83, 83, 42)   8736        activation_4[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 83, 83, 42)   168         separable_conv_1_reduction_1_stem
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 83, 83, 42)   2814        activation_3[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_st (None, 83, 83, 42)   3822        activation_5[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 83, 83, 42)   168         separable_conv_2_reduction_1_stem
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
reduction_add_1_stem_1 (Add)    (None, 83, 83, 42)   0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 83, 83, 42)   8736        activation_6[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 83, 83, 42)   0           reduction_add_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 83, 83, 42)   6432        activation_8[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 83, 83, 42)   2142        activation_10[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 83, 83, 42)   3822        activation_7[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_stem_1 (MaxPool (None, 83, 83, 42)   0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 83, 83, 42)   2814        activation_9[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 83, 83, 42)   2142        activation_11[0][0]
__________________________________________________________________________________________________
adjust_relu_1_stem_2 (Activatio (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
reduction_add_2_stem_1 (Add)    (None, 83, 83, 42)   0           reduction_left2_stem_1[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_stem_1 (Average (None, 83, 83, 42)   0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_stem_1 (Average (None, 83, 83, 42)   0           reduction_add_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_stem_1 (MaxPoo (None, 83, 83, 42)   0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 166, 166, 96) 0           adjust_relu_1_stem_2[0][0]
__________________________________________________________________________________________________
reduction_add3_stem_1 (Add)     (None, 83, 83, 42)   0           reduction_left3_stem_1[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_1 (Add)                     (None, 83, 83, 42)   0           reduction_add_2_stem_1[0][0]
                                                                 reduction_left4_stem_1[0][0]
__________________________________________________________________________________________________
reduction_add4_stem_1 (Add)     (None, 83, 83, 42)   0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_stem_1[0][0]
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 165, 165, 96) 0           zero_padding2d_1[0][0]
__________________________________________________________________________________________________
reduction_concat_stem_1 (Concat (None, 83, 83, 168)  0           reduction_add_2_stem_1[0][0]
                                                                 reduction_add3_stem_1[0][0]
                                                                 add_1[0][0]
                                                                 reduction_add4_stem_1[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_stem_2 (Avera (None, 83, 83, 96)   0           adjust_relu_1_stem_2[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_stem_2 (Avera (None, 83, 83, 96)   0           cropping2d_1[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 83, 83, 168)  0           reduction_concat_stem_1[0][0]
__________________________________________________________________________________________________
adjust_conv_1_stem_2 (Conv2D)   (None, 83, 83, 42)   4032        adjust_avg_pool_1_stem_2[0][0]
__________________________________________________________________________________________________
adjust_conv_2_stem_2 (Conv2D)   (None, 83, 83, 42)   4032        adjust_avg_pool_2_stem_2[0][0]
__________________________________________________________________________________________________
reduction_conv_1_stem_2 (Conv2D (None, 83, 83, 84)   14112       activation_12[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 83, 84)   0           adjust_conv_1_stem_2[0][0]
                                                                 adjust_conv_2_stem_2[0][0]
__________________________________________________________________________________________________
reduction_bn_1_stem_2 (BatchNor (None, 83, 83, 84)   336         reduction_conv_1_stem_2[0][0]
__________________________________________________________________________________________________
adjust_bn_stem_2 (BatchNormaliz (None, 83, 83, 84)   336         concatenate_1[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 83, 83, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 83, 83, 84)   0           adjust_bn_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 42, 42, 84)   9156        activation_13[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_st (None, 42, 42, 84)   11172       activation_15[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 42, 42, 84)   336         separable_conv_1_reduction_1_stem
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 42, 42, 84)   9156        activation_14[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_st (None, 42, 42, 84)   11172       activation_16[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 42, 42, 84)   336         separable_conv_2_reduction_1_stem
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 83, 83, 84)   0           adjust_bn_stem_2[0][0]
__________________________________________________________________________________________________
reduction_add_1_stem_2 (Add)    (None, 42, 42, 84)   0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 42, 42, 84)   11172       activation_17[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 83, 83, 84)   0           adjust_bn_stem_2[0][0]
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 42, 42, 84)   0           reduction_add_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 42, 42, 84)   9156        activation_19[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 42, 42, 84)   7812        activation_21[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 42, 42, 84)   11172       activation_18[0][0]
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_stem_2 (MaxPool (None, 42, 42, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 42, 42, 84)   9156        activation_20[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 42, 42, 84)   7812        activation_22[0][0]
__________________________________________________________________________________________________
adjust_relu_1_0 (Activation)    (None, 83, 83, 168)  0           reduction_concat_stem_1[0][0]
__________________________________________________________________________________________________
reduction_add_2_stem_2 (Add)    (None, 42, 42, 84)   0           reduction_left2_stem_2[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_stem_2 (Average (None, 42, 42, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_stem_2 (Average (None, 42, 42, 84)   0           reduction_add_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_stem_2 (MaxPoo (None, 42, 42, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
zero_padding2d_2 (ZeroPadding2D (None, 84, 84, 168)  0           adjust_relu_1_0[0][0]
__________________________________________________________________________________________________
reduction_add3_stem_2 (Add)     (None, 42, 42, 84)   0           reduction_left3_stem_2[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_2 (Add)                     (None, 42, 42, 84)   0           reduction_add_2_stem_2[0][0]
                                                                 reduction_left4_stem_2[0][0]
__________________________________________________________________________________________________
reduction_add4_stem_2 (Add)     (None, 42, 42, 84)   0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_stem_2[0][0]
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 83, 83, 168)  0           zero_padding2d_2[0][0]
__________________________________________________________________________________________________
reduction_concat_stem_2 (Concat (None, 42, 42, 336)  0           reduction_add_2_stem_2[0][0]
                                                                 reduction_add3_stem_2[0][0]
                                                                 add_2[0][0]
                                                                 reduction_add4_stem_2[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_0 (AveragePoo (None, 42, 42, 168)  0           adjust_relu_1_0[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_0 (AveragePoo (None, 42, 42, 168)  0           cropping2d_2[0][0]
__________________________________________________________________________________________________
adjust_conv_1_0 (Conv2D)        (None, 42, 42, 84)   14112       adjust_avg_pool_1_0[0][0]
__________________________________________________________________________________________________
adjust_conv_2_0 (Conv2D)        (None, 42, 42, 84)   14112       adjust_avg_pool_2_0[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 42, 42, 336)  0           reduction_concat_stem_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 42, 168)  0           adjust_conv_1_0[0][0]
                                                                 adjust_conv_2_0[0][0]
__________________________________________________________________________________________________
normal_conv_1_0 (Conv2D)        (None, 42, 42, 168)  56448       activation_23[0][0]
__________________________________________________________________________________________________
adjust_bn_0 (BatchNormalization (None, 42, 42, 168)  672         concatenate_2[0][0]
__________________________________________________________________________________________________
normal_bn_1_0 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_0[0][0]
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_0[0][0]
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_0[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_0 (None, 42, 42, 168)  32424       activation_24[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_26[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_0 (None, 42, 42, 168)  32424       activation_28[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_30[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_0 (None, 42, 42, 168)  29736       activation_32[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_0[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_0[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_0[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_0[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_0[0
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_0 (None, 42, 42, 168)  32424       activation_25[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_27[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_0 (None, 42, 42, 168)  32424       activation_29[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_31[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_0 (None, 42, 42, 168)  29736       activation_33[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_0[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_0[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_0[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_0[
__________________________________________________________________________________________________
normal_left3_0 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_0[0][0]
__________________________________________________________________________________________________
normal_left4_0 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
normal_right4_0 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_0[0
__________________________________________________________________________________________________
normal_add_1_0 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_0 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_0 (Add)            (None, 42, 42, 168)  0           normal_left3_0[0][0]
                                                                 adjust_bn_0[0][0]
__________________________________________________________________________________________________
normal_add_4_0 (Add)            (None, 42, 42, 168)  0           normal_left4_0[0][0]
                                                                 normal_right4_0[0][0]
__________________________________________________________________________________________________
normal_add_5_0 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_0[0][0]
__________________________________________________________________________________________________
normal_concat_0 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_0[0][0]
                                                                 normal_add_1_0[0][0]
                                                                 normal_add_2_0[0][0]
                                                                 normal_add_3_0[0][0]
                                                                 normal_add_4_0[0][0]
                                                                 normal_add_5_0[0][0]
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 42, 42, 336)  0           reduction_concat_stem_2[0][0]
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 42, 42, 1008) 0           normal_concat_0[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_1 (Conv2 (None, 42, 42, 168)  56448       activation_34[0][0]
__________________________________________________________________________________________________
normal_conv_1_1 (Conv2D)        (None, 42, 42, 168)  169344      activation_35[0][0]
__________________________________________________________________________________________________
adjust_bn_1 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_1[0][0]
__________________________________________________________________________________________________
normal_bn_1_1 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_1[0][0]
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_1[0][0]
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_1[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 42, 42, 168)  32424       activation_36[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_38[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 42, 42, 168)  32424       activation_40[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_42[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 42, 42, 168)  29736       activation_44[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_1[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_1[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_1[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_1[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_1[0
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 42, 42, 168)  32424       activation_37[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_39[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 42, 42, 168)  32424       activation_41[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_43[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 42, 42, 168)  29736       activation_45[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_1[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_1[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_1[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_1[
__________________________________________________________________________________________________
normal_left3_1 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_1[0][0]
__________________________________________________________________________________________________
normal_left4_1 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
normal_right4_1 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_1[0
__________________________________________________________________________________________________
normal_add_1_1 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_1 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_1 (Add)            (None, 42, 42, 168)  0           normal_left3_1[0][0]
                                                                 adjust_bn_1[0][0]
__________________________________________________________________________________________________
normal_add_4_1 (Add)            (None, 42, 42, 168)  0           normal_left4_1[0][0]
                                                                 normal_right4_1[0][0]
__________________________________________________________________________________________________
normal_add_5_1 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_1[0][0]
__________________________________________________________________________________________________
normal_concat_1 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_1[0][0]
                                                                 normal_add_1_1[0][0]
                                                                 normal_add_2_1[0][0]
                                                                 normal_add_3_1[0][0]
                                                                 normal_add_4_1[0][0]
                                                                 normal_add_5_1[0][0]
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 42, 42, 1008) 0           normal_concat_0[0][0]
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 42, 42, 1008) 0           normal_concat_1[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_2 (Conv2 (None, 42, 42, 168)  169344      activation_46[0][0]
__________________________________________________________________________________________________
normal_conv_1_2 (Conv2D)        (None, 42, 42, 168)  169344      activation_47[0][0]
__________________________________________________________________________________________________
adjust_bn_2 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_2[0][0]
__________________________________________________________________________________________________
normal_bn_1_2 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_2[0][0]
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_2[0][0]
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_2 (None, 42, 42, 168)  32424       activation_48[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_50[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_2 (None, 42, 42, 168)  32424       activation_52[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_54[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_2 (None, 42, 42, 168)  29736       activation_56[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_2[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_2[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_2[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_2[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_2[0
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_2 (None, 42, 42, 168)  32424       activation_49[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_51[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_2 (None, 42, 42, 168)  32424       activation_53[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_55[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_2 (None, 42, 42, 168)  29736       activation_57[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_2[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_2[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_2[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_2[
__________________________________________________________________________________________________
normal_left3_2 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_2[0][0]
__________________________________________________________________________________________________
normal_left4_2 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
normal_right4_2 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_2[0
__________________________________________________________________________________________________
normal_add_1_2 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_2 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_2 (Add)            (None, 42, 42, 168)  0           normal_left3_2[0][0]
                                                                 adjust_bn_2[0][0]
__________________________________________________________________________________________________
normal_add_4_2 (Add)            (None, 42, 42, 168)  0           normal_left4_2[0][0]
                                                                 normal_right4_2[0][0]
__________________________________________________________________________________________________
normal_add_5_2 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_2[0][0]
__________________________________________________________________________________________________
normal_concat_2 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_2[0][0]
                                                                 normal_add_1_2[0][0]
                                                                 normal_add_2_2[0][0]
                                                                 normal_add_3_2[0][0]
                                                                 normal_add_4_2[0][0]
                                                                 normal_add_5_2[0][0]
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 42, 42, 1008) 0           normal_concat_1[0][0]
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 42, 42, 1008) 0           normal_concat_2[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_3 (Conv2 (None, 42, 42, 168)  169344      activation_58[0][0]
__________________________________________________________________________________________________
normal_conv_1_3 (Conv2D)        (None, 42, 42, 168)  169344      activation_59[0][0]
__________________________________________________________________________________________________
adjust_bn_3 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_3[0][0]
__________________________________________________________________________________________________
normal_bn_1_3 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_3[0][0]
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_3[0][0]
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_3[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_3 (None, 42, 42, 168)  32424       activation_60[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_62[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_3 (None, 42, 42, 168)  32424       activation_64[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_66[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_3 (None, 42, 42, 168)  29736       activation_68[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_3[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_3[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_3[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_3[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_3[0
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_3 (None, 42, 42, 168)  32424       activation_61[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_63[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_3 (None, 42, 42, 168)  32424       activation_65[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_67[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_3 (None, 42, 42, 168)  29736       activation_69[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_3[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_3[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_3[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_3[
__________________________________________________________________________________________________
normal_left3_3 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_3[0][0]
__________________________________________________________________________________________________
normal_left4_3 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
normal_right4_3 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_3[0
__________________________________________________________________________________________________
normal_add_1_3 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_3 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_3 (Add)            (None, 42, 42, 168)  0           normal_left3_3[0][0]
                                                                 adjust_bn_3[0][0]
__________________________________________________________________________________________________
normal_add_4_3 (Add)            (None, 42, 42, 168)  0           normal_left4_3[0][0]
                                                                 normal_right4_3[0][0]
__________________________________________________________________________________________________
normal_add_5_3 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_3[0][0]
__________________________________________________________________________________________________
normal_concat_3 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_3[0][0]
                                                                 normal_add_1_3[0][0]
                                                                 normal_add_2_3[0][0]
                                                                 normal_add_3_3[0][0]
                                                                 normal_add_4_3[0][0]
                                                                 normal_add_5_3[0][0]
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 42, 42, 1008) 0           normal_concat_2[0][0]
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 42, 42, 1008) 0           normal_concat_3[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_4 (Conv2 (None, 42, 42, 168)  169344      activation_70[0][0]
__________________________________________________________________________________________________
normal_conv_1_4 (Conv2D)        (None, 42, 42, 168)  169344      activation_71[0][0]
__________________________________________________________________________________________________
adjust_bn_4 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_4[0][0]
__________________________________________________________________________________________________
normal_bn_1_4 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_4[0][0]
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_4[0][0]
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_4[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_4 (None, 42, 42, 168)  32424       activation_72[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_74[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_4 (None, 42, 42, 168)  32424       activation_76[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_78[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_4 (None, 42, 42, 168)  29736       activation_80[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_4[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_4[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_4[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_4[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_4[0
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_4 (None, 42, 42, 168)  32424       activation_73[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_75[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_4 (None, 42, 42, 168)  32424       activation_77[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_79[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_4 (None, 42, 42, 168)  29736       activation_81[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_4[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_4[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_4[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_4[
__________________________________________________________________________________________________
normal_left3_4 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_4[0][0]
__________________________________________________________________________________________________
normal_left4_4 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
normal_right4_4 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_4[0
__________________________________________________________________________________________________
normal_add_1_4 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_4 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_4 (Add)            (None, 42, 42, 168)  0           normal_left3_4[0][0]
                                                                 adjust_bn_4[0][0]
__________________________________________________________________________________________________
normal_add_4_4 (Add)            (None, 42, 42, 168)  0           normal_left4_4[0][0]
                                                                 normal_right4_4[0][0]
__________________________________________________________________________________________________
normal_add_5_4 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_4[0][0]
__________________________________________________________________________________________________
normal_concat_4 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_4[0][0]
                                                                 normal_add_1_4[0][0]
                                                                 normal_add_2_4[0][0]
                                                                 normal_add_3_4[0][0]
                                                                 normal_add_4_4[0][0]
                                                                 normal_add_5_4[0][0]
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 42, 42, 1008) 0           normal_concat_3[0][0]
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 42, 42, 1008) 0           normal_concat_4[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_5 (Conv2 (None, 42, 42, 168)  169344      activation_82[0][0]
__________________________________________________________________________________________________
normal_conv_1_5 (Conv2D)        (None, 42, 42, 168)  169344      activation_83[0][0]
__________________________________________________________________________________________________
adjust_bn_5 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_5[0][0]
__________________________________________________________________________________________________
normal_bn_1_5 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_5[0][0]
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_5[0][0]
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_5[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_5 (None, 42, 42, 168)  32424       activation_84[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_86[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_5 (None, 42, 42, 168)  32424       activation_88[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_90[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_5 (None, 42, 42, 168)  29736       activation_92[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_5[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_5[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_5[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_5[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_5[0
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_5 (None, 42, 42, 168)  32424       activation_85[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_87[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_5 (None, 42, 42, 168)  32424       activation_89[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_91[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_5 (None, 42, 42, 168)  29736       activation_93[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_5[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_5[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_5[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_5[
__________________________________________________________________________________________________
normal_left3_5 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_5[0][0]
__________________________________________________________________________________________________
normal_left4_5 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
normal_right4_5 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_5[0
__________________________________________________________________________________________________
normal_add_1_5 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_5 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_5 (Add)            (None, 42, 42, 168)  0           normal_left3_5[0][0]
                                                                 adjust_bn_5[0][0]
__________________________________________________________________________________________________
normal_add_4_5 (Add)            (None, 42, 42, 168)  0           normal_left4_5[0][0]
                                                                 normal_right4_5[0][0]
__________________________________________________________________________________________________
normal_add_5_5 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_5[0][0]
__________________________________________________________________________________________________
normal_concat_5 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_5[0][0]
                                                                 normal_add_1_5[0][0]
                                                                 normal_add_2_5[0][0]
                                                                 normal_add_3_5[0][0]
                                                                 normal_add_4_5[0][0]
                                                                 normal_add_5_5[0][0]
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 42, 42, 1008) 0           normal_concat_5[0][0]
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 42, 42, 1008) 0           normal_concat_4[0][0]
__________________________________________________________________________________________________
reduction_conv_1_reduce_6 (Conv (None, 42, 42, 336)  338688      activation_95[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_reduce_6 (None, 42, 42, 336)  338688      activation_94[0][0]
__________________________________________________________________________________________________
reduction_bn_1_reduce_6 (BatchN (None, 42, 42, 336)  1344        reduction_conv_1_reduce_6[0][0]
__________________________________________________________________________________________________
adjust_bn_reduce_6 (BatchNormal (None, 42, 42, 336)  1344        adjust_conv_projection_reduce_6[0
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 42, 42, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 42, 42, 336)  0           adjust_bn_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 21, 21, 336)  121296      activation_96[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_re (None, 21, 21, 336)  129360      activation_98[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 21, 21, 336)  1344        separable_conv_1_reduction_1_redu
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 21, 21, 336)  121296      activation_97[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_re (None, 21, 21, 336)  129360      activation_99[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 21, 21, 336)  1344        separable_conv_2_reduction_1_redu
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 42, 42, 336)  0           adjust_bn_reduce_6[0][0]
__________________________________________________________________________________________________
reduction_add_1_reduce_6 (Add)  (None, 21, 21, 336)  0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 21, 21, 336)  129360      activation_100[0][0]
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 42, 42, 336)  0           adjust_bn_reduce_6[0][0]
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 21, 21, 336)  0           reduction_add_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 21, 21, 336)  121296      activation_102[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 21, 21, 336)  115920      activation_104[0][0]
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 21, 21, 336)  129360      activation_101[0][0]
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_reduce_6 (MaxPo (None, 21, 21, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 21, 21, 336)  121296      activation_103[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 21, 21, 336)  115920      activation_105[0][0]
__________________________________________________________________________________________________
adjust_relu_1_7 (Activation)    (None, 42, 42, 1008) 0           normal_concat_5[0][0]
__________________________________________________________________________________________________
reduction_add_2_reduce_6 (Add)  (None, 21, 21, 336)  0           reduction_left2_reduce_6[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_reduce_6 (Avera (None, 21, 21, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_reduce_6 (Avera (None, 21, 21, 336)  0           reduction_add_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_reduce_6 (MaxP (None, 21, 21, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
zero_padding2d_3 (ZeroPadding2D (None, 43, 43, 1008) 0           adjust_relu_1_7[0][0]
__________________________________________________________________________________________________
reduction_add3_reduce_6 (Add)   (None, 21, 21, 336)  0           reduction_left3_reduce_6[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_3 (Add)                     (None, 21, 21, 336)  0           reduction_add_2_reduce_6[0][0]
                                                                 reduction_left4_reduce_6[0][0]
__________________________________________________________________________________________________
reduction_add4_reduce_6 (Add)   (None, 21, 21, 336)  0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_reduce_6[0][0]
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 42, 42, 1008) 0           zero_padding2d_3[0][0]
__________________________________________________________________________________________________
reduction_concat_reduce_6 (Conc (None, 21, 21, 1344) 0           reduction_add_2_reduce_6[0][0]
                                                                 reduction_add3_reduce_6[0][0]
                                                                 add_3[0][0]
                                                                 reduction_add4_reduce_6[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_7 (AveragePoo (None, 21, 21, 1008) 0           adjust_relu_1_7[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_7 (AveragePoo (None, 21, 21, 1008) 0           cropping2d_3[0][0]
__________________________________________________________________________________________________
adjust_conv_1_7 (Conv2D)        (None, 21, 21, 168)  169344      adjust_avg_pool_1_7[0][0]
__________________________________________________________________________________________________
adjust_conv_2_7 (Conv2D)        (None, 21, 21, 168)  169344      adjust_avg_pool_2_7[0][0]
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 21, 21, 1344) 0           reduction_concat_reduce_6[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 21, 336)  0           adjust_conv_1_7[0][0]
                                                                 adjust_conv_2_7[0][0]
__________________________________________________________________________________________________
normal_conv_1_7 (Conv2D)        (None, 21, 21, 336)  451584      activation_106[0][0]
__________________________________________________________________________________________________
adjust_bn_7 (BatchNormalization (None, 21, 21, 336)  1344        concatenate_3[0][0]
__________________________________________________________________________________________________
normal_bn_1_7 (BatchNormalizati (None, 21, 21, 336)  1344        normal_conv_1_7[0][0]
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_7[0][0]
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_7[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_7 (None, 21, 21, 336)  121296      activation_107[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_109[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_7 (None, 21, 21, 336)  121296      activation_111[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_113[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_7 (None, 21, 21, 336)  115920      activation_115[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_7[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_7[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_7[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_7[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_7[0
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_7 (None, 21, 21, 336)  121296      activation_108[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_110[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_7 (None, 21, 21, 336)  121296      activation_112[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_114[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_7 (None, 21, 21, 336)  115920      activation_116[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_7[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_7[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_7[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_7[
__________________________________________________________________________________________________
normal_left3_7 (AveragePooling2 (None, 21, 21, 336)  0           normal_bn_1_7[0][0]
__________________________________________________________________________________________________
normal_left4_7 (AveragePooling2 (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
normal_right4_7 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_7[0
__________________________________________________________________________________________________
normal_add_1_7 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_7 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_7 (Add)            (None, 21, 21, 336)  0           normal_left3_7[0][0]
                                                                 adjust_bn_7[0][0]
__________________________________________________________________________________________________
normal_add_4_7 (Add)            (None, 21, 21, 336)  0           normal_left4_7[0][0]
                                                                 normal_right4_7[0][0]
__________________________________________________________________________________________________
normal_add_5_7 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_7[0][0]
__________________________________________________________________________________________________
normal_concat_7 (Concatenate)   (None, 21, 21, 2016) 0           adjust_bn_7[0][0]
                                                                 normal_add_1_7[0][0]
                                                                 normal_add_2_7[0][0]
                                                                 normal_add_3_7[0][0]
                                                                 normal_add_4_7[0][0]
                                                                 normal_add_5_7[0][0]
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 21, 21, 1344) 0           reduction_concat_reduce_6[0][0]
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 21, 21, 2016) 0           normal_concat_7[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_8 (Conv2 (None, 21, 21, 336)  451584      activation_117[0][0]
__________________________________________________________________________________________________
normal_conv_1_8 (Conv2D)        (None, 21, 21, 336)  677376      activation_118[0][0]
__________________________________________________________________________________________________
adjust_bn_8 (BatchNormalization (None, 21, 21, 336)  1344        adjust_conv_projection_8[0][0]
__________________________________________________________________________________________________
normal_bn_1_8 (BatchNormalizati (None, 21, 21, 336)  1344        normal_conv_1_8[0][0]
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_8[0][0]
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_8[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_8 (None, 21, 21, 336)  121296      activation_119[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_121[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_8 (None, 21, 21, 336)  121296      activation_123[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_125[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_8 (None, 21, 21, 336)  115920      activation_127[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_8[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_8[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_8[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_8[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_8[0
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_8 (None, 21, 21, 336)  121296      activation_120[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_122[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_8 (None, 21, 21, 336)  121296      activation_124[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_126[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_8 (None, 21, 21, 336)  115920      activation_128[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_8[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_8[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_8[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_8[
__________________________________________________________________________________________________
normal_left3_8 (AveragePooling2 (None, 21, 21, 336)  0           normal_bn_1_8[0][0]
__________________________________________________________________________________________________
normal_left4_8 (AveragePooling2 (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
normal_right4_8 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_8[0
__________________________________________________________________________________________________
normal_add_1_8 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_8 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_8 (Add)            (None, 21, 21, 336)  0           normal_left3_8[0][0]
                                                                 adjust_bn_8[0][0]
__________________________________________________________________________________________________
normal_add_4_8 (Add)            (None, 21, 21, 336)  0           normal_left4_8[0][0]
                                                                 normal_right4_8[0][0]
__________________________________________________________________________________________________
normal_add_5_8 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_8[0][0]
__________________________________________________________________________________________________
normal_concat_8 (Concatenate)   (None, 21, 21, 2016) 0           adjust_bn_8[0][0]
                                                                 normal_add_1_8[0][0]
                                                                 normal_add_2_8[0][0]
                                                                 normal_add_3_8[0][0]
                                                                 normal_add_4_8[0][0]
                                                                 normal_add_5_8[0][0]
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 21, 21, 2016) 0           normal_concat_7[0][0]
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 21, 21, 2016) 0           normal_concat_8[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_9 (Conv2 (None, 21, 21, 336)  677376      activation_129[0][0]
__________________________________________________________________________________________________
normal_conv_1_9 (Conv2D)        (None, 21, 21, 336)  677376      activation_130[0][0]
__________________________________________________________________________________________________
adjust_bn_9 (BatchNormalization (None, 21, 21, 336)  1344        adjust_conv_projection_9[0][0]
__________________________________________________________________________________________________
normal_bn_1_9 (BatchNormalizati (None, 21, 21, 336)  1344        normal_conv_1_9[0][0]
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_9[0][0]
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_9[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_9 (None, 21, 21, 336)  121296      activation_131[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_133[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_9 (None, 21, 21, 336)  121296      activation_135[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_137[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_9 (None, 21, 21, 336)  115920      activation_139[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_9[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_9[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_9[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_9[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_9[0
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_9 (None, 21, 21, 336)  121296      activation_132[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_134[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_9 (None, 21, 21, 336)  121296      activation_136[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_138[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_9 (None, 21, 21, 336)  115920      activation_140[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_9[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_9[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_9[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_9[
__________________________________________________________________________________________________
normal_left3_9 (AveragePooling2 (None, 21, 21, 336)  0           normal_bn_1_9[0][0]
__________________________________________________________________________________________________
normal_left4_9 (AveragePooling2 (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
normal_right4_9 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_9[0
__________________________________________________________________________________________________
normal_add_1_9 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_9 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_9 (Add)            (None, 21, 21, 336)  0           normal_left3_9[0][0]
                                                                 adjust_bn_9[0][0]
__________________________________________________________________________________________________
normal_add_4_9 (Add)            (None, 21, 21, 336)  0           normal_left4_9[0][0]
                                                                 normal_right4_9[0][0]
__________________________________________________________________________________________________
normal_add_5_9 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_9[0][0]
__________________________________________________________________________________________________
normal_concat_9 (Concatenate)   (None, 21, 21, 2016) 0           adjust_bn_9[0][0]
                                                                 normal_add_1_9[0][0]
                                                                 normal_add_2_9[0][0]
                                                                 normal_add_3_9[0][0]
                                                                 normal_add_4_9[0][0]
                                                                 normal_add_5_9[0][0]
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 21, 21, 2016) 0           normal_concat_8[0][0]
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 21, 21, 2016) 0           normal_concat_9[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_10 (Conv (None, 21, 21, 336)  677376      activation_141[0][0]
__________________________________________________________________________________________________
normal_conv_1_10 (Conv2D)       (None, 21, 21, 336)  677376      activation_142[0][0]
__________________________________________________________________________________________________
adjust_bn_10 (BatchNormalizatio (None, 21, 21, 336)  1344        adjust_conv_projection_10[0][0]
__________________________________________________________________________________________________
normal_bn_1_10 (BatchNormalizat (None, 21, 21, 336)  1344        normal_conv_1_10[0][0]
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_10[0][0]
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_10[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 21, 21, 336)  121296      activation_143[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_145[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 21, 21, 336)  121296      activation_147[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_149[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 21, 21, 336)  115920      activation_151[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_10[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_10
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_10[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_10
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_10[
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 21, 21, 336)  121296      activation_144[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_146[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 21, 21, 336)  121296      activation_148[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_150[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 21, 21, 336)  115920      activation_152[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_10[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_10
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_10[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_10
__________________________________________________________________________________________________
normal_left3_10 (AveragePooling (None, 21, 21, 336)  0           normal_bn_1_10[0][0]
__________________________________________________________________________________________________
normal_left4_10 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
normal_right4_10 (AveragePoolin (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_10[
__________________________________________________________________________________________________
normal_add_1_10 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_10 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_10 (Add)           (None, 21, 21, 336)  0           normal_left3_10[0][0]
                                                                 adjust_bn_10[0][0]
__________________________________________________________________________________________________
normal_add_4_10 (Add)           (None, 21, 21, 336)  0           normal_left4_10[0][0]
                                                                 normal_right4_10[0][0]
__________________________________________________________________________________________________
normal_add_5_10 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_10[0][0]
__________________________________________________________________________________________________
normal_concat_10 (Concatenate)  (None, 21, 21, 2016) 0           adjust_bn_10[0][0]
                                                                 normal_add_1_10[0][0]
                                                                 normal_add_2_10[0][0]
                                                                 normal_add_3_10[0][0]
                                                                 normal_add_4_10[0][0]
                                                                 normal_add_5_10[0][0]
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 21, 21, 2016) 0           normal_concat_9[0][0]
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 21, 21, 2016) 0           normal_concat_10[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_11 (Conv (None, 21, 21, 336)  677376      activation_153[0][0]
__________________________________________________________________________________________________
normal_conv_1_11 (Conv2D)       (None, 21, 21, 336)  677376      activation_154[0][0]
__________________________________________________________________________________________________
adjust_bn_11 (BatchNormalizatio (None, 21, 21, 336)  1344        adjust_conv_projection_11[0][0]
__________________________________________________________________________________________________
normal_bn_1_11 (BatchNormalizat (None, 21, 21, 336)  1344        normal_conv_1_11[0][0]
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_11[0][0]
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_11[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 21, 21, 336)  121296      activation_155[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_157[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 21, 21, 336)  121296      activation_159[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_161[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 21, 21, 336)  115920      activation_163[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_11[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_11
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_11[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_11
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_11[
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 21, 21, 336)  121296      activation_156[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_158[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 21, 21, 336)  121296      activation_160[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_162[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 21, 21, 336)  115920      activation_164[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_11[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_11
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_11[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_11
__________________________________________________________________________________________________
normal_left3_11 (AveragePooling (None, 21, 21, 336)  0           normal_bn_1_11[0][0]
__________________________________________________________________________________________________
normal_left4_11 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
normal_right4_11 (AveragePoolin (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_11[
__________________________________________________________________________________________________
normal_add_1_11 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_11 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_11 (Add)           (None, 21, 21, 336)  0           normal_left3_11[0][0]
                                                                 adjust_bn_11[0][0]
__________________________________________________________________________________________________
normal_add_4_11 (Add)           (None, 21, 21, 336)  0           normal_left4_11[0][0]
                                                                 normal_right4_11[0][0]
__________________________________________________________________________________________________
normal_add_5_11 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_11[0][0]
__________________________________________________________________________________________________
normal_concat_11 (Concatenate)  (None, 21, 21, 2016) 0           adjust_bn_11[0][0]
                                                                 normal_add_1_11[0][0]
                                                                 normal_add_2_11[0][0]
                                                                 normal_add_3_11[0][0]
                                                                 normal_add_4_11[0][0]
                                                                 normal_add_5_11[0][0]
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 21, 21, 2016) 0           normal_concat_10[0][0]
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 21, 21, 2016) 0           normal_concat_11[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_12 (Conv (None, 21, 21, 336)  677376      activation_165[0][0]
__________________________________________________________________________________________________
normal_conv_1_12 (Conv2D)       (None, 21, 21, 336)  677376      activation_166[0][0]
__________________________________________________________________________________________________
adjust_bn_12 (BatchNormalizatio (None, 21, 21, 336)  1344        adjust_conv_projection_12[0][0]
__________________________________________________________________________________________________
normal_bn_1_12 (BatchNormalizat (None, 21, 21, 336)  1344        normal_conv_1_12[0][0]
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_12[0][0]
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_12[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 21, 21, 336)  121296      activation_167[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_169[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 21, 21, 336)  121296      activation_171[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_173[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 21, 21, 336)  115920      activation_175[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_12[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_12
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_12[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_12
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_12[
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 21, 21, 336)  121296      activation_168[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_170[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 21, 21, 336)  121296      activation_172[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_174[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 21, 21, 336)  115920      activation_176[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_12[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_12
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_12[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_12
__________________________________________________________________________________________________
normal_left3_12 (AveragePooling (None, 21, 21, 336)  0           normal_bn_1_12[0][0]
__________________________________________________________________________________________________
normal_left4_12 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
normal_right4_12 (AveragePoolin (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_12[
__________________________________________________________________________________________________
normal_add_1_12 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_12 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_12 (Add)           (None, 21, 21, 336)  0           normal_left3_12[0][0]
                                                                 adjust_bn_12[0][0]
__________________________________________________________________________________________________
normal_add_4_12 (Add)           (None, 21, 21, 336)  0           normal_left4_12[0][0]
                                                                 normal_right4_12[0][0]
__________________________________________________________________________________________________
normal_add_5_12 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_12[0][0]
__________________________________________________________________________________________________
normal_concat_12 (Concatenate)  (None, 21, 21, 2016) 0           adjust_bn_12[0][0]
                                                                 normal_add_1_12[0][0]
                                                                 normal_add_2_12[0][0]
                                                                 normal_add_3_12[0][0]
                                                                 normal_add_4_12[0][0]
                                                                 normal_add_5_12[0][0]
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 21, 21, 2016) 0           normal_concat_12[0][0]
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 21, 21, 2016) 0           normal_concat_11[0][0]
__________________________________________________________________________________________________
reduction_conv_1_reduce_12 (Con (None, 21, 21, 672)  1354752     activation_178[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_reduce_1 (None, 21, 21, 672)  1354752     activation_177[0][0]
__________________________________________________________________________________________________
reduction_bn_1_reduce_12 (Batch (None, 21, 21, 672)  2688        reduction_conv_1_reduce_12[0][0]
__________________________________________________________________________________________________
adjust_bn_reduce_12 (BatchNorma (None, 21, 21, 672)  2688        adjust_conv_projection_reduce_12[
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 21, 21, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 21, 21, 672)  0           adjust_bn_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 11, 11, 672)  468384      activation_179[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_re (None, 11, 11, 672)  484512      activation_181[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 11, 11, 672)  2688        separable_conv_1_reduction_1_redu
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 11, 11, 672)  468384      activation_180[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_re (None, 11, 11, 672)  484512      activation_182[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 11, 11, 672)  2688        separable_conv_2_reduction_1_redu
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 21, 21, 672)  0           adjust_bn_reduce_12[0][0]
__________________________________________________________________________________________________
reduction_add_1_reduce_12 (Add) (None, 11, 11, 672)  0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 11, 11, 672)  484512      activation_183[0][0]
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 21, 21, 672)  0           adjust_bn_reduce_12[0][0]
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 11, 11, 672)  0           reduction_add_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 11, 11, 672)  468384      activation_185[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 11, 11, 672)  457632      activation_187[0][0]
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 11, 11, 672)  484512      activation_184[0][0]
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_reduce_12 (MaxP (None, 11, 11, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 11, 11, 672)  468384      activation_186[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 11, 11, 672)  457632      activation_188[0][0]
__________________________________________________________________________________________________
adjust_relu_1_13 (Activation)   (None, 21, 21, 2016) 0           normal_concat_12[0][0]
__________________________________________________________________________________________________
reduction_add_2_reduce_12 (Add) (None, 11, 11, 672)  0           reduction_left2_reduce_12[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_reduce_12 (Aver (None, 11, 11, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_reduce_12 (Aver (None, 11, 11, 672)  0           reduction_add_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_reduce_12 (Max (None, 11, 11, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
zero_padding2d_4 (ZeroPadding2D (None, 22, 22, 2016) 0           adjust_relu_1_13[0][0]
__________________________________________________________________________________________________
reduction_add3_reduce_12 (Add)  (None, 11, 11, 672)  0           reduction_left3_reduce_12[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_4 (Add)                     (None, 11, 11, 672)  0           reduction_add_2_reduce_12[0][0]
                                                                 reduction_left4_reduce_12[0][0]
__________________________________________________________________________________________________
reduction_add4_reduce_12 (Add)  (None, 11, 11, 672)  0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_reduce_12[0][0]
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 21, 21, 2016) 0           zero_padding2d_4[0][0]
__________________________________________________________________________________________________
reduction_concat_reduce_12 (Con (None, 11, 11, 2688) 0           reduction_add_2_reduce_12[0][0]
                                                                 reduction_add3_reduce_12[0][0]
                                                                 add_4[0][0]
                                                                 reduction_add4_reduce_12[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_13 (AveragePo (None, 11, 11, 2016) 0           adjust_relu_1_13[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_13 (AveragePo (None, 11, 11, 2016) 0           cropping2d_4[0][0]
__________________________________________________________________________________________________
adjust_conv_1_13 (Conv2D)       (None, 11, 11, 336)  677376      adjust_avg_pool_1_13[0][0]
__________________________________________________________________________________________________
adjust_conv_2_13 (Conv2D)       (None, 11, 11, 336)  677376      adjust_avg_pool_2_13[0][0]
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 11, 11, 2688) 0           reduction_concat_reduce_12[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 11, 11, 672)  0           adjust_conv_1_13[0][0]
                                                                 adjust_conv_2_13[0][0]
__________________________________________________________________________________________________
normal_conv_1_13 (Conv2D)       (None, 11, 11, 672)  1806336     activation_189[0][0]
__________________________________________________________________________________________________
adjust_bn_13 (BatchNormalizatio (None, 11, 11, 672)  2688        concatenate_4[0][0]
__________________________________________________________________________________________________
normal_bn_1_13 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_13[0][0]
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_13[0][0]
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_13[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_190[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_192[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_194[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_196[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_198[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_13[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_13
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_13[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_13
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_13[
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_191[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_193[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_195[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_197[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_199[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_13[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_13
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_13[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_13
__________________________________________________________________________________________________
normal_left3_13 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_13[0][0]
__________________________________________________________________________________________________
normal_left4_13 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
normal_right4_13 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_13[
__________________________________________________________________________________________________
normal_add_1_13 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_13 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_13 (Add)           (None, 11, 11, 672)  0           normal_left3_13[0][0]
                                                                 adjust_bn_13[0][0]
__________________________________________________________________________________________________
normal_add_4_13 (Add)           (None, 11, 11, 672)  0           normal_left4_13[0][0]
                                                                 normal_right4_13[0][0]
__________________________________________________________________________________________________
normal_add_5_13 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_13[0][0]
__________________________________________________________________________________________________
normal_concat_13 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_13[0][0]
                                                                 normal_add_1_13[0][0]
                                                                 normal_add_2_13[0][0]
                                                                 normal_add_3_13[0][0]
                                                                 normal_add_4_13[0][0]
                                                                 normal_add_5_13[0][0]
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 11, 11, 2688) 0           reduction_concat_reduce_12[0][0]
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 11, 11, 4032) 0           normal_concat_13[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_14 (Conv (None, 11, 11, 672)  1806336     activation_200[0][0]
__________________________________________________________________________________________________
normal_conv_1_14 (Conv2D)       (None, 11, 11, 672)  2709504     activation_201[0][0]
__________________________________________________________________________________________________
adjust_bn_14 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_14[0][0]
__________________________________________________________________________________________________
normal_bn_1_14 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_14[0][0]
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_14[0][0]
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_14[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_202[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_204[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_206[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_208[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_210[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_14[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_14
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_14[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_14
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_14[
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_203[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_205[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_207[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_209[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_211[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_14[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_14
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_14[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_14
__________________________________________________________________________________________________
normal_left3_14 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_14[0][0]
__________________________________________________________________________________________________
normal_left4_14 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
normal_right4_14 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_14[
__________________________________________________________________________________________________
normal_add_1_14 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_14 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_14 (Add)           (None, 11, 11, 672)  0           normal_left3_14[0][0]
                                                                 adjust_bn_14[0][0]
__________________________________________________________________________________________________
normal_add_4_14 (Add)           (None, 11, 11, 672)  0           normal_left4_14[0][0]
                                                                 normal_right4_14[0][0]
__________________________________________________________________________________________________
normal_add_5_14 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_14[0][0]
__________________________________________________________________________________________________
normal_concat_14 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_14[0][0]
                                                                 normal_add_1_14[0][0]
                                                                 normal_add_2_14[0][0]
                                                                 normal_add_3_14[0][0]
                                                                 normal_add_4_14[0][0]
                                                                 normal_add_5_14[0][0]
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 11, 11, 4032) 0           normal_concat_13[0][0]
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 11, 11, 4032) 0           normal_concat_14[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_15 (Conv (None, 11, 11, 672)  2709504     activation_212[0][0]
__________________________________________________________________________________________________
normal_conv_1_15 (Conv2D)       (None, 11, 11, 672)  2709504     activation_213[0][0]
__________________________________________________________________________________________________
adjust_bn_15 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_15[0][0]
__________________________________________________________________________________________________
normal_bn_1_15 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_15[0][0]
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_15[0][0]
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_15[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_214[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_216[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_218[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_220[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_222[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_15[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_15
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_15[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_15
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_15[
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_215[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_217[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_219[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_221[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_223[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_15[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_15
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_15[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_15
__________________________________________________________________________________________________
normal_left3_15 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_15[0][0]
__________________________________________________________________________________________________
normal_left4_15 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
normal_right4_15 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_15[
__________________________________________________________________________________________________
normal_add_1_15 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_15 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_15 (Add)           (None, 11, 11, 672)  0           normal_left3_15[0][0]
                                                                 adjust_bn_15[0][0]
__________________________________________________________________________________________________
normal_add_4_15 (Add)           (None, 11, 11, 672)  0           normal_left4_15[0][0]
                                                                 normal_right4_15[0][0]
__________________________________________________________________________________________________
normal_add_5_15 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_15[0][0]
__________________________________________________________________________________________________
normal_concat_15 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_15[0][0]
                                                                 normal_add_1_15[0][0]
                                                                 normal_add_2_15[0][0]
                                                                 normal_add_3_15[0][0]
                                                                 normal_add_4_15[0][0]
                                                                 normal_add_5_15[0][0]
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 11, 11, 4032) 0           normal_concat_14[0][0]
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 11, 11, 4032) 0           normal_concat_15[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_16 (Conv (None, 11, 11, 672)  2709504     activation_224[0][0]
__________________________________________________________________________________________________
normal_conv_1_16 (Conv2D)       (None, 11, 11, 672)  2709504     activation_225[0][0]
__________________________________________________________________________________________________
adjust_bn_16 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_16[0][0]
__________________________________________________________________________________________________
normal_bn_1_16 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_16[0][0]
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_16[0][0]
__________________________________________________________________________________________________
activation_228 (Activation)     (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_16[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_226[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_228[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_230[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_232[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_234[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_16[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_16
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_16[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_16
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_16[
__________________________________________________________________________________________________
activation_227 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_227[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_229[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_231[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_233[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_235[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_16[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_16
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_16[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_16
__________________________________________________________________________________________________
normal_left3_16 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_16[0][0]
__________________________________________________________________________________________________
normal_left4_16 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
normal_right4_16 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_16[
__________________________________________________________________________________________________
normal_add_1_16 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_16 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_16 (Add)           (None, 11, 11, 672)  0           normal_left3_16[0][0]
                                                                 adjust_bn_16[0][0]
__________________________________________________________________________________________________
normal_add_4_16 (Add)           (None, 11, 11, 672)  0           normal_left4_16[0][0]
                                                                 normal_right4_16[0][0]
__________________________________________________________________________________________________
normal_add_5_16 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_16[0][0]
__________________________________________________________________________________________________
normal_concat_16 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_16[0][0]
                                                                 normal_add_1_16[0][0]
                                                                 normal_add_2_16[0][0]
                                                                 normal_add_3_16[0][0]
                                                                 normal_add_4_16[0][0]
                                                                 normal_add_5_16[0][0]
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 11, 11, 4032) 0           normal_concat_15[0][0]
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 11, 11, 4032) 0           normal_concat_16[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_17 (Conv (None, 11, 11, 672)  2709504     activation_236[0][0]
__________________________________________________________________________________________________
normal_conv_1_17 (Conv2D)       (None, 11, 11, 672)  2709504     activation_237[0][0]
__________________________________________________________________________________________________
adjust_bn_17 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_17[0][0]
__________________________________________________________________________________________________
normal_bn_1_17 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_17[0][0]
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_17[0][0]
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_17[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_238[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_240[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_242[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_244[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_246[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_17[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_17
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_17[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_17
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_17[
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_239[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_241[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_243[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_245[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_247[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_17[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_17
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_17[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_17
__________________________________________________________________________________________________
normal_left3_17 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_17[0][0]
__________________________________________________________________________________________________
normal_left4_17 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
normal_right4_17 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_17[
__________________________________________________________________________________________________
normal_add_1_17 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_17 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_17 (Add)           (None, 11, 11, 672)  0           normal_left3_17[0][0]
                                                                 adjust_bn_17[0][0]
__________________________________________________________________________________________________
normal_add_4_17 (Add)           (None, 11, 11, 672)  0           normal_left4_17[0][0]
                                                                 normal_right4_17[0][0]
__________________________________________________________________________________________________
normal_add_5_17 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_17[0][0]
__________________________________________________________________________________________________
normal_concat_17 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_17[0][0]
                                                                 normal_add_1_17[0][0]
                                                                 normal_add_2_17[0][0]
                                                                 normal_add_3_17[0][0]
                                                                 normal_add_4_17[0][0]
                                                                 normal_add_5_17[0][0]
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 11, 11, 4032) 0           normal_concat_16[0][0]
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 11, 11, 4032) 0           normal_concat_17[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_18 (Conv (None, 11, 11, 672)  2709504     activation_248[0][0]
__________________________________________________________________________________________________
normal_conv_1_18 (Conv2D)       (None, 11, 11, 672)  2709504     activation_249[0][0]
__________________________________________________________________________________________________
adjust_bn_18 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_18[0][0]
__________________________________________________________________________________________________
normal_bn_1_18 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_18[0][0]
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_18[0][0]
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_18[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_250[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_252[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_254[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_256[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_258[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_18[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_18
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_18[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_18
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_18[
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_251[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_253[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_255[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_257[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_259[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_18[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_18
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_18[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_18
__________________________________________________________________________________________________
normal_left3_18 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_18[0][0]
__________________________________________________________________________________________________
normal_left4_18 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
normal_right4_18 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_18[
__________________________________________________________________________________________________
normal_add_1_18 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_18 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_18 (Add)           (None, 11, 11, 672)  0           normal_left3_18[0][0]
                                                                 adjust_bn_18[0][0]
__________________________________________________________________________________________________
normal_add_4_18 (Add)           (None, 11, 11, 672)  0           normal_left4_18[0][0]
                                                                 normal_right4_18[0][0]
__________________________________________________________________________________________________
normal_add_5_18 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_18[0][0]
__________________________________________________________________________________________________
normal_concat_18 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_18[0][0]
                                                                 normal_add_1_18[0][0]
                                                                 normal_add_2_18[0][0]
                                                                 normal_add_3_18[0][0]
                                                                 normal_add_4_18[0][0]
                                                                 normal_add_5_18[0][0]
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 11, 11, 4032) 0           normal_concat_18[0][0]
==================================================================================================
Total params: 84,916,818
Trainable params: 0
Non-trainable params: 84,916,818
__________________________________________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 11, 11, 4032)  84916818
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 487872)        0
_________________________________________________________________
dropout025 (TimeDistributed) (None, 16, 487872)        0
_________________________________________________________________
lstm_1 (LSTM)                (None, 32)                62451840
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 99
=================================================================
Total params: 147,368,757
Trainable params: 62,451,939
Non-trainable params: 84,916,818
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14]  #
testSubjects = [9] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 32
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = False

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model NASNetLarge_seqLen16_lstm32_output3_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019-01-24_02-39-18
All frames and annotations from 1 datasets have been read by 2019-01-24 02:39:19.517253
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 02:39:28.968496!
Epoch 1/1
866/866 [==============================] - 636s 734ms/step - loss: 0.0710 - mean_absolute_error: 0.2050
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model NASNetLarge_seqLen16_lstm32_output3_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019-01-24_02-39-18
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 02:50:05.993623
Traceback (most recent call last):
  File "runCNN_LSTM.py", line 160, in <module>
    main()
  File "runCNN_LSTM.py", line 157, in main
    runCNN_LSTM(record = RECORD)
  File "runCNN_LSTM.py", line 150, in runCNN_LSTM
    num_outputs = num_outputs, batch_size = test_batch_size, stateful = STATEFUL, record = record)
  File "runCNN_LSTM.py", line 87, in evaluateCNN_LSTM
    output_begin, num_outputs, batch_size = test_batch_size, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/LSTM_VGG16Helper.py", line 70, in g
etTestBiwiForImageModel
    data_gen = TimeseriesGenerator(inputMatrix, labels, length=timesteps, batch_size=batch_size, start_index=start_in
dex)
UnboundLocalError: local variable 'start_index' referenced before assignment
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:02:08.497843: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:02:08.595226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:02:08.595484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:02:08.595496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:02:08.750945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:02:08.750970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:02:08.750975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:02:08.751114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-02-10 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 1024)                 20975616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    3075
=================================================================
Total params: 155,239,235
Trainable params: 20,978,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate = 0.000001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 1024
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_20
19-01-24_03-02-10
All frames and annotations from 1 datasets have been read by 2019-01-24 03:02:10.954012
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:02:19.840105!
Epoch 1/1
882/882 [==============================] - 28s 32ms/step - loss: 0.0809 - mean_absolute_error: 0.2249
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_
2019-01-24_03-02-10
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:02:49.170134
For the Subject 9 (M03):
882/882 [==============================] - 9s 10ms/step
        The absolute mean error on Pitch angle estimation: 11.72 Degree
        The absolute mean error on Yaw angle estimation: 17.23 Degree
        The absolute mean error on Roll angle estimation: 8.49 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 11.72 Degree
        The absolute mean error on Yaw angle estimations: 17.23 Degree
        The absolute mean error on Roll angle estimations: 8.49 Degree
subject9_Exp2019-01-24_03-02-10.png has been saved by 2019-01-24 03:03:07.536581.
Model Exp2019-01-24_03-02-10 has been evaluated successfully.
Model Exp2019-01-24_03-02-10 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:04:48.175242: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:04:48.271806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:04:48.272068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:04:48.272082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:04:48.430060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:04:48.430085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:04:48.430093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:04:48.430233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-04-49 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
dropout025_conv (TimeDistrib (1, 1, 4096)              0
_________________________________________________________________
lstm_1 (LSTM)                (1, 1024)                 20975616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    3075
=================================================================
Total params: 155,239,235
Trainable params: 20,978,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate = 0.000001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 1024
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_20
19-01-24_03-04-49
All frames and annotations from 1 datasets have been read by 2019-01-24 03:04:50.696832
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:04:59.585486!
Epoch 1/1
882/882 [==============================] - 28s 32ms/step - loss: 0.1531 - mean_absolute_error: 0.3032
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_
2019-01-24_03-04-49
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:05:28.786505
For the Subject 9 (M03):
882/882 [==============================] - 11s 13ms/step
        The absolute mean error on Pitch angle estimation: 17.15 Degree
        The absolute mean error on Yaw angle estimation: 29.23 Degree
        The absolute mean error on Roll angle estimation: 12.49 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 17.15 Degree
        The absolute mean error on Yaw angle estimations: 29.23 Degree
        The absolute mean error on Roll angle estimations: 12.49 Degree
subject9_Exp2019-01-24_03-04-49.png has been saved by 2019-01-24 03:05:48.992704.
Model Exp2019-01-24_03-04-49 has been evaluated successfully.
Model Exp2019-01-24_03-04-49 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:06:34.455313: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:06:34.553422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:06:34.553688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:06:34.553701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:06:34.709825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:06:34.709849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:06:34.709854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:06:34.709994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-06-36 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 1024)                 20975616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    3075
=================================================================
Total params: 155,239,235
Trainable params: 20,978,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate = 0.00001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 1024
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000010_20
19-01-24_03-06-36
All frames and annotations from 1 datasets have been read by 2019-01-24 03:06:36.899216
^[[B1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:06:45.777284!
Epoch 1/1
882/882 [==============================] - 28s 32ms/step - loss: 0.0747 - mean_absolute_error: 0.2131
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000010_
2019-01-24_03-06-36
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:07:15.196313
For the Subject 9 (M03):
882/882 [==============================] - 9s 10ms/step
        The absolute mean error on Pitch angle estimation: 13.52 Degree
        The absolute mean error on Yaw angle estimation: 17.68 Degree
        The absolute mean error on Roll angle estimation: 8.40 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 13.52 Degree
        The absolute mean error on Yaw angle estimations: 17.68 Degree
        The absolute mean error on Roll angle estimations: 8.40 Degree
subject9_Exp2019-01-24_03-06-36.png has been saved by 2019-01-24 03:07:33.609707.
Model Exp2019-01-24_03-06-36 has been evaluated successfully.
Model Exp2019-01-24_03-06-36 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:07:57.706695: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:07:57.786061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:07:57.786364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:07:57.786378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:07:57.942051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:07:57.942077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:07:57.942082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:07:57.942260: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-07-59 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 1024)                 20975616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    3075
=================================================================
Total params: 155,239,235
Trainable params: 20,978,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0000001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 1024
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000000_20
19-01-24_03-07-59
All frames and annotations from 1 datasets have been read by 2019-01-24 03:08:00.159361
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:08:09.032121!
Epoch 1/1
882/882 [==============================] - 28s 32ms/step - loss: 0.1061 - mean_absolute_error: 0.2542
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000000_
2019-01-24_03-07-59
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:08:38.239837
For the Subject 9 (M03):
882/882 [==============================] - 9s 11ms/step
        The absolute mean error on Pitch angle estimation: 24.90 Degree
        The absolute mean error on Yaw angle estimation: 31.73 Degree
        The absolute mean error on Roll angle estimation: 10.45 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 24.90 Degree
        The absolute mean error on Yaw angle estimations: 31.73 Degree
        The absolute mean error on Roll angle estimations: 10.45 Degree
subject9_Exp2019-01-24_03-07-59.png has been saved by 2019-01-24 03:08:56.640808.
Model Exp2019-01-24_03-07-59 has been evaluated successfully.
Model Exp2019-01-24_03-07-59 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:11:04.677237: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:11:04.773768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:11:04.774025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:11:04.774038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:11:04.928911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:11:04.928938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:11:04.928943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:11:04.929085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-11-06 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 1024)                 20975616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    3075
=================================================================
Total params: 155,239,235
Trainable params: 20,978,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.000001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 1024
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_20
19-01-24_03-11-06
All frames and annotations from 1 datasets have been read by 2019-01-24 03:11:07.149117
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:11:16.023092!
Epoch 1/1
882/882 [==============================] - 28s 32ms/step - loss: 0.0909 - mean_absolute_error: 0.2372
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm1024_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_
2019-01-24_03-11-06
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:11:45.199650
For the Subject 9 (M03):
882/882 [==============================] - 9s 10ms/step
        The absolute mean error on Pitch angle estimation: 13.31 Degree
        The absolute mean error on Yaw angle estimation: 17.66 Degree
        The absolute mean error on Roll angle estimation: 12.21 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 13.31 Degree
        The absolute mean error on Yaw angle estimations: 17.66 Degree
        The absolute mean error on Roll angle estimations: 12.21 Degree
subject9_Exp2019-01-24_03-11-06.png has been saved by 2019-01-24 03:12:03.578991.
Model Exp2019-01-24_03-11-06 has been evaluated successfully.
Model Exp2019-01-24_03-11-06 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:12:40.995577: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:12:41.093621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:12:41.093886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:12:41.093899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:12:41.248475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:12:41.248501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:12:41.248505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:12:41.248642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-12-41 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 24)                   395616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    75
=================================================================
Total params: 134,656,235
Trainable params: 395,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.000001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 24
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm24_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_2019
-01-24_03-12-41
All frames and annotations from 1 datasets have been read by 2019-01-24 03:12:42.811801
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:12:51.716972!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.1629 - mean_absolute_error: 0.3247
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm24_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000001_20
19-01-24_03-12-41
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:13:09.745825
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 16.87 Degree
        The absolute mean error on Yaw angle estimation: 24.95 Degree
        The absolute mean error on Roll angle estimation: 17.92 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 16.87 Degree
        The absolute mean error on Yaw angle estimations: 24.95 Degree
        The absolute mean error on Roll angle estimations: 17.92 Degree
subject9_Exp2019-01-24_03-12-41.png has been saved by 2019-01-24 03:13:27.212340.
Model Exp2019-01-24_03-12-41 has been evaluated successfully.
Model Exp2019-01-24_03-12-41 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:13:54.511735: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:13:54.591350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:13:54.591616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:13:54.591629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:13:54.746047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:13:54.746074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:13:54.746082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:13:54.746228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-13-55 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 24)                   395616
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    75
=================================================================
Total params: 134,656,235
Trainable params: 395,691
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 24
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm24_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019
-01-24_03-13-55
All frames and annotations from 1 datasets have been read by 2019-01-24 03:13:56.287086
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:14:05.174895!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0424 - mean_absolute_error: 0.1516
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm24_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_20
19-01-24_03-13-55
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:14:22.811476
For the Subject 9 (M03):
882/882 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 7.49 Degree
        The absolute mean error on Yaw angle estimation: 8.01 Degree
        The absolute mean error on Roll angle estimation: 4.18 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 7.49 Degree
        The absolute mean error on Yaw angle estimations: 8.01 Degree
        The absolute mean error on Roll angle estimations: 4.18 Degree
subject9_Exp2019-01-24_03-13-55.png has been saved by 2019-01-24 03:14:40.305205.
Model Exp2019-01-24_03-13-55 has been evaluated successfully.
Model Exp2019-01-24_03-13-55 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:16:03.823309: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:16:03.920360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:16:03.920662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:16:03.920676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:16:04.075977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:16:04.076003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:16:04.076010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:16:04.076192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-16-04 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.001000_2019
-01-24_03-16-04
All frames and annotations from 1 datasets have been read by 2019-01-24 03:16:05.595724
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:16:14.493106!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0663 - mean_absolute_error: 0.1968
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.001000_20
19-01-24_03-16-04
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:16:32.400973
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 19.00 Degree
        The absolute mean error on Yaw angle estimation: 25.73 Degree
        The absolute mean error on Roll angle estimation: 6.86 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 19.00 Degree
        The absolute mean error on Yaw angle estimations: 25.73 Degree
        The absolute mean error on Roll angle estimations: 6.86 Degree
subject9_Exp2019-01-24_03-16-04.png has been saved by 2019-01-24 03:16:49.871180.
Model Exp2019-01-24_03-16-04 has been evaluated successfully.
Model Exp2019-01-24_03-16-04 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:17:16.772433: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:17:16.869697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:17:16.869957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:17:16.869971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:17:17.025202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:17:17.025227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:17:17.025235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:17:17.025374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-17-17 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.00001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000010_2019
-01-24_03-17-17
All frames and annotations from 1 datasets have been read by 2019-01-24 03:17:18.598116
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:17:27.503894!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0768 - mean_absolute_error: 0.2173
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000010_20
19-01-24_03-17-17
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:17:45.401490
For the Subject 9 (M03):
882/882 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 15.00 Degree
        The absolute mean error on Yaw angle estimation: 23.60 Degree
        The absolute mean error on Roll angle estimation: 7.37 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 15.00 Degree
        The absolute mean error on Yaw angle estimations: 23.60 Degree
        The absolute mean error on Roll angle estimations: 7.37 Degree
subject9_Exp2019-01-24_03-17-17.png has been saved by 2019-01-24 03:18:02.907840.
Model Exp2019-01-24_03-17-17 has been evaluated successfully.
Model Exp2019-01-24_03-17-17 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:18:29.866636: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:18:29.946326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:18:29.946584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:18:29.946597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:18:30.102107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:18:30.102132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:18:30.102137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:18:30.102279: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-18-30 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019
-01-24_03-18-30
All frames and annotations from 1 datasets have been read by 2019-01-24 03:18:31.583949
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:18:40.480247!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0262 - mean_absolute_error: 0.1201
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_20
19-01-24_03-18-30
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:18:58.891962
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 6.96 Degree
        The absolute mean error on Yaw angle estimation: 6.71 Degree
        The absolute mean error on Roll angle estimation: 4.18 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 6.96 Degree
        The absolute mean error on Yaw angle estimations: 6.71 Degree
        The absolute mean error on Roll angle estimations: 4.18 Degree
subject9_Exp2019-01-24_03-18-30.png has been saved by 2019-01-24 03:19:16.383313.
Model Exp2019-01-24_03-18-30 has been evaluated successfully.
Model Exp2019-01-24_03-18-30 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:20:00.699025: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:20:00.795054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:20:00.795352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:20:00.795367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:20:00.949921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:20:00.949946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:20:00.949953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:20:00.950138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10505 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-20-01 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.0
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019
-01-24_03-20-01
All frames and annotations from 1 datasets have been read by 2019-01-24 03:20:02.453409
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:20:11.343854!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0212 - mean_absolute_error: 0.1011
Epoch 1 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_20
19-01-24_03-20-01
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:20:29.283992
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 8.02 Degree
        The absolute mean error on Yaw angle estimation: 5.57 Degree
        The absolute mean error on Roll angle estimation: 5.73 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 8.02 Degree
        The absolute mean error on Yaw angle estimations: 5.57 Degree
        The absolute mean error on Roll angle estimations: 5.73 Degree
subject9_Exp2019-01-24_03-20-01.png has been saved by 2019-01-24 03:20:46.655096.
Model Exp2019-01-24_03-20-01 has been evaluated successfully.
Model Exp2019-01-24_03-20-01 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:23:12.942356: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:23:13.039554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:23:13.039810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:23:13.039822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:23:13.195681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:23:13.195706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:23:13.195711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:23:13.195848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10505 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-23-13 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 3
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = subjectList # [s for s in subjectList if not s in testSubjects] #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs3_AdamOpt_lr-0.000100_2019
-01-24_03-23-13
All frames and annotations from 1 datasets have been read by 2019-01-24 03:23:14.678120
1. set (Dataset 9) being trained for epoch 1 by 2019-01-24 03:23:23.582848!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0251 - mean_absolute_error: 0.1114
Epoch 1 completed!
All frames and annotations from 1 datasets have been read by 2019-01-24 03:23:41.765841
1. set (Dataset 9) being trained for epoch 2 by 2019-01-24 03:23:50.663361!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0610
Epoch 2 completed!
All frames and annotations from 1 datasets have been read by 2019-01-24 03:24:07.495539
1. set (Dataset 9) being trained for epoch 3 by 2019-01-24 03:24:16.381800!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0509
Epoch 3 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs3_AdamOpt_lr-0.000100_20
19-01-24_03-23-13
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-24 03:24:33.036594
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 5.66 Degree
        The absolute mean error on Yaw angle estimation: 4.30 Degree
        The absolute mean error on Roll angle estimation: 2.24 Degree
On average in 1 test subjects:
        The absolute mean error on Pitch angle estimations: 5.66 Degree
        The absolute mean error on Yaw angle estimations: 4.30 Degree
        The absolute mean error on Roll angle estimations: 2.24 Degree
subject9_Exp2019-01-24_03-23-13.png has been saved by 2019-01-24 03:24:50.529637.
Model Exp2019-01-24_03-23-13 has been evaluated successfully.
Model Exp2019-01-24_03-23-13 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 03:29:03.385315: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 03:29:03.481526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 03:29:03.481793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.85GiB
2019-01-24 03:29:03.481808: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 03:29:03.637425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 03:29:03.637452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 03:29:03.637460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 03:29:03.637598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10504 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_03-29-04 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 50
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_201
9-01-24_03-29-04
All frames and annotations from 20 datasets have been read by 2019-01-24 03:29:08.760492
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 03:29:15.150500!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0138 - mean_absolute_error: 0.0812
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 03:29:33.099692!
Epoch 1/1
492/492 [==============================] - 9s 17ms/step - loss: 0.0108 - mean_absolute_error: 0.0748
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 03:29:47.966591!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0148 - mean_absolute_error: 0.0844
4. set (Dataset 19) being trained for epoch 1 by 2019-01-24 03:30:04.700892!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0174 - mean_absolute_error: 0.0959
5. set (Dataset 8) being trained for epoch 1 by 2019-01-24 03:30:21.103832!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0307 - mean_absolute_error: 0.1226
6. set (Dataset 23) being trained for epoch 1 by 2019-01-24 03:30:40.115510!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0311 - mean_absolute_error: 0.1302
7. set (Dataset 21) being trained for epoch 1 by 2019-01-24 03:30:56.412869!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0347 - mean_absolute_error: 0.1384
8. set (Dataset 16) being trained for epoch 1 by 2019-01-24 03:31:16.450684!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0120 - mean_absolute_error: 0.0781
9. set (Dataset 7) being trained for epoch 1 by 2019-01-24 03:31:41.062874!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0169 - mean_absolute_error: 0.0944
10. set (Dataset 12) being trained for epoch 1 by 2019-01-24 03:32:01.973549!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0139 - mean_absolute_error: 0.0894
11. set (Dataset 10) being trained for epoch 1 by 2019-01-24 03:32:22.227232!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0196 - mean_absolute_error: 0.0910
12. set (Dataset 1) being trained for epoch 1 by 2019-01-24 03:32:40.278615!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0257 - mean_absolute_error: 0.1094
13. set (Dataset 18) being trained for epoch 1 by 2019-01-24 03:32:54.930147!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0318 - mean_absolute_error: 0.1370
14. set (Dataset 2) being trained for epoch 1 by 2019-01-24 03:33:10.952473!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0235 - mean_absolute_error: 0.1095
15. set (Dataset 4) being trained for epoch 1 by 2019-01-24 03:33:27.508953!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0173 - mean_absolute_error: 0.0884
16. set (Dataset 20) being trained for epoch 1 by 2019-01-24 03:33:45.965954!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0226 - mean_absolute_error: 0.1064
17. set (Dataset 17) being trained for epoch 1 by 2019-01-24 03:33:59.612196!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0140 - mean_absolute_error: 0.0886
18. set (Dataset 6) being trained for epoch 1 by 2019-01-24 03:34:11.888421!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0500 - mean_absolute_error: 0.1497
19. set (Dataset 13) being trained for epoch 1 by 2019-01-24 03:34:26.842164!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0141 - mean_absolute_error: 0.0870
20. set (Dataset 11) being trained for epoch 1 by 2019-01-24 03:34:41.401603!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0199 - mean_absolute_error: 0.0961
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 03:34:56.076901
1. set (Dataset 6) being trained for epoch 2 by 2019-01-24 03:35:01.214038!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0348 - mean_absolute_error: 0.1247
2. set (Dataset 11) being trained for epoch 2 by 2019-01-24 03:35:16.494030!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0105 - mean_absolute_error: 0.0719
3. set (Dataset 10) being trained for epoch 2 by 2019-01-24 03:35:33.977708!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0204 - mean_absolute_error: 0.0964
4. set (Dataset 4) being trained for epoch 2 by 2019-01-24 03:35:54.312363!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0110 - mean_absolute_error: 0.0784
5. set (Dataset 23) being trained for epoch 2 by 2019-01-24 03:36:13.215318!
Epoch 1/1
569/569 [==============================] - 10s 17ms/step - loss: 0.0229 - mean_absolute_error: 0.1116
6. set (Dataset 13) being trained for epoch 2 by 2019-01-24 03:36:27.810704!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0086 - mean_absolute_error: 0.0660
7. set (Dataset 17) being trained for epoch 2 by 2019-01-24 03:36:39.930408!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0131 - mean_absolute_error: 0.0887
8. set (Dataset 1) being trained for epoch 2 by 2019-01-24 03:36:52.316719!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0324 - mean_absolute_error: 0.1192
9. set (Dataset 8) being trained for epoch 2 by 2019-01-24 03:37:08.958053!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0101 - mean_absolute_error: 0.0736
10. set (Dataset 7) being trained for epoch 2 by 2019-01-24 03:37:30.583304!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0099 - mean_absolute_error: 0.0752
11. set (Dataset 21) being trained for epoch 2 by 2019-01-24 03:37:50.333158!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0243 - mean_absolute_error: 0.1169
12. set (Dataset 22) being trained for epoch 2 by 2019-01-24 03:38:08.490686!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0100 - mean_absolute_error: 0.0784
13. set (Dataset 2) being trained for epoch 2 by 2019-01-24 03:38:25.922500!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0186 - mean_absolute_error: 0.0974
14. set (Dataset 24) being trained for epoch 2 by 2019-01-24 03:38:40.079874!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0101 - mean_absolute_error: 0.0782
15. set (Dataset 15) being trained for epoch 2 by 2019-01-24 03:38:55.226768!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0126 - mean_absolute_error: 0.0799
16. set (Dataset 20) being trained for epoch 2 by 2019-01-24 03:39:12.526851!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0102 - mean_absolute_error: 0.0763
17. set (Dataset 18) being trained for epoch 2 by 2019-01-24 03:39:28.319737!
Epoch 1/1
614/614 [==============================] - 10s 17ms/step - loss: 0.0170 - mean_absolute_error: 0.0986
18. set (Dataset 19) being trained for epoch 2 by 2019-01-24 03:39:43.662078!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0136 - mean_absolute_error: 0.0864
19. set (Dataset 12) being trained for epoch 2 by 2019-01-24 03:40:00.106162!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0071 - mean_absolute_error: 0.0614
20. set (Dataset 16) being trained for epoch 2 by 2019-01-24 03:40:22.241656!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0099 - mean_absolute_error: 0.0725
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 03:40:43.430504
1. set (Dataset 19) being trained for epoch 3 by 2019-01-24 03:40:48.262867!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0097 - mean_absolute_error: 0.0716
2. set (Dataset 16) being trained for epoch 3 by 2019-01-24 03:41:06.103559!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0548
3. set (Dataset 21) being trained for epoch 3 by 2019-01-24 03:41:28.492967!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0139 - mean_absolute_error: 0.0883
4. set (Dataset 15) being trained for epoch 3 by 2019-01-24 03:41:46.625469!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0069 - mean_absolute_error: 0.0610
5. set (Dataset 13) being trained for epoch 3 by 2019-01-24 03:42:03.174189!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0541
6. set (Dataset 12) being trained for epoch 3 by 2019-01-24 03:42:19.059589!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0461
7. set (Dataset 18) being trained for epoch 3 by 2019-01-24 03:42:38.416750!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0107 - mean_absolute_error: 0.0782
8. set (Dataset 22) being trained for epoch 3 by 2019-01-24 03:42:55.721459!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0578
9. set (Dataset 23) being trained for epoch 3 by 2019-01-24 03:43:12.875157!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0132 - mean_absolute_error: 0.0841
10. set (Dataset 8) being trained for epoch 3 by 2019-01-24 03:43:30.785337!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0082 - mean_absolute_error: 0.0682
11. set (Dataset 17) being trained for epoch 3 by 2019-01-24 03:43:48.332121!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0067 - mean_absolute_error: 0.0615
12. set (Dataset 6) being trained for epoch 3 by 2019-01-24 03:44:00.827670!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0217 - mean_absolute_error: 0.1046
13. set (Dataset 24) being trained for epoch 3 by 2019-01-24 03:44:15.507806!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0612
14. set (Dataset 11) being trained for epoch 3 by 2019-01-24 03:44:30.108086!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0501
15. set (Dataset 10) being trained for epoch 3 by 2019-01-24 03:44:47.465836!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0086 - mean_absolute_error: 0.0678
16. set (Dataset 20) being trained for epoch 3 by 2019-01-24 03:45:05.842143!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0069 - mean_absolute_error: 0.0644
17. set (Dataset 2) being trained for epoch 3 by 2019-01-24 03:45:20.913322!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0208 - mean_absolute_error: 0.1081
18. set (Dataset 4) being trained for epoch 3 by 2019-01-24 03:45:37.646089!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0064 - mean_absolute_error: 0.0614
19. set (Dataset 7) being trained for epoch 3 by 2019-01-24 03:45:58.512557!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0053 - mean_absolute_error: 0.0562
20. set (Dataset 1) being trained for epoch 3 by 2019-01-24 03:46:16.961844!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0096 - mean_absolute_error: 0.0712
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 03:46:30.300426
1. set (Dataset 4) being trained for epoch 4 by 2019-01-24 03:46:37.644259!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0527
2. set (Dataset 1) being trained for epoch 4 by 2019-01-24 03:46:55.766468!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0051 - mean_absolute_error: 0.0519
3. set (Dataset 17) being trained for epoch 4 by 2019-01-24 03:47:08.943192!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0078 - mean_absolute_error: 0.0671
4. set (Dataset 10) being trained for epoch 4 by 2019-01-24 03:47:23.356080!
Epoch 1/1
726/726 [==============================] - 14s 19ms/step - loss: 0.0042 - mean_absolute_error: 0.0490
5. set (Dataset 12) being trained for epoch 4 by 2019-01-24 03:47:44.147926!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0371
6. set (Dataset 7) being trained for epoch 4 by 2019-01-24 03:48:04.917433!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0400
7. set (Dataset 2) being trained for epoch 4 by 2019-01-24 03:48:23.814455!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0075 - mean_absolute_error: 0.0602
8. set (Dataset 6) being trained for epoch 4 by 2019-01-24 03:48:38.309999!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0169 - mean_absolute_error: 0.0906
9. set (Dataset 13) being trained for epoch 4 by 2019-01-24 03:48:52.970288!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0495
10. set (Dataset 23) being trained for epoch 4 by 2019-01-24 03:49:07.355578!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0121 - mean_absolute_error: 0.0778
11. set (Dataset 18) being trained for epoch 4 by 2019-01-24 03:49:23.394641!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0101 - mean_absolute_error: 0.0765
12. set (Dataset 19) being trained for epoch 4 by 2019-01-24 03:49:39.370045!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0090 - mean_absolute_error: 0.0713
13. set (Dataset 11) being trained for epoch 4 by 2019-01-24 03:49:54.032411!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0396
14. set (Dataset 16) being trained for epoch 4 by 2019-01-24 03:50:13.252038!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0570
15. set (Dataset 21) being trained for epoch 4 by 2019-01-24 03:50:35.828995!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0109 - mean_absolute_error: 0.0795
16. set (Dataset 20) being trained for epoch 4 by 2019-01-24 03:50:53.142523!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0598
17. set (Dataset 24) being trained for epoch 4 by 2019-01-24 03:51:08.057091!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0050 - mean_absolute_error: 0.0554
18. set (Dataset 15) being trained for epoch 4 by 2019-01-24 03:51:23.337141!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0061 - mean_absolute_error: 0.0591
19. set (Dataset 8) being trained for epoch 4 by 2019-01-24 03:51:42.984134!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0571
20. set (Dataset 22) being trained for epoch 4 by 2019-01-24 03:52:03.185046!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0522
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 03:52:19.664960
1. set (Dataset 15) being trained for epoch 5 by 2019-01-24 03:52:25.982724!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0526
2. set (Dataset 22) being trained for epoch 5 by 2019-01-24 03:52:44.340709!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0450
3. set (Dataset 18) being trained for epoch 5 by 2019-01-24 03:53:02.270096!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0082 - mean_absolute_error: 0.0687
4. set (Dataset 21) being trained for epoch 5 by 2019-01-24 03:53:19.242136!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0080 - mean_absolute_error: 0.0678
5. set (Dataset 7) being trained for epoch 5 by 2019-01-24 03:53:38.594871!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0410
6. set (Dataset 8) being trained for epoch 5 by 2019-01-24 03:53:59.690698!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0457
7. set (Dataset 24) being trained for epoch 5 by 2019-01-24 03:54:18.375605!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0041 - mean_absolute_error: 0.0502
8. set (Dataset 19) being trained for epoch 5 by 2019-01-24 03:54:32.376294!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0076 - mean_absolute_error: 0.0637
9. set (Dataset 12) being trained for epoch 5 by 2019-01-24 03:54:48.412929!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0391
10. set (Dataset 13) being trained for epoch 5 by 2019-01-24 03:55:06.664379!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0454
11. set (Dataset 2) being trained for epoch 5 by 2019-01-24 03:55:20.373064!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0534
12. set (Dataset 4) being trained for epoch 5 by 2019-01-24 03:55:36.758477!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0520
13. set (Dataset 16) being trained for epoch 5 by 2019-01-24 03:55:58.859513!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0541
14. set (Dataset 1) being trained for epoch 5 by 2019-01-24 03:56:20.452509!
Epoch 1/1
498/498 [==============================] - 9s 17ms/step - loss: 0.0061 - mean_absolute_error: 0.0580
15. set (Dataset 17) being trained for epoch 5 by 2019-01-24 03:56:32.853843!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0062 - mean_absolute_error: 0.0583
16. set (Dataset 20) being trained for epoch 5 by 2019-01-24 03:56:45.325255!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0546
17. set (Dataset 11) being trained for epoch 5 by 2019-01-24 03:57:01.113596!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0350
18. set (Dataset 10) being trained for epoch 5 by 2019-01-24 03:57:18.630064!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0494
19. set (Dataset 23) being trained for epoch 5 by 2019-01-24 03:57:37.004639!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0089 - mean_absolute_error: 0.0691
20. set (Dataset 6) being trained for epoch 5 by 2019-01-24 03:57:52.873347!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0149 - mean_absolute_error: 0.0825
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 03:58:07.177213
1. set (Dataset 10) being trained for epoch 6 by 2019-01-24 03:58:14.359068!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0433
2. set (Dataset 6) being trained for epoch 6 by 2019-01-24 03:58:32.815528!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0103 - mean_absolute_error: 0.0686
3. set (Dataset 2) being trained for epoch 6 by 2019-01-24 03:58:47.555268!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0488
4. set (Dataset 17) being trained for epoch 6 by 2019-01-24 03:59:00.686610!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0491
5. set (Dataset 8) being trained for epoch 6 by 2019-01-24 03:59:15.418460!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0449
6. set (Dataset 23) being trained for epoch 6 by 2019-01-24 03:59:34.897377!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0082 - mean_absolute_error: 0.0638
7. set (Dataset 11) being trained for epoch 6 by 2019-01-24 03:59:51.150521!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0331
8. set (Dataset 4) being trained for epoch 6 by 2019-01-24 04:00:08.989690!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0462
9. set (Dataset 7) being trained for epoch 6 by 2019-01-24 04:00:29.855790!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0356
10. set (Dataset 12) being trained for epoch 6 by 2019-01-24 04:00:50.457131!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0356
11. set (Dataset 24) being trained for epoch 6 by 2019-01-24 04:01:08.587824!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0469
12. set (Dataset 15) being trained for epoch 6 by 2019-01-24 04:01:23.684100!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0047 - mean_absolute_error: 0.0514
13. set (Dataset 1) being trained for epoch 6 by 2019-01-24 04:01:40.827824!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0530
14. set (Dataset 22) being trained for epoch 6 by 2019-01-24 04:01:55.963376!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0469
15. set (Dataset 18) being trained for epoch 6 by 2019-01-24 04:02:13.612032!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0075 - mean_absolute_error: 0.0660
16. set (Dataset 20) being trained for epoch 6 by 2019-01-24 04:02:30.384007!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0052 - mean_absolute_error: 0.0536
17. set (Dataset 16) being trained for epoch 6 by 2019-01-24 04:02:49.449208!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0490
18. set (Dataset 21) being trained for epoch 6 by 2019-01-24 04:03:11.717342!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0089 - mean_absolute_error: 0.0710
19. set (Dataset 13) being trained for epoch 6 by 2019-01-24 04:03:27.861536!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0432
20. set (Dataset 19) being trained for epoch 6 by 2019-01-24 04:03:41.432043!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0072 - mean_absolute_error: 0.0635
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:03:54.976810
1. set (Dataset 21) being trained for epoch 7 by 2019-01-24 04:04:00.928269!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0065 - mean_absolute_error: 0.0610
2. set (Dataset 19) being trained for epoch 7 by 2019-01-24 04:04:17.633462!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0057 - mean_absolute_error: 0.0554
3. set (Dataset 24) being trained for epoch 7 by 2019-01-24 04:04:31.626974!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0442
4. set (Dataset 18) being trained for epoch 7 by 2019-01-24 04:04:46.411452!
Epoch 1/1
614/614 [==============================] - 11s 17ms/step - loss: 0.0057 - mean_absolute_error: 0.0574
5. set (Dataset 23) being trained for epoch 7 by 2019-01-24 04:05:02.536615!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0072 - mean_absolute_error: 0.0602
6. set (Dataset 13) being trained for epoch 7 by 2019-01-24 04:05:17.719233!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0384
7. set (Dataset 16) being trained for epoch 7 by 2019-01-24 04:05:35.322651!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0444
8. set (Dataset 15) being trained for epoch 7 by 2019-01-24 04:05:58.075293!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0486
9. set (Dataset 8) being trained for epoch 7 by 2019-01-24 04:06:17.888118!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0424
10. set (Dataset 7) being trained for epoch 7 by 2019-01-24 04:06:39.660779!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0335
11. set (Dataset 11) being trained for epoch 7 by 2019-01-24 04:06:58.595197!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0310
12. set (Dataset 10) being trained for epoch 7 by 2019-01-24 04:07:16.127443!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0408
13. set (Dataset 22) being trained for epoch 7 by 2019-01-24 04:07:35.414849!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0439
14. set (Dataset 6) being trained for epoch 7 by 2019-01-24 04:07:52.444257!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0104 - mean_absolute_error: 0.0701
15. set (Dataset 2) being trained for epoch 7 by 2019-01-24 04:08:07.220211!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0479
16. set (Dataset 20) being trained for epoch 7 by 2019-01-24 04:08:21.799642!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0050 - mean_absolute_error: 0.0517
17. set (Dataset 1) being trained for epoch 7 by 2019-01-24 04:08:36.852673!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0526
18. set (Dataset 17) being trained for epoch 7 by 2019-01-24 04:08:49.659806!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0460
19. set (Dataset 12) being trained for epoch 7 by 2019-01-24 04:09:04.040660!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0332
20. set (Dataset 4) being trained for epoch 7 by 2019-01-24 04:09:24.852413!
Epoch 1/1
744/744 [==============================] - 13s 17ms/step - loss: 0.0035 - mean_absolute_error: 0.0441
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:09:42.233336
1. set (Dataset 17) being trained for epoch 8 by 2019-01-24 04:09:45.924416!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0035 - mean_absolute_error: 0.0440
2. set (Dataset 4) being trained for epoch 8 by 2019-01-24 04:10:00.717206!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0389
3. set (Dataset 11) being trained for epoch 8 by 2019-01-24 04:10:19.847021!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 0.0015 - mean_absolute_error: 0.0293
4. set (Dataset 2) being trained for epoch 8 by 2019-01-24 04:10:34.878114!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0460
5. set (Dataset 13) being trained for epoch 8 by 2019-01-24 04:10:48.895895!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0372
6. set (Dataset 12) being trained for epoch 8 by 2019-01-24 04:11:04.943056!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0297
7. set (Dataset 1) being trained for epoch 8 by 2019-01-24 04:11:23.451619!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0452
8. set (Dataset 10) being trained for epoch 8 by 2019-01-24 04:11:39.818542!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0371
9. set (Dataset 23) being trained for epoch 8 by 2019-01-24 04:11:58.568389!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0067 - mean_absolute_error: 0.0589
10. set (Dataset 8) being trained for epoch 8 by 2019-01-24 04:12:16.543093!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0411
11. set (Dataset 16) being trained for epoch 8 by 2019-01-24 04:12:39.319127!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0439
12. set (Dataset 21) being trained for epoch 8 by 2019-01-24 04:13:01.788181!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0628
13. set (Dataset 6) being trained for epoch 8 by 2019-01-24 04:13:18.437560!
Epoch 1/1
542/542 [==============================] - 9s 17ms/step - loss: 0.0092 - mean_absolute_error: 0.0674
14. set (Dataset 19) being trained for epoch 8 by 2019-01-24 04:13:32.773468!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0063 - mean_absolute_error: 0.0585
15. set (Dataset 24) being trained for epoch 8 by 2019-01-24 04:13:46.905234!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0030 - mean_absolute_error: 0.0426
16. set (Dataset 20) being trained for epoch 8 by 2019-01-24 04:14:01.458972!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0045 - mean_absolute_error: 0.0482
17. set (Dataset 22) being trained for epoch 8 by 2019-01-24 04:14:18.197986!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0439
18. set (Dataset 18) being trained for epoch 8 by 2019-01-24 04:14:35.957251!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0557
19. set (Dataset 7) being trained for epoch 8 by 2019-01-24 04:14:54.580792!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0330
20. set (Dataset 15) being trained for epoch 8 by 2019-01-24 04:15:14.305516!
Epoch 1/1
654/654 [==============================] - 11s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0485
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:15:30.315003
1. set (Dataset 18) being trained for epoch 9 by 2019-01-24 04:15:36.141621!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0520
2. set (Dataset 15) being trained for epoch 9 by 2019-01-24 04:15:53.581659!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0454
3. set (Dataset 16) being trained for epoch 9 by 2019-01-24 04:16:14.034970!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0425
4. set (Dataset 24) being trained for epoch 9 by 2019-01-24 04:16:34.832499!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0383
5. set (Dataset 12) being trained for epoch 9 by 2019-01-24 04:16:50.756965!
Epoch 1/1
732/732 [==============================] - 13s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0377
6. set (Dataset 7) being trained for epoch 9 by 2019-01-24 04:17:11.106678!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0291
7. set (Dataset 22) being trained for epoch 9 by 2019-01-24 04:17:30.866660!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0421
8. set (Dataset 21) being trained for epoch 9 by 2019-01-24 04:17:48.727215!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0060 - mean_absolute_error: 0.0585
9. set (Dataset 13) being trained for epoch 9 by 2019-01-24 04:18:05.118339!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0362
10. set (Dataset 23) being trained for epoch 9 by 2019-01-24 04:18:19.243955!
Epoch 1/1
569/569 [==============================] - 11s 18ms/step - loss: 0.0062 - mean_absolute_error: 0.0567
11. set (Dataset 1) being trained for epoch 9 by 2019-01-24 04:18:34.791099!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0497
12. set (Dataset 17) being trained for epoch 9 by 2019-01-24 04:18:47.407048!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0454
13. set (Dataset 19) being trained for epoch 9 by 2019-01-24 04:18:59.333959!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0537
14. set (Dataset 4) being trained for epoch 9 by 2019-01-24 04:19:15.692227!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0407
15. set (Dataset 11) being trained for epoch 9 by 2019-01-24 04:19:34.694241!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0296
16. set (Dataset 20) being trained for epoch 9 by 2019-01-24 04:19:50.408121!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0043 - mean_absolute_error: 0.0478
17. set (Dataset 6) being trained for epoch 9 by 2019-01-24 04:20:05.888432!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0087 - mean_absolute_error: 0.0663
18. set (Dataset 2) being trained for epoch 9 by 2019-01-24 04:20:20.538374!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0427
19. set (Dataset 8) being trained for epoch 9 by 2019-01-24 04:20:37.547236!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0405
20. set (Dataset 10) being trained for epoch 9 by 2019-01-24 04:20:58.659254!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0385
Epoch 9 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:21:16.236625
1. set (Dataset 2) being trained for epoch 10 by 2019-01-24 04:21:21.253543!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0380
2. set (Dataset 10) being trained for epoch 10 by 2019-01-24 04:21:37.684536!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0327
3. set (Dataset 1) being trained for epoch 10 by 2019-01-24 04:21:55.694175!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0037 - mean_absolute_error: 0.0430
4. set (Dataset 11) being trained for epoch 10 by 2019-01-24 04:22:10.657663!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0272
5. set (Dataset 7) being trained for epoch 10 by 2019-01-24 04:22:28.600619!
Epoch 1/1
745/745 [==============================] - 13s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0303
6. set (Dataset 8) being trained for epoch 10 by 2019-01-24 04:22:49.346651!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0362
7. set (Dataset 6) being trained for epoch 10 by 2019-01-24 04:23:08.884617!
Epoch 1/1
542/542 [==============================] - 9s 17ms/step - loss: 0.0080 - mean_absolute_error: 0.0622
8. set (Dataset 17) being trained for epoch 10 by 2019-01-24 04:23:22.103396!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0439
9. set (Dataset 12) being trained for epoch 10 by 2019-01-24 04:23:36.381865!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
10. set (Dataset 13) being trained for epoch 10 by 2019-01-24 04:23:54.255136!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0360
11. set (Dataset 22) being trained for epoch 10 by 2019-01-24 04:24:09.453064!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0446
12. set (Dataset 18) being trained for epoch 10 by 2019-01-24 04:24:27.160521!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0053 - mean_absolute_error: 0.0545
13. set (Dataset 4) being trained for epoch 10 by 2019-01-24 04:24:45.597436!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0385
14. set (Dataset 15) being trained for epoch 10 by 2019-01-24 04:25:05.518182!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0478
15. set (Dataset 16) being trained for epoch 10 by 2019-01-24 04:25:26.020772!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0411
16. set (Dataset 20) being trained for epoch 10 by 2019-01-24 04:25:47.814056!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0445
17. set (Dataset 19) being trained for epoch 10 by 2019-01-24 04:26:02.871056!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0540
18. set (Dataset 24) being trained for epoch 10 by 2019-01-24 04:26:16.564123!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0385
19. set (Dataset 23) being trained for epoch 10 by 2019-01-24 04:26:30.930933!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0062 - mean_absolute_error: 0.0567
20. set (Dataset 21) being trained for epoch 10 by 2019-01-24 04:26:47.494248!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0060 - mean_absolute_error: 0.0588
Epoch 10 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:27:03.193018
1. set (Dataset 24) being trained for epoch 11 by 2019-01-24 04:27:07.806349!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0347
2. set (Dataset 21) being trained for epoch 11 by 2019-01-24 04:27:22.867089!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0510
3. set (Dataset 22) being trained for epoch 11 by 2019-01-24 04:27:40.813278!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0028 - mean_absolute_error: 0.0387
4. set (Dataset 16) being trained for epoch 11 by 2019-01-24 04:28:02.003448!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0389
5. set (Dataset 8) being trained for epoch 11 by 2019-01-24 04:28:26.236973!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
6. set (Dataset 23) being trained for epoch 11 by 2019-01-24 04:28:45.550561!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0055 - mean_absolute_error: 0.0536
7. set (Dataset 19) being trained for epoch 11 by 2019-01-24 04:29:00.973270!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0517
8. set (Dataset 18) being trained for epoch 11 by 2019-01-24 04:29:15.951356!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0501
9. set (Dataset 7) being trained for epoch 11 by 2019-01-24 04:29:34.701823!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0315
10. set (Dataset 12) being trained for epoch 11 by 2019-01-24 04:29:55.118223!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0311
11. set (Dataset 6) being trained for epoch 11 by 2019-01-24 04:30:13.520032!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0078 - mean_absolute_error: 0.0614
12. set (Dataset 2) being trained for epoch 11 by 2019-01-24 04:30:28.498007!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0420
13. set (Dataset 15) being trained for epoch 11 by 2019-01-24 04:30:44.139037!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0481
14. set (Dataset 10) being trained for epoch 11 by 2019-01-24 04:31:03.155710!
Epoch 1/1
726/726 [==============================] - 14s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0352
15. set (Dataset 1) being trained for epoch 11 by 2019-01-24 04:31:21.849786!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0485
16. set (Dataset 20) being trained for epoch 11 by 2019-01-24 04:31:36.391120!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0439
17. set (Dataset 4) being trained for epoch 11 by 2019-01-24 04:31:54.015339!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0379
18. set (Dataset 11) being trained for epoch 11 by 2019-01-24 04:32:13.386478!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0292
19. set (Dataset 13) being trained for epoch 11 by 2019-01-24 04:32:28.545854!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0350
20. set (Dataset 17) being trained for epoch 11 by 2019-01-24 04:32:41.074737!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0441
Epoch 11 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:32:52.750780
1. set (Dataset 11) being trained for epoch 12 by 2019-01-24 04:32:58.403523!
Epoch 1/1
572/572 [==============================] - 11s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0266
2. set (Dataset 17) being trained for epoch 12 by 2019-01-24 04:33:12.710982!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0414
3. set (Dataset 6) being trained for epoch 12 by 2019-01-24 04:33:24.951690!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0066 - mean_absolute_error: 0.0577
4. set (Dataset 1) being trained for epoch 12 by 2019-01-24 04:33:39.961048!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0454
5. set (Dataset 23) being trained for epoch 12 by 2019-01-24 04:33:54.387312!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0563
6. set (Dataset 13) being trained for epoch 12 by 2019-01-24 04:34:09.340163!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0308
7. set (Dataset 4) being trained for epoch 12 by 2019-01-24 04:34:25.658169!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0358
8. set (Dataset 2) being trained for epoch 12 by 2019-01-24 04:34:44.189465!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0408
9. set (Dataset 8) being trained for epoch 12 by 2019-01-24 04:35:01.081920!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0355
10. set (Dataset 7) being trained for epoch 12 by 2019-01-24 04:35:22.636551!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
11. set (Dataset 19) being trained for epoch 12 by 2019-01-24 04:35:40.992827!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0534
12. set (Dataset 24) being trained for epoch 12 by 2019-01-24 04:35:54.648399!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0390
13. set (Dataset 10) being trained for epoch 12 by 2019-01-24 04:36:10.833073!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0353
14. set (Dataset 21) being trained for epoch 12 by 2019-01-24 04:36:29.844060!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0559
15. set (Dataset 22) being trained for epoch 12 by 2019-01-24 04:36:47.598312!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0384
16. set (Dataset 20) being trained for epoch 12 by 2019-01-24 04:37:05.206962!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0441
17. set (Dataset 15) being trained for epoch 12 by 2019-01-24 04:37:21.455024!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0447
18. set (Dataset 16) being trained for epoch 12 by 2019-01-24 04:37:41.869709!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0377
19. set (Dataset 12) being trained for epoch 12 by 2019-01-24 04:38:05.649144!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0313
20. set (Dataset 18) being trained for epoch 12 by 2019-01-24 04:38:24.979194!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0508
Epoch 12 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:38:40.466185
1. set (Dataset 16) being trained for epoch 13 by 2019-01-24 04:38:49.140345!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0357
2. set (Dataset 18) being trained for epoch 13 by 2019-01-24 04:39:11.946685!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0458
3. set (Dataset 19) being trained for epoch 13 by 2019-01-24 04:39:27.817660!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0484
4. set (Dataset 22) being trained for epoch 13 by 2019-01-24 04:39:43.281403!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0390
5. set (Dataset 13) being trained for epoch 13 by 2019-01-24 04:40:00.080320!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0485
6. set (Dataset 12) being trained for epoch 13 by 2019-01-24 04:40:16.139732!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0282
7. set (Dataset 15) being trained for epoch 13 by 2019-01-24 04:40:35.872758!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0449
8. set (Dataset 24) being trained for epoch 13 by 2019-01-24 04:40:52.460555!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0359
9. set (Dataset 23) being trained for epoch 13 by 2019-01-24 04:41:06.916681!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0536
10. set (Dataset 8) being trained for epoch 13 by 2019-01-24 04:41:25.032165!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0362
11. set (Dataset 4) being trained for epoch 13 by 2019-01-24 04:41:46.584305!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0349
12. set (Dataset 11) being trained for epoch 13 by 2019-01-24 04:42:05.678200!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0293
13. set (Dataset 21) being trained for epoch 13 by 2019-01-24 04:42:22.122947!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0052 - mean_absolute_error: 0.0538
14. set (Dataset 17) being trained for epoch 13 by 2019-01-24 04:42:37.098963!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0032 - mean_absolute_error: 0.0422
15. set (Dataset 6) being trained for epoch 13 by 2019-01-24 04:42:49.631584!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0586
16. set (Dataset 20) being trained for epoch 13 by 2019-01-24 04:43:04.832118!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0424
17. set (Dataset 10) being trained for epoch 13 by 2019-01-24 04:43:22.044566!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0348
18. set (Dataset 1) being trained for epoch 13 by 2019-01-24 04:43:40.038222!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0449
19. set (Dataset 7) being trained for epoch 13 by 2019-01-24 04:43:56.707839!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0290
20. set (Dataset 2) being trained for epoch 13 by 2019-01-24 04:44:15.417134!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0403
Epoch 13 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:44:29.099433
1. set (Dataset 1) being trained for epoch 14 by 2019-01-24 04:44:34.083723!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0395
2. set (Dataset 2) being trained for epoch 14 by 2019-01-24 04:44:48.011027!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0356
3. set (Dataset 4) being trained for epoch 14 by 2019-01-24 04:45:04.771004!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0332
4. set (Dataset 6) being trained for epoch 14 by 2019-01-24 04:45:23.341601!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0066 - mean_absolute_error: 0.0574
5. set (Dataset 12) being trained for epoch 14 by 2019-01-24 04:45:40.645862!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0283
6. set (Dataset 7) being trained for epoch 14 by 2019-01-24 04:46:01.839273!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
7. set (Dataset 10) being trained for epoch 14 by 2019-01-24 04:46:23.386619!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
8. set (Dataset 11) being trained for epoch 14 by 2019-01-24 04:46:42.132344!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0260
9. set (Dataset 13) being trained for epoch 14 by 2019-01-24 04:46:57.228507!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0321
10. set (Dataset 23) being trained for epoch 14 by 2019-01-24 04:47:11.347981!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0524
11. set (Dataset 15) being trained for epoch 14 by 2019-01-24 04:47:27.875430!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0032 - mean_absolute_error: 0.0430
12. set (Dataset 16) being trained for epoch 14 by 2019-01-24 04:47:48.851538!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0374
13. set (Dataset 17) being trained for epoch 14 by 2019-01-24 04:48:08.905457!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0426
14. set (Dataset 18) being trained for epoch 14 by 2019-01-24 04:48:21.930173!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0482
15. set (Dataset 19) being trained for epoch 14 by 2019-01-24 04:48:37.802485!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0492
16. set (Dataset 20) being trained for epoch 14 by 2019-01-24 04:48:52.430054!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0437
17. set (Dataset 21) being trained for epoch 14 by 2019-01-24 04:49:08.231364!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0046 - mean_absolute_error: 0.0518
18. set (Dataset 22) being trained for epoch 14 by 2019-01-24 04:49:26.451221!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0381
19. set (Dataset 8) being trained for epoch 14 by 2019-01-24 04:49:45.910307!
Epoch 1/1
772/772 [==============================] - 13s 17ms/step - loss: 0.0021 - mean_absolute_error: 0.0350
20. set (Dataset 24) being trained for epoch 14 by 2019-01-24 04:50:04.049896!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0356
Epoch 14 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:50:17.250459
1. set (Dataset 22) being trained for epoch 15 by 2019-01-24 04:50:23.589233!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0362
2. set (Dataset 24) being trained for epoch 15 by 2019-01-24 04:50:40.000972!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0328
3. set (Dataset 15) being trained for epoch 15 by 2019-01-24 04:50:55.251421!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0442
4. set (Dataset 19) being trained for epoch 15 by 2019-01-24 04:51:11.971391!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0490
5. set (Dataset 7) being trained for epoch 15 by 2019-01-24 04:51:28.797961!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0290
6. set (Dataset 8) being trained for epoch 15 by 2019-01-24 04:51:50.330947!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0331
7. set (Dataset 21) being trained for epoch 15 by 2019-01-24 04:52:10.309148!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0050 - mean_absolute_error: 0.0534
8. set (Dataset 16) being trained for epoch 15 by 2019-01-24 04:52:30.404259!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0356
9. set (Dataset 12) being trained for epoch 15 by 2019-01-24 04:52:54.035573!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 0.0015 - mean_absolute_error: 0.0292
10. set (Dataset 13) being trained for epoch 15 by 2019-01-24 04:53:12.436819!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0299
11. set (Dataset 10) being trained for epoch 15 by 2019-01-24 04:53:28.368301!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0307
12. set (Dataset 1) being trained for epoch 15 by 2019-01-24 04:53:46.668078!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0396
13. set (Dataset 18) being trained for epoch 15 by 2019-01-24 04:54:01.636387!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0479
14. set (Dataset 2) being trained for epoch 15 by 2019-01-24 04:54:17.895605!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0387
15. set (Dataset 4) being trained for epoch 15 by 2019-01-24 04:54:34.400338!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0326
16. set (Dataset 20) being trained for epoch 15 by 2019-01-24 04:54:53.269567!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0032 - mean_absolute_error: 0.0418
17. set (Dataset 17) being trained for epoch 15 by 2019-01-24 04:55:07.359016!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0405
18. set (Dataset 6) being trained for epoch 15 by 2019-01-24 04:55:19.818947!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0560
19. set (Dataset 23) being trained for epoch 15 by 2019-01-24 04:55:35.135031!
Epoch 1/1
569/569 [==============================] - 11s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0518
20. set (Dataset 11) being trained for epoch 15 by 2019-01-24 04:55:51.370772!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
Epoch 15 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 04:56:06.232247
1. set (Dataset 6) being trained for epoch 16 by 2019-01-24 04:56:11.367482!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0548
2. set (Dataset 11) being trained for epoch 16 by 2019-01-24 04:56:26.907908!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
3. set (Dataset 10) being trained for epoch 16 by 2019-01-24 04:56:44.558862!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0359
4. set (Dataset 4) being trained for epoch 16 by 2019-01-24 04:57:04.927075!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0332
5. set (Dataset 8) being trained for epoch 16 by 2019-01-24 04:57:26.157158!
Epoch 1/1
772/772 [==============================] - 15s 19ms/step - loss: 0.0018 - mean_absolute_error: 0.0323
6. set (Dataset 23) being trained for epoch 16 by 2019-01-24 04:57:46.104242!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0478
7. set (Dataset 17) being trained for epoch 16 by 2019-01-24 04:58:00.136386!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0029 - mean_absolute_error: 0.0398
8. set (Dataset 1) being trained for epoch 16 by 2019-01-24 04:58:12.656698!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0415
9. set (Dataset 7) being trained for epoch 16 by 2019-01-24 04:58:29.177778!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
10. set (Dataset 12) being trained for epoch 16 by 2019-01-24 04:58:49.664703!
Epoch 1/1
732/732 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
11. set (Dataset 21) being trained for epoch 16 by 2019-01-24 04:59:09.198926!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0518
12. set (Dataset 22) being trained for epoch 16 by 2019-01-24 04:59:27.083879!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0377
13. set (Dataset 2) being trained for epoch 16 by 2019-01-24 04:59:44.076173!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0388
14. set (Dataset 24) being trained for epoch 16 by 2019-01-24 04:59:58.101550!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0336
15. set (Dataset 15) being trained for epoch 16 by 2019-01-24 05:00:13.439268!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0425
16. set (Dataset 20) being trained for epoch 16 by 2019-01-24 05:00:30.590328!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0385
17. set (Dataset 18) being trained for epoch 16 by 2019-01-24 05:00:46.364917!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0460
18. set (Dataset 19) being trained for epoch 16 by 2019-01-24 05:01:02.383389!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0485
19. set (Dataset 13) being trained for epoch 16 by 2019-01-24 05:01:16.160546!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
20. set (Dataset 16) being trained for epoch 16 by 2019-01-24 05:01:33.527096!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0356
Epoch 16 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:01:54.781515
1. set (Dataset 19) being trained for epoch 17 by 2019-01-24 05:01:59.603781!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0457
2. set (Dataset 16) being trained for epoch 17 by 2019-01-24 05:02:17.476397!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0344
3. set (Dataset 21) being trained for epoch 17 by 2019-01-24 05:02:40.047864!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0489
4. set (Dataset 15) being trained for epoch 17 by 2019-01-24 05:02:57.811653!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0412
5. set (Dataset 23) being trained for epoch 17 by 2019-01-24 05:03:15.376378!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0481
6. set (Dataset 13) being trained for epoch 17 by 2019-01-24 05:03:30.230709!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0318
7. set (Dataset 18) being trained for epoch 17 by 2019-01-24 05:03:44.775268!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0448
8. set (Dataset 22) being trained for epoch 17 by 2019-01-24 05:04:02.258329!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0377
9. set (Dataset 8) being trained for epoch 17 by 2019-01-24 05:04:21.989849!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0339
10. set (Dataset 7) being trained for epoch 17 by 2019-01-24 05:04:43.386457!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
11. set (Dataset 17) being trained for epoch 17 by 2019-01-24 05:05:00.907700!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0396
12. set (Dataset 6) being trained for epoch 17 by 2019-01-24 05:05:13.146493!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0572
13. set (Dataset 24) being trained for epoch 17 by 2019-01-24 05:05:27.374783!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0346
14. set (Dataset 11) being trained for epoch 17 by 2019-01-24 05:05:42.047368!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0284
15. set (Dataset 10) being trained for epoch 17 by 2019-01-24 05:05:59.431453!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0316
16. set (Dataset 20) being trained for epoch 17 by 2019-01-24 05:06:17.749878!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0392
17. set (Dataset 2) being trained for epoch 17 by 2019-01-24 05:06:32.886796!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0391
18. set (Dataset 4) being trained for epoch 17 by 2019-01-24 05:06:49.572296!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0319
19. set (Dataset 12) being trained for epoch 17 by 2019-01-24 05:07:10.331180!
Epoch 1/1
732/732 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0272
20. set (Dataset 1) being trained for epoch 17 by 2019-01-24 05:07:28.893033!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0034 - mean_absolute_error: 0.0412
Epoch 17 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:07:42.805064
1. set (Dataset 4) being trained for epoch 18 by 2019-01-24 05:07:50.126438!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0306
2. set (Dataset 1) being trained for epoch 18 by 2019-01-24 05:08:08.410510!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0353
3. set (Dataset 17) being trained for epoch 18 by 2019-01-24 05:08:21.082553!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0406
4. set (Dataset 10) being trained for epoch 18 by 2019-01-24 05:08:35.448132!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0303
5. set (Dataset 13) being trained for epoch 18 by 2019-01-24 05:08:53.399140!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0296
6. set (Dataset 12) being trained for epoch 18 by 2019-01-24 05:09:09.189323!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.9143e-04 - mean_absolute_error: 0.0239
7. set (Dataset 2) being trained for epoch 18 by 2019-01-24 05:09:27.754517!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0382
8. set (Dataset 6) being trained for epoch 18 by 2019-01-24 05:09:42.137591!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0060 - mean_absolute_error: 0.0554
9. set (Dataset 23) being trained for epoch 18 by 2019-01-24 05:09:57.396772!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0477
10. set (Dataset 8) being trained for epoch 18 by 2019-01-24 05:10:15.567390!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0341
11. set (Dataset 18) being trained for epoch 18 by 2019-01-24 05:10:35.314993!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0036 - mean_absolute_error: 0.0455
12. set (Dataset 19) being trained for epoch 18 by 2019-01-24 05:10:51.620632!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0473
13. set (Dataset 11) being trained for epoch 18 by 2019-01-24 05:11:06.241290!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
14. set (Dataset 16) being trained for epoch 18 by 2019-01-24 05:11:25.134989!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0353
15. set (Dataset 21) being trained for epoch 18 by 2019-01-24 05:11:47.939854!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0478
16. set (Dataset 20) being trained for epoch 18 by 2019-01-24 05:12:04.525189!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0367
17. set (Dataset 24) being trained for epoch 18 by 2019-01-24 05:12:19.246567!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0322
18. set (Dataset 15) being trained for epoch 18 by 2019-01-24 05:12:34.382063!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0029 - mean_absolute_error: 0.0417
19. set (Dataset 7) being trained for epoch 18 by 2019-01-24 05:12:54.042823!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0281
20. set (Dataset 22) being trained for epoch 18 by 2019-01-24 05:13:14.084494!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0368
Epoch 18 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:13:30.470668
1. set (Dataset 15) being trained for epoch 19 by 2019-01-24 05:13:36.760357!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0397
2. set (Dataset 22) being trained for epoch 19 by 2019-01-24 05:13:55.135713!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0358
3. set (Dataset 18) being trained for epoch 19 by 2019-01-24 05:14:12.930379!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0438
4. set (Dataset 21) being trained for epoch 19 by 2019-01-24 05:14:30.176070!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0456
5. set (Dataset 12) being trained for epoch 19 by 2019-01-24 05:14:48.770414!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0359
6. set (Dataset 7) being trained for epoch 19 by 2019-01-24 05:15:09.313397!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
7. set (Dataset 24) being trained for epoch 19 by 2019-01-24 05:15:27.294013!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0326
8. set (Dataset 19) being trained for epoch 19 by 2019-01-24 05:15:41.219820!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0483
9. set (Dataset 13) being trained for epoch 19 by 2019-01-24 05:15:55.172386!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0385
10. set (Dataset 23) being trained for epoch 19 by 2019-01-24 05:16:09.504060!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0465
11. set (Dataset 2) being trained for epoch 19 by 2019-01-24 05:16:24.726830!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0397
12. set (Dataset 4) being trained for epoch 19 by 2019-01-24 05:16:41.372923!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0298
13. set (Dataset 16) being trained for epoch 19 by 2019-01-24 05:17:03.600180!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0352
14. set (Dataset 1) being trained for epoch 19 by 2019-01-24 05:17:24.899821!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0419
15. set (Dataset 17) being trained for epoch 19 by 2019-01-24 05:17:37.550274!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0400
16. set (Dataset 20) being trained for epoch 19 by 2019-01-24 05:17:50.161031!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0362
17. set (Dataset 11) being trained for epoch 19 by 2019-01-24 05:18:06.257466!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0272
18. set (Dataset 10) being trained for epoch 19 by 2019-01-24 05:18:23.642302!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
19. set (Dataset 8) being trained for epoch 19 by 2019-01-24 05:18:44.349796!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0323
20. set (Dataset 6) being trained for epoch 19 by 2019-01-24 05:19:03.566788!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0559
Epoch 19 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:19:17.658086
1. set (Dataset 10) being trained for epoch 20 by 2019-01-24 05:19:24.867218!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0298
2. set (Dataset 6) being trained for epoch 20 by 2019-01-24 05:19:42.756690!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0052 - mean_absolute_error: 0.0516
3. set (Dataset 2) being trained for epoch 20 by 2019-01-24 05:19:57.886110!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0364
4. set (Dataset 17) being trained for epoch 20 by 2019-01-24 05:20:10.745581!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0384
5. set (Dataset 7) being trained for epoch 20 by 2019-01-24 05:20:25.584409!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0256
6. set (Dataset 8) being trained for epoch 20 by 2019-01-24 05:20:46.826647!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
7. set (Dataset 11) being trained for epoch 20 by 2019-01-24 05:21:06.319087!
Epoch 1/1
572/572 [==============================] - 11s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0261
8. set (Dataset 4) being trained for epoch 20 by 2019-01-24 05:21:24.262933!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0296
9. set (Dataset 12) being trained for epoch 20 by 2019-01-24 05:21:45.252003!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0304
10. set (Dataset 13) being trained for epoch 20 by 2019-01-24 05:22:03.039968!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0307
11. set (Dataset 24) being trained for epoch 20 by 2019-01-24 05:22:16.325740!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0339
12. set (Dataset 15) being trained for epoch 20 by 2019-01-24 05:22:31.480616!
Epoch 1/1
654/654 [==============================] - 11s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0427
13. set (Dataset 1) being trained for epoch 20 by 2019-01-24 05:22:47.975079!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0394
14. set (Dataset 22) being trained for epoch 20 by 2019-01-24 05:23:03.439002!
Epoch 1/1
665/665 [==============================] - 12s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0362
15. set (Dataset 18) being trained for epoch 20 by 2019-01-24 05:23:20.881292!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0447
16. set (Dataset 20) being trained for epoch 20 by 2019-01-24 05:23:37.169438!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0376
17. set (Dataset 16) being trained for epoch 20 by 2019-01-24 05:23:56.049609!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0336
18. set (Dataset 21) being trained for epoch 20 by 2019-01-24 05:24:19.189367!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0473
19. set (Dataset 23) being trained for epoch 20 by 2019-01-24 05:24:35.941206!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0037 - mean_absolute_error: 0.0450
20. set (Dataset 19) being trained for epoch 20 by 2019-01-24 05:24:51.502684!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0043 - mean_absolute_error: 0.0465
Epoch 20 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:25:05.354616
1. set (Dataset 21) being trained for epoch 21 by 2019-01-24 05:25:11.304821!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0433
2. set (Dataset 19) being trained for epoch 21 by 2019-01-24 05:25:27.429137!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0430
3. set (Dataset 24) being trained for epoch 21 by 2019-01-24 05:25:41.227524!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0337
4. set (Dataset 18) being trained for epoch 21 by 2019-01-24 05:25:56.135484!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0415
5. set (Dataset 8) being trained for epoch 21 by 2019-01-24 05:26:14.966196!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0325
6. set (Dataset 23) being trained for epoch 21 by 2019-01-24 05:26:34.175197!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0441
7. set (Dataset 16) being trained for epoch 21 by 2019-01-24 05:26:53.293361!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0327
8. set (Dataset 15) being trained for epoch 21 by 2019-01-24 05:27:16.191779!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0399
9. set (Dataset 7) being trained for epoch 21 by 2019-01-24 05:27:35.537851!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0259
10. set (Dataset 12) being trained for epoch 21 by 2019-01-24 05:27:56.211559!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
11. set (Dataset 11) being trained for epoch 21 by 2019-01-24 05:28:15.174157!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0254
12. set (Dataset 10) being trained for epoch 21 by 2019-01-24 05:28:32.964327!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0314
13. set (Dataset 22) being trained for epoch 21 by 2019-01-24 05:28:52.374047!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0367
14. set (Dataset 6) being trained for epoch 21 by 2019-01-24 05:29:09.731356!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0061 - mean_absolute_error: 0.0548
15. set (Dataset 2) being trained for epoch 21 by 2019-01-24 05:29:24.557076!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0386
16. set (Dataset 20) being trained for epoch 21 by 2019-01-24 05:29:39.498607!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0371
17. set (Dataset 1) being trained for epoch 21 by 2019-01-24 05:29:54.463392!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0412
18. set (Dataset 17) being trained for epoch 21 by 2019-01-24 05:30:07.152382!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0382
19. set (Dataset 13) being trained for epoch 21 by 2019-01-24 05:30:19.104931!
Epoch 1/1
485/485 [==============================] - 8s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0312
20. set (Dataset 4) being trained for epoch 21 by 2019-01-24 05:30:34.971986!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0302
Epoch 21 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:30:52.987861
1. set (Dataset 17) being trained for epoch 22 by 2019-01-24 05:30:56.678194!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0371
2. set (Dataset 4) being trained for epoch 22 by 2019-01-24 05:31:11.386989!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0295
3. set (Dataset 11) being trained for epoch 22 by 2019-01-24 05:31:30.539709!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
4. set (Dataset 2) being trained for epoch 22 by 2019-01-24 05:31:45.874048!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0356
5. set (Dataset 23) being trained for epoch 22 by 2019-01-24 05:32:00.513895!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0481
6. set (Dataset 13) being trained for epoch 22 by 2019-01-24 05:32:15.731103!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0301
7. set (Dataset 1) being trained for epoch 22 by 2019-01-24 05:32:29.236189!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0369
8. set (Dataset 10) being trained for epoch 22 by 2019-01-24 05:32:45.354999!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0294
9. set (Dataset 8) being trained for epoch 22 by 2019-01-24 05:33:05.898808!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0318
10. set (Dataset 7) being trained for epoch 22 by 2019-01-24 05:33:27.843469!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.5694e-04 - mean_absolute_error: 0.0241
11. set (Dataset 16) being trained for epoch 22 by 2019-01-24 05:33:50.049225!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0338
12. set (Dataset 21) being trained for epoch 22 by 2019-01-24 05:34:12.891141!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0472
13. set (Dataset 6) being trained for epoch 22 by 2019-01-24 05:34:29.798036!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0056 - mean_absolute_error: 0.0533
14. set (Dataset 19) being trained for epoch 22 by 2019-01-24 05:34:44.525153!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0044 - mean_absolute_error: 0.0459
15. set (Dataset 24) being trained for epoch 22 by 2019-01-24 05:34:58.490081!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0326
16. set (Dataset 20) being trained for epoch 22 by 2019-01-24 05:35:12.988122!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0360
17. set (Dataset 22) being trained for epoch 22 by 2019-01-24 05:35:29.665154!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0364
18. set (Dataset 18) being trained for epoch 22 by 2019-01-24 05:35:47.265993!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0442
19. set (Dataset 12) being trained for epoch 22 by 2019-01-24 05:36:05.679942!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
20. set (Dataset 15) being trained for epoch 22 by 2019-01-24 05:36:25.121489!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0028 - mean_absolute_error: 0.0403
Epoch 22 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:36:41.802535
1. set (Dataset 18) being trained for epoch 23 by 2019-01-24 05:36:47.622184!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0028 - mean_absolute_error: 0.0405
2. set (Dataset 15) being trained for epoch 23 by 2019-01-24 05:37:05.346716!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0388
3. set (Dataset 16) being trained for epoch 23 by 2019-01-24 05:37:25.768375!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0326
4. set (Dataset 24) being trained for epoch 23 by 2019-01-24 05:37:46.993046!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0309
5. set (Dataset 13) being trained for epoch 23 by 2019-01-24 05:38:00.929901!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0506
6. set (Dataset 12) being trained for epoch 23 by 2019-01-24 05:38:16.992200!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0299
7. set (Dataset 22) being trained for epoch 23 by 2019-01-24 05:38:36.560905!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0346
8. set (Dataset 21) being trained for epoch 23 by 2019-01-24 05:38:54.799474!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0471
9. set (Dataset 23) being trained for epoch 23 by 2019-01-24 05:39:11.899740!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0429
10. set (Dataset 8) being trained for epoch 23 by 2019-01-24 05:39:29.768113!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0305
11. set (Dataset 1) being trained for epoch 23 by 2019-01-24 05:39:48.744008!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0367
12. set (Dataset 17) being trained for epoch 23 by 2019-01-24 05:40:01.737222!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0361
13. set (Dataset 19) being trained for epoch 23 by 2019-01-24 05:40:13.750838!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0457
14. set (Dataset 4) being trained for epoch 23 by 2019-01-24 05:40:30.106482!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
15. set (Dataset 11) being trained for epoch 23 by 2019-01-24 05:40:49.468981!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
16. set (Dataset 20) being trained for epoch 23 by 2019-01-24 05:41:05.340109!
Epoch 1/1
556/556 [==============================] - 10s 17ms/step - loss: 0.0023 - mean_absolute_error: 0.0367
17. set (Dataset 6) being trained for epoch 23 by 2019-01-24 05:41:20.235419!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0530
18. set (Dataset 2) being trained for epoch 23 by 2019-01-24 05:41:35.026229!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0364
19. set (Dataset 7) being trained for epoch 23 by 2019-01-24 05:41:51.837864!
Epoch 1/1
745/745 [==============================] - 13s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
20. set (Dataset 10) being trained for epoch 23 by 2019-01-24 05:42:12.091592!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0301
Epoch 23 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:42:29.705233
1. set (Dataset 2) being trained for epoch 24 by 2019-01-24 05:42:34.721317!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0321
2. set (Dataset 10) being trained for epoch 24 by 2019-01-24 05:42:51.263801!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0283
3. set (Dataset 1) being trained for epoch 24 by 2019-01-24 05:43:09.534018!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0383
4. set (Dataset 11) being trained for epoch 24 by 2019-01-24 05:43:24.192461!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0250
5. set (Dataset 12) being trained for epoch 24 by 2019-01-24 05:43:41.932128!
Epoch 1/1
732/732 [==============================] - 13s 17ms/step - loss: 0.0012 - mean_absolute_error: 0.0254
6. set (Dataset 7) being trained for epoch 24 by 2019-01-24 05:44:02.248011!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
7. set (Dataset 6) being trained for epoch 24 by 2019-01-24 05:44:20.953962!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0056 - mean_absolute_error: 0.0535
8. set (Dataset 17) being trained for epoch 24 by 2019-01-24 05:44:34.427737!
Epoch 1/1
395/395 [==============================] - 7s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0379
9. set (Dataset 13) being trained for epoch 24 by 2019-01-24 05:44:46.030134!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
10. set (Dataset 23) being trained for epoch 24 by 2019-01-24 05:45:00.560640!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0456
11. set (Dataset 22) being trained for epoch 24 by 2019-01-24 05:45:17.309259!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0359
12. set (Dataset 18) being trained for epoch 24 by 2019-01-24 05:45:34.986569!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0415
13. set (Dataset 4) being trained for epoch 24 by 2019-01-24 05:45:53.606156!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0288
14. set (Dataset 15) being trained for epoch 24 by 2019-01-24 05:46:13.184869!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0399
15. set (Dataset 16) being trained for epoch 24 by 2019-01-24 05:46:33.638564!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0319
16. set (Dataset 20) being trained for epoch 24 by 2019-01-24 05:46:55.197749!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0352
17. set (Dataset 19) being trained for epoch 24 by 2019-01-24 05:47:10.416043!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0461
18. set (Dataset 24) being trained for epoch 24 by 2019-01-24 05:47:24.173988!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0332
19. set (Dataset 8) being trained for epoch 24 by 2019-01-24 05:47:40.956067!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0329
20. set (Dataset 21) being trained for epoch 24 by 2019-01-24 05:48:00.489617!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0033 - mean_absolute_error: 0.0432
Epoch 24 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:48:16.849895
1. set (Dataset 24) being trained for epoch 25 by 2019-01-24 05:48:21.466875!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0294
2. set (Dataset 21) being trained for epoch 25 by 2019-01-24 05:48:36.526945!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0412
3. set (Dataset 22) being trained for epoch 25 by 2019-01-24 05:48:54.101918!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0346
4. set (Dataset 16) being trained for epoch 25 by 2019-01-24 05:49:14.938678!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0323
5. set (Dataset 7) being trained for epoch 25 by 2019-01-24 05:49:38.855361!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
6. set (Dataset 8) being trained for epoch 25 by 2019-01-24 05:49:59.950487!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0293
7. set (Dataset 19) being trained for epoch 25 by 2019-01-24 05:50:18.706833!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0040 - mean_absolute_error: 0.0446
8. set (Dataset 18) being trained for epoch 25 by 2019-01-24 05:50:34.015389!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0420
9. set (Dataset 12) being trained for epoch 25 by 2019-01-24 05:50:52.386556!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0271
10. set (Dataset 13) being trained for epoch 25 by 2019-01-24 05:51:10.600343!
Epoch 1/1
485/485 [==============================] - 8s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
11. set (Dataset 6) being trained for epoch 25 by 2019-01-24 05:51:24.293309!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0526
12. set (Dataset 2) being trained for epoch 25 by 2019-01-24 05:51:39.076041!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0364
13. set (Dataset 15) being trained for epoch 25 by 2019-01-24 05:51:54.420615!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0403
14. set (Dataset 10) being trained for epoch 25 by 2019-01-24 05:52:13.414798!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0321
15. set (Dataset 1) being trained for epoch 25 by 2019-01-24 05:52:31.584659!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0373
16. set (Dataset 20) being trained for epoch 25 by 2019-01-24 05:52:46.040476!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0355
17. set (Dataset 4) being trained for epoch 25 by 2019-01-24 05:53:03.446976!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0289
18. set (Dataset 11) being trained for epoch 25 by 2019-01-24 05:53:23.035324!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
19. set (Dataset 23) being trained for epoch 25 by 2019-01-24 05:53:38.434517!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0440
20. set (Dataset 17) being trained for epoch 25 by 2019-01-24 05:53:52.563109!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0368
Epoch 25 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:54:04.113229
1. set (Dataset 11) being trained for epoch 26 by 2019-01-24 05:54:09.758066!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
2. set (Dataset 17) being trained for epoch 26 by 2019-01-24 05:54:23.789188!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0360
3. set (Dataset 6) being trained for epoch 26 by 2019-01-24 05:54:36.286037!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0510
4. set (Dataset 1) being trained for epoch 26 by 2019-01-24 05:54:51.058897!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0032 - mean_absolute_error: 0.0402
5. set (Dataset 8) being trained for epoch 26 by 2019-01-24 05:55:08.013474!
Epoch 1/1
772/772 [==============================] - 13s 17ms/step - loss: 0.0017 - mean_absolute_error: 0.0319
6. set (Dataset 23) being trained for epoch 26 by 2019-01-24 05:55:26.870125!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0422
7. set (Dataset 4) being trained for epoch 26 by 2019-01-24 05:55:44.402961!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0288
8. set (Dataset 2) being trained for epoch 26 by 2019-01-24 05:56:02.708529!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0345
9. set (Dataset 7) being trained for epoch 26 by 2019-01-24 05:56:19.476309!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0260
10. set (Dataset 12) being trained for epoch 26 by 2019-01-24 05:56:40.478070!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0259
11. set (Dataset 19) being trained for epoch 26 by 2019-01-24 05:56:58.613567!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0453
12. set (Dataset 24) being trained for epoch 26 by 2019-01-24 05:57:12.240168!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0320
13. set (Dataset 10) being trained for epoch 26 by 2019-01-24 05:57:28.626931!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0295
14. set (Dataset 21) being trained for epoch 26 by 2019-01-24 05:57:47.631772!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0441
15. set (Dataset 22) being trained for epoch 26 by 2019-01-24 05:58:05.492201!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0356
16. set (Dataset 20) being trained for epoch 26 by 2019-01-24 05:58:22.746535!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0335
17. set (Dataset 15) being trained for epoch 26 by 2019-01-24 05:58:39.005808!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0399
18. set (Dataset 16) being trained for epoch 26 by 2019-01-24 05:59:00.177437!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0320
19. set (Dataset 13) being trained for epoch 26 by 2019-01-24 05:59:21.623422!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0308
20. set (Dataset 18) being trained for epoch 26 by 2019-01-24 05:59:36.479286!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0421
Epoch 26 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 05:59:51.895649
1. set (Dataset 16) being trained for epoch 27 by 2019-01-24 06:00:00.597133!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0304
2. set (Dataset 18) being trained for epoch 27 by 2019-01-24 06:00:23.205061!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0396
3. set (Dataset 19) being trained for epoch 27 by 2019-01-24 06:00:39.511641!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0433
4. set (Dataset 22) being trained for epoch 27 by 2019-01-24 06:00:55.109021!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0342
5. set (Dataset 23) being trained for epoch 27 by 2019-01-24 06:01:12.401728!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0416
6. set (Dataset 13) being trained for epoch 27 by 2019-01-24 06:01:27.458088!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0298
7. set (Dataset 15) being trained for epoch 27 by 2019-01-24 06:01:42.285395!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
8. set (Dataset 24) being trained for epoch 27 by 2019-01-24 06:01:58.562195!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
9. set (Dataset 8) being trained for epoch 27 by 2019-01-24 06:02:15.278541!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0315
10. set (Dataset 7) being trained for epoch 27 by 2019-01-24 06:02:36.930290!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
11. set (Dataset 4) being trained for epoch 27 by 2019-01-24 06:02:57.625060!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0286
12. set (Dataset 11) being trained for epoch 27 by 2019-01-24 06:03:16.698392!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
13. set (Dataset 21) being trained for epoch 27 by 2019-01-24 06:03:33.058055!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0445
14. set (Dataset 17) being trained for epoch 27 by 2019-01-24 06:03:48.373544!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
15. set (Dataset 6) being trained for epoch 27 by 2019-01-24 06:04:00.709757!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0491
16. set (Dataset 20) being trained for epoch 27 by 2019-01-24 06:04:15.931695!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0339
17. set (Dataset 10) being trained for epoch 27 by 2019-01-24 06:04:33.373453!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0315
18. set (Dataset 1) being trained for epoch 27 by 2019-01-24 06:04:51.138811!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0388
19. set (Dataset 12) being trained for epoch 27 by 2019-01-24 06:05:07.375715!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0247
20. set (Dataset 2) being trained for epoch 27 by 2019-01-24 06:05:25.472524!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0376
Epoch 27 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:05:39.040219
1. set (Dataset 1) being trained for epoch 28 by 2019-01-24 06:05:44.053599!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0365
2. set (Dataset 2) being trained for epoch 28 by 2019-01-24 06:05:58.404605!
Epoch 1/1
511/511 [==============================] - 10s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0332
3. set (Dataset 4) being trained for epoch 28 by 2019-01-24 06:06:15.441207!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0281
4. set (Dataset 6) being trained for epoch 28 by 2019-01-24 06:06:33.682362!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0493
5. set (Dataset 13) being trained for epoch 28 by 2019-01-24 06:06:48.145472!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0301
6. set (Dataset 12) being trained for epoch 28 by 2019-01-24 06:07:04.325816!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0243
7. set (Dataset 10) being trained for epoch 28 by 2019-01-24 06:07:24.975065!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0283
8. set (Dataset 11) being trained for epoch 28 by 2019-01-24 06:07:43.853145!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
9. set (Dataset 23) being trained for epoch 28 by 2019-01-24 06:07:59.819337!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0453
10. set (Dataset 8) being trained for epoch 28 by 2019-01-24 06:08:18.003601!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0305
11. set (Dataset 15) being trained for epoch 28 by 2019-01-24 06:08:38.338020!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0390
12. set (Dataset 16) being trained for epoch 28 by 2019-01-24 06:08:58.874482!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0018 - mean_absolute_error: 0.0315
13. set (Dataset 17) being trained for epoch 28 by 2019-01-24 06:09:20.012192!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0363
14. set (Dataset 18) being trained for epoch 28 by 2019-01-24 06:09:32.977287!
Epoch 1/1
614/614 [==============================] - 11s 17ms/step - loss: 0.0030 - mean_absolute_error: 0.0411
15. set (Dataset 19) being trained for epoch 28 by 2019-01-24 06:09:48.573262!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0441
16. set (Dataset 20) being trained for epoch 28 by 2019-01-24 06:10:03.012277!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0354
17. set (Dataset 21) being trained for epoch 28 by 2019-01-24 06:10:19.143172!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0419
18. set (Dataset 22) being trained for epoch 28 by 2019-01-24 06:10:36.715628!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0350
19. set (Dataset 7) being trained for epoch 28 by 2019-01-24 06:10:56.649358!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0271
20. set (Dataset 24) being trained for epoch 28 by 2019-01-24 06:11:14.786545!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0299
Epoch 28 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:11:28.165667
1. set (Dataset 22) being trained for epoch 29 by 2019-01-24 06:11:34.501147!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0333
2. set (Dataset 24) being trained for epoch 29 by 2019-01-24 06:11:51.511166!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0283
3. set (Dataset 15) being trained for epoch 29 by 2019-01-24 06:12:06.716726!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0395
4. set (Dataset 19) being trained for epoch 29 by 2019-01-24 06:12:23.452070!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0419
5. set (Dataset 12) being trained for epoch 29 by 2019-01-24 06:12:39.892175!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0274
6. set (Dataset 7) being trained for epoch 29 by 2019-01-24 06:13:00.805283!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0248
7. set (Dataset 21) being trained for epoch 29 by 2019-01-24 06:13:20.445176!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0034 - mean_absolute_error: 0.0440
8. set (Dataset 16) being trained for epoch 29 by 2019-01-24 06:13:41.243735!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0313
9. set (Dataset 13) being trained for epoch 29 by 2019-01-24 06:14:02.964147!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0325
10. set (Dataset 23) being trained for epoch 29 by 2019-01-24 06:14:17.056870!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0429
11. set (Dataset 10) being trained for epoch 29 by 2019-01-24 06:14:34.405903!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
12. set (Dataset 1) being trained for epoch 29 by 2019-01-24 06:14:52.365346!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0366
13. set (Dataset 18) being trained for epoch 29 by 2019-01-24 06:15:07.209101!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0409
14. set (Dataset 2) being trained for epoch 29 by 2019-01-24 06:15:23.329264!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0348
15. set (Dataset 4) being trained for epoch 29 by 2019-01-24 06:15:40.093521!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0280
16. set (Dataset 20) being trained for epoch 29 by 2019-01-24 06:15:58.990197!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0336
17. set (Dataset 17) being trained for epoch 29 by 2019-01-24 06:16:12.574735!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0369
18. set (Dataset 6) being trained for epoch 29 by 2019-01-24 06:16:24.904768!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0050 - mean_absolute_error: 0.0506
19. set (Dataset 8) being trained for epoch 29 by 2019-01-24 06:16:42.426025!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0326
20. set (Dataset 11) being trained for epoch 29 by 2019-01-24 06:17:02.148358!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
Epoch 29 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:17:17.002564
1. set (Dataset 6) being trained for epoch 30 by 2019-01-24 06:17:22.139439!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0500
2. set (Dataset 11) being trained for epoch 30 by 2019-01-24 06:17:37.522378!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.6268e-04 - mean_absolute_error: 0.0239
3. set (Dataset 10) being trained for epoch 30 by 2019-01-24 06:17:54.962781!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0295
4. set (Dataset 4) being trained for epoch 30 by 2019-01-24 06:18:15.178190!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
5. set (Dataset 7) being trained for epoch 30 by 2019-01-24 06:18:35.783663!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
6. set (Dataset 8) being trained for epoch 30 by 2019-01-24 06:18:56.700633!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0289
7. set (Dataset 17) being trained for epoch 30 by 2019-01-24 06:19:14.893714!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0367
8. set (Dataset 1) being trained for epoch 30 by 2019-01-24 06:19:27.026475!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0384
9. set (Dataset 12) being trained for epoch 30 by 2019-01-24 06:19:43.201835!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.2977e-04 - mean_absolute_error: 0.0230
10. set (Dataset 13) being trained for epoch 30 by 2019-01-24 06:20:01.288361!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0269
11. set (Dataset 21) being trained for epoch 30 by 2019-01-24 06:20:15.900664!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0448
12. set (Dataset 22) being trained for epoch 30 by 2019-01-24 06:20:33.875828!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0341
13. set (Dataset 2) being trained for epoch 30 by 2019-01-24 06:20:51.440882!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0357
14. set (Dataset 24) being trained for epoch 30 by 2019-01-24 06:21:05.211314!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
15. set (Dataset 15) being trained for epoch 30 by 2019-01-24 06:21:20.474997!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0382
16. set (Dataset 20) being trained for epoch 30 by 2019-01-24 06:21:37.575710!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0339
17. set (Dataset 18) being trained for epoch 30 by 2019-01-24 06:21:53.438686!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0410
18. set (Dataset 19) being trained for epoch 30 by 2019-01-24 06:22:09.454761!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0413
19. set (Dataset 23) being trained for epoch 30 by 2019-01-24 06:22:24.121675!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0410
20. set (Dataset 16) being trained for epoch 30 by 2019-01-24 06:22:43.185195!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0319
Epoch 30 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:23:04.483626
1. set (Dataset 19) being trained for epoch 31 by 2019-01-24 06:23:09.313931!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0036 - mean_absolute_error: 0.0415
2. set (Dataset 16) being trained for epoch 31 by 2019-01-24 06:23:27.405709!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0312
3. set (Dataset 21) being trained for epoch 31 by 2019-01-24 06:23:49.936751!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0424
4. set (Dataset 15) being trained for epoch 31 by 2019-01-24 06:24:07.712935!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0361
5. set (Dataset 8) being trained for epoch 31 by 2019-01-24 06:24:27.212972!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
6. set (Dataset 23) being trained for epoch 31 by 2019-01-24 06:24:46.363515!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0401
7. set (Dataset 18) being trained for epoch 31 by 2019-01-24 06:25:02.557142!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0395
8. set (Dataset 22) being trained for epoch 31 by 2019-01-24 06:25:19.878563!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0317
9. set (Dataset 7) being trained for epoch 31 by 2019-01-24 06:25:39.759581!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0256
10. set (Dataset 12) being trained for epoch 31 by 2019-01-24 06:26:00.289578!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
11. set (Dataset 17) being trained for epoch 31 by 2019-01-24 06:26:17.778060!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0363
12. set (Dataset 6) being trained for epoch 31 by 2019-01-24 06:26:30.369113!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0510
13. set (Dataset 24) being trained for epoch 31 by 2019-01-24 06:26:44.715040!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0299
14. set (Dataset 11) being trained for epoch 31 by 2019-01-24 06:26:59.343732!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.9040e-04 - mean_absolute_error: 0.0242
15. set (Dataset 10) being trained for epoch 31 by 2019-01-24 06:27:16.959361!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0302
16. set (Dataset 20) being trained for epoch 31 by 2019-01-24 06:27:35.708612!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0333
17. set (Dataset 2) being trained for epoch 31 by 2019-01-24 06:27:50.671493!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0353
18. set (Dataset 4) being trained for epoch 31 by 2019-01-24 06:28:07.086832!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
19. set (Dataset 13) being trained for epoch 31 by 2019-01-24 06:28:25.762959!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0281
20. set (Dataset 1) being trained for epoch 31 by 2019-01-24 06:28:39.595916!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0363
Epoch 31 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:28:53.226764
1. set (Dataset 4) being trained for epoch 32 by 2019-01-24 06:29:00.586073!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0261
2. set (Dataset 1) being trained for epoch 32 by 2019-01-24 06:29:18.841671!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0326
3. set (Dataset 17) being trained for epoch 32 by 2019-01-24 06:29:31.570922!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0367
4. set (Dataset 10) being trained for epoch 32 by 2019-01-24 06:29:45.800419!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
5. set (Dataset 23) being trained for epoch 32 by 2019-01-24 06:30:04.285865!
Epoch 1/1
569/569 [==============================] - 11s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0424
6. set (Dataset 13) being trained for epoch 32 by 2019-01-24 06:30:19.612388!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0270
7. set (Dataset 2) being trained for epoch 32 by 2019-01-24 06:30:33.436964!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0326
8. set (Dataset 6) being trained for epoch 32 by 2019-01-24 06:30:47.670330!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0049 - mean_absolute_error: 0.0498
9. set (Dataset 8) being trained for epoch 32 by 2019-01-24 06:31:05.462292!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0310
10. set (Dataset 7) being trained for epoch 32 by 2019-01-24 06:31:26.847884!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0250
11. set (Dataset 18) being trained for epoch 32 by 2019-01-24 06:31:46.386307!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0414
12. set (Dataset 19) being trained for epoch 32 by 2019-01-24 06:32:02.261366!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0431
13. set (Dataset 11) being trained for epoch 32 by 2019-01-24 06:32:17.212863!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0261
14. set (Dataset 16) being trained for epoch 32 by 2019-01-24 06:32:36.376158!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0311
15. set (Dataset 21) being trained for epoch 32 by 2019-01-24 06:32:58.902398!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0426
16. set (Dataset 20) being trained for epoch 32 by 2019-01-24 06:33:15.710093!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0325
17. set (Dataset 24) being trained for epoch 32 by 2019-01-24 06:33:30.565747!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0284
18. set (Dataset 15) being trained for epoch 32 by 2019-01-24 06:33:45.762229!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
19. set (Dataset 12) being trained for epoch 32 by 2019-01-24 06:34:05.293473!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
20. set (Dataset 22) being trained for epoch 32 by 2019-01-24 06:34:25.255170!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0364
Epoch 32 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:34:41.842867
1. set (Dataset 15) being trained for epoch 33 by 2019-01-24 06:34:48.138862!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0367
2. set (Dataset 22) being trained for epoch 33 by 2019-01-24 06:35:06.240192!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0324
3. set (Dataset 18) being trained for epoch 33 by 2019-01-24 06:35:24.240939!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0420
4. set (Dataset 21) being trained for epoch 33 by 2019-01-24 06:35:41.369451!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0392
5. set (Dataset 13) being trained for epoch 33 by 2019-01-24 06:35:57.583341!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0327
6. set (Dataset 12) being trained for epoch 33 by 2019-01-24 06:36:13.508772!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
7. set (Dataset 24) being trained for epoch 33 by 2019-01-24 06:36:31.256590!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0283
8. set (Dataset 19) being trained for epoch 33 by 2019-01-24 06:36:44.973108!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0413
9. set (Dataset 23) being trained for epoch 33 by 2019-01-24 06:36:59.666900!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0401
10. set (Dataset 8) being trained for epoch 33 by 2019-01-24 06:37:17.446816!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0299
11. set (Dataset 2) being trained for epoch 33 by 2019-01-24 06:37:36.182182!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0341
12. set (Dataset 4) being trained for epoch 33 by 2019-01-24 06:37:52.670309!
Epoch 1/1
744/744 [==============================] - 11s 14ms/step - loss: 0.0013 - mean_absolute_error: 0.0279
13. set (Dataset 16) being trained for epoch 33 by 2019-01-24 06:38:12.134223!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0315
14. set (Dataset 1) being trained for epoch 33 by 2019-01-24 06:38:33.906396!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0026 - mean_absolute_error: 0.0360
15. set (Dataset 17) being trained for epoch 33 by 2019-01-24 06:38:47.060045!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0352
16. set (Dataset 20) being trained for epoch 33 by 2019-01-24 06:38:59.737123!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0334
17. set (Dataset 11) being trained for epoch 33 by 2019-01-24 06:39:15.514346!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
18. set (Dataset 10) being trained for epoch 33 by 2019-01-24 06:39:33.096710!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0275
19. set (Dataset 7) being trained for epoch 33 by 2019-01-24 06:39:53.902777!
Epoch 1/1
745/745 [==============================] - 13s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0266
20. set (Dataset 6) being trained for epoch 33 by 2019-01-24 06:40:12.018935!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0508
Epoch 33 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:40:26.464590
1. set (Dataset 10) being trained for epoch 34 by 2019-01-24 06:40:33.639806!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
2. set (Dataset 6) being trained for epoch 34 by 2019-01-24 06:40:51.681788!
Epoch 1/1
542/542 [==============================] - 9s 17ms/step - loss: 0.0041 - mean_absolute_error: 0.0460
3. set (Dataset 2) being trained for epoch 34 by 2019-01-24 06:41:05.770587!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0324
4. set (Dataset 17) being trained for epoch 34 by 2019-01-24 06:41:18.809260!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0367
5. set (Dataset 12) being trained for epoch 34 by 2019-01-24 06:41:33.453733!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
6. set (Dataset 7) being trained for epoch 34 by 2019-01-24 06:41:54.041092!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0253
7. set (Dataset 11) being trained for epoch 34 by 2019-01-24 06:42:12.938965!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.9403e-04 - mean_absolute_error: 0.0229
8. set (Dataset 4) being trained for epoch 34 by 2019-01-24 06:42:30.719683!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
9. set (Dataset 13) being trained for epoch 34 by 2019-01-24 06:42:48.857428!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0281
10. set (Dataset 23) being trained for epoch 34 by 2019-01-24 06:43:03.157220!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0415
11. set (Dataset 24) being trained for epoch 34 by 2019-01-24 06:43:18.187466!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0295
12. set (Dataset 15) being trained for epoch 34 by 2019-01-24 06:43:33.639906!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0376
13. set (Dataset 1) being trained for epoch 34 by 2019-01-24 06:43:51.164752!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0376
14. set (Dataset 22) being trained for epoch 34 by 2019-01-24 06:44:06.655178!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0326
15. set (Dataset 18) being trained for epoch 34 by 2019-01-24 06:44:24.629305!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0407
16. set (Dataset 20) being trained for epoch 34 by 2019-01-24 06:44:41.383614!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0333
17. set (Dataset 16) being trained for epoch 34 by 2019-01-24 06:45:00.341449!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0299
18. set (Dataset 21) being trained for epoch 34 by 2019-01-24 06:45:22.882755!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0407
19. set (Dataset 8) being trained for epoch 34 by 2019-01-24 06:45:42.032171!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0305
20. set (Dataset 19) being trained for epoch 34 by 2019-01-24 06:46:00.787400!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0412
Epoch 34 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:46:14.376588
1. set (Dataset 21) being trained for epoch 35 by 2019-01-24 06:46:20.364612!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0394
2. set (Dataset 19) being trained for epoch 35 by 2019-01-24 06:46:36.700483!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0401
3. set (Dataset 24) being trained for epoch 35 by 2019-01-24 06:46:50.464677!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
4. set (Dataset 18) being trained for epoch 35 by 2019-01-24 06:47:05.098334!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0379
5. set (Dataset 7) being trained for epoch 35 by 2019-01-24 06:47:23.851774!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0249
6. set (Dataset 8) being trained for epoch 35 by 2019-01-24 06:47:45.001390!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
7. set (Dataset 16) being trained for epoch 35 by 2019-01-24 06:48:07.956146!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0306
8. set (Dataset 15) being trained for epoch 35 by 2019-01-24 06:48:30.533021!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0379
9. set (Dataset 12) being trained for epoch 35 by 2019-01-24 06:48:49.767837!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
10. set (Dataset 13) being trained for epoch 35 by 2019-01-24 06:49:07.809793!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
11. set (Dataset 11) being trained for epoch 35 by 2019-01-24 06:49:22.177252!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.2262e-04 - mean_absolute_error: 0.0238
12. set (Dataset 10) being trained for epoch 35 by 2019-01-24 06:49:39.735702!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
13. set (Dataset 22) being trained for epoch 35 by 2019-01-24 06:49:59.124682!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0339
14. set (Dataset 6) being trained for epoch 35 by 2019-01-24 06:50:16.446008!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0497
15. set (Dataset 2) being trained for epoch 35 by 2019-01-24 06:50:31.174131!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0333
16. set (Dataset 20) being trained for epoch 35 by 2019-01-24 06:50:45.616744!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0329
17. set (Dataset 1) being trained for epoch 35 by 2019-01-24 06:51:00.696684!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0382
18. set (Dataset 17) being trained for epoch 35 by 2019-01-24 06:51:13.150018!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0356
19. set (Dataset 23) being trained for epoch 35 by 2019-01-24 06:51:25.534262!
Epoch 1/1
569/569 [==============================] - 11s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0395
20. set (Dataset 4) being trained for epoch 35 by 2019-01-24 06:51:43.467841!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
Epoch 35 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:52:01.174278
1. set (Dataset 17) being trained for epoch 36 by 2019-01-24 06:52:04.862971!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0339
2. set (Dataset 4) being trained for epoch 36 by 2019-01-24 06:52:19.293354!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0273
3. set (Dataset 11) being trained for epoch 36 by 2019-01-24 06:52:38.220792!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0248
4. set (Dataset 2) being trained for epoch 36 by 2019-01-24 06:52:53.496148!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
5. set (Dataset 8) being trained for epoch 36 by 2019-01-24 06:53:10.620319!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0310
6. set (Dataset 23) being trained for epoch 36 by 2019-01-24 06:53:30.222084!
Epoch 1/1
569/569 [==============================] - 9s 16ms/step - loss: 0.0030 - mean_absolute_error: 0.0406
7. set (Dataset 1) being trained for epoch 36 by 2019-01-24 06:53:44.449347!
Epoch 1/1
498/498 [==============================] - 7s 14ms/step - loss: 0.0025 - mean_absolute_error: 0.0349
8. set (Dataset 10) being trained for epoch 36 by 2019-01-24 06:53:58.760229!
Epoch 1/1
726/726 [==============================] - 11s 15ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
9. set (Dataset 7) being trained for epoch 36 by 2019-01-24 06:54:17.249033!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.9579e-04 - mean_absolute_error: 0.0230
10. set (Dataset 12) being trained for epoch 36 by 2019-01-24 06:54:37.963075!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.8333e-04 - mean_absolute_error: 0.0231
11. set (Dataset 16) being trained for epoch 36 by 2019-01-24 06:54:59.878945!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0324
12. set (Dataset 21) being trained for epoch 36 by 2019-01-24 06:55:22.833805!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0399
13. set (Dataset 6) being trained for epoch 36 by 2019-01-24 06:55:39.676304!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0048 - mean_absolute_error: 0.0501
14. set (Dataset 19) being trained for epoch 36 by 2019-01-24 06:55:54.775011!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0427
15. set (Dataset 24) being trained for epoch 36 by 2019-01-24 06:56:08.710282!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
16. set (Dataset 20) being trained for epoch 36 by 2019-01-24 06:56:23.192536!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0322
17. set (Dataset 22) being trained for epoch 36 by 2019-01-24 06:56:39.443498!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0328
18. set (Dataset 18) being trained for epoch 36 by 2019-01-24 06:56:57.199745!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0393
19. set (Dataset 13) being trained for epoch 36 by 2019-01-24 06:57:12.943284!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
20. set (Dataset 15) being trained for epoch 36 by 2019-01-24 06:57:28.251598!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0377
Epoch 36 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 06:57:44.209530
1. set (Dataset 18) being trained for epoch 37 by 2019-01-24 06:57:50.036520!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0359
2. set (Dataset 15) being trained for epoch 37 by 2019-01-24 06:58:07.499791!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0352
3. set (Dataset 16) being trained for epoch 37 by 2019-01-24 06:58:28.465064!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0307
4. set (Dataset 24) being trained for epoch 37 by 2019-01-24 06:58:49.754517!
Epoch 1/1
492/492 [==============================] - 8s 17ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
5. set (Dataset 23) being trained for epoch 37 by 2019-01-24 06:59:03.673449!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0028 - mean_absolute_error: 0.0398
6. set (Dataset 13) being trained for epoch 37 by 2019-01-24 06:59:19.074364!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
7. set (Dataset 22) being trained for epoch 37 by 2019-01-24 06:59:34.344698!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0314
8. set (Dataset 21) being trained for epoch 37 by 2019-01-24 06:59:52.153601!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0391
9. set (Dataset 8) being trained for epoch 37 by 2019-01-24 07:00:11.244378!
Epoch 1/1
772/772 [==============================] - 15s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
10. set (Dataset 7) being trained for epoch 37 by 2019-01-24 07:00:33.607152!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
11. set (Dataset 1) being trained for epoch 37 by 2019-01-24 07:00:52.273887!
Epoch 1/1
498/498 [==============================] - 9s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0337
12. set (Dataset 17) being trained for epoch 37 by 2019-01-24 07:01:04.614314!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0363
13. set (Dataset 19) being trained for epoch 37 by 2019-01-24 07:01:16.513847!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0430
14. set (Dataset 4) being trained for epoch 37 by 2019-01-24 07:01:33.124649!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0276
15. set (Dataset 11) being trained for epoch 37 by 2019-01-24 07:01:52.267912!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
16. set (Dataset 20) being trained for epoch 37 by 2019-01-24 07:02:07.896836!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0322
17. set (Dataset 6) being trained for epoch 37 by 2019-01-24 07:02:23.060598!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0500
18. set (Dataset 2) being trained for epoch 37 by 2019-01-24 07:02:37.838057!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
19. set (Dataset 12) being trained for epoch 37 by 2019-01-24 07:02:54.434053!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0256
20. set (Dataset 10) being trained for epoch 37 by 2019-01-24 07:03:15.239655!
Epoch 1/1
726/726 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0268
Epoch 37 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:03:33.151067
1. set (Dataset 2) being trained for epoch 38 by 2019-01-24 07:03:38.182070!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0263
2. set (Dataset 10) being trained for epoch 38 by 2019-01-24 07:03:54.619801!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
3. set (Dataset 1) being trained for epoch 38 by 2019-01-24 07:04:12.760340!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0367
4. set (Dataset 11) being trained for epoch 38 by 2019-01-24 07:04:27.246613!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
5. set (Dataset 13) being trained for epoch 38 by 2019-01-24 07:04:42.071320!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
6. set (Dataset 12) being trained for epoch 38 by 2019-01-24 07:04:58.321128!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.6841e-04 - mean_absolute_error: 0.0228
7. set (Dataset 6) being trained for epoch 38 by 2019-01-24 07:05:16.600851!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0490
8. set (Dataset 17) being trained for epoch 38 by 2019-01-24 07:05:30.336340!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0370
9. set (Dataset 23) being trained for epoch 38 by 2019-01-24 07:05:42.855089!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0396
10. set (Dataset 8) being trained for epoch 38 by 2019-01-24 07:06:00.915984!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0301
11. set (Dataset 22) being trained for epoch 38 by 2019-01-24 07:06:21.355799!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0329
12. set (Dataset 18) being trained for epoch 38 by 2019-01-24 07:06:39.076982!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0396
13. set (Dataset 4) being trained for epoch 38 by 2019-01-24 07:06:57.409766!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
14. set (Dataset 15) being trained for epoch 38 by 2019-01-24 07:07:17.069495!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0377
15. set (Dataset 16) being trained for epoch 38 by 2019-01-24 07:07:37.698580!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0306
16. set (Dataset 20) being trained for epoch 38 by 2019-01-24 07:07:59.965312!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0318
17. set (Dataset 19) being trained for epoch 38 by 2019-01-24 07:08:14.785550!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0426
18. set (Dataset 24) being trained for epoch 38 by 2019-01-24 07:08:28.674297!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0282
19. set (Dataset 7) being trained for epoch 38 by 2019-01-24 07:08:45.342512!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0271
20. set (Dataset 21) being trained for epoch 38 by 2019-01-24 07:09:04.914145!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0422
Epoch 38 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:09:21.177619
1. set (Dataset 24) being trained for epoch 39 by 2019-01-24 07:09:25.809547!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
2. set (Dataset 21) being trained for epoch 39 by 2019-01-24 07:09:40.817079!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0361
3. set (Dataset 22) being trained for epoch 39 by 2019-01-24 07:09:58.673497!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0326
4. set (Dataset 16) being trained for epoch 39 by 2019-01-24 07:10:19.409002!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0293
5. set (Dataset 12) being trained for epoch 39 by 2019-01-24 07:10:42.785134!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.8062e-04 - mean_absolute_error: 0.0242
6. set (Dataset 7) being trained for epoch 39 by 2019-01-24 07:11:03.833547!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0251
7. set (Dataset 19) being trained for epoch 39 by 2019-01-24 07:11:22.626796!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0428
8. set (Dataset 18) being trained for epoch 39 by 2019-01-24 07:11:37.724086!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0379
9. set (Dataset 13) being trained for epoch 39 by 2019-01-24 07:11:53.556809!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0281
10. set (Dataset 23) being trained for epoch 39 by 2019-01-24 07:12:07.831122!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0389
11. set (Dataset 6) being trained for epoch 39 by 2019-01-24 07:12:23.507715!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0484
12. set (Dataset 2) being trained for epoch 39 by 2019-01-24 07:12:38.206994!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0310
13. set (Dataset 15) being trained for epoch 39 by 2019-01-24 07:12:53.543919!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0360
14. set (Dataset 10) being trained for epoch 39 by 2019-01-24 07:13:13.069891!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0266
15. set (Dataset 1) being trained for epoch 39 by 2019-01-24 07:13:31.172987!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0356
16. set (Dataset 20) being trained for epoch 39 by 2019-01-24 07:13:45.590754!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0323
17. set (Dataset 4) being trained for epoch 39 by 2019-01-24 07:14:02.901550!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0285
18. set (Dataset 11) being trained for epoch 39 by 2019-01-24 07:14:21.819853!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.8982e-04 - mean_absolute_error: 0.0243
19. set (Dataset 8) being trained for epoch 39 by 2019-01-24 07:14:39.771441!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0298
20. set (Dataset 17) being trained for epoch 39 by 2019-01-24 07:14:57.705425!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0350
Epoch 39 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:15:09.177926
1. set (Dataset 11) being trained for epoch 40 by 2019-01-24 07:15:14.831143!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.6340e-04 - mean_absolute_error: 0.0225
2. set (Dataset 17) being trained for epoch 40 by 2019-01-24 07:15:28.784316!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0325
3. set (Dataset 6) being trained for epoch 40 by 2019-01-24 07:15:41.125399!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0487
4. set (Dataset 1) being trained for epoch 40 by 2019-01-24 07:15:56.115707!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0384
5. set (Dataset 7) being trained for epoch 40 by 2019-01-24 07:16:12.571859!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
6. set (Dataset 8) being trained for epoch 40 by 2019-01-24 07:16:33.430067!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0281
7. set (Dataset 4) being trained for epoch 40 by 2019-01-24 07:16:54.855857!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0268
8. set (Dataset 2) being trained for epoch 40 by 2019-01-24 07:17:13.473216!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
9. set (Dataset 12) being trained for epoch 40 by 2019-01-24 07:17:29.961428!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.9241e-04 - mean_absolute_error: 0.0232
10. set (Dataset 13) being trained for epoch 40 by 2019-01-24 07:17:47.895968!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
11. set (Dataset 19) being trained for epoch 40 by 2019-01-24 07:18:01.469585!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0038 - mean_absolute_error: 0.0421
12. set (Dataset 24) being trained for epoch 40 by 2019-01-24 07:18:15.634395!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0301
13. set (Dataset 10) being trained for epoch 40 by 2019-01-24 07:18:31.950441!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
14. set (Dataset 21) being trained for epoch 40 by 2019-01-24 07:18:51.033942!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0408
15. set (Dataset 22) being trained for epoch 40 by 2019-01-24 07:19:09.010219!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0324
16. set (Dataset 20) being trained for epoch 40 by 2019-01-24 07:19:26.328428!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0323
17. set (Dataset 15) being trained for epoch 40 by 2019-01-24 07:19:42.494748!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0359
18. set (Dataset 16) being trained for epoch 40 by 2019-01-24 07:20:03.441500!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0297
19. set (Dataset 23) being trained for epoch 40 by 2019-01-24 07:20:25.530763!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0380
20. set (Dataset 18) being trained for epoch 40 by 2019-01-24 07:20:41.638746!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0368
Epoch 40 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:20:56.930365
1. set (Dataset 16) being trained for epoch 41 by 2019-01-24 07:21:05.608097!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0281
2. set (Dataset 18) being trained for epoch 41 by 2019-01-24 07:21:27.863719!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0354
3. set (Dataset 19) being trained for epoch 41 by 2019-01-24 07:21:44.091591!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0036 - mean_absolute_error: 0.0413
4. set (Dataset 22) being trained for epoch 41 by 2019-01-24 07:21:59.847626!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0339
5. set (Dataset 8) being trained for epoch 41 by 2019-01-24 07:22:19.565647!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0285
6. set (Dataset 23) being trained for epoch 41 by 2019-01-24 07:22:39.096442!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0383
7. set (Dataset 15) being trained for epoch 41 by 2019-01-24 07:22:55.674357!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0358
8. set (Dataset 24) being trained for epoch 41 by 2019-01-24 07:23:11.900944!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0273
9. set (Dataset 7) being trained for epoch 41 by 2019-01-24 07:23:28.761347!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0248
10. set (Dataset 12) being trained for epoch 41 by 2019-01-24 07:23:49.448171!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.5503e-04 - mean_absolute_error: 0.0239
11. set (Dataset 4) being trained for epoch 41 by 2019-01-24 07:24:09.974571!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0290
12. set (Dataset 11) being trained for epoch 41 by 2019-01-24 07:24:29.005720!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.7719e-04 - mean_absolute_error: 0.0230
13. set (Dataset 21) being trained for epoch 41 by 2019-01-24 07:24:45.146861!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0027 - mean_absolute_error: 0.0397
14. set (Dataset 17) being trained for epoch 41 by 2019-01-24 07:25:00.772104!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
15. set (Dataset 6) being trained for epoch 41 by 2019-01-24 07:25:13.110428!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0466
16. set (Dataset 20) being trained for epoch 41 by 2019-01-24 07:25:28.061927!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0317
17. set (Dataset 10) being trained for epoch 41 by 2019-01-24 07:25:45.338899!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0310
18. set (Dataset 1) being trained for epoch 41 by 2019-01-24 07:26:03.616535!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0045 - mean_absolute_error: 0.0472
19. set (Dataset 13) being trained for epoch 41 by 2019-01-24 07:26:17.710013!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0283
20. set (Dataset 2) being trained for epoch 41 by 2019-01-24 07:26:31.616717!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0344
Epoch 41 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:26:45.199845
1. set (Dataset 1) being trained for epoch 42 by 2019-01-24 07:26:50.184030!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0361
2. set (Dataset 2) being trained for epoch 42 by 2019-01-24 07:27:04.216443!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
3. set (Dataset 4) being trained for epoch 42 by 2019-01-24 07:27:20.811494!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0283
4. set (Dataset 6) being trained for epoch 42 by 2019-01-24 07:27:39.398225!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0048 - mean_absolute_error: 0.0489
5. set (Dataset 23) being trained for epoch 42 by 2019-01-24 07:27:54.941613!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0028 - mean_absolute_error: 0.0395
6. set (Dataset 13) being trained for epoch 42 by 2019-01-24 07:28:09.898417!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
7. set (Dataset 10) being trained for epoch 42 by 2019-01-24 07:28:26.039061!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0285
8. set (Dataset 11) being trained for epoch 42 by 2019-01-24 07:28:44.833955!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.0436e-04 - mean_absolute_error: 0.0230
9. set (Dataset 8) being trained for epoch 42 by 2019-01-24 07:29:02.808379!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0293
10. set (Dataset 7) being trained for epoch 42 by 2019-01-24 07:29:24.107197!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.4907e-04 - mean_absolute_error: 0.0237
11. set (Dataset 15) being trained for epoch 42 by 2019-01-24 07:29:43.919487!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0382
12. set (Dataset 16) being trained for epoch 42 by 2019-01-24 07:30:04.573080!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0305
13. set (Dataset 17) being trained for epoch 42 by 2019-01-24 07:30:25.002065!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0341
14. set (Dataset 18) being trained for epoch 42 by 2019-01-24 07:30:37.949079!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0392
15. set (Dataset 19) being trained for epoch 42 by 2019-01-24 07:30:53.806566!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0396
16. set (Dataset 20) being trained for epoch 42 by 2019-01-24 07:31:08.468780!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0331
17. set (Dataset 21) being trained for epoch 42 by 2019-01-24 07:31:24.967009!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0384
18. set (Dataset 22) being trained for epoch 42 by 2019-01-24 07:31:42.884687!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0318
19. set (Dataset 12) being trained for epoch 42 by 2019-01-24 07:32:02.002827!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
20. set (Dataset 24) being trained for epoch 42 by 2019-01-24 07:32:19.882969!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
Epoch 42 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:32:33.444164
1. set (Dataset 22) being trained for epoch 43 by 2019-01-24 07:32:39.777688!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0306
2. set (Dataset 24) being trained for epoch 43 by 2019-01-24 07:32:56.703009!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0266
3. set (Dataset 15) being trained for epoch 43 by 2019-01-24 07:33:12.425097!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0351
4. set (Dataset 19) being trained for epoch 43 by 2019-01-24 07:33:29.249180!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0407
5. set (Dataset 13) being trained for epoch 43 by 2019-01-24 07:33:43.003684!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0295
6. set (Dataset 12) being trained for epoch 43 by 2019-01-24 07:33:59.301818!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.2685e-04 - mean_absolute_error: 0.0234
7. set (Dataset 21) being trained for epoch 43 by 2019-01-24 07:34:18.398912!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0398
8. set (Dataset 16) being trained for epoch 43 by 2019-01-24 07:34:38.660680!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0015 - mean_absolute_error: 0.0292
9. set (Dataset 23) being trained for epoch 43 by 2019-01-24 07:35:01.210659!
Epoch 1/1
569/569 [==============================] - 9s 16ms/step - loss: 0.0026 - mean_absolute_error: 0.0375
10. set (Dataset 8) being trained for epoch 43 by 2019-01-24 07:35:18.276513!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
11. set (Dataset 10) being trained for epoch 43 by 2019-01-24 07:35:39.825482!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0271
12. set (Dataset 1) being trained for epoch 43 by 2019-01-24 07:35:58.184526!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0413
13. set (Dataset 18) being trained for epoch 43 by 2019-01-24 07:36:13.040076!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0378
14. set (Dataset 2) being trained for epoch 43 by 2019-01-24 07:36:29.108293!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0282
15. set (Dataset 4) being trained for epoch 43 by 2019-01-24 07:36:45.614056!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
16. set (Dataset 20) being trained for epoch 43 by 2019-01-24 07:37:04.334079!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0313
17. set (Dataset 17) being trained for epoch 43 by 2019-01-24 07:37:18.142393!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0328
18. set (Dataset 6) being trained for epoch 43 by 2019-01-24 07:37:30.386622!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0045 - mean_absolute_error: 0.0477
19. set (Dataset 7) being trained for epoch 43 by 2019-01-24 07:37:48.020829!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0259
20. set (Dataset 11) being trained for epoch 43 by 2019-01-24 07:38:07.171181!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
Epoch 43 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:38:21.848850
1. set (Dataset 6) being trained for epoch 44 by 2019-01-24 07:38:26.989550!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0040 - mean_absolute_error: 0.0455
2. set (Dataset 11) being trained for epoch 44 by 2019-01-24 07:38:42.755312!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.3342e-04 - mean_absolute_error: 0.0225
3. set (Dataset 10) being trained for epoch 44 by 2019-01-24 07:39:00.220329!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0292
4. set (Dataset 4) being trained for epoch 44 by 2019-01-24 07:39:20.831961!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
5. set (Dataset 12) being trained for epoch 44 by 2019-01-24 07:39:41.501823!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0240
6. set (Dataset 7) being trained for epoch 44 by 2019-01-24 07:40:02.107888!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
7. set (Dataset 17) being trained for epoch 44 by 2019-01-24 07:40:19.449176!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0340
8. set (Dataset 1) being trained for epoch 44 by 2019-01-24 07:40:31.631378!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0398
9. set (Dataset 13) being trained for epoch 44 by 2019-01-24 07:40:45.481243!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0250
10. set (Dataset 23) being trained for epoch 44 by 2019-01-24 07:40:59.654368!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0026 - mean_absolute_error: 0.0380
11. set (Dataset 21) being trained for epoch 44 by 2019-01-24 07:41:16.196280!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0383
12. set (Dataset 22) being trained for epoch 44 by 2019-01-24 07:41:33.847684!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0309
13. set (Dataset 2) being trained for epoch 44 by 2019-01-24 07:41:51.314729!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
14. set (Dataset 24) being trained for epoch 44 by 2019-01-24 07:42:05.486286!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0279
15. set (Dataset 15) being trained for epoch 44 by 2019-01-24 07:42:20.821161!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0361
16. set (Dataset 20) being trained for epoch 44 by 2019-01-24 07:42:38.256028!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0018 - mean_absolute_error: 0.0319
17. set (Dataset 18) being trained for epoch 44 by 2019-01-24 07:42:54.502287!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0381
18. set (Dataset 19) being trained for epoch 44 by 2019-01-24 07:43:10.422036!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0415
19. set (Dataset 8) being trained for epoch 44 by 2019-01-24 07:43:27.223305!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0295
20. set (Dataset 16) being trained for epoch 44 by 2019-01-24 07:43:50.461929!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0303
Epoch 44 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:44:11.410713
1. set (Dataset 19) being trained for epoch 45 by 2019-01-24 07:44:16.235596!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0033 - mean_absolute_error: 0.0387
2. set (Dataset 16) being trained for epoch 45 by 2019-01-24 07:44:34.251873!
Epoch 1/1
914/914 [==============================] - 16s 17ms/step - loss: 0.0015 - mean_absolute_error: 0.0290
3. set (Dataset 21) being trained for epoch 45 by 2019-01-24 07:44:56.237307!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0383
4. set (Dataset 15) being trained for epoch 45 by 2019-01-24 07:45:13.943990!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0350
5. set (Dataset 7) being trained for epoch 45 by 2019-01-24 07:45:33.203520!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
6. set (Dataset 8) being trained for epoch 45 by 2019-01-24 07:45:54.800154!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0275
7. set (Dataset 18) being trained for epoch 45 by 2019-01-24 07:46:14.453270!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0370
8. set (Dataset 22) being trained for epoch 45 by 2019-01-24 07:46:31.890965!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0313
9. set (Dataset 12) being trained for epoch 45 by 2019-01-24 07:46:51.040303!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.2405e-04 - mean_absolute_error: 0.0236
10. set (Dataset 13) being trained for epoch 45 by 2019-01-24 07:47:09.187225!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
11. set (Dataset 17) being trained for epoch 45 by 2019-01-24 07:47:21.851322!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0334
12. set (Dataset 6) being trained for epoch 45 by 2019-01-24 07:47:34.117606!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0464
13. set (Dataset 24) being trained for epoch 45 by 2019-01-24 07:47:48.723651!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0303
14. set (Dataset 11) being trained for epoch 45 by 2019-01-24 07:48:03.108986!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 9.5420e-04 - mean_absolute_error: 0.0242
15. set (Dataset 10) being trained for epoch 45 by 2019-01-24 07:48:20.203362!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
16. set (Dataset 20) being trained for epoch 45 by 2019-01-24 07:48:38.303969!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
17. set (Dataset 2) being trained for epoch 45 by 2019-01-24 07:48:53.272729!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0290
18. set (Dataset 4) being trained for epoch 45 by 2019-01-24 07:49:09.880642!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
19. set (Dataset 23) being trained for epoch 45 by 2019-01-24 07:49:28.852326!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0386
20. set (Dataset 1) being trained for epoch 45 by 2019-01-24 07:49:44.066473!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0378
Epoch 45 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:49:57.506379
1. set (Dataset 4) being trained for epoch 46 by 2019-01-24 07:50:04.833042!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0251
2. set (Dataset 1) being trained for epoch 46 by 2019-01-24 07:50:23.178274!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0329
3. set (Dataset 17) being trained for epoch 46 by 2019-01-24 07:50:35.808913!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0343
4. set (Dataset 10) being trained for epoch 46 by 2019-01-24 07:50:50.204963!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
5. set (Dataset 8) being trained for epoch 46 by 2019-01-24 07:51:11.241248!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
6. set (Dataset 23) being trained for epoch 46 by 2019-01-24 07:51:30.566176!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0375
7. set (Dataset 2) being trained for epoch 46 by 2019-01-24 07:51:45.918852!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
8. set (Dataset 6) being trained for epoch 46 by 2019-01-24 07:52:00.442526!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0486
9. set (Dataset 7) being trained for epoch 46 by 2019-01-24 07:52:17.558144!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
10. set (Dataset 12) being trained for epoch 46 by 2019-01-24 07:52:38.547666!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.7204e-04 - mean_absolute_error: 0.0228
11. set (Dataset 18) being trained for epoch 46 by 2019-01-24 07:52:57.436994!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0025 - mean_absolute_error: 0.0389
12. set (Dataset 19) being trained for epoch 46 by 2019-01-24 07:53:13.768823!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0403
13. set (Dataset 11) being trained for epoch 46 by 2019-01-24 07:53:28.506046!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0260
14. set (Dataset 16) being trained for epoch 46 by 2019-01-24 07:53:47.639682!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0296
15. set (Dataset 21) being trained for epoch 46 by 2019-01-24 07:54:10.579688!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0383
16. set (Dataset 20) being trained for epoch 46 by 2019-01-24 07:54:27.636776!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0305
17. set (Dataset 24) being trained for epoch 46 by 2019-01-24 07:54:42.441437!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
18. set (Dataset 15) being trained for epoch 46 by 2019-01-24 07:54:57.652055!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0365
19. set (Dataset 13) being trained for epoch 46 by 2019-01-24 07:55:14.105676!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
20. set (Dataset 22) being trained for epoch 46 by 2019-01-24 07:55:29.311841!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0326
Epoch 46 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 07:55:45.641229
1. set (Dataset 15) being trained for epoch 47 by 2019-01-24 07:55:51.940765!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
2. set (Dataset 22) being trained for epoch 47 by 2019-01-24 07:56:10.248644!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0314
3. set (Dataset 18) being trained for epoch 47 by 2019-01-24 07:56:27.952628!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0371
4. set (Dataset 21) being trained for epoch 47 by 2019-01-24 07:56:45.142478!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0378
5. set (Dataset 23) being trained for epoch 47 by 2019-01-24 07:57:01.958420!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0367
6. set (Dataset 13) being trained for epoch 47 by 2019-01-24 07:57:17.326322!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0250
7. set (Dataset 24) being trained for epoch 47 by 2019-01-24 07:57:30.775377!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0266
8. set (Dataset 19) being trained for epoch 47 by 2019-01-24 07:57:44.470604!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0395
9. set (Dataset 8) being trained for epoch 47 by 2019-01-24 07:58:01.103157!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
10. set (Dataset 7) being trained for epoch 47 by 2019-01-24 07:58:22.570511!
Epoch 1/1
745/745 [==============================] - 13s 17ms/step - loss: 0.0010 - mean_absolute_error: 0.0249
11. set (Dataset 2) being trained for epoch 47 by 2019-01-24 07:58:40.678217!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0263
12. set (Dataset 4) being trained for epoch 47 by 2019-01-24 07:58:57.271391!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
13. set (Dataset 16) being trained for epoch 47 by 2019-01-24 07:59:19.144909!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0307
14. set (Dataset 1) being trained for epoch 47 by 2019-01-24 07:59:40.322641!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0354
15. set (Dataset 17) being trained for epoch 47 by 2019-01-24 07:59:53.191582!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0327
16. set (Dataset 20) being trained for epoch 47 by 2019-01-24 08:00:05.621419!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0308
17. set (Dataset 11) being trained for epoch 47 by 2019-01-24 08:00:21.275532!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.5873e-04 - mean_absolute_error: 0.0228
18. set (Dataset 10) being trained for epoch 47 by 2019-01-24 08:00:38.752899!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0293
19. set (Dataset 12) being trained for epoch 47 by 2019-01-24 08:00:59.300438!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.6064e-04 - mean_absolute_error: 0.0225
20. set (Dataset 6) being trained for epoch 47 by 2019-01-24 08:01:17.557893!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0491
Epoch 47 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 08:01:31.779649
1. set (Dataset 10) being trained for epoch 48 by 2019-01-24 08:01:38.956617!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0274
2. set (Dataset 6) being trained for epoch 48 by 2019-01-24 08:01:57.299952!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0465
3. set (Dataset 2) being trained for epoch 48 by 2019-01-24 08:02:12.109810!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
4. set (Dataset 17) being trained for epoch 48 by 2019-01-24 08:02:25.041773!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0334
5. set (Dataset 13) being trained for epoch 48 by 2019-01-24 08:02:36.989739!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0260
6. set (Dataset 12) being trained for epoch 48 by 2019-01-24 08:02:52.938526!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 8.8659e-04 - mean_absolute_error: 0.0232
7. set (Dataset 11) being trained for epoch 48 by 2019-01-24 08:03:12.365141!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 9.2742e-04 - mean_absolute_error: 0.0236
8. set (Dataset 4) being trained for epoch 48 by 2019-01-24 08:03:29.710230!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0274
9. set (Dataset 23) being trained for epoch 48 by 2019-01-24 08:03:48.762869!
Epoch 1/1
569/569 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0380
10. set (Dataset 8) being trained for epoch 48 by 2019-01-24 08:04:06.995562!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
11. set (Dataset 24) being trained for epoch 48 by 2019-01-24 08:04:25.970274!
Epoch 1/1
492/492 [==============================] - 8s 17ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
12. set (Dataset 15) being trained for epoch 48 by 2019-01-24 08:04:40.833134!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0362
13. set (Dataset 1) being trained for epoch 48 by 2019-01-24 08:04:57.895277!
Epoch 1/1
498/498 [==============================] - 9s 17ms/step - loss: 0.0028 - mean_absolute_error: 0.0368
14. set (Dataset 22) being trained for epoch 48 by 2019-01-24 08:05:12.976843!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0321
15. set (Dataset 18) being trained for epoch 48 by 2019-01-24 08:05:31.022608!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
16. set (Dataset 20) being trained for epoch 48 by 2019-01-24 08:05:47.297293!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0303
17. set (Dataset 16) being trained for epoch 48 by 2019-01-24 08:06:06.525490!
Epoch 1/1
914/914 [==============================] - 16s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0298
18. set (Dataset 21) being trained for epoch 48 by 2019-01-24 08:06:28.549486!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0378
19. set (Dataset 7) being trained for epoch 48 by 2019-01-24 08:06:47.670743!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
20. set (Dataset 19) being trained for epoch 48 by 2019-01-24 08:07:06.388301!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0406
Epoch 48 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 08:07:19.795303
1. set (Dataset 21) being trained for epoch 49 by 2019-01-24 08:07:25.746898!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
2. set (Dataset 19) being trained for epoch 49 by 2019-01-24 08:07:42.369667!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0390
3. set (Dataset 24) being trained for epoch 49 by 2019-01-24 08:07:55.977624!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
4. set (Dataset 18) being trained for epoch 49 by 2019-01-24 08:08:10.584871!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
5. set (Dataset 12) being trained for epoch 49 by 2019-01-24 08:08:28.899846!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.9201e-04 - mean_absolute_error: 0.0246
6. set (Dataset 7) being trained for epoch 49 by 2019-01-24 08:08:49.647073!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.9684e-04 - mean_absolute_error: 0.0232
7. set (Dataset 16) being trained for epoch 49 by 2019-01-24 08:09:11.800717!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0299
8. set (Dataset 15) being trained for epoch 49 by 2019-01-24 08:09:34.879386!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0346
9. set (Dataset 13) being trained for epoch 49 by 2019-01-24 08:09:51.241978!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0259
10. set (Dataset 23) being trained for epoch 49 by 2019-01-24 08:10:05.570228!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0382
11. set (Dataset 11) being trained for epoch 49 by 2019-01-24 08:10:21.442420!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.5300e-04 - mean_absolute_error: 0.0241
12. set (Dataset 10) being trained for epoch 49 by 2019-01-24 08:10:38.735123!
Epoch 1/1
726/726 [==============================] - 13s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
13. set (Dataset 22) being trained for epoch 49 by 2019-01-24 08:10:58.554680!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0338
14. set (Dataset 6) being trained for epoch 49 by 2019-01-24 08:11:15.578426!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0471
15. set (Dataset 2) being trained for epoch 49 by 2019-01-24 08:11:30.341305!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
16. set (Dataset 20) being trained for epoch 49 by 2019-01-24 08:11:45.032559!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0296
17. set (Dataset 1) being trained for epoch 49 by 2019-01-24 08:12:00.177286!
Epoch 1/1
498/498 [==============================] - 9s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0346
18. set (Dataset 17) being trained for epoch 49 by 2019-01-24 08:12:12.626751!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0347
19. set (Dataset 8) being trained for epoch 49 by 2019-01-24 08:12:27.351488!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0290
20. set (Dataset 4) being trained for epoch 49 by 2019-01-24 08:12:48.530750!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
Epoch 49 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 08:13:06.369551
1. set (Dataset 17) being trained for epoch 50 by 2019-01-24 08:13:10.060627!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
2. set (Dataset 4) being trained for epoch 50 by 2019-01-24 08:13:24.710535!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 9.9254e-04 - mean_absolute_error: 0.0245
3. set (Dataset 11) being trained for epoch 50 by 2019-01-24 08:13:44.323442!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.7994e-04 - mean_absolute_error: 0.0228
4. set (Dataset 2) being trained for epoch 50 by 2019-01-24 08:13:59.575187!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
5. set (Dataset 7) being trained for epoch 50 by 2019-01-24 08:14:16.364527!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0250
6. set (Dataset 8) being trained for epoch 50 by 2019-01-24 08:14:37.691300!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
7. set (Dataset 1) being trained for epoch 50 by 2019-01-24 08:14:56.746539!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0358
8. set (Dataset 10) being trained for epoch 50 by 2019-01-24 08:15:12.916000!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
9. set (Dataset 12) being trained for epoch 50 by 2019-01-24 08:15:33.364179!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.1772e-04 - mean_absolute_error: 0.0231
10. set (Dataset 13) being trained for epoch 50 by 2019-01-24 08:15:51.250782!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0249
11. set (Dataset 16) being trained for epoch 50 by 2019-01-24 08:16:08.725115!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0297
12. set (Dataset 21) being trained for epoch 50 by 2019-01-24 08:16:31.374591!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0387
13. set (Dataset 6) being trained for epoch 50 by 2019-01-24 08:16:47.906825!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0457
14. set (Dataset 19) being trained for epoch 50 by 2019-01-24 08:17:02.687849!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0037 - mean_absolute_error: 0.0415
15. set (Dataset 24) being trained for epoch 50 by 2019-01-24 08:17:16.668035!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0281
16. set (Dataset 20) being trained for epoch 50 by 2019-01-24 08:17:30.757686!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0310
17. set (Dataset 22) being trained for epoch 50 by 2019-01-24 08:17:47.528685!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0334
18. set (Dataset 18) being trained for epoch 50 by 2019-01-24 08:18:05.413626!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0370
19. set (Dataset 23) being trained for epoch 50 by 2019-01-24 08:18:22.234277!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0363
20. set (Dataset 15) being trained for epoch 50 by 2019-01-24 08:18:38.853870!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0344
Epoch 50 completed!
Exp2019-01-24_03-29-04.h5 has been saved.
The subjects are trained: [(17, 'M10'), (4, 'F04'), (11, 'M05'), (2, 'F02'), (7, 'M01'), (8, 'M02'), (1, 'F01'), (10,
 'M04'), (12, 'M06'), (13, 'M07'), (16, 'M09'), (21, 'F02'), (6, 'F06'), (19, 'M11'), (24, 'M14'), (20, 'M12'), (22,
'M01'), (18, 'F05'), (23, 'M13'), (15, 'F03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_2
019-01-24_03-29-04
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-24 08:18:52.847218
For the Subject 3 (F03):
730/730 [==============================] - 7s 9ms/step
        The absolute mean error on Pitch angle estimation: 13.47 Degree
        The absolute mean error on Yaw angle estimation: 21.05 Degree
        The absolute mean error on Roll angle estimation: 6.74 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Pitch angle estimation: 9.76 Degree
        The absolute mean error on Yaw angle estimation: 32.72 Degree
        The absolute mean error on Roll angle estimation: 5.61 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 13.98 Degree
        The absolute mean error on Yaw angle estimation: 21.24 Degree
        The absolute mean error on Roll angle estimation: 9.58 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 19.86 Degree
        The absolute mean error on Yaw angle estimation: 34.57 Degree
        The absolute mean error on Roll angle estimation: 12.31 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 14.27 Degree
        The absolute mean error on Yaw angle estimations: 27.39 Degree
        The absolute mean error on Roll angle estimations: 8.56 Degree
subject3_Exp2019-01-24_03-29-04.png has been saved by 2019-01-24 08:20:00.039986.
subject5_Exp2019-01-24_03-29-04.png has been saved by 2019-01-24 08:20:00.243837.
subject9_Exp2019-01-24_03-29-04.png has been saved by 2019-01-24 08:20:00.447956.
subject14_Exp2019-01-24_03-29-04.png has been saved by 2019-01-24 08:20:00.670212.
Model Exp2019-01-24_03-29-04 has been evaluated successfully.
Model Exp2019-01-24_03-29-04 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-24_03-29-04 trainMore
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 19:28:42.662339: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 19:28:42.758673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 19:28:42.758930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 19:28:42.758942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 19:28:42.915069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 19:28:42.915094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 19:28:42.915098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 19:28:42.915236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-24_03-29-04.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

Training model Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43
All frames and annotations from 20 datasets have been read by 2019-01-24 19:28:48.285270
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 19:28:54.694174!
Epoch 1/1
665/665 [==============================] - 14s 20ms/step - loss: 0.0018 - mean_absolute_error: 0.0306
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 19:29:13.052050!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 19:29:28.240241!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0337
4. set (Dataset 19) being trained for epoch 1 by 2019-01-24 19:29:44.823240!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0395
5. set (Dataset 8) being trained for epoch 1 by 2019-01-24 19:30:01.876514!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
6. set (Dataset 23) being trained for epoch 1 by 2019-01-24 19:30:21.135740!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0370
7. set (Dataset 21) being trained for epoch 1 by 2019-01-24 19:30:37.787977!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0397
8. set (Dataset 16) being trained for epoch 1 by 2019-01-24 19:30:58.113566!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0292
9. set (Dataset 7) being trained for epoch 1 by 2019-01-24 19:31:22.078451!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0248
10. set (Dataset 12) being trained for epoch 1 by 2019-01-24 19:31:42.964253!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.6534e-04 - mean_absolute_error: 0.0231
11. set (Dataset 10) being trained for epoch 1 by 2019-01-24 19:32:03.323711!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0292
12. set (Dataset 1) being trained for epoch 1 by 2019-01-24 19:32:21.418583!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0331
13. set (Dataset 18) being trained for epoch 1 by 2019-01-24 19:32:36.320757!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0025 - mean_absolute_error: 0.0383
14. set (Dataset 2) being trained for epoch 1 by 2019-01-24 19:32:52.845410!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0268
15. set (Dataset 4) being trained for epoch 1 by 2019-01-24 19:33:09.428163!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0263
16. set (Dataset 20) being trained for epoch 1 by 2019-01-24 19:33:28.391768!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
17. set (Dataset 17) being trained for epoch 1 by 2019-01-24 19:33:42.456725!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
18. set (Dataset 6) being trained for epoch 1 by 2019-01-24 19:33:54.858187!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0449
19. set (Dataset 13) being trained for epoch 1 by 2019-01-24 19:34:09.578550!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0263
20. set (Dataset 11) being trained for epoch 1 by 2019-01-24 19:34:23.950687!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.8987e-04 - mean_absolute_error: 0.0234
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 19:34:38.816083
1. set (Dataset 6) being trained for epoch 2 by 2019-01-24 19:34:44.006653!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0451
2. set (Dataset 11) being trained for epoch 2 by 2019-01-24 19:34:59.772207!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.8185e-04 - mean_absolute_error: 0.0232
3. set (Dataset 10) being trained for epoch 2 by 2019-01-24 19:35:17.220867!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0299
4. set (Dataset 4) being trained for epoch 2 by 2019-01-24 19:35:37.782333!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0275
5. set (Dataset 23) being trained for epoch 2 by 2019-01-24 19:35:57.087519!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0383
6. set (Dataset 13) being trained for epoch 2 by 2019-01-24 19:36:12.197544!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 8.6599e-04 - mean_absolute_error: 0.0228
7. set (Dataset 17) being trained for epoch 2 by 2019-01-24 19:36:24.787611!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0323
8. set (Dataset 1) being trained for epoch 2 by 2019-01-24 19:36:37.082634!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0366
9. set (Dataset 8) being trained for epoch 2 by 2019-01-24 19:36:53.764912!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
10. set (Dataset 7) being trained for epoch 2 by 2019-01-24 19:37:15.145825!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.1588e-04 - mean_absolute_error: 0.0234
11. set (Dataset 21) being trained for epoch 2 by 2019-01-24 19:37:34.606029!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0389
12. set (Dataset 22) being trained for epoch 2 by 2019-01-24 19:37:52.565267!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0315
13. set (Dataset 2) being trained for epoch 2 by 2019-01-24 19:38:09.681750!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0261
14. set (Dataset 24) being trained for epoch 2 by 2019-01-24 19:38:23.494749!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
15. set (Dataset 15) being trained for epoch 2 by 2019-01-24 19:38:38.687054!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0346
16. set (Dataset 20) being trained for epoch 2 by 2019-01-24 19:38:55.869959!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0300
17. set (Dataset 18) being trained for epoch 2 by 2019-01-24 19:39:11.841842!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0353
18. set (Dataset 19) being trained for epoch 2 by 2019-01-24 19:39:27.939085!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0405
19. set (Dataset 12) being trained for epoch 2 by 2019-01-24 19:39:44.232117!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
20. set (Dataset 16) being trained for epoch 2 by 2019-01-24 19:40:06.357387!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0312
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 19:40:27.285346
1. set (Dataset 19) being trained for epoch 3 by 2019-01-24 19:40:32.162864!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0400
2. set (Dataset 16) being trained for epoch 3 by 2019-01-24 19:40:50.153304!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0277
3. set (Dataset 21) being trained for epoch 3 by 2019-01-24 19:41:12.602956!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0367
4. set (Dataset 15) being trained for epoch 3 by 2019-01-24 19:41:30.456403!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0337
5. set (Dataset 13) being trained for epoch 3 by 2019-01-24 19:41:47.431400!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0269
6. set (Dataset 12) being trained for epoch 3 by 2019-01-24 19:42:03.623976!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 8.1176e-04 - mean_absolute_error: 0.0224
7. set (Dataset 18) being trained for epoch 3 by 2019-01-24 19:42:23.150212!
Epoch 1/1
614/614 [==============================] - 12s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0360
8. set (Dataset 22) being trained for epoch 3 by 2019-01-24 19:42:41.177698!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0313
9. set (Dataset 23) being trained for epoch 3 by 2019-01-24 19:42:58.846763!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0350
10. set (Dataset 8) being trained for epoch 3 by 2019-01-24 19:43:16.949087!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
11. set (Dataset 17) being trained for epoch 3 by 2019-01-24 19:43:34.600046!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0018 - mean_absolute_error: 0.0331
12. set (Dataset 6) being trained for epoch 3 by 2019-01-24 19:43:47.273070!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0043 - mean_absolute_error: 0.0461
13. set (Dataset 24) being trained for epoch 3 by 2019-01-24 19:44:02.186420!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0260
14. set (Dataset 11) being trained for epoch 3 by 2019-01-24 19:44:16.830152!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.5223e-04 - mean_absolute_error: 0.0231
15. set (Dataset 10) being trained for epoch 3 by 2019-01-24 19:44:34.324142!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
16. set (Dataset 20) being trained for epoch 3 by 2019-01-24 19:44:53.090476!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0309
17. set (Dataset 2) being trained for epoch 3 by 2019-01-24 19:45:08.471111!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0282
18. set (Dataset 4) being trained for epoch 3 by 2019-01-24 19:45:25.060599!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
19. set (Dataset 7) being trained for epoch 3 by 2019-01-24 19:45:45.989808!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0250
20. set (Dataset 1) being trained for epoch 3 by 2019-01-24 19:46:04.484196!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0326
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 19:46:17.738348
1. set (Dataset 4) being trained for epoch 4 by 2019-01-24 19:46:25.155571!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0266
2. set (Dataset 1) being trained for epoch 4 by 2019-01-24 19:46:43.633776!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0303
3. set (Dataset 17) being trained for epoch 4 by 2019-01-24 19:46:56.738743!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0330
4. set (Dataset 10) being trained for epoch 4 by 2019-01-24 19:47:11.135830!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0275
5. set (Dataset 12) being trained for epoch 4 by 2019-01-24 19:47:31.493310!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.2903e-04 - mean_absolute_error: 0.0223
6. set (Dataset 7) being trained for epoch 4 by 2019-01-24 19:47:52.268794!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.7608e-04 - mean_absolute_error: 0.0228
7. set (Dataset 2) being trained for epoch 4 by 2019-01-24 19:48:10.744610!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
8. set (Dataset 6) being trained for epoch 4 by 2019-01-24 19:48:25.128754!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0488
9. set (Dataset 13) being trained for epoch 4 by 2019-01-24 19:48:39.725405!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
10. set (Dataset 23) being trained for epoch 4 by 2019-01-24 19:48:54.070334!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0362
11. set (Dataset 18) being trained for epoch 4 by 2019-01-24 19:49:10.575862!
Epoch 1/1
614/614 [==============================] - 11s 17ms/step - loss: 0.0022 - mean_absolute_error: 0.0357
12. set (Dataset 19) being trained for epoch 4 by 2019-01-24 19:49:26.238468!
Epoch 1/1
502/502 [==============================] - 10s 19ms/step - loss: 0.0035 - mean_absolute_error: 0.0404
13. set (Dataset 11) being trained for epoch 4 by 2019-01-24 19:49:41.520376!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 9.2725e-04 - mean_absolute_error: 0.0237
14. set (Dataset 16) being trained for epoch 4 by 2019-01-24 19:50:01.038882!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0298
15. set (Dataset 21) being trained for epoch 4 by 2019-01-24 19:50:23.247880!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0025 - mean_absolute_error: 0.0379
16. set (Dataset 20) being trained for epoch 4 by 2019-01-24 19:50:40.531072!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
17. set (Dataset 24) being trained for epoch 4 by 2019-01-24 19:50:55.262603!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
18. set (Dataset 15) being trained for epoch 4 by 2019-01-24 19:51:11.034321!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0357
19. set (Dataset 8) being trained for epoch 4 by 2019-01-24 19:51:30.437562!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0295
20. set (Dataset 22) being trained for epoch 4 by 2019-01-24 19:51:50.777594!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0318
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 19:52:07.411844
1. set (Dataset 15) being trained for epoch 5 by 2019-01-24 19:52:13.766758!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0343
2. set (Dataset 22) being trained for epoch 5 by 2019-01-24 19:52:31.952289!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0292
3. set (Dataset 18) being trained for epoch 5 by 2019-01-24 19:52:50.064140!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0350
4. set (Dataset 21) being trained for epoch 5 by 2019-01-24 19:53:07.110989!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0357
5. set (Dataset 7) being trained for epoch 5 by 2019-01-24 19:53:26.133174!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
6. set (Dataset 8) being trained for epoch 5 by 2019-01-24 19:53:47.151046!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0272
7. set (Dataset 24) being trained for epoch 5 by 2019-01-24 19:54:05.628777!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0260
8. set (Dataset 19) being trained for epoch 5 by 2019-01-24 19:54:19.636201!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0395
9. set (Dataset 12) being trained for epoch 5 by 2019-01-24 19:54:35.775749!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.4527e-04 - mean_absolute_error: 0.0228
10. set (Dataset 13) being trained for epoch 5 by 2019-01-24 19:54:54.014478!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
11. set (Dataset 2) being trained for epoch 5 by 2019-01-24 19:55:07.939971!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
12. set (Dataset 4) being trained for epoch 5 by 2019-01-24 19:55:24.521338!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0261
13. set (Dataset 16) being trained for epoch 5 by 2019-01-24 19:55:46.595638!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0298
14. set (Dataset 1) being trained for epoch 5 by 2019-01-24 19:56:07.768093!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0331
15. set (Dataset 17) being trained for epoch 5 by 2019-01-24 19:56:20.477278!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0373
16. set (Dataset 20) being trained for epoch 5 by 2019-01-24 19:56:32.880522!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0304
17. set (Dataset 11) being trained for epoch 5 by 2019-01-24 19:56:48.578195!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 8.6229e-04 - mean_absolute_error: 0.0226
18. set (Dataset 10) being trained for epoch 5 by 2019-01-24 19:57:06.547681!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0272
19. set (Dataset 23) being trained for epoch 5 by 2019-01-24 19:57:25.116239!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0369
20. set (Dataset 6) being trained for epoch 5 by 2019-01-24 19:57:41.004678!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0461
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 19:57:55.077243
1. set (Dataset 10) being trained for epoch 6 by 2019-01-24 19:58:02.320686!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
2. set (Dataset 6) being trained for epoch 6 by 2019-01-24 19:58:20.822741!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0038 - mean_absolute_error: 0.0438
3. set (Dataset 2) being trained for epoch 6 by 2019-01-24 19:58:36.159191!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0270
4. set (Dataset 17) being trained for epoch 6 by 2019-01-24 19:58:49.403418!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0340
5. set (Dataset 8) being trained for epoch 6 by 2019-01-24 19:59:04.285844!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0015 - mean_absolute_error: 0.0300
6. set (Dataset 23) being trained for epoch 6 by 2019-01-24 19:59:24.216171!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0365
7. set (Dataset 11) being trained for epoch 6 by 2019-01-24 19:59:40.139662!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.6783e-04 - mean_absolute_error: 0.0230
8. set (Dataset 4) being trained for epoch 6 by 2019-01-24 19:59:57.805518!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
9. set (Dataset 7) being trained for epoch 6 by 2019-01-24 20:00:18.676766!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
10. set (Dataset 12) being trained for epoch 6 by 2019-01-24 20:00:39.348545!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 7.7089e-04 - mean_absolute_error: 0.0216
11. set (Dataset 24) being trained for epoch 6 by 2019-01-24 20:00:57.178720!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0282
12. set (Dataset 15) being trained for epoch 6 by 2019-01-24 20:01:12.356411!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0359
13. set (Dataset 1) being trained for epoch 6 by 2019-01-24 20:01:29.223493!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0328
14. set (Dataset 22) being trained for epoch 6 by 2019-01-24 20:01:44.614739!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0024 - mean_absolute_error: 0.0346
15. set (Dataset 18) being trained for epoch 6 by 2019-01-24 20:02:02.861115!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0361
16. set (Dataset 20) being trained for epoch 6 by 2019-01-24 20:02:19.280748!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
17. set (Dataset 16) being trained for epoch 6 by 2019-01-24 20:02:38.032795!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0284
18. set (Dataset 21) being trained for epoch 6 by 2019-01-24 20:03:00.523193!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0386
19. set (Dataset 13) being trained for epoch 6 by 2019-01-24 20:03:17.044088!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
20. set (Dataset 19) being trained for epoch 6 by 2019-01-24 20:03:30.613009!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0392
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:03:44.219672
1. set (Dataset 21) being trained for epoch 7 by 2019-01-24 20:03:50.223875!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0353
2. set (Dataset 19) being trained for epoch 7 by 2019-01-24 20:04:06.657667!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0376
3. set (Dataset 24) being trained for epoch 7 by 2019-01-24 20:04:20.635169!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
4. set (Dataset 18) being trained for epoch 7 by 2019-01-24 20:04:35.320796!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0354
5. set (Dataset 23) being trained for epoch 7 by 2019-01-24 20:04:51.790452!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0343
6. set (Dataset 13) being trained for epoch 7 by 2019-01-24 20:05:06.825796!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0248
7. set (Dataset 16) being trained for epoch 7 by 2019-01-24 20:05:24.236410!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0287
8. set (Dataset 15) being trained for epoch 7 by 2019-01-24 20:05:47.498751!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0344
9. set (Dataset 8) being trained for epoch 7 by 2019-01-24 20:06:06.857888!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
10. set (Dataset 7) being trained for epoch 7 by 2019-01-24 20:06:28.650595!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 9.0373e-04 - mean_absolute_error: 0.0235
11. set (Dataset 11) being trained for epoch 7 by 2019-01-24 20:06:48.302020!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 9.0556e-04 - mean_absolute_error: 0.0234
12. set (Dataset 10) being trained for epoch 7 by 2019-01-24 20:07:06.251319!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0279
13. set (Dataset 22) being trained for epoch 7 by 2019-01-24 20:07:26.049389!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0308
14. set (Dataset 6) being trained for epoch 7 by 2019-01-24 20:07:43.493105!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0469
15. set (Dataset 2) being trained for epoch 7 by 2019-01-24 20:07:58.600475!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
16. set (Dataset 20) being trained for epoch 7 by 2019-01-24 20:08:13.187116!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0288
17. set (Dataset 1) being trained for epoch 7 by 2019-01-24 20:08:28.444292!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0348
18. set (Dataset 17) being trained for epoch 7 by 2019-01-24 20:08:41.131107!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0317
19. set (Dataset 12) being trained for epoch 7 by 2019-01-24 20:08:55.707021!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.2911e-04 - mean_absolute_error: 0.0222
20. set (Dataset 4) being trained for epoch 7 by 2019-01-24 20:09:16.306098!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0273
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:09:34.370184
1. set (Dataset 17) being trained for epoch 8 by 2019-01-24 20:09:38.129813!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0313
2. set (Dataset 4) being trained for epoch 8 by 2019-01-24 20:09:52.849191!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
3. set (Dataset 11) being trained for epoch 8 by 2019-01-24 20:10:12.190291!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.2402e-04 - mean_absolute_error: 0.0223
4. set (Dataset 2) being trained for epoch 8 by 2019-01-24 20:10:27.697838!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
5. set (Dataset 13) being trained for epoch 8 by 2019-01-24 20:10:41.715110!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.2975e-04 - mean_absolute_error: 0.0234
6. set (Dataset 12) being trained for epoch 8 by 2019-01-24 20:10:57.746625!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.6334e-04 - mean_absolute_error: 0.0230
7. set (Dataset 1) being trained for epoch 8 by 2019-01-24 20:11:16.104854!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0342
8. set (Dataset 10) being trained for epoch 8 by 2019-01-24 20:11:32.308196!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
9. set (Dataset 23) being trained for epoch 8 by 2019-01-24 20:11:50.791620!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0371
10. set (Dataset 8) being trained for epoch 8 by 2019-01-24 20:12:08.736456!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0264
11. set (Dataset 16) being trained for epoch 8 by 2019-01-24 20:12:31.595036!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0286
12. set (Dataset 21) being trained for epoch 8 by 2019-01-24 20:12:53.955602!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0368
13. set (Dataset 6) being trained for epoch 8 by 2019-01-24 20:13:10.623200!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0447
14. set (Dataset 19) being trained for epoch 8 by 2019-01-24 20:13:25.161192!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0036 - mean_absolute_error: 0.0411
15. set (Dataset 24) being trained for epoch 8 by 2019-01-24 20:13:39.268856!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0268
16. set (Dataset 20) being trained for epoch 8 by 2019-01-24 20:13:54.061735!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
17. set (Dataset 22) being trained for epoch 8 by 2019-01-24 20:14:10.804254!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0312
18. set (Dataset 18) being trained for epoch 8 by 2019-01-24 20:14:28.596325!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0357
19. set (Dataset 7) being trained for epoch 8 by 2019-01-24 20:14:47.115177!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
20. set (Dataset 15) being trained for epoch 8 by 2019-01-24 20:15:06.745290!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:15:23.225694
1. set (Dataset 18) being trained for epoch 9 by 2019-01-24 20:15:29.099242!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0020 - mean_absolute_error: 0.0346
2. set (Dataset 15) being trained for epoch 9 by 2019-01-24 20:15:46.854840!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0325
3. set (Dataset 16) being trained for epoch 9 by 2019-01-24 20:16:07.512440!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0286
4. set (Dataset 24) being trained for epoch 9 by 2019-01-24 20:16:28.889245!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
5. set (Dataset 12) being trained for epoch 9 by 2019-01-24 20:16:44.916216!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0245
6. set (Dataset 7) being trained for epoch 9 by 2019-01-24 20:17:05.565207!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 9.2393e-04 - mean_absolute_error: 0.0240
7. set (Dataset 22) being trained for epoch 9 by 2019-01-24 20:17:25.569670!
Epoch 1/1
665/665 [==============================] - 11s 17ms/step - loss: 0.0020 - mean_absolute_error: 0.0322
8. set (Dataset 21) being trained for epoch 9 by 2019-01-24 20:17:43.049369!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0377
9. set (Dataset 13) being trained for epoch 9 by 2019-01-24 20:17:59.351600!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.3086e-04 - mean_absolute_error: 0.0238
10. set (Dataset 23) being trained for epoch 9 by 2019-01-24 20:18:13.525235!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
11. set (Dataset 1) being trained for epoch 9 by 2019-01-24 20:18:28.779059!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0321
12. set (Dataset 17) being trained for epoch 9 by 2019-01-24 20:18:41.770502!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
13. set (Dataset 19) being trained for epoch 9 by 2019-01-24 20:18:54.118955!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0382
14. set (Dataset 4) being trained for epoch 9 by 2019-01-24 20:19:10.665234!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0272
15. set (Dataset 11) being trained for epoch 9 by 2019-01-24 20:19:29.965423!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 8.1962e-04 - mean_absolute_error: 0.0223
16. set (Dataset 20) being trained for epoch 9 by 2019-01-24 20:19:46.012551!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
17. set (Dataset 6) being trained for epoch 9 by 2019-01-24 20:20:01.106012!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0459
18. set (Dataset 2) being trained for epoch 9 by 2019-01-24 20:20:15.882771!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
19. set (Dataset 8) being trained for epoch 9 by 2019-01-24 20:20:32.751274!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0285
20. set (Dataset 10) being trained for epoch 9 by 2019-01-24 20:20:54.390459!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
Epoch 9 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:21:11.988222
1. set (Dataset 2) being trained for epoch 10 by 2019-01-24 20:21:17.065145!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0248
2. set (Dataset 10) being trained for epoch 10 by 2019-01-24 20:21:33.392181!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 9.3707e-04 - mean_absolute_error: 0.0238
3. set (Dataset 1) being trained for epoch 10 by 2019-01-24 20:21:51.615056!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0334
4. set (Dataset 11) being trained for epoch 10 by 2019-01-24 20:22:06.789873!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.1105e-04 - mean_absolute_error: 0.0223
5. set (Dataset 7) being trained for epoch 10 by 2019-01-24 20:22:24.839305!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.2108e-04 - mean_absolute_error: 0.0235
6. set (Dataset 8) being trained for epoch 10 by 2019-01-24 20:22:45.892459!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
7. set (Dataset 6) being trained for epoch 10 by 2019-01-24 20:23:05.516324!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0044 - mean_absolute_error: 0.0458
8. set (Dataset 17) being trained for epoch 10 by 2019-01-24 20:23:19.400906!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
9. set (Dataset 12) being trained for epoch 10 by 2019-01-24 20:23:34.096783!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.1277e-04 - mean_absolute_error: 0.0221
10. set (Dataset 13) being trained for epoch 10 by 2019-01-24 20:23:52.092168!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 8.6747e-04 - mean_absolute_error: 0.0225
11. set (Dataset 22) being trained for epoch 10 by 2019-01-24 20:24:07.022421!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0324
12. set (Dataset 18) being trained for epoch 10 by 2019-01-24 20:24:24.890270!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0365
13. set (Dataset 4) being trained for epoch 10 by 2019-01-24 20:24:43.333133!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0264
14. set (Dataset 15) being trained for epoch 10 by 2019-01-24 20:25:03.043499!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0020 - mean_absolute_error: 0.0339
15. set (Dataset 16) being trained for epoch 10 by 2019-01-24 20:25:24.123557!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0014 - mean_absolute_error: 0.0282
16. set (Dataset 20) being trained for epoch 10 by 2019-01-24 20:25:46.526009!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0304
17. set (Dataset 19) being trained for epoch 10 by 2019-01-24 20:26:01.464534!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0035 - mean_absolute_error: 0.0397
18. set (Dataset 24) being trained for epoch 10 by 2019-01-24 20:26:15.560166!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
19. set (Dataset 23) being trained for epoch 10 by 2019-01-24 20:26:29.922622!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0356
20. set (Dataset 21) being trained for epoch 10 by 2019-01-24 20:26:46.579794!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0371
Epoch 10 completed!
Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.h5 has been saved.
The subjects are trained: [(2, 'F02'), (10, 'M04'), (1, 'F01'), (11, 'M05'), (7, 'M01'), (8, 'M02'), (6, 'F06'), (17,
 'M10'), (12, 'M06'), (13, 'M07'), (22, 'M01'), (18, 'F05'), (4, 'F04'), (15, 'F03'), (16, 'M09'), (20, 'M12'), (19,
'M11'), (24, 'M14'), (23, 'M13'), (21, 'F02')]
Evaluating model Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-24 20:27:00.168143
For the Subject 3 (F03):
730/730 [==============================] - 7s 9ms/step
        The absolute mean error on Pitch angle estimation: 15.94 Degree
        The absolute mean error on Yaw angle estimation: 25.46 Degree
        The absolute mean error on Roll angle estimation: 5.79 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Pitch angle estimation: 8.49 Degree
        The absolute mean error on Yaw angle estimation: 26.51 Degree
        The absolute mean error on Roll angle estimation: 5.16 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 12.13 Degree
        The absolute mean error on Yaw angle estimation: 23.67 Degree
        The absolute mean error on Roll angle estimation: 9.65 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 18.24 Degree
        The absolute mean error on Yaw angle estimation: 44.45 Degree
        The absolute mean error on Roll angle estimation: 10.71 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 13.70 Degree
        The absolute mean error on Yaw angle estimations: 30.02 Degree
        The absolute mean error on Roll angle estimations: 7.83 Degree
subject3_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png has been saved by 2019-01-24 20:28:05.955959.
subject5_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png has been saved by 2019-01-24 20:28:06.158999.
subject9_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png has been saved by 2019-01-24 20:28:06.363493.
subject14_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png has been saved by 2019-01-24 20:28:06.586072.
Model Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43 has been evaluated successfully.
Model Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-24_03-29-04_and_2019-01-24_19-28-43 trainMore
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 20:31:44.348975: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 20:31:44.446577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 20:31:44.446884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 20:31:44.446900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 20:31:44.603139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 20:31:44.603166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 20:31:44.603171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 20:31:44.603347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

Training model Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43_and_2019-01-24_20-31-45
All frames and annotations from 20 datasets have been read by 2019-01-24 20:31:50.220271
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 20:31:56.631172!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0312
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 20:32:14.351804!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 20:32:29.924750!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
4. set (Dataset 19) being trained for epoch 1 by 2019-01-24 20:32:46.421981!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0387
5. set (Dataset 8) being trained for epoch 1 by 2019-01-24 20:33:03.402563!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0284
6. set (Dataset 23) being trained for epoch 1 by 2019-01-24 20:33:23.080984!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0351
7. set (Dataset 21) being trained for epoch 1 by 2019-01-24 20:33:39.221523!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0356
8. set (Dataset 16) being trained for epoch 1 by 2019-01-24 20:33:59.963117!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0282
9. set (Dataset 7) being trained for epoch 1 by 2019-01-24 20:34:24.039131!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0243
10. set (Dataset 12) being trained for epoch 1 by 2019-01-24 20:34:44.759076!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.1604e-04 - mean_absolute_error: 0.0222
11. set (Dataset 10) being trained for epoch 1 by 2019-01-24 20:35:05.355978!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
12. set (Dataset 1) being trained for epoch 1 by 2019-01-24 20:35:23.876105!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0341
13. set (Dataset 18) being trained for epoch 1 by 2019-01-24 20:35:38.968438!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0376
14. set (Dataset 2) being trained for epoch 1 by 2019-01-24 20:35:55.075587!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
15. set (Dataset 4) being trained for epoch 1 by 2019-01-24 20:36:11.794186!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
16. set (Dataset 20) being trained for epoch 1 by 2019-01-24 20:36:30.564616!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0300
17. set (Dataset 17) being trained for epoch 1 by 2019-01-24 20:36:44.795399!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0349
18. set (Dataset 6) being trained for epoch 1 by 2019-01-24 20:36:57.015014!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0466
19. set (Dataset 13) being trained for epoch 1 by 2019-01-24 20:37:11.588805!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
20. set (Dataset 11) being trained for epoch 1 by 2019-01-24 20:37:26.056677!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 7.7114e-04 - mean_absolute_error: 0.0216
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:37:40.928111
1. set (Dataset 6) being trained for epoch 2 by 2019-01-24 20:37:46.116033!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0414
2. set (Dataset 11) being trained for epoch 2 by 2019-01-24 20:38:01.683565!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.3752e-04 - mean_absolute_error: 0.0223
3. set (Dataset 10) being trained for epoch 2 by 2019-01-24 20:38:19.264548!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0280
4. set (Dataset 4) being trained for epoch 2 by 2019-01-24 20:38:40.080273!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
5. set (Dataset 23) being trained for epoch 2 by 2019-01-24 20:38:59.200108!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0353
6. set (Dataset 13) being trained for epoch 2 by 2019-01-24 20:39:14.273807!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
7. set (Dataset 17) being trained for epoch 2 by 2019-01-24 20:39:26.792148!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0313
8. set (Dataset 1) being trained for epoch 2 by 2019-01-24 20:39:39.289859!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0415
9. set (Dataset 8) being trained for epoch 2 by 2019-01-24 20:39:56.062931!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
10. set (Dataset 7) being trained for epoch 2 by 2019-01-24 20:40:17.651154!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.0731e-04 - mean_absolute_error: 0.0235
11. set (Dataset 21) being trained for epoch 2 by 2019-01-24 20:40:36.962064!
Epoch 1/1
634/634 [==============================] - 11s 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0385
12. set (Dataset 22) being trained for epoch 2 by 2019-01-24 20:40:54.504568!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0300
13. set (Dataset 2) being trained for epoch 2 by 2019-01-24 20:41:11.714798!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0274
14. set (Dataset 24) being trained for epoch 2 by 2019-01-24 20:41:25.903185!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
15. set (Dataset 15) being trained for epoch 2 by 2019-01-24 20:41:41.074899!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
16. set (Dataset 20) being trained for epoch 2 by 2019-01-24 20:41:58.523892!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0309
17. set (Dataset 18) being trained for epoch 2 by 2019-01-24 20:42:14.546111!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0344
18. set (Dataset 19) being trained for epoch 2 by 2019-01-24 20:42:30.308614!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0033 - mean_absolute_error: 0.0383
19. set (Dataset 12) being trained for epoch 2 by 2019-01-24 20:42:46.359922!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0240
20. set (Dataset 16) being trained for epoch 2 by 2019-01-24 20:43:08.084225!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0297
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:43:28.798193
1. set (Dataset 19) being trained for epoch 3 by 2019-01-24 20:43:33.671664!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0372
2. set (Dataset 16) being trained for epoch 3 by 2019-01-24 20:43:51.465933!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0272
3. set (Dataset 21) being trained for epoch 3 by 2019-01-24 20:44:13.710595!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0379
4. set (Dataset 15) being trained for epoch 3 by 2019-01-24 20:44:31.429350!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
5. set (Dataset 13) being trained for epoch 3 by 2019-01-24 20:44:47.824403!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
6. set (Dataset 12) being trained for epoch 3 by 2019-01-24 20:45:03.479939!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.2216e-04 - mean_absolute_error: 0.0224
7. set (Dataset 18) being trained for epoch 3 by 2019-01-24 20:45:22.700684!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
8. set (Dataset 22) being trained for epoch 3 by 2019-01-24 20:45:40.087448!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0301
9. set (Dataset 23) being trained for epoch 3 by 2019-01-24 20:45:57.443198!
Epoch 1/1
569/569 [==============================] - 10s 17ms/step - loss: 0.0021 - mean_absolute_error: 0.0343
10. set (Dataset 8) being trained for epoch 3 by 2019-01-24 20:46:15.125518!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
11. set (Dataset 17) being trained for epoch 3 by 2019-01-24 20:46:32.861043!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0338
12. set (Dataset 6) being trained for epoch 3 by 2019-01-24 20:46:45.217560!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0441
13. set (Dataset 24) being trained for epoch 3 by 2019-01-24 20:46:59.756233!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0263
14. set (Dataset 11) being trained for epoch 3 by 2019-01-24 20:47:14.364597!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.7063e-04 - mean_absolute_error: 0.0241
15. set (Dataset 10) being trained for epoch 3 by 2019-01-24 20:47:31.895257!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0274
16. set (Dataset 20) being trained for epoch 3 by 2019-01-24 20:47:50.458002!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0299
17. set (Dataset 2) being trained for epoch 3 by 2019-01-24 20:48:05.665272!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
18. set (Dataset 4) being trained for epoch 3 by 2019-01-24 20:48:22.298871!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0272
19. set (Dataset 7) being trained for epoch 3 by 2019-01-24 20:48:43.396848!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 9.0721e-04 - mean_absolute_error: 0.0232
20. set (Dataset 1) being trained for epoch 3 by 2019-01-24 20:49:02.187478!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0346
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:49:15.595174
1. set (Dataset 4) being trained for epoch 4 by 2019-01-24 20:49:22.969440!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
2. set (Dataset 1) being trained for epoch 4 by 2019-01-24 20:49:41.213475!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0280
3. set (Dataset 17) being trained for epoch 4 by 2019-01-24 20:49:54.358449!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0327
4. set (Dataset 10) being trained for epoch 4 by 2019-01-24 20:50:08.690779!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0266
5. set (Dataset 12) being trained for epoch 4 by 2019-01-24 20:50:29.130938!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.3662e-04 - mean_absolute_error: 0.0222
6. set (Dataset 7) being trained for epoch 4 by 2019-01-24 20:50:50.210903!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 9.2035e-04 - mean_absolute_error: 0.0235
7. set (Dataset 2) being trained for epoch 4 by 2019-01-24 20:51:09.112658!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
8. set (Dataset 6) being trained for epoch 4 by 2019-01-24 20:51:23.642860!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0462
9. set (Dataset 13) being trained for epoch 4 by 2019-01-24 20:51:38.355057!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 8.1383e-04 - mean_absolute_error: 0.0224
10. set (Dataset 23) being trained for epoch 4 by 2019-01-24 20:51:52.574252!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0353
11. set (Dataset 18) being trained for epoch 4 by 2019-01-24 20:52:08.828822!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0336
12. set (Dataset 19) being trained for epoch 4 by 2019-01-24 20:52:24.944989!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0385
13. set (Dataset 11) being trained for epoch 4 by 2019-01-24 20:52:39.726256!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0247
14. set (Dataset 16) being trained for epoch 4 by 2019-01-24 20:52:58.632345!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0291
15. set (Dataset 21) being trained for epoch 4 by 2019-01-24 20:53:21.036805!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0377
16. set (Dataset 20) being trained for epoch 4 by 2019-01-24 20:53:37.906402!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0288
17. set (Dataset 24) being trained for epoch 4 by 2019-01-24 20:53:52.392604!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
18. set (Dataset 15) being trained for epoch 4 by 2019-01-24 20:54:07.843665!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0336
19. set (Dataset 8) being trained for epoch 4 by 2019-01-24 20:54:27.671885!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0289
20. set (Dataset 22) being trained for epoch 4 by 2019-01-24 20:54:47.977420!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0307
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 20:55:04.900287
1. set (Dataset 15) being trained for epoch 5 by 2019-01-24 20:55:11.238818!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0339
2. set (Dataset 22) being trained for epoch 5 by 2019-01-24 20:55:29.483219!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0297
3. set (Dataset 18) being trained for epoch 5 by 2019-01-24 20:55:47.529821!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0343
4. set (Dataset 21) being trained for epoch 5 by 2019-01-24 20:56:04.612413!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0349
5. set (Dataset 7) being trained for epoch 5 by 2019-01-24 20:56:24.124448!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0240
6. set (Dataset 8) being trained for epoch 5 by 2019-01-24 20:56:45.527561!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0272
7. set (Dataset 24) being trained for epoch 5 by 2019-01-24 20:57:03.847741!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0254
8. set (Dataset 19) being trained for epoch 5 by 2019-01-24 20:57:18.093295!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0033 - mean_absolute_error: 0.0392
9. set (Dataset 12) being trained for epoch 5 by 2019-01-24 20:57:34.864573!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.2943e-04 - mean_absolute_error: 0.0234
10. set (Dataset 13) being trained for epoch 5 by 2019-01-24 20:57:53.019328!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.0773e-04 - mean_absolute_error: 0.0234
11. set (Dataset 2) being trained for epoch 5 by 2019-01-24 20:58:06.839662!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
12. set (Dataset 4) being trained for epoch 5 by 2019-01-24 20:58:23.516278!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
13. set (Dataset 16) being trained for epoch 5 by 2019-01-24 20:58:45.687834!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0293
14. set (Dataset 1) being trained for epoch 5 by 2019-01-24 20:59:07.426753!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0342
15. set (Dataset 17) being trained for epoch 5 by 2019-01-24 20:59:19.984549!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0320
16. set (Dataset 20) being trained for epoch 5 by 2019-01-24 20:59:32.733071!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
17. set (Dataset 11) being trained for epoch 5 by 2019-01-24 20:59:48.650154!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.1431e-04 - mean_absolute_error: 0.0219
18. set (Dataset 10) being trained for epoch 5 by 2019-01-24 21:00:06.121740!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
19. set (Dataset 23) being trained for epoch 5 by 2019-01-24 21:00:24.804222!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0360
20. set (Dataset 6) being trained for epoch 5 by 2019-01-24 21:00:40.390927!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0441
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:00:54.672355
1. set (Dataset 10) being trained for epoch 6 by 2019-01-24 21:01:01.907973!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0261
2. set (Dataset 6) being trained for epoch 6 by 2019-01-24 21:01:20.546375!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0035 - mean_absolute_error: 0.0416
3. set (Dataset 2) being trained for epoch 6 by 2019-01-24 21:01:35.729824!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
4. set (Dataset 17) being trained for epoch 6 by 2019-01-24 21:01:48.821823!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
5. set (Dataset 8) being trained for epoch 6 by 2019-01-24 21:02:03.708605!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
6. set (Dataset 23) being trained for epoch 6 by 2019-01-24 21:02:23.191701!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0343
7. set (Dataset 11) being trained for epoch 6 by 2019-01-24 21:02:38.919747!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 8.3884e-04 - mean_absolute_error: 0.0226
8. set (Dataset 4) being trained for epoch 6 by 2019-01-24 21:02:56.992214!
Epoch 1/1
744/744 [==============================] - 13s 17ms/step - loss: 0.0010 - mean_absolute_error: 0.0250
9. set (Dataset 7) being trained for epoch 6 by 2019-01-24 21:03:17.612887!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 9.6704e-04 - mean_absolute_error: 0.0241
10. set (Dataset 12) being trained for epoch 6 by 2019-01-24 21:03:38.480101!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.0003e-04 - mean_absolute_error: 0.0217
11. set (Dataset 24) being trained for epoch 6 by 2019-01-24 21:03:56.208031!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0273
12. set (Dataset 15) being trained for epoch 6 by 2019-01-24 21:04:11.390946!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0022 - mean_absolute_error: 0.0353
13. set (Dataset 1) being trained for epoch 6 by 2019-01-24 21:04:28.704174!
Epoch 1/1
498/498 [==============================] - 9s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0345
14. set (Dataset 22) being trained for epoch 6 by 2019-01-24 21:04:43.805190!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0324
15. set (Dataset 18) being trained for epoch 6 by 2019-01-24 21:05:01.692095!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0342
16. set (Dataset 20) being trained for epoch 6 by 2019-01-24 21:05:17.978944!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0294
17. set (Dataset 16) being trained for epoch 6 by 2019-01-24 21:05:36.871915!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0281
18. set (Dataset 21) being trained for epoch 6 by 2019-01-24 21:05:59.002795!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0374
19. set (Dataset 13) being trained for epoch 6 by 2019-01-24 21:06:15.567529!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
20. set (Dataset 19) being trained for epoch 6 by 2019-01-24 21:06:29.134902!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0382
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:06:42.629368
1. set (Dataset 21) being trained for epoch 7 by 2019-01-24 21:06:48.625185!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0373
2. set (Dataset 19) being trained for epoch 7 by 2019-01-24 21:07:05.098351!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0360
3. set (Dataset 24) being trained for epoch 7 by 2019-01-24 21:07:18.837107!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
4. set (Dataset 18) being trained for epoch 7 by 2019-01-24 21:07:33.510803!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0346
5. set (Dataset 23) being trained for epoch 7 by 2019-01-24 21:07:49.900774!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0347
6. set (Dataset 13) being trained for epoch 7 by 2019-01-24 21:08:05.029699!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0250
7. set (Dataset 16) being trained for epoch 7 by 2019-01-24 21:08:22.619227!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0276
8. set (Dataset 15) being trained for epoch 7 by 2019-01-24 21:08:45.202188!
Epoch 1/1
654/654 [==============================] - 11s 17ms/step - loss: 0.0018 - mean_absolute_error: 0.0328
9. set (Dataset 8) being trained for epoch 7 by 2019-01-24 21:09:04.448747!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0279
10. set (Dataset 7) being trained for epoch 7 by 2019-01-24 21:09:26.217592!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.4063e-04 - mean_absolute_error: 0.0231
11. set (Dataset 11) being trained for epoch 7 by 2019-01-24 21:09:45.423304!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.6381e-04 - mean_absolute_error: 0.0230
12. set (Dataset 10) being trained for epoch 7 by 2019-01-24 21:10:03.108265!
Epoch 1/1
726/726 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
13. set (Dataset 22) being trained for epoch 7 by 2019-01-24 21:10:23.137665!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0313
14. set (Dataset 6) being trained for epoch 7 by 2019-01-24 21:10:40.264886!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0443
15. set (Dataset 2) being trained for epoch 7 by 2019-01-24 21:10:55.075946!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
16. set (Dataset 20) being trained for epoch 7 by 2019-01-24 21:11:09.463794!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0290
17. set (Dataset 1) being trained for epoch 7 by 2019-01-24 21:11:24.802504!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0326
18. set (Dataset 17) being trained for epoch 7 by 2019-01-24 21:11:37.523801!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0314
19. set (Dataset 12) being trained for epoch 7 by 2019-01-24 21:11:52.019023!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 8.5955e-04 - mean_absolute_error: 0.0227
20. set (Dataset 4) being trained for epoch 7 by 2019-01-24 21:12:12.659700!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0272
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:12:30.239281
1. set (Dataset 17) being trained for epoch 8 by 2019-01-24 21:12:33.983893!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
2. set (Dataset 4) being trained for epoch 8 by 2019-01-24 21:12:48.715321!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 8.9928e-04 - mean_absolute_error: 0.0237
3. set (Dataset 11) being trained for epoch 8 by 2019-01-24 21:13:07.728809!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.1319e-04 - mean_absolute_error: 0.0224
4. set (Dataset 2) being trained for epoch 8 by 2019-01-24 21:13:23.220521!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0263
5. set (Dataset 13) being trained for epoch 8 by 2019-01-24 21:13:37.183335!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.3219e-04 - mean_absolute_error: 0.0237
6. set (Dataset 12) being trained for epoch 8 by 2019-01-24 21:13:53.206925!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 7.5830e-04 - mean_absolute_error: 0.0213
7. set (Dataset 1) being trained for epoch 8 by 2019-01-24 21:14:12.096207!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0323
8. set (Dataset 10) being trained for epoch 8 by 2019-01-24 21:14:28.320328!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0253
9. set (Dataset 23) being trained for epoch 8 by 2019-01-24 21:14:47.177165!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0350
10. set (Dataset 8) being trained for epoch 8 by 2019-01-24 21:15:05.130066!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0281
11. set (Dataset 16) being trained for epoch 8 by 2019-01-24 21:15:27.879626!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
12. set (Dataset 21) being trained for epoch 8 by 2019-01-24 21:15:50.415672!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0363
13. set (Dataset 6) being trained for epoch 8 by 2019-01-24 21:16:07.128483!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0038 - mean_absolute_error: 0.0431
14. set (Dataset 19) being trained for epoch 8 by 2019-01-24 21:16:22.140372!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0036 - mean_absolute_error: 0.0408
15. set (Dataset 24) being trained for epoch 8 by 2019-01-24 21:16:35.525869!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0256
16. set (Dataset 20) being trained for epoch 8 by 2019-01-24 21:16:49.781465!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
17. set (Dataset 22) being trained for epoch 8 by 2019-01-24 21:17:06.249223!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0315
18. set (Dataset 18) being trained for epoch 8 by 2019-01-24 21:17:24.135708!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
19. set (Dataset 7) being trained for epoch 8 by 2019-01-24 21:17:42.801079!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 9.9870e-04 - mean_absolute_error: 0.0241
20. set (Dataset 15) being trained for epoch 8 by 2019-01-24 21:18:02.712332!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0334
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:18:19.113780
1. set (Dataset 18) being trained for epoch 9 by 2019-01-24 21:18:24.983680!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0342
2. set (Dataset 15) being trained for epoch 9 by 2019-01-24 21:18:42.390111!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0311
3. set (Dataset 16) being trained for epoch 9 by 2019-01-24 21:19:03.230834!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0279
4. set (Dataset 24) being trained for epoch 9 by 2019-01-24 21:19:24.582004!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0248
5. set (Dataset 12) being trained for epoch 9 by 2019-01-24 21:19:40.867122!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.4090e-04 - mean_absolute_error: 0.0237
6. set (Dataset 7) being trained for epoch 9 by 2019-01-24 21:20:01.746033!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 7.8241e-04 - mean_absolute_error: 0.0217
7. set (Dataset 22) being trained for epoch 9 by 2019-01-24 21:20:21.667317!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0313
8. set (Dataset 21) being trained for epoch 9 by 2019-01-24 21:20:39.439479!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0380
9. set (Dataset 13) being trained for epoch 9 by 2019-01-24 21:20:55.549733!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.5964e-04 - mean_absolute_error: 0.0240
10. set (Dataset 23) being trained for epoch 9 by 2019-01-24 21:21:09.779127!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0336
11. set (Dataset 1) being trained for epoch 9 by 2019-01-24 21:21:25.241649!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0315
12. set (Dataset 17) being trained for epoch 9 by 2019-01-24 21:21:37.974955!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0305
13. set (Dataset 19) being trained for epoch 9 by 2019-01-24 21:21:50.186549!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0377
14. set (Dataset 4) being trained for epoch 9 by 2019-01-24 21:22:06.834158!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0261
15. set (Dataset 11) being trained for epoch 9 by 2019-01-24 21:22:26.362094!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.9228e-04 - mean_absolute_error: 0.0232
16. set (Dataset 20) being trained for epoch 9 by 2019-01-24 21:22:42.256223!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
17. set (Dataset 6) being trained for epoch 9 by 2019-01-24 21:22:57.429160!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0445
18. set (Dataset 2) being trained for epoch 9 by 2019-01-24 21:23:12.597400!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
19. set (Dataset 8) being trained for epoch 9 by 2019-01-24 21:23:29.572349!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0285
20. set (Dataset 10) being trained for epoch 9 by 2019-01-24 21:23:50.473972!
Epoch 1/1
726/726 [==============================] - 13s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0261
Epoch 9 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:24:07.624014
1. set (Dataset 2) being trained for epoch 10 by 2019-01-24 21:24:12.693918!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 9.1478e-04 - mean_absolute_error: 0.0237
2. set (Dataset 10) being trained for epoch 10 by 2019-01-24 21:24:29.208257!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 9.6323e-04 - mean_absolute_error: 0.0240
3. set (Dataset 1) being trained for epoch 10 by 2019-01-24 21:24:47.172433!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0337
4. set (Dataset 11) being trained for epoch 10 by 2019-01-24 21:25:01.933620!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 7.7623e-04 - mean_absolute_error: 0.0217
5. set (Dataset 7) being trained for epoch 10 by 2019-01-24 21:25:19.968240!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.6108e-04 - mean_absolute_error: 0.0229
6. set (Dataset 8) being trained for epoch 10 by 2019-01-24 21:25:41.101055!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
7. set (Dataset 6) being trained for epoch 10 by 2019-01-24 21:26:00.155218!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0449
8. set (Dataset 17) being trained for epoch 10 by 2019-01-24 21:26:13.777771!
Epoch 1/1
395/395 [==============================] - 7s 17ms/step - loss: 0.0017 - mean_absolute_error: 0.0309
9. set (Dataset 12) being trained for epoch 10 by 2019-01-24 21:26:27.894834!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 7.9609e-04 - mean_absolute_error: 0.0218
10. set (Dataset 13) being trained for epoch 10 by 2019-01-24 21:26:45.941227!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 8.7323e-04 - mean_absolute_error: 0.0228
11. set (Dataset 22) being trained for epoch 10 by 2019-01-24 21:27:01.372082!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0331
12. set (Dataset 18) being trained for epoch 10 by 2019-01-24 21:27:19.228438!
Epoch 1/1
614/614 [==============================] - 11s 17ms/step - loss: 0.0024 - mean_absolute_error: 0.0370
13. set (Dataset 4) being trained for epoch 10 by 2019-01-24 21:27:37.339475!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0259
14. set (Dataset 15) being trained for epoch 10 by 2019-01-24 21:27:56.917738!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0339
15. set (Dataset 16) being trained for epoch 10 by 2019-01-24 21:28:17.271153!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0277
16. set (Dataset 20) being trained for epoch 10 by 2019-01-24 21:28:39.017840!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0284
17. set (Dataset 19) being trained for epoch 10 by 2019-01-24 21:28:54.023067!
Epoch 1/1
502/502 [==============================] - 10s 19ms/step - loss: 0.0034 - mean_absolute_error: 0.0390
18. set (Dataset 24) being trained for epoch 10 by 2019-01-24 21:29:08.303187!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0251
19. set (Dataset 23) being trained for epoch 10 by 2019-01-24 21:29:22.544749!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0340
20. set (Dataset 21) being trained for epoch 10 by 2019-01-24 21:29:38.779926!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0350
Epoch 10 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:29:54.837472
1. set (Dataset 24) being trained for epoch 11 by 2019-01-24 21:29:59.508940!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0250
2. set (Dataset 21) being trained for epoch 11 by 2019-01-24 21:30:14.451393!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0361
3. set (Dataset 22) being trained for epoch 11 by 2019-01-24 21:30:32.730931!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0313
4. set (Dataset 16) being trained for epoch 11 by 2019-01-24 21:30:53.409445!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0271
5. set (Dataset 8) being trained for epoch 11 by 2019-01-24 21:31:17.663746!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0272
6. set (Dataset 23) being trained for epoch 11 by 2019-01-24 21:31:37.042812!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0354
7. set (Dataset 19) being trained for epoch 11 by 2019-01-24 21:31:52.161829!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0384
8. set (Dataset 18) being trained for epoch 11 by 2019-01-24 21:32:07.307536!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0321
9. set (Dataset 7) being trained for epoch 11 by 2019-01-24 21:32:25.753406!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.8001e-04 - mean_absolute_error: 0.0227
10. set (Dataset 12) being trained for epoch 11 by 2019-01-24 21:32:46.436652!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.0715e-04 - mean_absolute_error: 0.0235
11. set (Dataset 6) being trained for epoch 11 by 2019-01-24 21:33:04.838709!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0445
12. set (Dataset 2) being trained for epoch 11 by 2019-01-24 21:33:19.705627!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0274
13. set (Dataset 15) being trained for epoch 11 by 2019-01-24 21:33:35.193752!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
14. set (Dataset 10) being trained for epoch 11 by 2019-01-24 21:33:54.336810!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0264
15. set (Dataset 1) being trained for epoch 11 by 2019-01-24 21:34:12.279974!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0319
16. set (Dataset 20) being trained for epoch 11 by 2019-01-24 21:34:26.611052!
Epoch 1/1
556/556 [==============================] - 10s 17ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
17. set (Dataset 4) being trained for epoch 11 by 2019-01-24 21:34:43.732092!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0259
18. set (Dataset 11) being trained for epoch 11 by 2019-01-24 21:35:02.703214!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 7.8561e-04 - mean_absolute_error: 0.0218
19. set (Dataset 13) being trained for epoch 11 by 2019-01-24 21:35:17.824407!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.8158e-04 - mean_absolute_error: 0.0247
20. set (Dataset 17) being trained for epoch 11 by 2019-01-24 21:35:30.477136!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0351
Epoch 11 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:35:42.368707
1. set (Dataset 11) being trained for epoch 12 by 2019-01-24 21:35:48.071399!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 7.5094e-04 - mean_absolute_error: 0.0211
2. set (Dataset 17) being trained for epoch 12 by 2019-01-24 21:36:02.332669!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0018 - mean_absolute_error: 0.0319
3. set (Dataset 6) being trained for epoch 12 by 2019-01-24 21:36:14.897657!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0421
4. set (Dataset 1) being trained for epoch 12 by 2019-01-24 21:36:29.757066!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0330
5. set (Dataset 23) being trained for epoch 12 by 2019-01-24 21:36:44.249916!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0335
6. set (Dataset 13) being trained for epoch 12 by 2019-01-24 21:36:59.473807!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
7. set (Dataset 4) being trained for epoch 12 by 2019-01-24 21:37:15.638300!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0264
8. set (Dataset 2) being trained for epoch 12 by 2019-01-24 21:37:33.874775!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0272
9. set (Dataset 8) being trained for epoch 12 by 2019-01-24 21:37:50.880635!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0013 - mean_absolute_error: 0.0275
10. set (Dataset 7) being trained for epoch 12 by 2019-01-24 21:38:12.913972!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.3784e-04 - mean_absolute_error: 0.0224
11. set (Dataset 19) being trained for epoch 12 by 2019-01-24 21:38:31.184910!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0397
12. set (Dataset 24) being trained for epoch 12 by 2019-01-24 21:38:44.746122!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0260
13. set (Dataset 10) being trained for epoch 12 by 2019-01-24 21:39:01.041760!
Epoch 1/1
726/726 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
14. set (Dataset 21) being trained for epoch 12 by 2019-01-24 21:39:20.805796!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0376
15. set (Dataset 22) being trained for epoch 12 by 2019-01-24 21:39:38.612742!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0306
16. set (Dataset 20) being trained for epoch 12 by 2019-01-24 21:39:56.179667!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
17. set (Dataset 15) being trained for epoch 12 by 2019-01-24 21:40:12.656976!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0018 - mean_absolute_error: 0.0322
18. set (Dataset 16) being trained for epoch 12 by 2019-01-24 21:40:33.552501!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0278
19. set (Dataset 12) being trained for epoch 12 by 2019-01-24 21:40:57.266407!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0244
20. set (Dataset 18) being trained for epoch 12 by 2019-01-24 21:41:16.375095!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0332
Epoch 12 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:41:32.001223
1. set (Dataset 16) being trained for epoch 13 by 2019-01-24 21:41:40.721731!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
2. set (Dataset 18) being trained for epoch 13 by 2019-01-24 21:42:03.028582!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0318
3. set (Dataset 19) being trained for epoch 13 by 2019-01-24 21:42:19.028983!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0379
4. set (Dataset 22) being trained for epoch 13 by 2019-01-24 21:42:34.562597!
Epoch 1/1
665/665 [==============================] - 12s 17ms/step - loss: 0.0019 - mean_absolute_error: 0.0318
5. set (Dataset 13) being trained for epoch 13 by 2019-01-24 21:42:50.973801!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
6. set (Dataset 12) being trained for epoch 13 by 2019-01-24 21:43:07.235091!
Epoch 1/1
732/732 [==============================] - 13s 17ms/step - loss: 7.9040e-04 - mean_absolute_error: 0.0219
7. set (Dataset 15) being trained for epoch 13 by 2019-01-24 21:43:26.406650!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0330
8. set (Dataset 24) being trained for epoch 13 by 2019-01-24 21:43:42.989092!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0259
9. set (Dataset 23) being trained for epoch 13 by 2019-01-24 21:43:57.371261!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0347
10. set (Dataset 8) being trained for epoch 13 by 2019-01-24 21:44:15.289542!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
11. set (Dataset 4) being trained for epoch 13 by 2019-01-24 21:44:36.796573!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0260
12. set (Dataset 11) being trained for epoch 13 by 2019-01-24 21:44:56.383595!
Epoch 1/1
572/572 [==============================] - 11s 18ms/step - loss: 8.2030e-04 - mean_absolute_error: 0.0221
13. set (Dataset 21) being trained for epoch 13 by 2019-01-24 21:45:12.971321!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0377
14. set (Dataset 17) being trained for epoch 13 by 2019-01-24 21:45:28.078864!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0301
15. set (Dataset 6) being trained for epoch 13 by 2019-01-24 21:45:40.570417!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0417
16. set (Dataset 20) being trained for epoch 13 by 2019-01-24 21:45:55.755371!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0291
17. set (Dataset 10) being trained for epoch 13 by 2019-01-24 21:46:13.333816!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0278
18. set (Dataset 1) being trained for epoch 13 by 2019-01-24 21:46:31.406164!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0324
19. set (Dataset 7) being trained for epoch 13 by 2019-01-24 21:46:47.924798!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 8.0964e-04 - mean_absolute_error: 0.0226
20. set (Dataset 2) being trained for epoch 13 by 2019-01-24 21:47:06.781549!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
Epoch 13 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:47:20.333306
1. set (Dataset 1) being trained for epoch 14 by 2019-01-24 21:47:25.369850!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0316
2. set (Dataset 2) being trained for epoch 14 by 2019-01-24 21:47:39.484360!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 8.8859e-04 - mean_absolute_error: 0.0232
3. set (Dataset 4) being trained for epoch 14 by 2019-01-24 21:47:56.358724!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
4. set (Dataset 6) being trained for epoch 14 by 2019-01-24 21:48:14.860745!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0441
5. set (Dataset 12) being trained for epoch 14 by 2019-01-24 21:48:31.835668!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 9.6931e-04 - mean_absolute_error: 0.0242
6. set (Dataset 7) being trained for epoch 14 by 2019-01-24 21:48:53.060887!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 8.7874e-04 - mean_absolute_error: 0.0230
7. set (Dataset 10) being trained for epoch 14 by 2019-01-24 21:49:13.929404!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0254
8. set (Dataset 11) being trained for epoch 14 by 2019-01-24 21:49:32.464916!
Epoch 1/1
572/572 [==============================] - 11s 18ms/step - loss: 7.8967e-04 - mean_absolute_error: 0.0219
9. set (Dataset 13) being trained for epoch 14 by 2019-01-24 21:49:47.862074!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 8.7611e-04 - mean_absolute_error: 0.0230
10. set (Dataset 23) being trained for epoch 14 by 2019-01-24 21:50:02.134247!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0366
11. set (Dataset 15) being trained for epoch 14 by 2019-01-24 21:50:19.024584!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0327
12. set (Dataset 16) being trained for epoch 14 by 2019-01-24 21:50:39.763818!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
13. set (Dataset 17) being trained for epoch 14 by 2019-01-24 21:50:59.990961!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0310
14. set (Dataset 18) being trained for epoch 14 by 2019-01-24 21:51:13.177769!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0321
15. set (Dataset 19) being trained for epoch 14 by 2019-01-24 21:51:29.113806!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0400
16. set (Dataset 20) being trained for epoch 14 by 2019-01-24 21:51:43.724232!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0301
17. set (Dataset 21) being trained for epoch 14 by 2019-01-24 21:51:59.865253!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0371
18. set (Dataset 22) being trained for epoch 14 by 2019-01-24 21:52:18.099050!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0298
19. set (Dataset 8) being trained for epoch 14 by 2019-01-24 21:52:37.818050!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
20. set (Dataset 24) being trained for epoch 14 by 2019-01-24 21:52:56.868706!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0254
Epoch 14 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:53:10.145989
1. set (Dataset 22) being trained for epoch 15 by 2019-01-24 21:53:16.526850!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0292
2. set (Dataset 24) being trained for epoch 15 by 2019-01-24 21:53:33.207815!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 9.8593e-04 - mean_absolute_error: 0.0243
3. set (Dataset 15) being trained for epoch 15 by 2019-01-24 21:53:48.572459!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0327
4. set (Dataset 19) being trained for epoch 15 by 2019-01-24 21:54:05.153464!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0371
5. set (Dataset 7) being trained for epoch 15 by 2019-01-24 21:54:21.768996!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0245
6. set (Dataset 8) being trained for epoch 15 by 2019-01-24 21:54:42.842795!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0261
7. set (Dataset 21) being trained for epoch 15 by 2019-01-24 21:55:03.238099!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0380
8. set (Dataset 16) being trained for epoch 15 by 2019-01-24 21:55:23.435524!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
9. set (Dataset 12) being trained for epoch 15 by 2019-01-24 21:55:47.425827!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 7.9556e-04 - mean_absolute_error: 0.0221
10. set (Dataset 13) being trained for epoch 15 by 2019-01-24 21:56:05.930988!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.7251e-04 - mean_absolute_error: 0.0241
11. set (Dataset 10) being trained for epoch 15 by 2019-01-24 21:56:21.907168!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0249
12. set (Dataset 1) being trained for epoch 15 by 2019-01-24 21:56:39.940313!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0301
13. set (Dataset 18) being trained for epoch 15 by 2019-01-24 21:56:54.905807!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0347
14. set (Dataset 2) being trained for epoch 15 by 2019-01-24 21:57:11.003640!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0247
15. set (Dataset 4) being trained for epoch 15 by 2019-01-24 21:57:27.799519!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
16. set (Dataset 20) being trained for epoch 15 by 2019-01-24 21:57:46.793933!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
17. set (Dataset 17) being trained for epoch 15 by 2019-01-24 21:58:00.690178!
Epoch 1/1
395/395 [==============================] - 8s 19ms/step - loss: 0.0017 - mean_absolute_error: 0.0315
18. set (Dataset 6) being trained for epoch 15 by 2019-01-24 21:58:13.418040!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0408
19. set (Dataset 23) being trained for epoch 15 by 2019-01-24 21:58:28.854909!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0373
20. set (Dataset 11) being trained for epoch 15 by 2019-01-24 21:58:44.651230!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.5915e-04 - mean_absolute_error: 0.0227
Epoch 15 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 21:58:59.269271
1. set (Dataset 6) being trained for epoch 16 by 2019-01-24 21:59:04.452890!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0408
2. set (Dataset 11) being trained for epoch 16 by 2019-01-24 21:59:20.206696!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 7.7487e-04 - mean_absolute_error: 0.0217
3. set (Dataset 10) being trained for epoch 16 by 2019-01-24 21:59:37.495069!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0285
4. set (Dataset 4) being trained for epoch 16 by 2019-01-24 21:59:58.292771!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0263
5. set (Dataset 8) being trained for epoch 16 by 2019-01-24 22:00:19.194345!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
6. set (Dataset 23) being trained for epoch 16 by 2019-01-24 22:00:38.918416!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
7. set (Dataset 17) being trained for epoch 16 by 2019-01-24 22:00:53.087352!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0311
8. set (Dataset 1) being trained for epoch 16 by 2019-01-24 22:01:05.402752!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0310
9. set (Dataset 7) being trained for epoch 16 by 2019-01-24 22:01:21.966928!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.2506e-04 - mean_absolute_error: 0.0226
10. set (Dataset 12) being trained for epoch 16 by 2019-01-24 22:01:42.544024!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 7.0355e-04 - mean_absolute_error: 0.0205
11. set (Dataset 21) being trained for epoch 16 by 2019-01-24 22:02:01.743290!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0373
12. set (Dataset 22) being trained for epoch 16 by 2019-01-24 22:02:19.710673!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0308
13. set (Dataset 2) being trained for epoch 16 by 2019-01-24 22:02:37.009103!
Epoch 1/1
511/511 [==============================] - 10s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
14. set (Dataset 24) being trained for epoch 16 by 2019-01-24 22:02:51.270887!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0010 - mean_absolute_error: 0.0248
15. set (Dataset 15) being trained for epoch 16 by 2019-01-24 22:03:06.885195!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
16. set (Dataset 20) being trained for epoch 16 by 2019-01-24 22:03:24.285254!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
17. set (Dataset 18) being trained for epoch 16 by 2019-01-24 22:03:40.284380!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0324
18. set (Dataset 19) being trained for epoch 16 by 2019-01-24 22:03:56.401133!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0032 - mean_absolute_error: 0.0376
19. set (Dataset 13) being trained for epoch 16 by 2019-01-24 22:04:10.062990!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 9.5312e-04 - mean_absolute_error: 0.0236
20. set (Dataset 16) being trained for epoch 16 by 2019-01-24 22:04:27.741950!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0286
Epoch 16 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:04:48.319528
1. set (Dataset 19) being trained for epoch 17 by 2019-01-24 22:04:53.197613!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0031 - mean_absolute_error: 0.0373
2. set (Dataset 16) being trained for epoch 17 by 2019-01-24 22:05:11.252520!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0269
3. set (Dataset 21) being trained for epoch 17 by 2019-01-24 22:05:33.562143!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0347
4. set (Dataset 15) being trained for epoch 17 by 2019-01-24 22:05:51.268410!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0311
5. set (Dataset 23) being trained for epoch 17 by 2019-01-24 22:06:08.638696!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0333
6. set (Dataset 13) being trained for epoch 17 by 2019-01-24 22:06:23.939979!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 9.6853e-04 - mean_absolute_error: 0.0239
7. set (Dataset 18) being trained for epoch 17 by 2019-01-24 22:06:38.879107!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
8. set (Dataset 22) being trained for epoch 17 by 2019-01-24 22:06:56.296851!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0299
9. set (Dataset 8) being trained for epoch 17 by 2019-01-24 22:07:15.958267!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
10. set (Dataset 7) being trained for epoch 17 by 2019-01-24 22:07:37.827820!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 8.5408e-04 - mean_absolute_error: 0.0228
11. set (Dataset 17) being trained for epoch 17 by 2019-01-24 22:07:55.118823!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0324
12. set (Dataset 6) being trained for epoch 17 by 2019-01-24 22:08:07.559752!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0422
13. set (Dataset 24) being trained for epoch 17 by 2019-01-24 22:08:22.263105!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 9.9980e-04 - mean_absolute_error: 0.0248
14. set (Dataset 11) being trained for epoch 17 by 2019-01-24 22:08:36.822198!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.8510e-04 - mean_absolute_error: 0.0230
15. set (Dataset 10) being trained for epoch 17 by 2019-01-24 22:08:54.260078!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
16. set (Dataset 20) being trained for epoch 17 by 2019-01-24 22:09:12.627727!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0289
17. set (Dataset 2) being trained for epoch 17 by 2019-01-24 22:09:27.776367!
Epoch 1/1
511/511 [==============================] - 9s 17ms/step - loss: 0.0011 - mean_absolute_error: 0.0265
18. set (Dataset 4) being trained for epoch 17 by 2019-01-24 22:09:44.125920!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0274
19. set (Dataset 12) being trained for epoch 17 by 2019-01-24 22:10:05.215475!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 8.0077e-04 - mean_absolute_error: 0.0219
20. set (Dataset 1) being trained for epoch 17 by 2019-01-24 22:10:23.952520!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0321
Epoch 17 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:10:37.494384
1. set (Dataset 4) being trained for epoch 18 by 2019-01-24 22:10:44.870492!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
2. set (Dataset 1) being trained for epoch 18 by 2019-01-24 22:11:03.355375!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0286
3. set (Dataset 17) being trained for epoch 18 by 2019-01-24 22:11:15.896233!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0318
4. set (Dataset 10) being trained for epoch 18 by 2019-01-24 22:11:30.314549!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 9.3564e-04 - mean_absolute_error: 0.0238
5. set (Dataset 13) being trained for epoch 18 by 2019-01-24 22:11:48.329043!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 8.7903e-04 - mean_absolute_error: 0.0227
6. set (Dataset 12) being trained for epoch 18 by 2019-01-24 22:12:04.400227!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 7.7723e-04 - mean_absolute_error: 0.0218
7. set (Dataset 2) being trained for epoch 18 by 2019-01-24 22:12:22.928729!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0248
8. set (Dataset 6) being trained for epoch 18 by 2019-01-24 22:12:37.483336!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0422
9. set (Dataset 23) being trained for epoch 18 by 2019-01-24 22:12:52.929448!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0021 - mean_absolute_error: 0.0351
10. set (Dataset 8) being trained for epoch 18 by 2019-01-24 22:13:11.243761!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0283
11. set (Dataset 18) being trained for epoch 18 by 2019-01-24 22:13:31.196061!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0019 - mean_absolute_error: 0.0335
12. set (Dataset 19) being trained for epoch 18 by 2019-01-24 22:13:47.527947!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0377
13. set (Dataset 11) being trained for epoch 18 by 2019-01-24 22:14:02.458551!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 9.0874e-04 - mean_absolute_error: 0.0235
14. set (Dataset 16) being trained for epoch 18 by 2019-01-24 22:14:21.518115!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0279
15. set (Dataset 21) being trained for epoch 18 by 2019-01-24 22:14:44.075876!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0364
16. set (Dataset 20) being trained for epoch 18 by 2019-01-24 22:15:01.152281!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0015 - mean_absolute_error: 0.0295
17. set (Dataset 24) being trained for epoch 18 by 2019-01-24 22:15:15.972312!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 9.3829e-04 - mean_absolute_error: 0.0235
18. set (Dataset 15) being trained for epoch 18 by 2019-01-24 22:15:31.275494!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0334
19. set (Dataset 7) being trained for epoch 18 by 2019-01-24 22:15:50.870144!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0254
20. set (Dataset 22) being trained for epoch 18 by 2019-01-24 22:16:10.775921!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0308
Epoch 18 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:16:27.694057
1. set (Dataset 15) being trained for epoch 19 by 2019-01-24 22:16:34.087348!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0322
2. set (Dataset 22) being trained for epoch 19 by 2019-01-24 22:16:52.059445!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0289
3. set (Dataset 18) being trained for epoch 19 by 2019-01-24 22:17:10.190036!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0332
4. set (Dataset 21) being trained for epoch 19 by 2019-01-24 22:17:27.376040!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0338
5. set (Dataset 12) being trained for epoch 19 by 2019-01-24 22:17:46.016050!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 9.0564e-04 - mean_absolute_error: 0.0230
6. set (Dataset 7) being trained for epoch 19 by 2019-01-24 22:18:06.912843!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 7.7413e-04 - mean_absolute_error: 0.0215
7. set (Dataset 24) being trained for epoch 19 by 2019-01-24 22:18:25.073418!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
8. set (Dataset 19) being trained for epoch 19 by 2019-01-24 22:18:39.263832!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0373
9. set (Dataset 13) being trained for epoch 19 by 2019-01-24 22:18:53.327901!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
10. set (Dataset 23) being trained for epoch 19 by 2019-01-24 22:19:07.665549!
Epoch 1/1
569/569 [==============================] - 11s 18ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
11. set (Dataset 2) being trained for epoch 19 by 2019-01-24 22:19:23.302403!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0010 - mean_absolute_error: 0.0250
12. set (Dataset 4) being trained for epoch 19 by 2019-01-24 22:19:40.015532!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
13. set (Dataset 16) being trained for epoch 19 by 2019-01-24 22:20:02.299471!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
14. set (Dataset 1) being trained for epoch 19 by 2019-01-24 22:20:24.028097!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0023 - mean_absolute_error: 0.0336
15. set (Dataset 17) being trained for epoch 19 by 2019-01-24 22:20:37.089776!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0314
16. set (Dataset 20) being trained for epoch 19 by 2019-01-24 22:20:49.545504!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0287
17. set (Dataset 11) being trained for epoch 19 by 2019-01-24 22:21:05.544343!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.2719e-04 - mean_absolute_error: 0.0223
18. set (Dataset 10) being trained for epoch 19 by 2019-01-24 22:21:23.285843!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0256
19. set (Dataset 8) being trained for epoch 19 by 2019-01-24 22:21:44.128580!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0275
20. set (Dataset 6) being trained for epoch 19 by 2019-01-24 22:22:03.642314!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0452
Epoch 19 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:22:18.147700
1. set (Dataset 10) being trained for epoch 20 by 2019-01-24 22:22:25.376591!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 9.2904e-04 - mean_absolute_error: 0.0238
2. set (Dataset 6) being trained for epoch 20 by 2019-01-24 22:22:43.607920!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0420
3. set (Dataset 2) being trained for epoch 20 by 2019-01-24 22:22:58.402277!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
4. set (Dataset 17) being trained for epoch 20 by 2019-01-24 22:23:11.179733!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0016 - mean_absolute_error: 0.0303
5. set (Dataset 7) being trained for epoch 20 by 2019-01-24 22:23:26.028694!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 8.8849e-04 - mean_absolute_error: 0.0232
6. set (Dataset 8) being trained for epoch 20 by 2019-01-24 22:23:47.559132!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
7. set (Dataset 11) being trained for epoch 20 by 2019-01-24 22:24:07.450745!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 8.6955e-04 - mean_absolute_error: 0.0229
8. set (Dataset 4) being trained for epoch 20 by 2019-01-24 22:24:24.994528!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0260
9. set (Dataset 12) being trained for epoch 20 by 2019-01-24 22:24:45.718196!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 6.6081e-04 - mean_absolute_error: 0.0203
10. set (Dataset 13) being trained for epoch 20 by 2019-01-24 22:25:03.681172!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 8.1229e-04 - mean_absolute_error: 0.0219
11. set (Dataset 24) being trained for epoch 20 by 2019-01-24 22:25:17.095734!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
12. set (Dataset 15) being trained for epoch 20 by 2019-01-24 22:25:32.259920!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0020 - mean_absolute_error: 0.0339
13. set (Dataset 1) being trained for epoch 20 by 2019-01-24 22:25:49.529332!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0338
14. set (Dataset 22) being trained for epoch 20 by 2019-01-24 22:26:05.175398!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0017 - mean_absolute_error: 0.0298
15. set (Dataset 18) being trained for epoch 20 by 2019-01-24 22:26:23.105792!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0019 - mean_absolute_error: 0.0337
16. set (Dataset 20) being trained for epoch 20 by 2019-01-24 22:26:39.538671!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
17. set (Dataset 16) being trained for epoch 20 by 2019-01-24 22:26:58.288104!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0013 - mean_absolute_error: 0.0268
18. set (Dataset 21) being trained for epoch 20 by 2019-01-24 22:27:20.728661!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0023 - mean_absolute_error: 0.0366
19. set (Dataset 23) being trained for epoch 20 by 2019-01-24 22:27:37.544565!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0018 - mean_absolute_error: 0.0319
20. set (Dataset 19) being trained for epoch 20 by 2019-01-24 22:27:52.679320!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0384
Epoch 20 completed!
Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45.h5 has been saved.
The subjects are trained: [(10, 'M04'), (6, 'F06'), (2, 'F02'), (17, 'M10'), (7, 'M01'), (8, 'M02'), (11, 'M05'), (4,
 'F04'), (12, 'M06'), (13, 'M07'), (24, 'M14'), (15, 'F03'), (1, 'F01'), (22, 'M01'), (18, 'F05'), (20, 'M12'), (16,
'M09'), (21, 'F02'), (23, 'M13'), (19, 'M11')]
Evaluating model Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43_and_2019-01-24_20-31-45
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-24 22:28:03.944281
For the Subject 3 (F03):
730/730 [==============================] - 7s 10ms/step
        The absolute mean error on Pitch angle estimation: 17.05 Degree
        The absolute mean error on Yaw angle estimation: 22.16 Degree
        The absolute mean error on Roll angle estimation: 11.19 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Pitch angle estimation: 9.64 Degree
        The absolute mean error on Yaw angle estimation: 32.03 Degree
        The absolute mean error on Roll angle estimation: 11.89 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 13.40 Degree
        The absolute mean error on Yaw angle estimation: 28.43 Degree
        The absolute mean error on Roll angle estimation: 11.92 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 19.25 Degree
        The absolute mean error on Yaw angle estimation: 40.11 Degree
        The absolute mean error on Roll angle estimation: 14.62 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 14.84 Degree
        The absolute mean error on Yaw angle estimations: 30.68 Degree
        The absolute mean error on Roll angle estimations: 12.41 Degree
subject3_Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45.png has been saved by 2019-01-24 22:29:09.871026.
subject5_Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45.png has been saved by 2019-01-24 22:29:10.108642.
subject9_Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45.png has been saved by 2019-01-24 22:29:10.309698.
subject14_Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45.png has been saved by 2019-01-24 22:29:10.530726.
Model Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45 has been evaluated successfully.
Model Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 22:38:45.739515: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 22:38:45.836055: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 22:38:45.836312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 22:38:45.836325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 22:38:45.992642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 22:38:45.992670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 22:38:45.992677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 22:38:45.992818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_22-38-46 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 10
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs10_AdamOpt_lr-0.000100_201
9-01-24_22-38-46
All frames and annotations from 20 datasets have been read by 2019-01-24 22:38:51.033502
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 22:38:57.433685!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0132 - mean_absolute_error: 0.0807
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 22:39:15.082642!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0130 - mean_absolute_error: 0.0831
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 22:39:30.282798!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0245 - mean_absolute_error: 0.1061
4. set (Dataset 19) being trained for epoch 1 by 2019-01-24 22:39:46.835181!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0153 - mean_absolute_error: 0.0859
5. set (Dataset 8) being trained for epoch 1 by 2019-01-24 22:40:03.667297!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0374 - mean_absolute_error: 0.1450
6. set (Dataset 23) being trained for epoch 1 by 2019-01-24 22:40:22.868339!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0356 - mean_absolute_error: 0.1383
7. set (Dataset 21) being trained for epoch 1 by 2019-01-24 22:40:39.287987!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0297 - mean_absolute_error: 0.1307
8. set (Dataset 16) being trained for epoch 1 by 2019-01-24 22:40:59.692977!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0143 - mean_absolute_error: 0.0860
9. set (Dataset 7) being trained for epoch 1 by 2019-01-24 22:41:23.649418!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0316 - mean_absolute_error: 0.1283
10. set (Dataset 12) being trained for epoch 1 by 2019-01-24 22:41:44.410314!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0212 - mean_absolute_error: 0.1071
11. set (Dataset 10) being trained for epoch 1 by 2019-01-24 22:42:04.890735!
Epoch 1/1
726/726 [==============================] - 13s 17ms/step - loss: 0.0294 - mean_absolute_error: 0.1148
12. set (Dataset 1) being trained for epoch 1 by 2019-01-24 22:42:22.665887!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0447 - mean_absolute_error: 0.1424
13. set (Dataset 18) being trained for epoch 1 by 2019-01-24 22:42:37.519238!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0233 - mean_absolute_error: 0.1164
14. set (Dataset 2) being trained for epoch 1 by 2019-01-24 22:42:53.689329!
Epoch 1/1
511/511 [==============================] - 10s 19ms/step - loss: 0.0439 - mean_absolute_error: 0.1561
15. set (Dataset 4) being trained for epoch 1 by 2019-01-24 22:43:10.846545!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0358 - mean_absolute_error: 0.1301
16. set (Dataset 20) being trained for epoch 1 by 2019-01-24 22:43:29.583636!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0223 - mean_absolute_error: 0.1094
17. set (Dataset 17) being trained for epoch 1 by 2019-01-24 22:43:43.381643!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0130 - mean_absolute_error: 0.0872
18. set (Dataset 6) being trained for epoch 1 by 2019-01-24 22:43:55.987645!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0424 - mean_absolute_error: 0.1434
19. set (Dataset 13) being trained for epoch 1 by 2019-01-24 22:44:10.720255!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0112 - mean_absolute_error: 0.0771
20. set (Dataset 11) being trained for epoch 1 by 2019-01-24 22:44:25.298601!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0194 - mean_absolute_error: 0.0951
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:44:39.746039
1. set (Dataset 6) being trained for epoch 2 by 2019-01-24 22:44:44.926746!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0200 - mean_absolute_error: 0.1022
2. set (Dataset 11) being trained for epoch 2 by 2019-01-24 22:45:00.441700!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0108 - mean_absolute_error: 0.0734
3. set (Dataset 10) being trained for epoch 2 by 2019-01-24 22:45:18.011358!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0191 - mean_absolute_error: 0.0934
4. set (Dataset 4) being trained for epoch 2 by 2019-01-24 22:45:38.789456!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0201 - mean_absolute_error: 0.0958
5. set (Dataset 23) being trained for epoch 2 by 2019-01-24 22:45:57.967803!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0224 - mean_absolute_error: 0.1064
6. set (Dataset 13) being trained for epoch 2 by 2019-01-24 22:46:13.296478!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0062 - mean_absolute_error: 0.0583
7. set (Dataset 17) being trained for epoch 2 by 2019-01-24 22:46:25.595922!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0143 - mean_absolute_error: 0.0914
8. set (Dataset 1) being trained for epoch 2 by 2019-01-24 22:46:37.811321!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0355 - mean_absolute_error: 0.1242
9. set (Dataset 8) being trained for epoch 2 by 2019-01-24 22:46:54.881616!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0367 - mean_absolute_error: 0.1402
10. set (Dataset 7) being trained for epoch 2 by 2019-01-24 22:47:16.198944!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0183 - mean_absolute_error: 0.0941
11. set (Dataset 21) being trained for epoch 2 by 2019-01-24 22:47:35.800605!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0239 - mean_absolute_error: 0.1179
12. set (Dataset 22) being trained for epoch 2 by 2019-01-24 22:47:53.691182!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0085 - mean_absolute_error: 0.0669
13. set (Dataset 2) being trained for epoch 2 by 2019-01-24 22:48:10.872834!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0254 - mean_absolute_error: 0.1165
14. set (Dataset 24) being trained for epoch 2 by 2019-01-24 22:48:25.047768!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0090 - mean_absolute_error: 0.0694
15. set (Dataset 15) being trained for epoch 2 by 2019-01-24 22:48:40.394998!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0153 - mean_absolute_error: 0.0894
16. set (Dataset 20) being trained for epoch 2 by 2019-01-24 22:48:57.499468!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0137 - mean_absolute_error: 0.0906
17. set (Dataset 18) being trained for epoch 2 by 2019-01-24 22:49:13.762642!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0187 - mean_absolute_error: 0.1054
18. set (Dataset 19) being trained for epoch 2 by 2019-01-24 22:49:30.018262!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0145 - mean_absolute_error: 0.0930
19. set (Dataset 12) being trained for epoch 2 by 2019-01-24 22:49:46.192489!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0150 - mean_absolute_error: 0.0947
20. set (Dataset 16) being trained for epoch 2 by 2019-01-24 22:50:08.373351!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0102 - mean_absolute_error: 0.0723
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:50:29.420834
1. set (Dataset 19) being trained for epoch 3 by 2019-01-24 22:50:34.307503!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0098 - mean_absolute_error: 0.0741
2. set (Dataset 16) being trained for epoch 3 by 2019-01-24 22:50:52.338253!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0067 - mean_absolute_error: 0.0602
3. set (Dataset 21) being trained for epoch 3 by 2019-01-24 22:51:14.889127!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0207 - mean_absolute_error: 0.1036
4. set (Dataset 15) being trained for epoch 3 by 2019-01-24 22:51:33.043124!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0096 - mean_absolute_error: 0.0716
5. set (Dataset 13) being trained for epoch 3 by 2019-01-24 22:51:49.778770!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0081 - mean_absolute_error: 0.0729
6. set (Dataset 12) being trained for epoch 3 by 2019-01-24 22:52:05.487494!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0117 - mean_absolute_error: 0.0812
7. set (Dataset 18) being trained for epoch 3 by 2019-01-24 22:52:24.719065!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0121 - mean_absolute_error: 0.0816
8. set (Dataset 22) being trained for epoch 3 by 2019-01-24 22:52:42.397365!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0070 - mean_absolute_error: 0.0603
9. set (Dataset 23) being trained for epoch 3 by 2019-01-24 22:53:00.166900!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0157 - mean_absolute_error: 0.0915
10. set (Dataset 8) being trained for epoch 3 by 2019-01-24 22:53:18.231187!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0147 - mean_absolute_error: 0.0827
11. set (Dataset 17) being trained for epoch 3 by 2019-01-24 22:53:36.048399!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0089 - mean_absolute_error: 0.0737
12. set (Dataset 6) being trained for epoch 3 by 2019-01-24 22:53:48.273117!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0238 - mean_absolute_error: 0.1074
13. set (Dataset 24) being trained for epoch 3 by 2019-01-24 22:54:03.015293!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0548
14. set (Dataset 11) being trained for epoch 3 by 2019-01-24 22:54:17.677219!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0073 - mean_absolute_error: 0.0649
15. set (Dataset 10) being trained for epoch 3 by 2019-01-24 22:54:35.579298!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0124 - mean_absolute_error: 0.0772
16. set (Dataset 20) being trained for epoch 3 by 2019-01-24 22:54:54.192093!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0095 - mean_absolute_error: 0.0746
17. set (Dataset 2) being trained for epoch 3 by 2019-01-24 22:55:09.248361!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0160 - mean_absolute_error: 0.0933
18. set (Dataset 4) being trained for epoch 3 by 2019-01-24 22:55:26.183161!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0075 - mean_absolute_error: 0.0641
19. set (Dataset 7) being trained for epoch 3 by 2019-01-24 22:55:47.580879!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0071 - mean_absolute_error: 0.0616
20. set (Dataset 1) being trained for epoch 3 by 2019-01-24 22:56:06.076502!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0205 - mean_absolute_error: 0.0980
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 22:56:19.294151
1. set (Dataset 4) being trained for epoch 4 by 2019-01-24 22:56:26.676617!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0041 - mean_absolute_error: 0.0480
2. set (Dataset 1) being trained for epoch 4 by 2019-01-24 22:56:45.052237!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0130 - mean_absolute_error: 0.0808
3. set (Dataset 17) being trained for epoch 4 by 2019-01-24 22:56:57.671805!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0128 - mean_absolute_error: 0.0843
4. set (Dataset 10) being trained for epoch 4 by 2019-01-24 22:57:12.160977!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0075 - mean_absolute_error: 0.0612
5. set (Dataset 12) being trained for epoch 4 by 2019-01-24 22:57:32.722466!
Epoch 1/1
732/732 [==============================] - 14s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0549
6. set (Dataset 7) being trained for epoch 4 by 2019-01-24 22:57:53.861228!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0417
7. set (Dataset 2) being trained for epoch 4 by 2019-01-24 22:58:12.576005!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0075 - mean_absolute_error: 0.0665
8. set (Dataset 6) being trained for epoch 4 by 2019-01-24 22:58:27.316154!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0115 - mean_absolute_error: 0.0758
9. set (Dataset 13) being trained for epoch 4 by 2019-01-24 22:58:41.831392!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0056 - mean_absolute_error: 0.0551
10. set (Dataset 23) being trained for epoch 4 by 2019-01-24 22:58:55.931921!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0147 - mean_absolute_error: 0.0877
11. set (Dataset 18) being trained for epoch 4 by 2019-01-24 22:59:12.065594!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0106 - mean_absolute_error: 0.0770
12. set (Dataset 19) being trained for epoch 4 by 2019-01-24 22:59:28.120802!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0087 - mean_absolute_error: 0.0681
13. set (Dataset 11) being trained for epoch 4 by 2019-01-24 22:59:42.582441!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0422
14. set (Dataset 16) being trained for epoch 4 by 2019-01-24 23:00:01.530629!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0072 - mean_absolute_error: 0.0602
15. set (Dataset 21) being trained for epoch 4 by 2019-01-24 23:00:24.682215!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0207 - mean_absolute_error: 0.1040
16. set (Dataset 20) being trained for epoch 4 by 2019-01-24 23:00:41.729216!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0088 - mean_absolute_error: 0.0735
17. set (Dataset 24) being trained for epoch 4 by 2019-01-24 23:00:56.752960!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0533
18. set (Dataset 15) being trained for epoch 4 by 2019-01-24 23:01:11.912861!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0079 - mean_absolute_error: 0.0655
19. set (Dataset 8) being trained for epoch 4 by 2019-01-24 23:01:31.220043!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0070 - mean_absolute_error: 0.0633
20. set (Dataset 22) being trained for epoch 4 by 2019-01-24 23:01:51.601806!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0588
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:02:07.940579
1. set (Dataset 15) being trained for epoch 5 by 2019-01-24 23:02:14.278721!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0069 - mean_absolute_error: 0.0619
2. set (Dataset 22) being trained for epoch 5 by 2019-01-24 23:02:32.440344!
Epoch 1/1
665/665 [==============================] - 12s 17ms/step - loss: 0.0051 - mean_absolute_error: 0.0506
3. set (Dataset 18) being trained for epoch 5 by 2019-01-24 23:02:49.911351!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0095 - mean_absolute_error: 0.0722
4. set (Dataset 21) being trained for epoch 5 by 2019-01-24 23:03:07.125617!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0177 - mean_absolute_error: 0.0942
5. set (Dataset 7) being trained for epoch 5 by 2019-01-24 23:03:26.054460!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0486
6. set (Dataset 8) being trained for epoch 5 by 2019-01-24 23:03:47.167570!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0525
7. set (Dataset 24) being trained for epoch 5 by 2019-01-24 23:04:05.948013!
Epoch 1/1
492/492 [==============================] - 9s 17ms/step - loss: 0.0046 - mean_absolute_error: 0.0536
8. set (Dataset 19) being trained for epoch 5 by 2019-01-24 23:04:19.427959!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0075 - mean_absolute_error: 0.0646
9. set (Dataset 12) being trained for epoch 5 by 2019-01-24 23:04:35.411061!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0494
10. set (Dataset 13) being trained for epoch 5 by 2019-01-24 23:04:53.163899!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0502
11. set (Dataset 2) being trained for epoch 5 by 2019-01-24 23:05:07.115912!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0050 - mean_absolute_error: 0.0546
12. set (Dataset 4) being trained for epoch 5 by 2019-01-24 23:05:23.907404!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0475
13. set (Dataset 16) being trained for epoch 5 by 2019-01-24 23:05:46.150738!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0550
14. set (Dataset 1) being trained for epoch 5 by 2019-01-24 23:06:07.888506!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0113 - mean_absolute_error: 0.0772
15. set (Dataset 17) being trained for epoch 5 by 2019-01-24 23:06:20.681638!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0085 - mean_absolute_error: 0.0715
16. set (Dataset 20) being trained for epoch 5 by 2019-01-24 23:06:33.184657!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0074 - mean_absolute_error: 0.0650
17. set (Dataset 11) being trained for epoch 5 by 2019-01-24 23:06:48.850900!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0030 - mean_absolute_error: 0.0382
18. set (Dataset 10) being trained for epoch 5 by 2019-01-24 23:07:06.786450!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0535
19. set (Dataset 23) being trained for epoch 5 by 2019-01-24 23:07:25.280019!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0121 - mean_absolute_error: 0.0798
20. set (Dataset 6) being trained for epoch 5 by 2019-01-24 23:07:40.665053!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0096 - mean_absolute_error: 0.0697
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:07:54.716225
1. set (Dataset 10) being trained for epoch 6 by 2019-01-24 23:08:01.927591!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0470
2. set (Dataset 6) being trained for epoch 6 by 2019-01-24 23:08:20.060999!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0071 - mean_absolute_error: 0.0592
3. set (Dataset 2) being trained for epoch 6 by 2019-01-24 23:08:35.392704!
Epoch 1/1
511/511 [==============================] - 9s 17ms/step - loss: 0.0037 - mean_absolute_error: 0.0475
4. set (Dataset 17) being trained for epoch 6 by 2019-01-24 23:08:48.108457!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0077 - mean_absolute_error: 0.0674
5. set (Dataset 8) being trained for epoch 6 by 2019-01-24 23:09:03.267173!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0504
6. set (Dataset 23) being trained for epoch 6 by 2019-01-24 23:09:22.713734!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0105 - mean_absolute_error: 0.0745
7. set (Dataset 11) being trained for epoch 6 by 2019-01-24 23:09:39.115758!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0346
8. set (Dataset 4) being trained for epoch 6 by 2019-01-24 23:09:56.812150!
Epoch 1/1
744/744 [==============================] - 13s 17ms/step - loss: 0.0031 - mean_absolute_error: 0.0417
9. set (Dataset 7) being trained for epoch 6 by 2019-01-24 23:10:17.354445!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0022 - mean_absolute_error: 0.0361
10. set (Dataset 12) being trained for epoch 6 by 2019-01-24 23:10:37.932058!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0406
11. set (Dataset 24) being trained for epoch 6 by 2019-01-24 23:10:55.575992!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0481
12. set (Dataset 15) being trained for epoch 6 by 2019-01-24 23:11:10.800174!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0070 - mean_absolute_error: 0.0615
13. set (Dataset 1) being trained for epoch 6 by 2019-01-24 23:11:27.749982!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0080 - mean_absolute_error: 0.0648
14. set (Dataset 22) being trained for epoch 6 by 2019-01-24 23:11:43.173571!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0066 - mean_absolute_error: 0.0578
15. set (Dataset 18) being trained for epoch 6 by 2019-01-24 23:12:01.089404!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0079 - mean_absolute_error: 0.0669
16. set (Dataset 20) being trained for epoch 6 by 2019-01-24 23:12:17.423347!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0619
17. set (Dataset 16) being trained for epoch 6 by 2019-01-24 23:12:36.328637!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0559
18. set (Dataset 21) being trained for epoch 6 by 2019-01-24 23:12:58.810511!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0139 - mean_absolute_error: 0.0856
19. set (Dataset 13) being trained for epoch 6 by 2019-01-24 23:13:14.915910!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0476
20. set (Dataset 19) being trained for epoch 6 by 2019-01-24 23:13:28.797144!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0060 - mean_absolute_error: 0.0569
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:13:41.780619
1. set (Dataset 21) being trained for epoch 7 by 2019-01-24 23:13:47.785486!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0101 - mean_absolute_error: 0.0732
2. set (Dataset 19) being trained for epoch 7 by 2019-01-24 23:14:04.689638!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0497
3. set (Dataset 24) being trained for epoch 7 by 2019-01-24 23:14:18.551392!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0487
4. set (Dataset 18) being trained for epoch 7 by 2019-01-24 23:14:33.432619!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0060 - mean_absolute_error: 0.0578
5. set (Dataset 23) being trained for epoch 7 by 2019-01-24 23:14:49.749812!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0086 - mean_absolute_error: 0.0668
6. set (Dataset 13) being trained for epoch 7 by 2019-01-24 23:15:04.948447!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0421
7. set (Dataset 16) being trained for epoch 7 by 2019-01-24 23:15:22.392319!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0053 - mean_absolute_error: 0.0520
8. set (Dataset 15) being trained for epoch 7 by 2019-01-24 23:15:45.271916!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0564
9. set (Dataset 8) being trained for epoch 7 by 2019-01-24 23:16:04.814742!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0573
10. set (Dataset 7) being trained for epoch 7 by 2019-01-24 23:16:26.367144!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0064 - mean_absolute_error: 0.0563
11. set (Dataset 11) being trained for epoch 7 by 2019-01-24 23:16:45.382349!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0376
12. set (Dataset 10) being trained for epoch 7 by 2019-01-24 23:17:03.029496!
Epoch 1/1
377/726 [==============>...............] - ETA: 6s - loss: 0.0044 - mean_absolute_error: 0.0486^C
Model Exp2019-01-24_22-38-46 has been interrupted.
Exp2019-01-24_22-38-46.h5 has been saved.
Model Exp2019-01-24_22-38-46 has been recorded successfully.
Terminating...
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py  E
xp2019-01-24_22-38-46
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 23:18:08.357576: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 23:18:08.456279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 23:18:08.456585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 23:18:08.456599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 23:18:08.612575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 23:18:08.612604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 23:18:08.612609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 23:18:08.612789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-24_22-38-46.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11,
'M05'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21,
'F02'), (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-24 23:18:11.613004
For the Subject 3 (F03):
730/730 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 9.63 Degree
        The absolute mean error on Yaw angle estimation: 21.59 Degree
        The absolute mean error on Roll angle estimation: 17.62 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Pitch angle estimation: 7.50 Degree
        The absolute mean error on Yaw angle estimation: 21.30 Degree
        The absolute mean error on Roll angle estimation: 6.22 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 52.71 Degree
        The absolute mean error on Yaw angle estimation: 33.57 Degree
        The absolute mean error on Roll angle estimation: 7.04 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 15.12 Degree
        The absolute mean error on Yaw angle estimation: 27.05 Degree
        The absolute mean error on Roll angle estimation: 14.64 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 21.24 Degree
        The absolute mean error on Yaw angle estimations: 25.88 Degree
        The absolute mean error on Roll angle estimations: 11.38 Degree
subject3_Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09.png has been saved by 2019-01-24 23:19:18.009466.
subject5_Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09.png has been saved by 2019-01-24 23:19:18.207849.
subject9_Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09.png has been saved by 2019-01-24 23:19:18.404245.
subject14_Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09.png has been saved by 2019-01-24 23:19:18.623051.
Model Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09 has been evaluated successfully.
Model Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 23:19:56.103872: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 23:19:56.201545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 23:19:56.201821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 23:19:56.201836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 23:19:56.357084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 23:19:56.357111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 23:19:56.357120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 23:19:56.357256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10471 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_23-19-57 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 10
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs10_AdamOpt_lr-0.000100_201
9-01-24_23-19-57
All frames and annotations from 20 datasets have been read by 2019-01-24 23:20:01.417194
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 23:20:07.807230!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0254 - mean_absolute_error: 0.1106
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 23:20:25.694679!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0137 - mean_absolute_error: 0.0852
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 23:20:41.262993!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0247 - mean_absolute_error: 0.1101
4. set (Dataset 19) being trained for epoch 1 by 2019-01-24 23:20:58.098984!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0164 - mean_absolute_error: 0.0936
5. set (Dataset 8) being trained for epoch 1 by 2019-01-24 23:21:14.832041!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0589 - mean_absolute_error: 0.1729
6. set (Dataset 23) being trained for epoch 1 by 2019-01-24 23:21:34.405146!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0437 - mean_absolute_error: 0.1584
7. set (Dataset 21) being trained for epoch 1 by 2019-01-24 23:21:50.701510!
Epoch 1/1
634/634 [==============================] - 11s 17ms/step - loss: 0.0370 - mean_absolute_error: 0.1451
8. set (Dataset 16) being trained for epoch 1 by 2019-01-24 23:22:10.525139!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0226 - mean_absolute_error: 0.1088
9. set (Dataset 7) being trained for epoch 1 by 2019-01-24 23:22:35.074822!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0560 - mean_absolute_error: 0.1782
10. set (Dataset 12) being trained for epoch 1 by 2019-01-24 23:22:55.820901!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0317 - mean_absolute_error: 0.1413
11. set (Dataset 10) being trained for epoch 1 by 2019-01-24 23:23:16.014949!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0435 - mean_absolute_error: 0.1452
12. set (Dataset 1) being trained for epoch 1 by 2019-01-24 23:23:34.006247!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0596 - mean_absolute_error: 0.1724
13. set (Dataset 18) being trained for epoch 1 by 2019-01-24 23:23:48.805457!
Epoch 1/1
614/614 [==============================] - 11s 17ms/step - loss: 0.0348 - mean_absolute_error: 0.1449
14. set (Dataset 2) being trained for epoch 1 by 2019-01-24 23:24:04.560281!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0534 - mean_absolute_error: 0.1775
15. set (Dataset 4) being trained for epoch 1 by 2019-01-24 23:24:21.283606!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0371 - mean_absolute_error: 0.1407
16. set (Dataset 20) being trained for epoch 1 by 2019-01-24 23:24:40.024702!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0221 - mean_absolute_error: 0.1095
17. set (Dataset 17) being trained for epoch 1 by 2019-01-24 23:24:53.683054!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0143 - mean_absolute_error: 0.0914
18. set (Dataset 6) being trained for epoch 1 by 2019-01-24 23:25:06.167825!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0539 - mean_absolute_error: 0.1592
19. set (Dataset 13) being trained for epoch 1 by 2019-01-24 23:25:21.056352!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0177 - mean_absolute_error: 0.1005
20. set (Dataset 11) being trained for epoch 1 by 2019-01-24 23:25:35.617004!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0211 - mean_absolute_error: 0.1018
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:25:50.353159
1. set (Dataset 6) being trained for epoch 2 by 2019-01-24 23:25:55.503028!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0386 - mean_absolute_error: 0.1294
2. set (Dataset 11) being trained for epoch 2 by 2019-01-24 23:26:10.828205!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0117 - mean_absolute_error: 0.0807
3. set (Dataset 10) being trained for epoch 2 by 2019-01-24 23:26:28.383316!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0251 - mean_absolute_error: 0.1053
4. set (Dataset 4) being trained for epoch 2 by 2019-01-24 23:26:48.690014!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0170 - mean_absolute_error: 0.1009
5. set (Dataset 23) being trained for epoch 2 by 2019-01-24 23:27:07.704897!
Epoch 1/1
569/569 [==============================] - 10s 17ms/step - loss: 0.0352 - mean_absolute_error: 0.1399
6. set (Dataset 13) being trained for epoch 2 by 2019-01-24 23:27:22.235649!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 0.0138 - mean_absolute_error: 0.0886
7. set (Dataset 17) being trained for epoch 2 by 2019-01-24 23:27:35.173371!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0146 - mean_absolute_error: 0.0911
8. set (Dataset 1) being trained for epoch 2 by 2019-01-24 23:27:47.400042!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0524 - mean_absolute_error: 0.1575
9. set (Dataset 8) being trained for epoch 2 by 2019-01-24 23:28:04.236557!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0267 - mean_absolute_error: 0.1168
10. set (Dataset 7) being trained for epoch 2 by 2019-01-24 23:28:25.921064!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0293 - mean_absolute_error: 0.1217
11. set (Dataset 21) being trained for epoch 2 by 2019-01-24 23:28:45.829689!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0256 - mean_absolute_error: 0.1177
12. set (Dataset 22) being trained for epoch 2 by 2019-01-24 23:29:03.522634!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0113 - mean_absolute_error: 0.0795
13. set (Dataset 2) being trained for epoch 2 by 2019-01-24 23:29:20.600099!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0417 - mean_absolute_error: 0.1592
14. set (Dataset 24) being trained for epoch 2 by 2019-01-24 23:29:34.680555!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0126 - mean_absolute_error: 0.0871
15. set (Dataset 15) being trained for epoch 2 by 2019-01-24 23:29:50.142388!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0183 - mean_absolute_error: 0.0964
16. set (Dataset 20) being trained for epoch 2 by 2019-01-24 23:30:07.447583!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0182 - mean_absolute_error: 0.1009
17. set (Dataset 18) being trained for epoch 2 by 2019-01-24 23:30:23.434928!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0240 - mean_absolute_error: 0.1173
18. set (Dataset 19) being trained for epoch 2 by 2019-01-24 23:30:39.515266!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0144 - mean_absolute_error: 0.0849
19. set (Dataset 12) being trained for epoch 2 by 2019-01-24 23:30:55.895873!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0190 - mean_absolute_error: 0.0993
20. set (Dataset 16) being trained for epoch 2 by 2019-01-24 23:31:17.856317!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0150 - mean_absolute_error: 0.0888
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:31:38.984211
1. set (Dataset 19) being trained for epoch 3 by 2019-01-24 23:31:43.827814!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0102 - mean_absolute_error: 0.0731
2. set (Dataset 16) being trained for epoch 3 by 2019-01-24 23:32:01.354903!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0106 - mean_absolute_error: 0.0731
3. set (Dataset 21) being trained for epoch 3 by 2019-01-24 23:32:23.871813!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0211 - mean_absolute_error: 0.1072
4. set (Dataset 15) being trained for epoch 3 by 2019-01-24 23:32:41.586012!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0096 - mean_absolute_error: 0.0715
5. set (Dataset 13) being trained for epoch 3 by 2019-01-24 23:32:58.690246!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0105 - mean_absolute_error: 0.0793
6. set (Dataset 12) being trained for epoch 3 by 2019-01-24 23:33:14.727066!
Epoch 1/1
732/732 [==============================] - 14s 18ms/step - loss: 0.0123 - mean_absolute_error: 0.0774
7. set (Dataset 18) being trained for epoch 3 by 2019-01-24 23:33:34.143864!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0163 - mean_absolute_error: 0.0985
8. set (Dataset 22) being trained for epoch 3 by 2019-01-24 23:33:51.713172!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0084 - mean_absolute_error: 0.0706
9. set (Dataset 23) being trained for epoch 3 by 2019-01-24 23:34:09.062415!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0203 - mean_absolute_error: 0.1055
10. set (Dataset 8) being trained for epoch 3 by 2019-01-24 23:34:27.093969!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0126 - mean_absolute_error: 0.0836
11. set (Dataset 17) being trained for epoch 3 by 2019-01-24 23:34:44.584468!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0101 - mean_absolute_error: 0.0760
12. set (Dataset 6) being trained for epoch 3 by 2019-01-24 23:34:57.110555!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0442 - mean_absolute_error: 0.1423
13. set (Dataset 24) being trained for epoch 3 by 2019-01-24 23:35:11.322838!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0070 - mean_absolute_error: 0.0649
14. set (Dataset 11) being trained for epoch 3 by 2019-01-24 23:35:26.271409!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0439
15. set (Dataset 10) being trained for epoch 3 by 2019-01-24 23:35:43.610551!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0149 - mean_absolute_error: 0.0780
16. set (Dataset 20) being trained for epoch 3 by 2019-01-24 23:36:01.968241!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0124 - mean_absolute_error: 0.0854
17. set (Dataset 2) being trained for epoch 3 by 2019-01-24 23:36:17.020459!
Epoch 1/1
511/511 [==============================] - 9s 17ms/step - loss: 0.0252 - mean_absolute_error: 0.1184
18. set (Dataset 4) being trained for epoch 3 by 2019-01-24 23:36:33.247167!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0081 - mean_absolute_error: 0.0682
19. set (Dataset 7) being trained for epoch 3 by 2019-01-24 23:36:54.361515!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0096 - mean_absolute_error: 0.0740
20. set (Dataset 1) being trained for epoch 3 by 2019-01-24 23:37:13.015272!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0308 - mean_absolute_error: 0.1208
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:37:26.416347
1. set (Dataset 4) being trained for epoch 4 by 2019-01-24 23:37:33.764228!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0555
2. set (Dataset 1) being trained for epoch 4 by 2019-01-24 23:37:52.128537!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0126 - mean_absolute_error: 0.0818
3. set (Dataset 17) being trained for epoch 4 by 2019-01-24 23:38:04.813978!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0184 - mean_absolute_error: 0.1038
4. set (Dataset 10) being trained for epoch 4 by 2019-01-24 23:38:19.046770!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0101 - mean_absolute_error: 0.0715
5. set (Dataset 12) being trained for epoch 4 by 2019-01-24 23:38:39.250344!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0565
6. set (Dataset 7) being trained for epoch 4 by 2019-01-24 23:39:00.079279!
Epoch 1/1
745/745 [==============================] - 13s 17ms/step - loss: 0.0071 - mean_absolute_error: 0.0633
7. set (Dataset 2) being trained for epoch 4 by 2019-01-24 23:39:18.186000!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0135 - mean_absolute_error: 0.0932
8. set (Dataset 6) being trained for epoch 4 by 2019-01-24 23:39:32.500684!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0310 - mean_absolute_error: 0.1192
9. set (Dataset 13) being trained for epoch 4 by 2019-01-24 23:39:46.952892!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0056 - mean_absolute_error: 0.0535
10. set (Dataset 23) being trained for epoch 4 by 2019-01-24 23:40:01.144982!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0351 - mean_absolute_error: 0.1433
11. set (Dataset 18) being trained for epoch 4 by 2019-01-24 23:40:17.121625!
Epoch 1/1
614/614 [==============================] - 10s 17ms/step - loss: 0.0200 - mean_absolute_error: 0.1064
12. set (Dataset 19) being trained for epoch 4 by 2019-01-24 23:40:32.525785!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0170 - mean_absolute_error: 0.0970
13. set (Dataset 11) being trained for epoch 4 by 2019-01-24 23:40:47.197762!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0215 - mean_absolute_error: 0.1086
14. set (Dataset 16) being trained for epoch 4 by 2019-01-24 23:41:06.542787!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0231 - mean_absolute_error: 0.1117
15. set (Dataset 21) being trained for epoch 4 by 2019-01-24 23:41:29.136358!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0210 - mean_absolute_error: 0.1046
16. set (Dataset 20) being trained for epoch 4 by 2019-01-24 23:41:46.282540!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0102 - mean_absolute_error: 0.0772
17. set (Dataset 24) being trained for epoch 4 by 2019-01-24 23:42:00.975552!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0573
18. set (Dataset 15) being trained for epoch 4 by 2019-01-24 23:42:16.058349!
Epoch 1/1
654/654 [==============================] - 11s 17ms/step - loss: 0.0075 - mean_absolute_error: 0.0636
19. set (Dataset 8) being trained for epoch 4 by 2019-01-24 23:42:35.132247!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0085 - mean_absolute_error: 0.0685
20. set (Dataset 22) being trained for epoch 4 by 2019-01-24 23:42:55.324093!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0592
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:43:11.876304
1. set (Dataset 15) being trained for epoch 5 by 2019-01-24 23:43:18.195452!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0569
2. set (Dataset 22) being trained for epoch 5 by 2019-01-24 23:43:36.125413!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0459
3. set (Dataset 18) being trained for epoch 5 by 2019-01-24 23:43:54.262419!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0107 - mean_absolute_error: 0.0766
4. set (Dataset 21) being trained for epoch 5 by 2019-01-24 23:44:11.394153!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0151 - mean_absolute_error: 0.0887
5. set (Dataset 7) being trained for epoch 5 by 2019-01-24 23:44:30.238235!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0071 - mean_absolute_error: 0.0608
6. set (Dataset 8) being trained for epoch 5 by 2019-01-24 23:44:51.743876!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0554
7. set (Dataset 24) being trained for epoch 5 by 2019-01-24 23:45:10.068072!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0528
8. set (Dataset 19) being trained for epoch 5 by 2019-01-24 23:45:23.796477!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0093 - mean_absolute_error: 0.0712
9. set (Dataset 12) being trained for epoch 5 by 2019-01-24 23:45:40.191505!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0049 - mean_absolute_error: 0.0517
10. set (Dataset 13) being trained for epoch 5 by 2019-01-24 23:45:58.295354!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 0.0054 - mean_absolute_error: 0.0526
11. set (Dataset 2) being trained for epoch 5 by 2019-01-24 23:46:12.386464!
Epoch 1/1
511/511 [==============================] - 9s 19ms/step - loss: 0.0104 - mean_absolute_error: 0.0785
12. set (Dataset 4) being trained for epoch 5 by 2019-01-24 23:46:29.222941!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0549
13. set (Dataset 16) being trained for epoch 5 by 2019-01-24 23:46:51.156097!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0071 - mean_absolute_error: 0.0617
14. set (Dataset 1) being trained for epoch 5 by 2019-01-24 23:47:12.594650!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0113 - mean_absolute_error: 0.0794
15. set (Dataset 17) being trained for epoch 5 by 2019-01-24 23:47:25.513729!
Epoch 1/1
395/395 [==============================] - 7s 19ms/step - loss: 0.0092 - mean_absolute_error: 0.0732
16. set (Dataset 20) being trained for epoch 5 by 2019-01-24 23:47:38.319738!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0092 - mean_absolute_error: 0.0737
17. set (Dataset 11) being trained for epoch 5 by 2019-01-24 23:47:54.037790!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0397
18. set (Dataset 10) being trained for epoch 5 by 2019-01-24 23:48:11.559828!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0070 - mean_absolute_error: 0.0608
19. set (Dataset 23) being trained for epoch 5 by 2019-01-24 23:48:29.792577!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0144 - mean_absolute_error: 0.0870
20. set (Dataset 6) being trained for epoch 5 by 2019-01-24 23:48:45.214121!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0249 - mean_absolute_error: 0.1077
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:48:59.374698
1. set (Dataset 10) being trained for epoch 6 by 2019-01-24 23:49:06.573575!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0052 - mean_absolute_error: 0.0551
2. set (Dataset 6) being trained for epoch 6 by 2019-01-24 23:49:24.838596!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0173 - mean_absolute_error: 0.0888
3. set (Dataset 2) being trained for epoch 6 by 2019-01-24 23:49:39.631715!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0077 - mean_absolute_error: 0.0692
4. set (Dataset 17) being trained for epoch 6 by 2019-01-24 23:49:52.573031!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0073 - mean_absolute_error: 0.0645
5. set (Dataset 8) being trained for epoch 6 by 2019-01-24 23:50:07.406502!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0043 - mean_absolute_error: 0.0494
6. set (Dataset 23) being trained for epoch 6 by 2019-01-24 23:50:27.103831!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0131 - mean_absolute_error: 0.0826
7. set (Dataset 11) being trained for epoch 6 by 2019-01-24 23:50:43.253015!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0417
8. set (Dataset 4) being trained for epoch 6 by 2019-01-24 23:51:00.842149!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0039 - mean_absolute_error: 0.0474
9. set (Dataset 7) being trained for epoch 6 by 2019-01-24 23:51:22.437261!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0044 - mean_absolute_error: 0.0484
10. set (Dataset 12) being trained for epoch 6 by 2019-01-24 23:51:43.644236!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0427
11. set (Dataset 24) being trained for epoch 6 by 2019-01-24 23:52:01.175568!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0501
12. set (Dataset 15) being trained for epoch 6 by 2019-01-24 23:52:16.505947!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0061 - mean_absolute_error: 0.0592
13. set (Dataset 1) being trained for epoch 6 by 2019-01-24 23:52:33.485176!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0079 - mean_absolute_error: 0.0670
14. set (Dataset 22) being trained for epoch 6 by 2019-01-24 23:52:49.063047!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0562
15. set (Dataset 18) being trained for epoch 6 by 2019-01-24 23:53:07.126958!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0093 - mean_absolute_error: 0.0715
16. set (Dataset 20) being trained for epoch 6 by 2019-01-24 23:53:23.588960!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0063 - mean_absolute_error: 0.0598
17. set (Dataset 16) being trained for epoch 6 by 2019-01-24 23:53:42.392078!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0543
18. set (Dataset 21) being trained for epoch 6 by 2019-01-24 23:54:05.002869!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0138 - mean_absolute_error: 0.0857
19. set (Dataset 13) being trained for epoch 6 by 2019-01-24 23:54:21.133237!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 0.0050 - mean_absolute_error: 0.0506
20. set (Dataset 19) being trained for epoch 6 by 2019-01-24 23:54:35.095039!
Epoch 1/1
502/502 [==============================] - 9s 19ms/step - loss: 0.0095 - mean_absolute_error: 0.0703
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-24 23:54:48.805736
1. set (Dataset 21) being trained for epoch 7 by 2019-01-24 23:54:54.776630!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0107 - mean_absolute_error: 0.0750
2. set (Dataset 19) being trained for epoch 7 by 2019-01-24 23:55:10.922457!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0069 - mean_absolute_error: 0.0577
3. set (Dataset 24) being trained for epoch 7 by 2019-01-24 23:55:24.439937!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0036 - mean_absolute_error: 0.0469
4. set (Dataset 18) being trained for epoch 7 by 2019-01-24 23:55:39.478590!
Epoch 1/1
349/614 [================>.............] - ETA: 4s - loss: 0.0078 - mean_absolute_error: 0.0676^C
Model Exp2019-01-24_23-19-57 has been interrupted.
Exp2019-01-24_23-19-57.h5 has been saved.
Model Exp2019-01-24_23-19-57 has been recorded successfully.
Terminating...
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 23:56:14.255241: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 23:56:14.335441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 23:56:14.335741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 23:56:14.335754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 23:56:14.490386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 23:56:14.490412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 23:56:14.490417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 23:56:14.490596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_23-56-15 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 10
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs10_AdamOpt_lr-0.000100_201
9-01-24_23-56-15
All frames and annotations from 20 datasets have been read by 2019-01-24 23:56:19.577075
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 23:56:25.982740!
Epoch 1/1
665/665 [==============================] - 14s 20ms/step - loss: 0.0160 - mean_absolute_error: 0.0880
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 23:56:44.604533!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0138 - mean_absolute_error: 0.0859
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 23:56:59.870706!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0201 - mean_absolute_error: 0.0985
^C
Model Exp2019-01-24_23-56-15 has been interrupted.
Exp2019-01-24_23-56-15.h5 has been saved.
Model Exp2019-01-24_23-56-15 has been recorded successfully.
Terminating...
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 23:57:27.747426: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 23:57:27.844583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 23:57:27.844886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 23:57:27.844901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 23:57:28.001055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 23:57:28.001080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 23:57:28.001085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 23:57:28.001262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_23-57-28 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 10
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs10_AdamOpt_lr-0.000100_201
9-01-24_23-57-28
All frames and annotations from 20 datasets have been read by 2019-01-24 23:57:33.212944
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 23:57:39.614227!
Epoch 1/1
406/665 [=================>............] - ETA: 5s - loss: 0.0210 - mean_absolute_error: 0.1016^C
Model Exp2019-01-24_23-57-28 has been interrupted.
Exp2019-01-24_23-57-28.h5 has been saved.
Model Exp2019-01-24_23-57-28 has been recorded successfully.
Terminating...
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-24 23:58:25.678998: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-24 23:58:25.775792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-24 23:58:25.776098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-24 23:58:25.776113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-24 23:58:25.932021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-24 23:58:25.932046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-24 23:58:25.932050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-24 23:58:25.932229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-24_23-58-26 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019
-01-24_23-58-26
All frames and annotations from 20 datasets have been read by 2019-01-24 23:58:30.921022
1. set (Dataset 22) being trained for epoch 1 by 2019-01-24 23:58:37.316285!
Epoch 1/1
665/665 [==============================] - 13s 20ms/step - loss: 0.0193 - mean_absolute_error: 0.0962
2. set (Dataset 24) being trained for epoch 1 by 2019-01-24 23:58:55.460263!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0142 - mean_absolute_error: 0.0838
3. set (Dataset 15) being trained for epoch 1 by 2019-01-24 23:59:10.633704!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0186 - mean_absolute_error: 0.0971
4. set (Dataset 19) being trained for epoch 1 by 2019-01-24 23:59:27.438082!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0145 - mean_absolute_error: 0.0879
5. set (Dataset 8) being trained for epoch 1 by 2019-01-24 23:59:44.207879!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0510 - mean_absolute_error: 0.1739
6. set (Dataset 23) being trained for epoch 1 by 2019-01-25 00:00:03.962270!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0330 - mean_absolute_error: 0.1359
7. set (Dataset 21) being trained for epoch 1 by 2019-01-25 00:00:20.363327!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0303 - mean_absolute_error: 0.1275
8. set (Dataset 16) being trained for epoch 1 by 2019-01-25 00:00:40.457688!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0143 - mean_absolute_error: 0.0878
9. set (Dataset 7) being trained for epoch 1 by 2019-01-25 00:01:04.268780!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0390 - mean_absolute_error: 0.1392
10. set (Dataset 12) being trained for epoch 1 by 2019-01-25 00:01:25.264405!
Epoch 1/1
732/732 [==============================] - 13s 17ms/step - loss: 0.0280 - mean_absolute_error: 0.1251
11. set (Dataset 10) being trained for epoch 1 by 2019-01-25 00:01:45.160887!
Epoch 1/1
726/726 [==============================] - 13s 19ms/step - loss: 0.0284 - mean_absolute_error: 0.1150
12. set (Dataset 1) being trained for epoch 1 by 2019-01-25 00:02:03.739638!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0358 - mean_absolute_error: 0.1401
13. set (Dataset 18) being trained for epoch 1 by 2019-01-25 00:02:18.844782!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0233 - mean_absolute_error: 0.1131
14. set (Dataset 2) being trained for epoch 1 by 2019-01-25 00:02:35.089971!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0670 - mean_absolute_error: 0.1998
15. set (Dataset 4) being trained for epoch 1 by 2019-01-25 00:02:51.671153!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0369 - mean_absolute_error: 0.1558
16. set (Dataset 20) being trained for epoch 1 by 2019-01-25 00:03:10.632889!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0276 - mean_absolute_error: 0.1248
17. set (Dataset 17) being trained for epoch 1 by 2019-01-25 00:03:24.402477!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0133 - mean_absolute_error: 0.0868
18. set (Dataset 6) being trained for epoch 1 by 2019-01-25 00:03:36.713636!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0447 - mean_absolute_error: 0.1491
19. set (Dataset 13) being trained for epoch 1 by 2019-01-25 00:03:51.363614!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0141 - mean_absolute_error: 0.0899
20. set (Dataset 11) being trained for epoch 1 by 2019-01-25 00:04:05.400556!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0178 - mean_absolute_error: 0.0952
Epoch 1 completed!
Exp2019-01-24_23-58-26.h5 has been saved.
The subjects are trained: [(22, 'M01'), (24, 'M14'), (15, 'F03'), (19, 'M11'), (8, 'M02'), (23, 'M13'), (21, 'F02'),
(16, 'M09'), (7, 'M01'), (12, 'M06'), (10, 'M04'), (1, 'F01'), (18, 'F05'), (2, 'F02'), (4, 'F04'), (20, 'M12'), (17,
 'M10'), (6, 'F06'), (13, 'M07'), (11, 'M05')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_20
19-01-24_23-58-26
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 00:04:17.905473
For the Subject 3 (F03):
730/730 [==============================] - 7s 9ms/step
        The absolute mean error on Pitch angle estimation: 19.81 Degree
        The absolute mean error on Yaw angle estimation: 44.90 Degree
        The absolute mean error on Roll angle estimation: 38.87 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Pitch angle estimation: 14.42 Degree
        The absolute mean error on Yaw angle estimation: 31.58 Degree
        The absolute mean error on Roll angle estimation: 5.68 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 22.72 Degree
        The absolute mean error on Yaw angle estimation: 25.20 Degree
        The absolute mean error on Roll angle estimation: 6.84 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 13.38 Degree
        The absolute mean error on Yaw angle estimation: 37.81 Degree
        The absolute mean error on Roll angle estimation: 18.46 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 17.58 Degree
        The absolute mean error on Yaw angle estimations: 34.87 Degree
        The absolute mean error on Roll angle estimations: 17.46 Degree
subject3_Exp2019-01-24_23-58-26.png has been saved by 2019-01-25 00:05:23.529928.
subject5_Exp2019-01-24_23-58-26.png has been saved by 2019-01-25 00:05:23.731394.
subject9_Exp2019-01-24_23-58-26.png has been saved by 2019-01-25 00:05:23.930828.
subject14_Exp2019-01-24_23-58-26.png has been saved by 2019-01-25 00:05:24.149558.
Model Exp2019-01-24_23-58-26 has been evaluated successfully.
Model Exp2019-01-24_23-58-26 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git add --all
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git commit -m "1 epoch trainings"
[master 7e60581] 1 epoch trainings
 33 files changed, 1589 insertions(+), 6955 deletions(-)
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/output_Exp2019-0
1-24_03-29-04_and_2019-01-24_19-28-43.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject14_Exp201
9-01-24_03-29-04_and_2019-01-24_19-28-43.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject3_Exp2019
-01-24_03-29-04_and_2019-01-24_19-28-43.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject5_Exp2019
-01-24_03-29-04_and_2019-01-24_19-28-43.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject9_Exp2019
-01-24_03-29-04_and_2019-01-24_19-28-43.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45/output_Exp2019-0
1-24_19-28-43_and_2019-01-24_20-31-45.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45/subject14_Exp201
9-01-24_19-28-43_and_2019-01-24_20-31-45.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45/subject3_Exp2019
-01-24_19-28-43_and_2019-01-24_20-31-45.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45/subject5_Exp2019
-01-24_19-28-43_and_2019-01-24_20-31-45.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_19-28-43_and_2019-01-24_20-31-45/subject9_Exp2019
-01-24_19-28-43_and_2019-01-24_20-31-45.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46/output_Exp2019-01-24_22-38-46.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09/output_Exp2019-0
1-24_22-38-46_and_2019-01-24_23-18-09.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09/subject14_Exp201
9-01-24_22-38-46_and_2019-01-24_23-18-09.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09/subject3_Exp2019
-01-24_22-38-46_and_2019-01-24_23-18-09.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09/subject5_Exp2019
-01-24_22-38-46_and_2019-01-24_23-18-09.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46_and_2019-01-24_23-18-09/subject9_Exp2019
-01-24_22-38-46_and_2019-01-24_23-18-09.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-19-57/output_Exp2019-01-24_23-19-57.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-56-15/output_Exp2019-01-24_23-56-15.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-57-28/output_Exp2019-01-24_23-57-28.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-58-26/output_Exp2019-01-24_23-58-26.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-58-26/subject14_Exp2019-01-24_23-58-26.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-58-26/subject3_Exp2019-01-24_23-58-26.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-58-26/subject5_Exp2019-01-24_23-58-26.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-58-26/subject9_Exp2019-01-24_23-58-26.png
 rewrite DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_/output_Last_Model.txt (100%)
 rewrite DeepRL_For_HPE/LSTM_VGG16/results/Last_Model__/output_Last_Model.txt (100%)
 rewrite DeepRL_For_HPE/LSTM_VGG16/results/Last_Model___/output_Last_Model.txt (100%)
 copy DeepRL_For_HPE/LSTM_VGG16/results/{Last_Model__ => Last_Model_____}/output_Last_Model.txt (100%)
 copy DeepRL_For_HPE/LSTM_VGG16/results/{Last_Model___ => Last_Model______}/output_Last_Model.txt (100%)
 copy DeepRL_For_HPE/LSTM_VGG16/results/{Last_Model_ => Last_Model_______}/output_Last_Model.txt (99%)
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git push
Password for 'https://muratcancicek@bitbucket.org':
Counting objects: 41, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (39/39), done.
Writing objects: 100% (41/41), 2.79 MiB | 845.00 KiB/s, done.
Total 41 (delta 11), reused 0 (delta 0)
To https://muratcancicek@bitbucket.org/muratcancicek/deep_rl_for_head_pose_est.git
   108b39d..7e60581  master -> master
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git pull
remote: Counting objects: 7, done.
remote: Compressing objects: 100% (7/7), done.
remote: Total 7 (delta 5), reused 0 (delta 0)
Unpacking objects: 100% (7/7), done.
From https://bitbucket.org/muratcancicek/deep_rl_for_head_pose_est
   7e60581..c8143d6  master     -> origin/master
Updating 7e60581..c8143d6
Fast-forward
 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-14_03-28-28/Model.txt         |     1 -
 .../results/Exp2019-01-14_03-28-28/subject9_2019-01-14_03-28-28.png        |   Bin 159574 -> 0 bytes
 .../output_Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26.txt              |    45 -
 .../scrollback_Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26.txt          |  1051 --
 .../subject18_Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26.png           |   Bin 181575 -> 0 bytes
 .../subject21_Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26.png           |   Bin 179552 -> 0 bytes
 .../subject24_Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26.png           |   Bin 163604 -> 0 bytes
 .../subject9_Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26.png            |   Bin 176672 -> 0 bytes
 .../results/Exp2019-01-22_04-52-46/output_Exp2019-01-22_04-52-46.txt       |   514 -
 .../results/Exp2019-01-22_04-52-46/scrollback_Exp2019-01-22_04-52-46.txt   |  1367 ---
 .../results/Exp2019-01-22_04-52-46/subject18_Exp2019-01-22_04-52-46.png    |   Bin 176038 -> 0 bytes
 .../results/Exp2019-01-22_04-52-46/subject21_Exp2019-01-22_04-52-46.png    |   Bin 180003 -> 0 bytes
 .../results/Exp2019-01-22_04-52-46/subject24_Exp2019-01-22_04-52-46.png    |   Bin 158789 -> 0 bytes
 .../results/Exp2019-01-22_04-52-46/subject9_Exp2019-01-22_04-52-46.png     |   Bin 169024 -> 0 bytes
 .../output_Exp2019-01-22_21-11-39_and_2019-01-22_22-32-44.txt              |   491 -
 .../subject9_Exp2019-01-22_21-11-39_and_2019-01-22_22-32-44.png            |   Bin 156021 -> 0 bytes
 .../results/Exp2019-01-22_22-43-59/output_Exp2019-01-22_22-43-59.txt       |    99 -
 .../results/Exp2019-01-22_22-43-59/subject9_Exp2019-01-22_22-43-59.png     |   Bin 166187 -> 0 bytes
 .../output_Exp2019-01-22_22-49-31_and_2019-01-22_23-15-08.txt              |    55 -
 .../subject9_Exp2019-01-22_22-49-31_and_2019-01-22_23-15-08.png            |   Bin 136419 -> 0 bytes
 .../results/Exp2019-01-22_23-22-00/output_Exp2019-01-22_23-22-00.txt       |   111 -
 .../results/Exp2019-01-22_23-22-00/subject9_Exp2019-01-22_23-22-00.png     |   Bin 118095 -> 0 bytes
 .../results/Exp2019-01-22_23-48-13/output_Exp2019-01-22_23-48-13.txt       |    92 -
 .../results/Exp2019-01-22_23-48-13/subject9_Exp2019-01-22_23-48-13.png     |   Bin 177866 -> 0 bytes
 .../results/Exp2019-01-23_00-03-42/output_Exp2019-01-23_00-03-42.txt       |   115 -
 .../results/Exp2019-01-23_00-03-42/subject9_Exp2019-01-23_00-03-42.png     |   Bin 168748 -> 0 bytes
 .../results/Exp2019-01-23_00-15-57/output_Exp2019-01-23_00-15-57.txt       |   252 -
 .../results/Exp2019-01-23_00-15-57/subject18_Exp2019-01-23_00-15-57.png    |   Bin 189184 -> 0 bytes
 .../results/Exp2019-01-23_00-15-57/subject21_Exp2019-01-23_00-15-57.png    |   Bin 193841 -> 0 bytes
 .../results/Exp2019-01-23_00-15-57/subject24_Exp2019-01-23_00-15-57.png    |   Bin 163658 -> 0 bytes
 .../results/Exp2019-01-23_00-15-57/subject9_Exp2019-01-23_00-15-57.png     |   Bin 168395 -> 0 bytes
 .../results/Exp2019-01-23_01-52-53/output_Exp2019-01-23_01-52-53.txt       |    77 -
 .../results/Exp2019-01-23_01-54-26/output_Exp2019-01-23_01-54-26.txt       |   228 -
 .../results/Exp2019-01-23_01-54-26/subject18_Exp2019-01-23_01-54-26.png    |   Bin 179267 -> 0 bytes
 .../results/Exp2019-01-23_01-54-26/subject21_Exp2019-01-23_01-54-26.png    |   Bin 186841 -> 0 bytes
 .../results/Exp2019-01-23_01-54-26/subject24_Exp2019-01-23_01-54-26.png    |   Bin 166394 -> 0 bytes
 .../results/Exp2019-01-23_01-54-26/subject9_Exp2019-01-23_01-54-26.png     |   Bin 168153 -> 0 bytes
 .../results/Exp2019-01-23_02-44-12/output_Exp2019-01-23_02-44-12.txt       |   224 -
 .../results/Exp2019-01-23_02-44-12/subject18_Exp2019-01-23_02-44-12.png    |   Bin 176344 -> 0 bytes
 .../results/Exp2019-01-23_02-44-12/subject21_Exp2019-01-23_02-44-12.png    |   Bin 184855 -> 0 bytes
 .../results/Exp2019-01-23_02-44-12/subject24_Exp2019-01-23_02-44-12.png    |   Bin 172651 -> 0 bytes
 .../results/Exp2019-01-23_02-44-12/subject9_Exp2019-01-23_02-44-12.png     |   Bin 168070 -> 0 bytes
 .../results/Exp2019-01-23_03-41-32/output_Exp2019-01-23_03-41-32.txt       |   938 --
 .../results/Exp2019-01-23_03-41-32/scrollback_Exp2019-01-23_03-41-32.txt   |  2617 -----
 .../results/Exp2019-01-23_03-41-32/subject18_Exp2019-01-23_03-41-32.png    |   Bin 182911 -> 0 bytes
 .../results/Exp2019-01-23_03-41-32/subject21_Exp2019-01-23_03-41-32.png    |   Bin 191919 -> 0 bytes
 .../results/Exp2019-01-23_03-41-32/subject24_Exp2019-01-23_03-41-32.png    |   Bin 166652 -> 0 bytes
 .../results/Exp2019-01-23_03-41-32/subject9_Exp2019-01-23_03-41-32.png     |   Bin 162886 -> 0 bytes
 .../results/Exp2019-01-24_00-14-10/output_Exp2019-01-24_00-14-10.txt       |   278 -
 .../results/Exp2019-01-24_00-14-10/subject1_Exp2019-01-24_00-14-10.png     |   Bin 147694 -> 0 bytes
 .../results/Exp2019-01-24_01-10-43/output_Exp2019-01-24_01-10-43.txt       |    97 -
 .../results/Exp2019-01-24_01-38-02/output_Exp2019-01-24_01-38-02.txt       |  2309 ----
 .../results/Exp2019-01-24_01-41-06/output_Exp2019-01-24_01-41-06.txt       |  2323 ----
 .../results/Exp2019-01-24_01-41-06/subject1_Exp2019-01-24_01-41-06.png     |   Bin 162990 -> 0 bytes
 .../results/Exp2019-01-24_01-57-24/output_Exp2019-01-24_01-57-24.txt       |  2323 ----
 .../results/Exp2019-01-24_01-57-24/subject9_Exp2019-01-24_01-57-24.png     |   Bin 186685 -> 0 bytes
 .../results/Exp2019-01-24_02-05-24/output_Exp2019-01-24_02-05-24.txt       |  2323 ----
 .../results/Exp2019-01-24_02-05-24/subject9_Exp2019-01-24_02-05-24.png     |   Bin 181291 -> 0 bytes
 .../results/Exp2019-01-24_02-12-24/output_Exp2019-01-24_02-12-24.txt       |  2323 ----
 .../results/Exp2019-01-24_02-12-24/subject9_Exp2019-01-24_02-12-24.png     |   Bin 119747 -> 0 bytes
 .../results/Exp2019-01-24_02-19-26/output_Exp2019-01-24_02-19-26.txt       |  2323 ----
 .../results/Exp2019-01-24_02-19-26/subject9_Exp2019-01-24_02-19-26.png     |   Bin 161521 -> 0 bytes
 .../results/Exp2019-01-24_03-02-10/output_Exp2019-01-24_03-02-10.txt       |   109 -
 .../results/Exp2019-01-24_03-02-10/subject9_Exp2019-01-24_03-02-10.png     |   Bin 192567 -> 0 bytes
 .../results/Exp2019-01-24_03-04-49/output_Exp2019-01-24_03-04-49.txt       |   111 -
 .../results/Exp2019-01-24_03-04-49/subject9_Exp2019-01-24_03-04-49.png     |   Bin 182664 -> 0 bytes
 .../results/Exp2019-01-24_03-06-36/output_Exp2019-01-24_03-06-36.txt       |   109 -
 .../results/Exp2019-01-24_03-06-36/subject9_Exp2019-01-24_03-06-36.png     |   Bin 199294 -> 0 bytes
 .../results/Exp2019-01-24_03-07-59/output_Exp2019-01-24_03-07-59.txt       |   109 -
 .../results/Exp2019-01-24_03-07-59/subject9_Exp2019-01-24_03-07-59.png     |   Bin 182666 -> 0 bytes
 .../results/Exp2019-01-24_03-11-06/output_Exp2019-01-24_03-11-06.txt       |   109 -
 .../results/Exp2019-01-24_03-11-06/subject9_Exp2019-01-24_03-11-06.png     |   Bin 188452 -> 0 bytes
 .../results/Exp2019-01-24_03-12-41/output_Exp2019-01-24_03-12-41.txt       |   109 -
 .../results/Exp2019-01-24_03-12-41/subject9_Exp2019-01-24_03-12-41.png     |   Bin 202673 -> 0 bytes
 .../results/Exp2019-01-24_03-13-55/output_Exp2019-01-24_03-13-55.txt       |   109 -
 .../results/Exp2019-01-24_03-13-55/subject9_Exp2019-01-24_03-13-55.png     |   Bin 178882 -> 0 bytes
 .../results/Exp2019-01-24_03-16-04/output_Exp2019-01-24_03-16-04.txt       |   109 -
 .../results/Exp2019-01-24_03-16-04/subject9_Exp2019-01-24_03-16-04.png     |   Bin 116057 -> 0 bytes
 .../results/Exp2019-01-24_03-17-17/output_Exp2019-01-24_03-17-17.txt       |   109 -
 .../results/Exp2019-01-24_03-17-17/subject9_Exp2019-01-24_03-17-17.png     |   Bin 155824 -> 0 bytes
 .../results/Exp2019-01-24_03-18-30/output_Exp2019-01-24_03-18-30.txt       |   109 -
 .../results/Exp2019-01-24_03-18-30/subject9_Exp2019-01-24_03-18-30.png     |   Bin 177064 -> 0 bytes
 .../results/Exp2019-01-24_03-20-01/output_Exp2019-01-24_03-20-01.txt       |   109 -
 .../results/Exp2019-01-24_03-20-01/subject9_Exp2019-01-24_03-20-01.png     |   Bin 183268 -> 0 bytes
 .../results/Exp2019-01-24_03-23-13/output_Exp2019-01-24_03-23-13.txt       |   113 -
 .../results/Exp2019-01-24_03-23-13/subject9_Exp2019-01-24_03-23-13.png     |   Bin 171607 -> 0 bytes
 .../results/Exp2019-01-24_03-29-04/output_Exp2019-01-24_03-29-04.txt       |  1173 --
 .../results/Exp2019-01-24_03-29-04/scrollback_Exp2019-01-24_03-29-04.txt   | 19407 --------------------------------
 .../results/Exp2019-01-24_03-29-04/subject14_Exp2019-01-24_03-29-04.png    |   Bin 230514 -> 0 bytes
 .../results/Exp2019-01-24_03-29-04/subject3_Exp2019-01-24_03-29-04.png     |   Bin 189349 -> 0 bytes
 .../results/Exp2019-01-24_03-29-04/subject5_Exp2019-01-24_03-29-04.png     |   Bin 194730 -> 0 bytes
 .../results/Exp2019-01-24_03-29-04/subject9_Exp2019-01-24_03-29-04.png     |   Bin 202996 -> 0 bytes
 .../output_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.txt              |   254 -
 .../subject14_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png           |   Bin 221538 -> 0 bytes
 .../subject3_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png            |   Bin 179795 -> 0 bytes
 .../subject5_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png            |   Bin 187987 -> 0 bytes
 .../subject9_Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43.png            |   Bin 193804 -> 0 bytes
 .../results/Exp2019-01-24_22-38-46/output_Exp2019-01-24_22-38-46.txt       |   234 -
 .../results/Exp2019-01-24_23-19-57/output_Exp2019-01-24_23-19-57.txt       |   226 -
 .../results/Exp2019-01-24_23-56-15/output_Exp2019-01-24_23-56-15.txt       |    99 -
 .../results/Exp2019-01-24_23-57-28/output_Exp2019-01-24_23-57-28.txt       |    97 -
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_/output_Last_Model.txt        |     1 -
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model__/output_Last_Model.txt       |     1 -
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model___/output_Last_Model.txt      |     1 -
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model____/output_Last_Model.txt     |  2313 ----
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_____/output_Last_Model.txt    |  2309 ----
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model______/output_Last_Model.txt   |  2309 ----
 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_______/output_Last_Model.txt  |  2309 ----
 DeepRL_For_HPE/Note_Files/commands.txt                                     |     2 +-
 109 files changed, 1 insertion(+), 54624 deletions(-)
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-14_03-28-28/Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-14_03-28-28/subject9_2019-01-14_03-28-28.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26/output_Exp2019-0
1-16_03-24-38_and_2019-01-20_00-46-26.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26/scrollback_Exp20
19-01-16_03-24-38_and_2019-01-20_00-46-26.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26/subject18_Exp201
9-01-16_03-24-38_and_2019-01-20_00-46-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26/subject21_Exp201
9-01-16_03-24-38_and_2019-01-20_00-46-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26/subject24_Exp201
9-01-16_03-24-38_and_2019-01-20_00-46-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-16_03-24-38_and_2019-01-20_00-46-26/subject9_Exp2019
-01-16_03-24-38_and_2019-01-20_00-46-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_04-52-46/output_Exp2019-01-22_04-52-46.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_04-52-46/scrollback_Exp2019-01-22_04-52-46.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_04-52-46/subject18_Exp2019-01-22_04-52-46.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_04-52-46/subject21_Exp2019-01-22_04-52-46.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_04-52-46/subject24_Exp2019-01-22_04-52-46.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_04-52-46/subject9_Exp2019-01-22_04-52-46.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_21-11-39_and_2019-01-22_22-32-44/output_Exp2019-0
1-22_21-11-39_and_2019-01-22_22-32-44.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_21-11-39_and_2019-01-22_22-32-44/subject9_Exp2019
-01-22_21-11-39_and_2019-01-22_22-32-44.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_22-43-59/output_Exp2019-01-22_22-43-59.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_22-43-59/subject9_Exp2019-01-22_22-43-59.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_22-49-31_and_2019-01-22_23-15-08/output_Exp2019-0
1-22_22-49-31_and_2019-01-22_23-15-08.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_22-49-31_and_2019-01-22_23-15-08/subject9_Exp2019
-01-22_22-49-31_and_2019-01-22_23-15-08.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_23-22-00/output_Exp2019-01-22_23-22-00.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_23-22-00/subject9_Exp2019-01-22_23-22-00.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_23-48-13/output_Exp2019-01-22_23-48-13.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-22_23-48-13/subject9_Exp2019-01-22_23-48-13.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-03-42/output_Exp2019-01-23_00-03-42.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-03-42/subject9_Exp2019-01-23_00-03-42.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-15-57/output_Exp2019-01-23_00-15-57.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-15-57/subject18_Exp2019-01-23_00-15-57.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-15-57/subject21_Exp2019-01-23_00-15-57.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-15-57/subject24_Exp2019-01-23_00-15-57.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_00-15-57/subject9_Exp2019-01-23_00-15-57.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_01-52-53/output_Exp2019-01-23_01-52-53.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_01-54-26/output_Exp2019-01-23_01-54-26.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_01-54-26/subject18_Exp2019-01-23_01-54-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_01-54-26/subject21_Exp2019-01-23_01-54-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_01-54-26/subject24_Exp2019-01-23_01-54-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_01-54-26/subject9_Exp2019-01-23_01-54-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_02-44-12/output_Exp2019-01-23_02-44-12.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_02-44-12/subject18_Exp2019-01-23_02-44-12.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_02-44-12/subject21_Exp2019-01-23_02-44-12.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_02-44-12/subject24_Exp2019-01-23_02-44-12.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_02-44-12/subject9_Exp2019-01-23_02-44-12.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_03-41-32/output_Exp2019-01-23_03-41-32.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_03-41-32/scrollback_Exp2019-01-23_03-41-32.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_03-41-32/subject18_Exp2019-01-23_03-41-32.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_03-41-32/subject21_Exp2019-01-23_03-41-32.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_03-41-32/subject24_Exp2019-01-23_03-41-32.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-23_03-41-32/subject9_Exp2019-01-23_03-41-32.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_00-14-10/output_Exp2019-01-24_00-14-10.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_00-14-10/subject1_Exp2019-01-24_00-14-10.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_01-10-43/output_Exp2019-01-24_01-10-43.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_01-38-02/output_Exp2019-01-24_01-38-02.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_01-41-06/output_Exp2019-01-24_01-41-06.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_01-41-06/subject1_Exp2019-01-24_01-41-06.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_01-57-24/output_Exp2019-01-24_01-57-24.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_01-57-24/subject9_Exp2019-01-24_01-57-24.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_02-05-24/output_Exp2019-01-24_02-05-24.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_02-05-24/subject9_Exp2019-01-24_02-05-24.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_02-12-24/output_Exp2019-01-24_02-12-24.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_02-12-24/subject9_Exp2019-01-24_02-12-24.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_02-19-26/output_Exp2019-01-24_02-19-26.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_02-19-26/subject9_Exp2019-01-24_02-19-26.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-02-10/output_Exp2019-01-24_03-02-10.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-02-10/subject9_Exp2019-01-24_03-02-10.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-04-49/output_Exp2019-01-24_03-04-49.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-04-49/subject9_Exp2019-01-24_03-04-49.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-06-36/output_Exp2019-01-24_03-06-36.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-06-36/subject9_Exp2019-01-24_03-06-36.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-07-59/output_Exp2019-01-24_03-07-59.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-07-59/subject9_Exp2019-01-24_03-07-59.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-11-06/output_Exp2019-01-24_03-11-06.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-11-06/subject9_Exp2019-01-24_03-11-06.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-12-41/output_Exp2019-01-24_03-12-41.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-12-41/subject9_Exp2019-01-24_03-12-41.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-13-55/output_Exp2019-01-24_03-13-55.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-13-55/subject9_Exp2019-01-24_03-13-55.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-16-04/output_Exp2019-01-24_03-16-04.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-16-04/subject9_Exp2019-01-24_03-16-04.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-17-17/output_Exp2019-01-24_03-17-17.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-17-17/subject9_Exp2019-01-24_03-17-17.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-18-30/output_Exp2019-01-24_03-18-30.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-18-30/subject9_Exp2019-01-24_03-18-30.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-20-01/output_Exp2019-01-24_03-20-01.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-20-01/subject9_Exp2019-01-24_03-20-01.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-23-13/output_Exp2019-01-24_03-23-13.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-23-13/subject9_Exp2019-01-24_03-23-13.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04/output_Exp2019-01-24_03-29-04.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04/scrollback_Exp2019-01-24_03-29-04.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04/subject14_Exp2019-01-24_03-29-04.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04/subject3_Exp2019-01-24_03-29-04.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04/subject5_Exp2019-01-24_03-29-04.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04/subject9_Exp2019-01-24_03-29-04.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/output_Exp2019-0
1-24_03-29-04_and_2019-01-24_19-28-43.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject14_Exp201
9-01-24_03-29-04_and_2019-01-24_19-28-43.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject3_Exp2019
-01-24_03-29-04_and_2019-01-24_19-28-43.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject5_Exp2019
-01-24_03-29-04_and_2019-01-24_19-28-43.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_03-29-04_and_2019-01-24_19-28-43/subject9_Exp2019
-01-24_03-29-04_and_2019-01-24_19-28-43.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_22-38-46/output_Exp2019-01-24_22-38-46.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-19-57/output_Exp2019-01-24_23-19-57.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-56-15/output_Exp2019-01-24_23-56-15.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-24_23-57-28/output_Exp2019-01-24_23-57-28.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_/output_Last_Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model__/output_Last_Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model___/output_Last_Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model____/output_Last_Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_____/output_Last_Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model______/output_Last_Model.txt
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model_______/output_Last_Model.txt
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-24_23-58-26 trainMore
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 01:00:49.710810: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 01:00:49.808400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 01:00:49.808668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 01:00:49.808682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 01:00:49.964423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 01:00:49.964449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 01:00:49.964457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 01:00:49.964598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10471 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-24_23-58-26.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

Training model Exp2019-01-24_23-58-26_and_2019-01-25_01-00-50
All frames and annotations from 20 datasets have been read by 2019-01-25 01:00:55.291479
1. set (Dataset 22) being trained for epoch 1 by 2019-01-25 01:01:01.703416!
Epoch 1/1
665/665 [==============================] - 13s 20ms/step - loss: 0.0136 - mean_absolute_error: 0.0841
2. set (Dataset 24) being trained for epoch 1 by 2019-01-25 01:01:19.489056!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0088 - mean_absolute_error: 0.0693
3. set (Dataset 15) being trained for epoch 1 by 2019-01-25 01:01:35.069446!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0184 - mean_absolute_error: 0.0946
4. set (Dataset 19) being trained for epoch 1 by 2019-01-25 01:01:51.718790!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0130 - mean_absolute_error: 0.0852
5. set (Dataset 8) being trained for epoch 1 by 2019-01-25 01:02:08.452734!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0196 - mean_absolute_error: 0.1037
6. set (Dataset 23) being trained for epoch 1 by 2019-01-25 01:02:28.010292!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0243 - mean_absolute_error: 0.1166
7. set (Dataset 21) being trained for epoch 1 by 2019-01-25 01:02:44.394112!
Epoch 1/1
634/634 [==============================] - 11s 17ms/step - loss: 0.0235 - mean_absolute_error: 0.1160
8. set (Dataset 16) being trained for epoch 1 by 2019-01-25 01:03:04.313346!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0100 - mean_absolute_error: 0.0753
9. set (Dataset 7) being trained for epoch 1 by 2019-01-25 01:03:29.080434!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0140 - mean_absolute_error: 0.0864
10. set (Dataset 12) being trained for epoch 1 by 2019-01-25 01:03:50.034971!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0125 - mean_absolute_error: 0.0864
11. set (Dataset 10) being trained for epoch 1 by 2019-01-25 01:04:10.473111!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0101 - mean_absolute_error: 0.0698
12. set (Dataset 1) being trained for epoch 1 by 2019-01-25 01:04:28.435449!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0168 - mean_absolute_error: 0.0936
13. set (Dataset 18) being trained for epoch 1 by 2019-01-25 01:04:43.429030!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0149 - mean_absolute_error: 0.0949
14. set (Dataset 2) being trained for epoch 1 by 2019-01-25 01:04:59.690087!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0407 - mean_absolute_error: 0.1539
15. set (Dataset 4) being trained for epoch 1 by 2019-01-25 01:05:16.334337!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0131 - mean_absolute_error: 0.0884
16. set (Dataset 20) being trained for epoch 1 by 2019-01-25 01:05:35.125089!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0130 - mean_absolute_error: 0.0836
17. set (Dataset 17) being trained for epoch 1 by 2019-01-25 01:05:48.931898!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0104 - mean_absolute_error: 0.0764
18. set (Dataset 6) being trained for epoch 1 by 2019-01-25 01:06:01.390361!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0290 - mean_absolute_error: 0.1210
19. set (Dataset 13) being trained for epoch 1 by 2019-01-25 01:06:16.171205!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0097 - mean_absolute_error: 0.0739
20. set (Dataset 11) being trained for epoch 1 by 2019-01-25 01:06:30.688006!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0156 - mean_absolute_error: 0.0845
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:06:45.186303
1. set (Dataset 6) being trained for epoch 2 by 2019-01-25 01:06:50.379905!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0193 - mean_absolute_error: 0.0992
2. set (Dataset 11) being trained for epoch 2 by 2019-01-25 01:07:05.868680!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0082 - mean_absolute_error: 0.0676
3. set (Dataset 10) being trained for epoch 2 by 2019-01-25 01:07:23.235195!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0212 - mean_absolute_error: 0.0977
4. set (Dataset 4) being trained for epoch 2 by 2019-01-25 01:07:43.867976!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0107 - mean_absolute_error: 0.0812
5. set (Dataset 23) being trained for epoch 2 by 2019-01-25 01:08:02.704483!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0196 - mean_absolute_error: 0.1012
6. set (Dataset 13) being trained for epoch 2 by 2019-01-25 01:08:18.054434!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0065 - mean_absolute_error: 0.0599
7. set (Dataset 17) being trained for epoch 2 by 2019-01-25 01:08:30.541286!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0100 - mean_absolute_error: 0.0757
8. set (Dataset 1) being trained for epoch 2 by 2019-01-25 01:08:42.678766!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0344 - mean_absolute_error: 0.1358
9. set (Dataset 8) being trained for epoch 2 by 2019-01-25 01:08:59.309922!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0143 - mean_absolute_error: 0.0842
10. set (Dataset 7) being trained for epoch 2 by 2019-01-25 01:09:21.407646!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0090 - mean_absolute_error: 0.0699
11. set (Dataset 21) being trained for epoch 2 by 2019-01-25 01:09:40.703814!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0195 - mean_absolute_error: 0.1040
12. set (Dataset 22) being trained for epoch 2 by 2019-01-25 01:09:58.644687!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0081 - mean_absolute_error: 0.0638
13. set (Dataset 2) being trained for epoch 2 by 2019-01-25 01:10:15.454800!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0342 - mean_absolute_error: 0.1289
14. set (Dataset 24) being trained for epoch 2 by 2019-01-25 01:10:29.138416!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0082 - mean_absolute_error: 0.0669
15. set (Dataset 15) being trained for epoch 2 by 2019-01-25 01:10:44.368492!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0096 - mean_absolute_error: 0.0719
16. set (Dataset 20) being trained for epoch 2 by 2019-01-25 01:11:01.955830!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0100 - mean_absolute_error: 0.0752
17. set (Dataset 18) being trained for epoch 2 by 2019-01-25 01:11:17.891896!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0136 - mean_absolute_error: 0.0889
18. set (Dataset 19) being trained for epoch 2 by 2019-01-25 01:11:33.936063!
Epoch 1/1
502/502 [==============================] - 9s 17ms/step - loss: 0.0103 - mean_absolute_error: 0.0732
19. set (Dataset 12) being trained for epoch 2 by 2019-01-25 01:11:49.968427!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0109 - mean_absolute_error: 0.0721
20. set (Dataset 16) being trained for epoch 2 by 2019-01-25 01:12:11.867653!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0089 - mean_absolute_error: 0.0665
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:12:32.514744
1. set (Dataset 19) being trained for epoch 3 by 2019-01-25 01:12:37.388589!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0072 - mean_absolute_error: 0.0601
2. set (Dataset 16) being trained for epoch 3 by 2019-01-25 01:12:55.188653!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0061 - mean_absolute_error: 0.0563
3. set (Dataset 21) being trained for epoch 3 by 2019-01-25 01:13:17.537832!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0135 - mean_absolute_error: 0.0847
4. set (Dataset 15) being trained for epoch 3 by 2019-01-25 01:13:35.171778!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0078 - mean_absolute_error: 0.0651
5. set (Dataset 13) being trained for epoch 3 by 2019-01-25 01:13:51.785012!
Epoch 1/1
485/485 [==============================] - 9s 19ms/step - loss: 0.0050 - mean_absolute_error: 0.0533
6. set (Dataset 12) being trained for epoch 3 by 2019-01-25 01:14:08.313086!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0089 - mean_absolute_error: 0.0644
7. set (Dataset 18) being trained for epoch 3 by 2019-01-25 01:14:27.512442!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0104 - mean_absolute_error: 0.0779
8. set (Dataset 22) being trained for epoch 3 by 2019-01-25 01:14:44.808043!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0061 - mean_absolute_error: 0.0547
9. set (Dataset 23) being trained for epoch 3 by 2019-01-25 01:15:02.037262!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0143 - mean_absolute_error: 0.0877
10. set (Dataset 8) being trained for epoch 3 by 2019-01-25 01:15:20.308699!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0082 - mean_absolute_error: 0.0674
11. set (Dataset 17) being trained for epoch 3 by 2019-01-25 01:15:38.082619!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0077 - mean_absolute_error: 0.0662
12. set (Dataset 6) being trained for epoch 3 by 2019-01-25 01:15:50.552691!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0205 - mean_absolute_error: 0.0966
13. set (Dataset 24) being trained for epoch 3 by 2019-01-25 01:16:05.343233!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0052 - mean_absolute_error: 0.0544
14. set (Dataset 11) being trained for epoch 3 by 2019-01-25 01:16:20.244698!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0050 - mean_absolute_error: 0.0530
15. set (Dataset 10) being trained for epoch 3 by 2019-01-25 01:16:38.108429!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0128 - mean_absolute_error: 0.0795
16. set (Dataset 20) being trained for epoch 3 by 2019-01-25 01:16:56.861771!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0082 - mean_absolute_error: 0.0679
17. set (Dataset 2) being trained for epoch 3 by 2019-01-25 01:17:11.824669!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0301 - mean_absolute_error: 0.1158
18. set (Dataset 4) being trained for epoch 3 by 2019-01-25 01:17:28.668175!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0074 - mean_absolute_error: 0.0666
19. set (Dataset 7) being trained for epoch 3 by 2019-01-25 01:17:50.216662!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0056 - mean_absolute_error: 0.0575
20. set (Dataset 1) being trained for epoch 3 by 2019-01-25 01:18:08.578489!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0171 - mean_absolute_error: 0.0981
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:18:22.118110
1. set (Dataset 4) being trained for epoch 4 by 2019-01-25 01:18:29.504795!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0495
2. set (Dataset 1) being trained for epoch 4 by 2019-01-25 01:18:47.879280!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0112 - mean_absolute_error: 0.0778
3. set (Dataset 17) being trained for epoch 4 by 2019-01-25 01:19:00.463546!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0100 - mean_absolute_error: 0.0763
4. set (Dataset 10) being trained for epoch 4 by 2019-01-25 01:19:14.931296!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0069 - mean_absolute_error: 0.0612
5. set (Dataset 12) being trained for epoch 4 by 2019-01-25 01:19:35.414395!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0475
6. set (Dataset 7) being trained for epoch 4 by 2019-01-25 01:19:56.142442!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0036 - mean_absolute_error: 0.0440
7. set (Dataset 2) being trained for epoch 4 by 2019-01-25 01:20:14.762831!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0138 - mean_absolute_error: 0.0811
8. set (Dataset 6) being trained for epoch 4 by 2019-01-25 01:20:29.050902!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0243 - mean_absolute_error: 0.1030
9. set (Dataset 13) being trained for epoch 4 by 2019-01-25 01:20:43.615730!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0487
10. set (Dataset 23) being trained for epoch 4 by 2019-01-25 01:20:57.944530!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0156 - mean_absolute_error: 0.0904
11. set (Dataset 18) being trained for epoch 4 by 2019-01-25 01:21:14.095613!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0129 - mean_absolute_error: 0.0854
12. set (Dataset 19) being trained for epoch 4 by 2019-01-25 01:21:30.107653!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0081 - mean_absolute_error: 0.0647
13. set (Dataset 11) being trained for epoch 4 by 2019-01-25 01:21:44.852208!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0408
14. set (Dataset 16) being trained for epoch 4 by 2019-01-25 01:22:03.877919!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0594
15. set (Dataset 21) being trained for epoch 4 by 2019-01-25 01:22:26.440881!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0139 - mean_absolute_error: 0.0838
16. set (Dataset 20) being trained for epoch 4 by 2019-01-25 01:22:43.589987!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0086 - mean_absolute_error: 0.0691
17. set (Dataset 24) being trained for epoch 4 by 2019-01-25 01:22:58.603612!
Epoch 1/1
492/492 [==============================] - 9s 19ms/step - loss: 0.0047 - mean_absolute_error: 0.0519
18. set (Dataset 15) being trained for epoch 4 by 2019-01-25 01:23:14.275924!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0069 - mean_absolute_error: 0.0617
19. set (Dataset 8) being trained for epoch 4 by 2019-01-25 01:23:33.782200!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0054 - mean_absolute_error: 0.0554
20. set (Dataset 22) being trained for epoch 4 by 2019-01-25 01:23:54.571267!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0536
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:24:11.107638
1. set (Dataset 15) being trained for epoch 5 by 2019-01-25 01:24:17.481863!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0061 - mean_absolute_error: 0.0575
2. set (Dataset 22) being trained for epoch 5 by 2019-01-25 01:24:36.057737!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0464
3. set (Dataset 18) being trained for epoch 5 by 2019-01-25 01:24:54.128989!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0092 - mean_absolute_error: 0.0726
4. set (Dataset 21) being trained for epoch 5 by 2019-01-25 01:25:11.449849!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0168 - mean_absolute_error: 0.0894
5. set (Dataset 7) being trained for epoch 5 by 2019-01-25 01:25:30.254472!
Epoch 1/1
745/745 [==============================] - 13s 17ms/step - loss: 0.0043 - mean_absolute_error: 0.0485
6. set (Dataset 8) being trained for epoch 5 by 2019-01-25 01:25:51.059137!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0507
7. set (Dataset 24) being trained for epoch 5 by 2019-01-25 01:26:09.644983!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0038 - mean_absolute_error: 0.0468
8. set (Dataset 19) being trained for epoch 5 by 2019-01-25 01:26:23.501376!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0058 - mean_absolute_error: 0.0550
9. set (Dataset 12) being trained for epoch 5 by 2019-01-25 01:26:39.767109!
Epoch 1/1
732/732 [==============================] - 14s 19ms/step - loss: 0.0046 - mean_absolute_error: 0.0491
10. set (Dataset 13) being trained for epoch 5 by 2019-01-25 01:26:58.350827!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0460
11. set (Dataset 2) being trained for epoch 5 by 2019-01-25 01:27:12.417567!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0070 - mean_absolute_error: 0.0665
12. set (Dataset 4) being trained for epoch 5 by 2019-01-25 01:27:29.115682!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0045 - mean_absolute_error: 0.0506
13. set (Dataset 16) being trained for epoch 5 by 2019-01-25 01:27:51.155943!
Epoch 1/1
914/914 [==============================] - 17s 19ms/step - loss: 0.0057 - mean_absolute_error: 0.0548
14. set (Dataset 1) being trained for epoch 5 by 2019-01-25 01:28:13.154896!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0116 - mean_absolute_error: 0.0797
15. set (Dataset 17) being trained for epoch 5 by 2019-01-25 01:28:25.755266!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0077 - mean_absolute_error: 0.0655
16. set (Dataset 20) being trained for epoch 5 by 2019-01-25 01:28:38.359597!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0098 - mean_absolute_error: 0.0682
17. set (Dataset 11) being trained for epoch 5 by 2019-01-25 01:28:54.157993!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0427
18. set (Dataset 10) being trained for epoch 5 by 2019-01-25 01:29:11.778325!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0564
19. set (Dataset 23) being trained for epoch 5 by 2019-01-25 01:29:30.224438!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0123 - mean_absolute_error: 0.0800
20. set (Dataset 6) being trained for epoch 5 by 2019-01-25 01:29:45.733718!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0193 - mean_absolute_error: 0.0913
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:30:00.454193
1. set (Dataset 10) being trained for epoch 6 by 2019-01-25 01:30:07.691492!
Epoch 1/1
726/726 [==============================] - 13s 17ms/step - loss: 0.0052 - mean_absolute_error: 0.0528
2. set (Dataset 6) being trained for epoch 6 by 2019-01-25 01:30:25.459915!
Epoch 1/1
542/542 [==============================] - 9s 18ms/step - loss: 0.0164 - mean_absolute_error: 0.0817
3. set (Dataset 2) being trained for epoch 6 by 2019-01-25 01:30:40.091127!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0611
4. set (Dataset 17) being trained for epoch 6 by 2019-01-25 01:30:53.311678!
Epoch 1/1
395/395 [==============================] - 8s 19ms/step - loss: 0.0062 - mean_absolute_error: 0.0576
5. set (Dataset 8) being trained for epoch 6 by 2019-01-25 01:31:08.697032!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0040 - mean_absolute_error: 0.0477
6. set (Dataset 23) being trained for epoch 6 by 2019-01-25 01:31:27.983057!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0117 - mean_absolute_error: 0.0765
7. set (Dataset 11) being trained for epoch 6 by 2019-01-25 01:31:44.078920!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0027 - mean_absolute_error: 0.0375
8. set (Dataset 4) being trained for epoch 6 by 2019-01-25 01:32:01.851961!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0454
9. set (Dataset 7) being trained for epoch 6 by 2019-01-25 01:32:22.734903!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0436
10. set (Dataset 12) being trained for epoch 6 by 2019-01-25 01:32:43.364455!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0033 - mean_absolute_error: 0.0419
11. set (Dataset 24) being trained for epoch 6 by 2019-01-25 01:33:01.323967!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0479
12. set (Dataset 15) being trained for epoch 6 by 2019-01-25 01:33:16.666254!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0066 - mean_absolute_error: 0.0598
13. set (Dataset 1) being trained for epoch 6 by 2019-01-25 01:33:33.743049!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0092 - mean_absolute_error: 0.0710
14. set (Dataset 22) being trained for epoch 6 by 2019-01-25 01:33:49.159650!
Epoch 1/1
665/665 [==============================] - 12s 19ms/step - loss: 0.0055 - mean_absolute_error: 0.0518
15. set (Dataset 18) being trained for epoch 6 by 2019-01-25 01:34:07.518140!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0088 - mean_absolute_error: 0.0724
16. set (Dataset 20) being trained for epoch 6 by 2019-01-25 01:34:24.115461!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0076 - mean_absolute_error: 0.0624
17. set (Dataset 16) being trained for epoch 6 by 2019-01-25 01:34:42.759693!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0047 - mean_absolute_error: 0.0502
18. set (Dataset 21) being trained for epoch 6 by 2019-01-25 01:35:05.010219!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0146 - mean_absolute_error: 0.0851
19. set (Dataset 13) being trained for epoch 6 by 2019-01-25 01:35:21.199472!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0448
20. set (Dataset 19) being trained for epoch 6 by 2019-01-25 01:35:34.768796!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0051 - mean_absolute_error: 0.0526
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:35:48.078291
1. set (Dataset 21) being trained for epoch 7 by 2019-01-25 01:35:54.088735!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0114 - mean_absolute_error: 0.0742
2. set (Dataset 19) being trained for epoch 7 by 2019-01-25 01:36:10.722288!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0483
3. set (Dataset 24) being trained for epoch 7 by 2019-01-25 01:36:24.420313!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0029 - mean_absolute_error: 0.0411
4. set (Dataset 18) being trained for epoch 7 by 2019-01-25 01:36:39.205315!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0070 - mean_absolute_error: 0.0639
5. set (Dataset 23) being trained for epoch 7 by 2019-01-25 01:36:56.183265!
Epoch 1/1
569/569 [==============================] - 11s 19ms/step - loss: 0.0089 - mean_absolute_error: 0.0678
6. set (Dataset 13) being trained for epoch 7 by 2019-01-25 01:37:11.737318!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0424
7. set (Dataset 16) being trained for epoch 7 by 2019-01-25 01:37:29.231750!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0485
8. set (Dataset 15) being trained for epoch 7 by 2019-01-25 01:37:52.268653!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0054 - mean_absolute_error: 0.0553
9. set (Dataset 8) being trained for epoch 7 by 2019-01-25 01:38:11.916651!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.0067 - mean_absolute_error: 0.0561
10. set (Dataset 7) being trained for epoch 7 by 2019-01-25 01:38:33.850574!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0440
11. set (Dataset 11) being trained for epoch 7 by 2019-01-25 01:38:53.065149!
Epoch 1/1
572/572 [==============================] - 10s 17ms/step - loss: 0.0023 - mean_absolute_error: 0.0361
12. set (Dataset 10) being trained for epoch 7 by 2019-01-25 01:39:10.295364!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0053 - mean_absolute_error: 0.0547
13. set (Dataset 22) being trained for epoch 7 by 2019-01-25 01:39:29.908433!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0050 - mean_absolute_error: 0.0511
14. set (Dataset 6) being trained for epoch 7 by 2019-01-25 01:39:47.080130!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0164 - mean_absolute_error: 0.0819
15. set (Dataset 2) being trained for epoch 7 by 2019-01-25 01:40:02.006846!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0055 - mean_absolute_error: 0.0582
16. set (Dataset 20) being trained for epoch 7 by 2019-01-25 01:40:16.737358!
Epoch 1/1
556/556 [==============================] - 10s 19ms/step - loss: 0.0072 - mean_absolute_error: 0.0626
17. set (Dataset 1) being trained for epoch 7 by 2019-01-25 01:40:32.284196!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0089 - mean_absolute_error: 0.0687
18. set (Dataset 17) being trained for epoch 7 by 2019-01-25 01:40:45.018602!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0060 - mean_absolute_error: 0.0570
19. set (Dataset 12) being trained for epoch 7 by 2019-01-25 01:40:59.528989!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0032 - mean_absolute_error: 0.0421
20. set (Dataset 4) being trained for epoch 7 by 2019-01-25 01:41:20.301449!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0033 - mean_absolute_error: 0.0436
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:41:38.524366
1. set (Dataset 17) being trained for epoch 8 by 2019-01-25 01:41:42.267058!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0519
2. set (Dataset 4) being trained for epoch 8 by 2019-01-25 01:41:56.921597!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0025 - mean_absolute_error: 0.0382
3. set (Dataset 11) being trained for epoch 8 by 2019-01-25 01:42:15.849990!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0020 - mean_absolute_error: 0.0327
4. set (Dataset 2) being trained for epoch 8 by 2019-01-25 01:42:31.467028!
Epoch 1/1
511/511 [==============================] - 10s 19ms/step - loss: 0.0035 - mean_absolute_error: 0.0466
5. set (Dataset 13) being trained for epoch 8 by 2019-01-25 01:42:46.043309!
Epoch 1/1
485/485 [==============================] - 8s 17ms/step - loss: 0.0037 - mean_absolute_error: 0.0417
6. set (Dataset 12) being trained for epoch 8 by 2019-01-25 01:43:01.835661!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0403
7. set (Dataset 1) being trained for epoch 8 by 2019-01-25 01:43:20.141740!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0064 - mean_absolute_error: 0.0579
8. set (Dataset 10) being trained for epoch 8 by 2019-01-25 01:43:36.440976!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0470
9. set (Dataset 23) being trained for epoch 8 by 2019-01-25 01:43:55.290155!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0103 - mean_absolute_error: 0.0731
10. set (Dataset 8) being trained for epoch 8 by 2019-01-25 01:44:13.299529!
Epoch 1/1
772/772 [==============================] - 15s 19ms/step - loss: 0.0031 - mean_absolute_error: 0.0423
11. set (Dataset 16) being trained for epoch 8 by 2019-01-25 01:44:36.695309!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0508
12. set (Dataset 21) being trained for epoch 8 by 2019-01-25 01:44:59.218212!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0122 - mean_absolute_error: 0.0787
13. set (Dataset 6) being trained for epoch 8 by 2019-01-25 01:45:15.834092!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0160 - mean_absolute_error: 0.0817
14. set (Dataset 19) being trained for epoch 8 by 2019-01-25 01:45:30.394989!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0044 - mean_absolute_error: 0.0510
15. set (Dataset 24) being trained for epoch 8 by 2019-01-25 01:45:44.016575!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0030 - mean_absolute_error: 0.0417
16. set (Dataset 20) being trained for epoch 8 by 2019-01-25 01:45:58.382971!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0070 - mean_absolute_error: 0.0636
17. set (Dataset 22) being trained for epoch 8 by 2019-01-25 01:46:14.621283!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0046 - mean_absolute_error: 0.0475
18. set (Dataset 18) being trained for epoch 8 by 2019-01-25 01:46:32.612818!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0631
19. set (Dataset 7) being trained for epoch 8 by 2019-01-25 01:46:51.210918!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0026 - mean_absolute_error: 0.0383
20. set (Dataset 15) being trained for epoch 8 by 2019-01-25 01:47:11.238576!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0057 - mean_absolute_error: 0.0558
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 01:47:27.477762
1. set (Dataset 18) being trained for epoch 9 by 2019-01-25 01:47:33.351450!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0579
2. set (Dataset 15) being trained for epoch 9 by 2019-01-25 01:47:50.698338!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0048 - mean_absolute_error: 0.0513
3. set (Dataset 16) being trained for epoch 9 by 2019-01-25 01:48:11.251623!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0037 - mean_absolute_error: 0.0456
4. set (Dataset 24) being trained for epoch 9 by 2019-01-25 01:48:32.599533!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0031 - mean_absolute_error: 0.0388
5. set (Dataset 12) being trained for epoch 9 by 2019-01-25 01:48:48.813229!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0034 - mean_absolute_error: 0.0421
6. set (Dataset 7) being trained for epoch 9 by 2019-01-25 01:49:09.304848!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0024 - mean_absolute_error: 0.0362
7. set (Dataset 22) being trained for epoch 9 by 2019-01-25 01:49:29.085523!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0461
8. set (Dataset 21) being trained for epoch 9 by 2019-01-25 01:49:47.168129!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0106 - mean_absolute_error: 0.0741
9. set (Dataset 13) being trained for epoch 9 by 2019-01-25 01:50:03.483596!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0042 - mean_absolute_error: 0.0449
10. set (Dataset 23) being trained for epoch 9 by 2019-01-25 01:50:17.576792!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0079 - mean_absolute_error: 0.0640
11. set (Dataset 1) being trained for epoch 9 by 2019-01-25 01:50:32.965765!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0079 - mean_absolute_error: 0.0649
12. set (Dataset 17) being trained for epoch 9 by 2019-01-25 01:50:46.016655!
Epoch 1/1
127/395 [========>.....................] - ETA: 4s - loss: 0.0079 - mean_absolute_error: 0.0675^C
Model Exp2019-01-24_23-58-26_and_2019-01-25_01-00-50 has been interrupted.
Exp2019-01-24_23-58-26_and_2019-01-25_01-00-50.h5 has been saved.
Model Exp2019-01-24_23-58-26_and_2019-01-25_01-00-50 has been recorded successfully.
Terminating...
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ ^C
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ pytho continueTrainigCNN_LSTM.py Exp
2019-01-24_23-58-26_and_2019-01-25_01-00-50
No command 'pytho' found, did you mean:
 Command 'python' from package 'python-minimal' (main)
 Command 'python' from package 'python3' (main)
pytho: command not found
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-24_23-58-26_and_2019-01-25_01-00-50
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 02:01:36.438411: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 02:01:36.535147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 02:01:36.535403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 02:01:36.535416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 02:01:36.690404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 02:01:36.690430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 02:01:36.690436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 02:01:36.690574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10471 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-24_23-58-26_and_2019-01-25_01-00-50.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 2
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11,
'M05'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21,
'F02'), (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-24_23-58-26_and_2019-01-25_01-00-50_and_2019-01-25_02-01-37
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 02:01:39.642053
For the Subject 3 (F03):
730/730 [==============================] - 8s 10ms/step
        The absolute mean error on Pitch angle estimation: 9.38 Degree
        The absolute mean error on Yaw angle estimation: 45.14 Degree
        The absolute mean error on Roll angle estimation: 10.93 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Pitch angle estimation: 6.65 Degree
        The absolute mean error on Yaw angle estimation: 18.57 Degree
        The absolute mean error on Roll angle estimation: 7.53 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Pitch angle estimation: 35.04 Degree
        The absolute mean error on Yaw angle estimation: 20.67 Degree
        The absolute mean error on Roll angle estimation: 10.21 Degree
For the Subject 14 (M08):
797/797 [==============================] - 7s 9ms/step
        The absolute mean error on Pitch angle estimation: 18.71 Degree
        The absolute mean error on Yaw angle estimation: 65.55 Degree
        The absolute mean error on Roll angle estimation: 13.19 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 17.45 Degree
        The absolute mean error on Yaw angle estimations: 37.48 Degree
        The absolute mean error on Roll angle estimations: 10.47 Degree
subject3_Exp2019-01-25_01-00-50_and_2019-01-25_02-01-37.png has been saved by 2019-01-25 02:02:45.343161.
subject5_Exp2019-01-25_01-00-50_and_2019-01-25_02-01-37.png has been saved by 2019-01-25 02:02:45.542471.
subject9_Exp2019-01-25_01-00-50_and_2019-01-25_02-01-37.png has been saved by 2019-01-25 02:02:45.742288.
subject14_Exp2019-01-25_01-00-50_and_2019-01-25_02-01-37.png has been saved by 2019-01-25 02:02:45.960065.
Model Exp2019-01-25_01-00-50_and_2019-01-25_02-01-37 has been evaluated successfully.
Model Exp2019-01-25_01-00-50_and_2019-01-25_02-01-37 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 02:12:12.548937: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 02:12:12.646562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 02:12:12.646820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 02:12:12.646831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 02:12:12.802003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 02:12:12.802030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 02:12:12.802035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 02:12:12.802179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_02-12-13 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 1)                    11
=================================================================
Total params: 134,424,835
Trainable params: 164,291
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 4
num_outputs = 1

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 2
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [9] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs2_AdamOpt_lr-0.000100_2019
-01-25_02-12-13
All frames and annotations from 0 datasets have been read by 2019-01-25 02:12:13.467111
Epoch 1 completed!
All frames and annotations from 0 datasets have been read by 2019-01-25 02:12:13.467291
Epoch 2 completed!
The subjects are trained: []
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs2_AdamOpt_lr-0.000100_20
19-01-25_02-12-13
The subjects will be tested: [(9, 'M03')]
All frames and annotations from 1 datasets have been read by 2019-01-25 02:12:14.311808
For the Subject 9 (M03):
882/882 [==============================] - 9s 10ms/step
        The absolute mean error on Yaw angle estimation: 81.42 Degree
On average in 1 test subjects:
        The absolute mean error on Yaw angle estimations: 81.42 Degree
subject9_Exp2019-01-25_02-12-13.png has been saved by 2019-01-25 02:12:32.290081.
Model Exp2019-01-25_02-12-13 has been evaluated successfully.
Model Exp2019-01-25_02-12-13 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 02:13:29.969111: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 02:13:30.066422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 02:13:30.066723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 02:13:30.066736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 02:13:30.221677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 02:13:30.221706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 02:13:30.221711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 02:13:30.221891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_02-13-30 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 1)                    11
=================================================================
Total params: 134,424,835
Trainable params: 164,291
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 4
num_outputs = 1

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 2
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [1] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs2_AdamOpt_lr-0.000100_2019
-01-25_02-13-30
All frames and annotations from 1 datasets have been read by 2019-01-25 02:13:31.718638
1. set (Dataset 9) being trained for epoch 1 by 2019-01-25 02:13:40.605179!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0284 - mean_absolute_error: 0.1222
Epoch 1 completed!
All frames and annotations from 1 datasets have been read by 2019-01-25 02:13:58.920846
1. set (Dataset 9) being trained for epoch 2 by 2019-01-25 02:14:07.783973!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0076 - mean_absolute_error: 0.0690
Epoch 2 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs2_AdamOpt_lr-0.000100_20
19-01-25_02-13-30
The subjects will be tested: [(1, 'F01')]
All frames and annotations from 1 datasets have been read by 2019-01-25 02:14:24.612777
For the Subject 1 (F01):
498/498 [==============================] - 5s 9ms/step
        The absolute mean error on Yaw angle estimation: 32.99 Degree
On average in 1 test subjects:
        The absolute mean error on Yaw angle estimations: 32.99 Degree
subject1_Exp2019-01-25_02-13-30.png has been saved by 2019-01-25 02:14:34.477406.
Model Exp2019-01-25_02-13-30 has been evaluated successfully.
Model Exp2019-01-25_02-13-30 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 02:17:12.277457: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 02:17:12.373849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 02:17:12.374109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 02:17:12.374122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 02:17:12.529509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 02:17:12.529536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 02:17:12.529542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 02:17:12.529686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_02-17-13 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 1)                    11
=================================================================
Total params: 134,424,835
Trainable params: 164,291
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 4
num_outputs = 1

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 5
train_batch_size = 1
test_batch_size = 1

subjectList = [9] # [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [1] # [3, 5, 9, 14] # [9, 18, 21, 24] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs5_AdamOpt_lr-0.000100_2019
-01-25_02-17-13
All frames and annotations from 1 datasets have been read by 2019-01-25 02:17:14.034303
1. set (Dataset 9) being trained for epoch 1 by 2019-01-25 02:17:22.920089!
Epoch 1/1
882/882 [==============================] - 17s 19ms/step - loss: 0.0309 - mean_absolute_error: 0.1299
Epoch 1 completed!
All frames and annotations from 1 datasets have been read by 2019-01-25 02:17:41.051509
1. set (Dataset 9) being trained for epoch 2 by 2019-01-25 02:17:49.952718!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0068 - mean_absolute_error: 0.0651
Epoch 2 completed!
All frames and annotations from 1 datasets have been read by 2019-01-25 02:18:06.563496
1. set (Dataset 9) being trained for epoch 3 by 2019-01-25 02:18:15.441047!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0059 - mean_absolute_error: 0.0610
Epoch 3 completed!
All frames and annotations from 1 datasets have been read by 2019-01-25 02:18:32.437372
1. set (Dataset 9) being trained for epoch 4 by 2019-01-25 02:18:41.301581!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0053 - mean_absolute_error: 0.0577
Epoch 4 completed!
All frames and annotations from 1 datasets have been read by 2019-01-25 02:18:58.123911
1. set (Dataset 9) being trained for epoch 5 by 2019-01-25 02:19:07.008641!
Epoch 1/1
882/882 [==============================] - 16s 18ms/step - loss: 0.0035 - mean_absolute_error: 0.0465
Epoch 5 completed!
The subjects are trained: [(9, 'M03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs5_AdamOpt_lr-0.000100_20
19-01-25_02-17-13
The subjects will be tested: [(1, 'F01')]
All frames and annotations from 1 datasets have been read by 2019-01-25 02:19:23.713215
For the Subject 1 (F01):
498/498 [==============================] - 5s 10ms/step
        The absolute mean error on Yaw angle estimation: 31.70 Degree
On average in 1 test subjects:
        The absolute mean error on Yaw angle estimations: 31.70 Degree
subject1_Exp2019-01-25_02-17-13.png has been saved by 2019-01-25 02:19:33.607358.
Model Exp2019-01-25_02-17-13 has been evaluated successfully.
Model Exp2019-01-25_02-17-13 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 02:20:22.436877: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 02:20:22.535061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 02:20:22.535318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 02:20:22.535331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 02:20:22.690645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 02:20:22.690671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 02:20:22.690676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 02:20:22.690816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10471 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_02-20-23 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 1)                    11
=================================================================
Total params: 134,424,835
Trainable params: 164,291
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 4
num_outputs = 1

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_2019
-01-25_02-20-23
All frames and annotations from 20 datasets have been read by 2019-01-25 02:20:27.798691
1. set (Dataset 22) being trained for epoch 1 by 2019-01-25 02:20:34.177755!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0339 - mean_absolute_error: 0.1320
2. set (Dataset 24) being trained for epoch 1 by 2019-01-25 02:20:52.014574!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0208 - mean_absolute_error: 0.1050
3. set (Dataset 15) being trained for epoch 1 by 2019-01-25 02:21:07.263773!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0300 - mean_absolute_error: 0.1234
4. set (Dataset 19) being trained for epoch 1 by 2019-01-25 02:21:23.906998!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0281 - mean_absolute_error: 0.1301
5. set (Dataset 8) being trained for epoch 1 by 2019-01-25 02:21:40.444927!
Epoch 1/1
772/772 [==============================] - 14s 19ms/step - loss: 0.1666 - mean_absolute_error: 0.3505
6. set (Dataset 23) being trained for epoch 1 by 2019-01-25 02:22:00.317616!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0490 - mean_absolute_error: 0.1694
7. set (Dataset 21) being trained for epoch 1 by 2019-01-25 02:22:16.370298!
Epoch 1/1
634/634 [==============================] - 12s 18ms/step - loss: 0.0244 - mean_absolute_error: 0.1212
8. set (Dataset 16) being trained for epoch 1 by 2019-01-25 02:22:36.642541!
Epoch 1/1
914/914 [==============================] - 17s 18ms/step - loss: 0.0194 - mean_absolute_error: 0.1023
9. set (Dataset 7) being trained for epoch 1 by 2019-01-25 02:23:00.714024!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0763 - mean_absolute_error: 0.2237
10. set (Dataset 12) being trained for epoch 1 by 2019-01-25 02:23:21.524732!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0476 - mean_absolute_error: 0.1789
11. set (Dataset 10) being trained for epoch 1 by 2019-01-25 02:23:41.921222!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0846 - mean_absolute_error: 0.2300
12. set (Dataset 1) being trained for epoch 1 by 2019-01-25 02:24:00.348083!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.1110 - mean_absolute_error: 0.2561
13. set (Dataset 18) being trained for epoch 1 by 2019-01-25 02:24:15.046121!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0580 - mean_absolute_error: 0.1795
14. set (Dataset 2) being trained for epoch 1 by 2019-01-25 02:24:31.149780!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0811 - mean_absolute_error: 0.2351
15. set (Dataset 4) being trained for epoch 1 by 2019-01-25 02:24:47.814298!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0777 - mean_absolute_error: 0.2136
16. set (Dataset 20) being trained for epoch 1 by 2019-01-25 02:25:06.480518!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0551 - mean_absolute_error: 0.1696
17. set (Dataset 17) being trained for epoch 1 by 2019-01-25 02:25:20.171436!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0194 - mean_absolute_error: 0.1031
18. set (Dataset 6) being trained for epoch 1 by 2019-01-25 02:25:32.296458!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0788 - mean_absolute_error: 0.1932
19. set (Dataset 13) being trained for epoch 1 by 2019-01-25 02:25:46.750113!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0342 - mean_absolute_error: 0.1433
20. set (Dataset 11) being trained for epoch 1 by 2019-01-25 02:26:01.393356!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0788 - mean_absolute_error: 0.2282
Epoch 1 completed!
Exp2019-01-25_02-20-23.h5 has been saved.
The subjects are trained: [(22, 'M01'), (24, 'M14'), (15, 'F03'), (19, 'M11'), (8, 'M02'), (23, 'M13'), (21, 'F02'),
(16, 'M09'), (7, 'M01'), (12, 'M06'), (10, 'M04'), (1, 'F01'), (18, 'F05'), (2, 'F02'), (4, 'F04'), (20, 'M12'), (17,
 'M10'), (6, 'F06'), (13, 'M07'), (11, 'M05')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000100_20
19-01-25_02-20-23
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 02:26:14.361510
For the Subject 3 (F03):
730/730 [==============================] - 7s 10ms/step
        The absolute mean error on Yaw angle estimation: 30.00 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Yaw angle estimation: 26.51 Degree
For the Subject 9 (M03):
882/882 [==============================] - 9s 10ms/step
        The absolute mean error on Yaw angle estimation: 28.37 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Yaw angle estimation: 33.44 Degree
On average in 4 test subjects:
        The absolute mean error on Yaw angle estimations: 29.58 Degree
subject3_Exp2019-01-25_02-20-23.png has been saved by 2019-01-25 02:27:20.010353.
subject5_Exp2019-01-25_02-20-23.png has been saved by 2019-01-25 02:27:20.091591.
subject9_Exp2019-01-25_02-20-23.png has been saved by 2019-01-25 02:27:20.169493.
subject14_Exp2019-01-25_02-20-23.png has been saved by 2019-01-25 02:27:20.260000.
Model Exp2019-01-25_02-20-23 has been evaluated successfully.
Model Exp2019-01-25_02-20-23 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 02:37:36.254583: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 02:37:36.353181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 02:37:36.353435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 02:37:36.353447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 02:37:36.509015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 02:37:36.509043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 02:37:36.509048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 02:37:36.509187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_02-37-37 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   164280
_________________________________________________________________
dense_1 (Dense)              (1, 1)                    11
=================================================================
Total params: 134,424,835
Trainable params: 164,291
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 4
num_outputs = 1

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 3
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs3_AdamOpt_lr-0.000100_2019
-01-25_02-37-37
All frames and annotations from 20 datasets have been read by 2019-01-25 02:37:41.561643
1. set (Dataset 22) being trained for epoch 1 by 2019-01-25 02:37:47.976202!
Epoch 1/1
665/665 [==============================] - 13s 19ms/step - loss: 0.0217 - mean_absolute_error: 0.1056
2. set (Dataset 24) being trained for epoch 1 by 2019-01-25 02:38:05.650928!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0204 - mean_absolute_error: 0.0985
3. set (Dataset 15) being trained for epoch 1 by 2019-01-25 02:38:20.877196!
Epoch 1/1
654/654 [==============================] - 12s 18ms/step - loss: 0.0356 - mean_absolute_error: 0.1274
4. set (Dataset 19) being trained for epoch 1 by 2019-01-25 02:38:37.803361!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0232 - mean_absolute_error: 0.1140
5. set (Dataset 8) being trained for epoch 1 by 2019-01-25 02:38:54.576576!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0813 - mean_absolute_error: 0.2338
6. set (Dataset 23) being trained for epoch 1 by 2019-01-25 02:39:13.673552!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0478 - mean_absolute_error: 0.1635
7. set (Dataset 21) being trained for epoch 1 by 2019-01-25 02:39:30.012012!
Epoch 1/1
634/634 [==============================] - 11s 18ms/step - loss: 0.0175 - mean_absolute_error: 0.0973
8. set (Dataset 16) being trained for epoch 1 by 2019-01-25 02:39:50.094093!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0201 - mean_absolute_error: 0.0986
9. set (Dataset 7) being trained for epoch 1 by 2019-01-25 02:40:13.988827!
Epoch 1/1
745/745 [==============================] - 13s 18ms/step - loss: 0.0341 - mean_absolute_error: 0.1383
10. set (Dataset 12) being trained for epoch 1 by 2019-01-25 02:40:34.596781!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0304 - mean_absolute_error: 0.1410
11. set (Dataset 10) being trained for epoch 1 by 2019-01-25 02:40:55.345559!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0724 - mean_absolute_error: 0.2101
12. set (Dataset 1) being trained for epoch 1 by 2019-01-25 02:41:13.848895!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0757 - mean_absolute_error: 0.2204
13. set (Dataset 18) being trained for epoch 1 by 2019-01-25 02:41:28.629642!
Epoch 1/1
614/614 [==============================] - 11s 18ms/step - loss: 0.0326 - mean_absolute_error: 0.1391
14. set (Dataset 2) being trained for epoch 1 by 2019-01-25 02:41:44.565705!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0921 - mean_absolute_error: 0.2557
15. set (Dataset 4) being trained for epoch 1 by 2019-01-25 02:42:01.177156!
Epoch 1/1
744/744 [==============================] - 14s 19ms/step - loss: 0.0901 - mean_absolute_error: 0.2441
16. set (Dataset 20) being trained for epoch 1 by 2019-01-25 02:42:20.594677!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0361 - mean_absolute_error: 0.1303
17. set (Dataset 17) being trained for epoch 1 by 2019-01-25 02:42:34.375741!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0178 - mean_absolute_error: 0.1006
18. set (Dataset 6) being trained for epoch 1 by 2019-01-25 02:42:46.621262!
Epoch 1/1
542/542 [==============================] - 10s 19ms/step - loss: 0.0429 - mean_absolute_error: 0.1421
19. set (Dataset 13) being trained for epoch 1 by 2019-01-25 02:43:01.584916!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0195 - mean_absolute_error: 0.1080
20. set (Dataset 11) being trained for epoch 1 by 2019-01-25 02:43:16.065701!
Epoch 1/1
572/572 [==============================] - 11s 19ms/step - loss: 0.0412 - mean_absolute_error: 0.1538
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 02:43:31.064379
1. set (Dataset 6) being trained for epoch 2 by 2019-01-25 02:43:36.238694!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0142 - mean_absolute_error: 0.0868
2. set (Dataset 11) being trained for epoch 2 by 2019-01-25 02:43:51.655671!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0118 - mean_absolute_error: 0.0771
3. set (Dataset 10) being trained for epoch 2 by 2019-01-25 02:44:09.230307!
Epoch 1/1
726/726 [==============================] - 13s 18ms/step - loss: 0.0203 - mean_absolute_error: 0.1078
4. set (Dataset 4) being trained for epoch 2 by 2019-01-25 02:44:29.594658!
Epoch 1/1
744/744 [==============================] - 14s 18ms/step - loss: 0.0464 - mean_absolute_error: 0.1602
5. set (Dataset 23) being trained for epoch 2 by 2019-01-25 02:44:48.685920!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0660 - mean_absolute_error: 0.1847
6. set (Dataset 13) being trained for epoch 2 by 2019-01-25 02:45:03.711709!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0186 - mean_absolute_error: 0.1043
7. set (Dataset 17) being trained for epoch 2 by 2019-01-25 02:45:16.363773!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0175 - mean_absolute_error: 0.0899
8. set (Dataset 1) being trained for epoch 2 by 2019-01-25 02:45:28.635013!
Epoch 1/1
498/498 [==============================] - 9s 18ms/step - loss: 0.0609 - mean_absolute_error: 0.1988
9. set (Dataset 8) being trained for epoch 2 by 2019-01-25 02:45:45.594941!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0148 - mean_absolute_error: 0.0968
10. set (Dataset 7) being trained for epoch 2 by 2019-01-25 02:46:07.315105!
Epoch 1/1
745/745 [==============================] - 14s 18ms/step - loss: 0.0112 - mean_absolute_error: 0.0775
11. set (Dataset 21) being trained for epoch 2 by 2019-01-25 02:46:26.981445!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0100 - mean_absolute_error: 0.0761
12. set (Dataset 22) being trained for epoch 2 by 2019-01-25 02:46:45.275829!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0138 - mean_absolute_error: 0.0859
13. set (Dataset 2) being trained for epoch 2 by 2019-01-25 02:47:02.425403!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.1066 - mean_absolute_error: 0.2782
14. set (Dataset 24) being trained for epoch 2 by 2019-01-25 02:47:16.155330!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0153 - mean_absolute_error: 0.0905
15. set (Dataset 15) being trained for epoch 2 by 2019-01-25 02:47:31.400664!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0288 - mean_absolute_error: 0.1131
16. set (Dataset 20) being trained for epoch 2 by 2019-01-25 02:47:49.006416!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0188 - mean_absolute_error: 0.1056
17. set (Dataset 18) being trained for epoch 2 by 2019-01-25 02:48:04.933763!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0332 - mean_absolute_error: 0.1460
18. set (Dataset 19) being trained for epoch 2 by 2019-01-25 02:48:21.287990!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0204 - mean_absolute_error: 0.1044
19. set (Dataset 12) being trained for epoch 2 by 2019-01-25 02:48:37.714990!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0433 - mean_absolute_error: 0.1733
20. set (Dataset 16) being trained for epoch 2 by 2019-01-25 02:48:59.586350!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0136 - mean_absolute_error: 0.0821
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 02:49:20.442509
1. set (Dataset 19) being trained for epoch 3 by 2019-01-25 02:49:25.309273!
Epoch 1/1
502/502 [==============================] - 9s 18ms/step - loss: 0.0111 - mean_absolute_error: 0.0752
2. set (Dataset 16) being trained for epoch 3 by 2019-01-25 02:49:43.163550!
Epoch 1/1
914/914 [==============================] - 16s 18ms/step - loss: 0.0065 - mean_absolute_error: 0.0576
3. set (Dataset 21) being trained for epoch 3 by 2019-01-25 02:50:05.526770!
Epoch 1/1
634/634 [==============================] - 12s 19ms/step - loss: 0.0130 - mean_absolute_error: 0.0856
4. set (Dataset 15) being trained for epoch 3 by 2019-01-25 02:50:23.695795!
Epoch 1/1
654/654 [==============================] - 12s 19ms/step - loss: 0.0207 - mean_absolute_error: 0.0993
5. set (Dataset 13) being trained for epoch 3 by 2019-01-25 02:50:40.814154!
Epoch 1/1
485/485 [==============================] - 9s 18ms/step - loss: 0.0185 - mean_absolute_error: 0.1111
6. set (Dataset 12) being trained for epoch 3 by 2019-01-25 02:50:56.747275!
Epoch 1/1
732/732 [==============================] - 13s 18ms/step - loss: 0.0111 - mean_absolute_error: 0.0861
7. set (Dataset 18) being trained for epoch 3 by 2019-01-25 02:51:15.980794!
Epoch 1/1
614/614 [==============================] - 11s 19ms/step - loss: 0.0191 - mean_absolute_error: 0.1104
8. set (Dataset 22) being trained for epoch 3 by 2019-01-25 02:51:33.862598!
Epoch 1/1
665/665 [==============================] - 12s 18ms/step - loss: 0.0088 - mean_absolute_error: 0.0703
9. set (Dataset 23) being trained for epoch 3 by 2019-01-25 02:51:51.202805!
Epoch 1/1
569/569 [==============================] - 10s 18ms/step - loss: 0.0209 - mean_absolute_error: 0.1106
10. set (Dataset 8) being trained for epoch 3 by 2019-01-25 02:52:09.092002!
Epoch 1/1
772/772 [==============================] - 14s 18ms/step - loss: 0.0091 - mean_absolute_error: 0.0736
11. set (Dataset 17) being trained for epoch 3 by 2019-01-25 02:52:26.803826!
Epoch 1/1
395/395 [==============================] - 7s 18ms/step - loss: 0.0121 - mean_absolute_error: 0.0834
12. set (Dataset 6) being trained for epoch 3 by 2019-01-25 02:52:39.150182!
Epoch 1/1
542/542 [==============================] - 10s 18ms/step - loss: 0.0355 - mean_absolute_error: 0.1356
13. set (Dataset 24) being trained for epoch 3 by 2019-01-25 02:52:53.460339!
Epoch 1/1
492/492 [==============================] - 9s 18ms/step - loss: 0.0083 - mean_absolute_error: 0.0688
14. set (Dataset 11) being trained for epoch 3 by 2019-01-25 02:53:08.118417!
Epoch 1/1
572/572 [==============================] - 10s 18ms/step - loss: 0.0114 - mean_absolute_error: 0.0766
15. set (Dataset 10) being trained for epoch 3 by 2019-01-25 02:53:25.849479!
Epoch 1/1
726/726 [==============================] - 14s 19ms/step - loss: 0.0114 - mean_absolute_error: 0.0812
16. set (Dataset 20) being trained for epoch 3 by 2019-01-25 02:53:44.927676!
Epoch 1/1
556/556 [==============================] - 10s 18ms/step - loss: 0.0120 - mean_absolute_error: 0.0840
17. set (Dataset 2) being trained for epoch 3 by 2019-01-25 02:54:00.158248!
Epoch 1/1
511/511 [==============================] - 9s 18ms/step - loss: 0.0372 - mean_absolute_error: 0.1461
18. set (Dataset 4) being trained for epoch 3 by 2019-01-25 02:54:16.865736!
Epoch 1/1
744/744 [==============================] - 13s 18ms/step - loss: 0.0223 - mean_absolute_error: 0.1131
19. set (Dataset 7) being trained for epoch 3 by 2019-01-25 02:54:37.974460!
Epoch 1/1
745/745 [==============================] - 14s 19ms/step - loss: 0.0059 - mean_absolute_error: 0.0599
20. set (Dataset 1) being trained for epoch 3 by 2019-01-25 02:54:56.886909!
Epoch 1/1
498/498 [==============================] - 9s 19ms/step - loss: 0.0225 - mean_absolute_error: 0.1124
Epoch 3 completed!
Exp2019-01-25_02-37-37.h5 has been saved.
The subjects are trained: [(19, 'M11'), (16, 'M09'), (21, 'F02'), (15, 'F03'), (13, 'M07'), (12, 'M06'), (18, 'F05'),
 (22, 'M01'), (23, 'M13'), (8, 'M02'), (17, 'M10'), (6, 'F06'), (24, 'M14'), (11, 'M05'), (10, 'M04'), (20, 'M12'), (
2, 'F02'), (4, 'F04'), (7, 'M01'), (1, 'F01')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output1_BatchSize1_inEpochs1_outEpochs3_AdamOpt_lr-0.000100_20
19-01-25_02-37-37
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 02:55:08.697361
For the Subject 3 (F03):
730/730 [==============================] - 7s 9ms/step
        The absolute mean error on Yaw angle estimation: 27.62 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 9ms/step
        The absolute mean error on Yaw angle estimation: 33.56 Degree
For the Subject 9 (M03):
882/882 [==============================] - 8s 9ms/step
        The absolute mean error on Yaw angle estimation: 38.50 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Yaw angle estimation: 32.66 Degree
On average in 4 test subjects:
        The absolute mean error on Yaw angle estimations: 33.09 Degree
subject3_Exp2019-01-25_02-37-37.png has been saved by 2019-01-25 02:56:14.181957.
subject5_Exp2019-01-25_02-37-37.png has been saved by 2019-01-25 02:56:14.268012.
subject9_Exp2019-01-25_02-37-37.png has been saved by 2019-01-25 02:56:14.352156.
subject14_Exp2019-01-25_02-37-37.png has been saved by 2019-01-25 02:56:14.445270.
Model Exp2019-01-25_02-37-37 has been evaluated successfully.
Model Exp2019-01-25_02-37-37 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 03:00:05.830349: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 03:00:05.928002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 03:00:05.928266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 03:00:05.928280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 03:00:06.082986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 03:00:06.083012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 03:00:06.083021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 03:00:06.083160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10471 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_03-00-06 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 4096)              134260544
_________________________________________________________________
lstm_1 (LSTM)                (1, 320)                  5653760
_________________________________________________________________
dense_1 (Dense)              (1, 1)                    321
=================================================================
Total params: 139,914,625
Trainable params: 5,654,081
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 4
num_outputs = 1

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.00001
in_epochs = 1
out_epochs = 1
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 320
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm320_output1_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000010_201
9-01-25_03-00-06
All frames and annotations from 20 datasets have been read by 2019-01-25 03:00:11.395658
1. set (Dataset 22) being trained for epoch 1 by 2019-01-25 03:00:17.786702!
Epoch 1/1
665/665 [==============================] - 14s 22ms/step - loss: 0.0465 - mean_absolute_error: 0.1700
2. set (Dataset 24) being trained for epoch 1 by 2019-01-25 03:00:37.300343!
Epoch 1/1
492/492 [==============================] - 10s 20ms/step - loss: 0.0292 - mean_absolute_error: 0.1350
3. set (Dataset 15) being trained for epoch 1 by 2019-01-25 03:00:53.841138!
Epoch 1/1
654/654 [==============================] - 14s 21ms/step - loss: 0.0419 - mean_absolute_error: 0.1583
4. set (Dataset 19) being trained for epoch 1 by 2019-01-25 03:01:12.308737!
Epoch 1/1
502/502 [==============================] - 10s 20ms/step - loss: 0.0441 - mean_absolute_error: 0.1525
5. set (Dataset 8) being trained for epoch 1 by 2019-01-25 03:01:30.333808!
Epoch 1/1
772/772 [==============================] - 16s 21ms/step - loss: 0.0567 - mean_absolute_error: 0.1710
6. set (Dataset 23) being trained for epoch 1 by 2019-01-25 03:01:51.763594!
Epoch 1/1
569/569 [==============================] - 12s 20ms/step - loss: 0.0491 - mean_absolute_error: 0.1716
7. set (Dataset 21) being trained for epoch 1 by 2019-01-25 03:02:09.518619!
Epoch 1/1
634/634 [==============================] - 13s 21ms/step - loss: 0.0222 - mean_absolute_error: 0.1155
8. set (Dataset 16) being trained for epoch 1 by 2019-01-25 03:02:31.412682!
Epoch 1/1
914/914 [==============================] - 19s 21ms/step - loss: 0.0221 - mean_absolute_error: 0.1121
9. set (Dataset 7) being trained for epoch 1 by 2019-01-25 03:02:58.028008!
Epoch 1/1
745/745 [==============================] - 15s 21ms/step - loss: 0.0278 - mean_absolute_error: 0.1259
10. set (Dataset 12) being trained for epoch 1 by 2019-01-25 03:03:20.874736!
Epoch 1/1
732/732 [==============================] - 15s 21ms/step - loss: 0.0261 - mean_absolute_error: 0.1248
11. set (Dataset 10) being trained for epoch 1 by 2019-01-25 03:03:43.134818!
Epoch 1/1
726/726 [==============================] - 15s 21ms/step - loss: 0.0417 - mean_absolute_error: 0.1536
12. set (Dataset 1) being trained for epoch 1 by 2019-01-25 03:04:03.297902!
Epoch 1/1
498/498 [==============================] - 10s 21ms/step - loss: 0.0477 - mean_absolute_error: 0.1661
13. set (Dataset 18) being trained for epoch 1 by 2019-01-25 03:04:19.627694!
Epoch 1/1
614/614 [==============================] - 13s 21ms/step - loss: 0.0330 - mean_absolute_error: 0.1337
14. set (Dataset 2) being trained for epoch 1 by 2019-01-25 03:04:37.495788!
Epoch 1/1
511/511 [==============================] - 10s 20ms/step - loss: 0.0324 - mean_absolute_error: 0.1362
15. set (Dataset 4) being trained for epoch 1 by 2019-01-25 03:04:55.455035!
Epoch 1/1
744/744 [==============================] - 15s 21ms/step - loss: 0.0329 - mean_absolute_error: 0.1336
16. set (Dataset 20) being trained for epoch 1 by 2019-01-25 03:05:16.295140!
Epoch 1/1
556/556 [==============================] - 11s 20ms/step - loss: 0.0405 - mean_absolute_error: 0.1396
17. set (Dataset 17) being trained for epoch 1 by 2019-01-25 03:05:31.354325!
Epoch 1/1
395/395 [==============================] - 8s 21ms/step - loss: 0.0188 - mean_absolute_error: 0.1063
18. set (Dataset 6) being trained for epoch 1 by 2019-01-25 03:05:44.824934!
Epoch 1/1
542/542 [==============================] - 11s 21ms/step - loss: 0.0370 - mean_absolute_error: 0.1423
19. set (Dataset 13) being trained for epoch 1 by 2019-01-25 03:06:01.064996!
Epoch 1/1
485/485 [==============================] - 10s 21ms/step - loss: 0.0175 - mean_absolute_error: 0.1050
20. set (Dataset 11) being trained for epoch 1 by 2019-01-25 03:06:16.834199!
Epoch 1/1
572/572 [==============================] - 12s 20ms/step - loss: 0.0256 - mean_absolute_error: 0.1189
Epoch 1 completed!
Exp2019-01-25_03-00-06.h5 has been saved.
The subjects are trained: [(22, 'M01'), (24, 'M14'), (15, 'F03'), (19, 'M11'), (8, 'M02'), (23, 'M13'), (21, 'F02'),
(16, 'M09'), (7, 'M01'), (12, 'M06'), (10, 'M04'), (1, 'F01'), (18, 'F05'), (2, 'F02'), (4, 'F04'), (20, 'M12'), (17,
 'M10'), (6, 'F06'), (13, 'M07'), (11, 'M05')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm320_output1_BatchSize1_inEpochs1_outEpochs1_AdamOpt_lr-0.000010_2
019-01-25_03-00-06
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 03:06:31.063741
For the Subject 3 (F03):
730/730 [==============================] - 7s 10ms/step
        The absolute mean error on Yaw angle estimation: 111.08 Degree
For the Subject 5 (F05):
946/946 [==============================] - 9s 10ms/step
        The absolute mean error on Yaw angle estimation: 21.64 Degree
For the Subject 9 (M03):
882/882 [==============================] - 9s 10ms/step
        The absolute mean error on Yaw angle estimation: 31.99 Degree
For the Subject 14 (M08):
797/797 [==============================] - 8s 10ms/step
        The absolute mean error on Yaw angle estimation: 59.61 Degree
On average in 4 test subjects:
        The absolute mean error on Yaw angle estimations: 56.08 Degree
subject3_Exp2019-01-25_03-00-06.png has been saved by 2019-01-25 03:07:37.726594.
subject5_Exp2019-01-25_03-00-06.png has been saved by 2019-01-25 03:07:37.810034.
subject9_Exp2019-01-25_03-00-06.png has been saved by 2019-01-25 03:07:37.894124.
subject14_Exp2019-01-25_03-00-06.png has been saved by 2019-01-25 03:07:37.987302.
Model Exp2019-01-25_03-00-06 has been evaluated successfully.
Model Exp2019-01-25_03-00-06 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 03:10:42.497085: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 03:10:42.594324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 03:10:42.594584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 03:10:42.594595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 03:10:42.752190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 03:10:42.752216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 03:10:42.752221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 03:10:42.752359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_03-11-29 has been started to be evaluated.
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            (None, 331, 331, 3)  0
__________________________________________________________________________________________________
stem_conv1 (Conv2D)             (None, 165, 165, 96) 2592        input_1[0][0]
__________________________________________________________________________________________________
stem_bn1 (BatchNormalization)   (None, 165, 165, 96) 384         stem_conv1[0][0]
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
reduction_conv_1_stem_1 (Conv2D (None, 165, 165, 42) 4032        activation_1[0][0]
__________________________________________________________________________________________________
reduction_bn_1_stem_1 (BatchNor (None, 165, 165, 42) 168         reduction_conv_1_stem_1[0][0]
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 165, 165, 42) 0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 83, 83, 42)   2814        activation_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_st (None, 83, 83, 42)   8736        activation_4[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 83, 83, 42)   168         separable_conv_1_reduction_1_stem
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 83, 83, 42)   2814        activation_3[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_st (None, 83, 83, 42)   3822        activation_5[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 83, 83, 42)   168         separable_conv_2_reduction_1_stem
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
reduction_add_1_stem_1 (Add)    (None, 83, 83, 42)   0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 83, 83, 42)   8736        activation_6[0][0]
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 83, 83, 42)   0           reduction_add_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 83, 83, 42)   6432        activation_8[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 83, 83, 42)   2142        activation_10[0][0]
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 83, 83, 42)   3822        activation_7[0][0]
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 83, 83, 42)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_stem_1 (MaxPool (None, 83, 83, 42)   0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 83, 83, 42)   2814        activation_9[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 83, 83, 42)   2142        activation_11[0][0]
__________________________________________________________________________________________________
adjust_relu_1_stem_2 (Activatio (None, 165, 165, 96) 0           stem_bn1[0][0]
__________________________________________________________________________________________________
reduction_add_2_stem_1 (Add)    (None, 83, 83, 42)   0           reduction_left2_stem_1[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_stem_1 (Average (None, 83, 83, 42)   0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 83, 83, 42)   168         separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_stem_1 (Average (None, 83, 83, 42)   0           reduction_add_1_stem_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 83, 83, 42)   168         separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_stem_1 (MaxPoo (None, 83, 83, 42)   0           reduction_bn_1_stem_1[0][0]
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 166, 166, 96) 0           adjust_relu_1_stem_2[0][0]
__________________________________________________________________________________________________
reduction_add3_stem_1 (Add)     (None, 83, 83, 42)   0           reduction_left3_stem_1[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_1 (Add)                     (None, 83, 83, 42)   0           reduction_add_2_stem_1[0][0]
                                                                 reduction_left4_stem_1[0][0]
__________________________________________________________________________________________________
reduction_add4_stem_1 (Add)     (None, 83, 83, 42)   0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_stem_1[0][0]
__________________________________________________________________________________________________
cropping2d_1 (Cropping2D)       (None, 165, 165, 96) 0           zero_padding2d_1[0][0]
__________________________________________________________________________________________________
reduction_concat_stem_1 (Concat (None, 83, 83, 168)  0           reduction_add_2_stem_1[0][0]
                                                                 reduction_add3_stem_1[0][0]
                                                                 add_1[0][0]
                                                                 reduction_add4_stem_1[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_stem_2 (Avera (None, 83, 83, 96)   0           adjust_relu_1_stem_2[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_stem_2 (Avera (None, 83, 83, 96)   0           cropping2d_1[0][0]
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 83, 83, 168)  0           reduction_concat_stem_1[0][0]
__________________________________________________________________________________________________
adjust_conv_1_stem_2 (Conv2D)   (None, 83, 83, 42)   4032        adjust_avg_pool_1_stem_2[0][0]
__________________________________________________________________________________________________
adjust_conv_2_stem_2 (Conv2D)   (None, 83, 83, 42)   4032        adjust_avg_pool_2_stem_2[0][0]
__________________________________________________________________________________________________
reduction_conv_1_stem_2 (Conv2D (None, 83, 83, 84)   14112       activation_12[0][0]
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 83, 83, 84)   0           adjust_conv_1_stem_2[0][0]
                                                                 adjust_conv_2_stem_2[0][0]
__________________________________________________________________________________________________
reduction_bn_1_stem_2 (BatchNor (None, 83, 83, 84)   336         reduction_conv_1_stem_2[0][0]
__________________________________________________________________________________________________
adjust_bn_stem_2 (BatchNormaliz (None, 83, 83, 84)   336         concatenate_1[0][0]
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 83, 83, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 83, 83, 84)   0           adjust_bn_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 42, 42, 84)   9156        activation_13[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_st (None, 42, 42, 84)   11172       activation_15[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 42, 42, 84)   336         separable_conv_1_reduction_1_stem
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 42, 42, 84)   9156        activation_14[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_st (None, 42, 42, 84)   11172       activation_16[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 42, 42, 84)   336         separable_conv_2_reduction_1_stem
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 83, 83, 84)   0           adjust_bn_stem_2[0][0]
__________________________________________________________________________________________________
reduction_add_1_stem_2 (Add)    (None, 42, 42, 84)   0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_s
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 42, 42, 84)   11172       activation_17[0][0]
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 83, 83, 84)   0           adjust_bn_stem_2[0][0]
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 42, 42, 84)   0           reduction_add_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 42, 42, 84)   9156        activation_19[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 42, 42, 84)   7812        activation_21[0][0]
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 42, 42, 84)   11172       activation_18[0][0]
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 42, 42, 84)   0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_stem_2 (MaxPool (None, 42, 42, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 42, 42, 84)   9156        activation_20[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 42, 42, 84)   7812        activation_22[0][0]
__________________________________________________________________________________________________
adjust_relu_1_0 (Activation)    (None, 83, 83, 168)  0           reduction_concat_stem_1[0][0]
__________________________________________________________________________________________________
reduction_add_2_stem_2 (Add)    (None, 42, 42, 84)   0           reduction_left2_stem_2[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_stem_2 (Average (None, 42, 42, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 42, 42, 84)   336         separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_stem_2 (Average (None, 42, 42, 84)   0           reduction_add_1_stem_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 42, 42, 84)   336         separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_stem_2 (MaxPoo (None, 42, 42, 84)   0           reduction_bn_1_stem_2[0][0]
__________________________________________________________________________________________________
zero_padding2d_2 (ZeroPadding2D (None, 84, 84, 168)  0           adjust_relu_1_0[0][0]
__________________________________________________________________________________________________
reduction_add3_stem_2 (Add)     (None, 42, 42, 84)   0           reduction_left3_stem_2[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_2 (Add)                     (None, 42, 42, 84)   0           reduction_add_2_stem_2[0][0]
                                                                 reduction_left4_stem_2[0][0]
__________________________________________________________________________________________________
reduction_add4_stem_2 (Add)     (None, 42, 42, 84)   0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_stem_2[0][0]
__________________________________________________________________________________________________
cropping2d_2 (Cropping2D)       (None, 83, 83, 168)  0           zero_padding2d_2[0][0]
__________________________________________________________________________________________________
reduction_concat_stem_2 (Concat (None, 42, 42, 336)  0           reduction_add_2_stem_2[0][0]
                                                                 reduction_add3_stem_2[0][0]
                                                                 add_2[0][0]
                                                                 reduction_add4_stem_2[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_0 (AveragePoo (None, 42, 42, 168)  0           adjust_relu_1_0[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_0 (AveragePoo (None, 42, 42, 168)  0           cropping2d_2[0][0]
__________________________________________________________________________________________________
adjust_conv_1_0 (Conv2D)        (None, 42, 42, 84)   14112       adjust_avg_pool_1_0[0][0]
__________________________________________________________________________________________________
adjust_conv_2_0 (Conv2D)        (None, 42, 42, 84)   14112       adjust_avg_pool_2_0[0][0]
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 42, 42, 336)  0           reduction_concat_stem_2[0][0]
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 42, 168)  0           adjust_conv_1_0[0][0]
                                                                 adjust_conv_2_0[0][0]
__________________________________________________________________________________________________
normal_conv_1_0 (Conv2D)        (None, 42, 42, 168)  56448       activation_23[0][0]
__________________________________________________________________________________________________
adjust_bn_0 (BatchNormalization (None, 42, 42, 168)  672         concatenate_2[0][0]
__________________________________________________________________________________________________
normal_bn_1_0 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_0[0][0]
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_0[0][0]
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_0[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_0 (None, 42, 42, 168)  32424       activation_24[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_26[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_0 (None, 42, 42, 168)  32424       activation_28[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_30[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_0 (None, 42, 42, 168)  29736       activation_32[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_0[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_0[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_0[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_0[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_0[0
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_0 (None, 42, 42, 168)  32424       activation_25[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_27[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_0 (None, 42, 42, 168)  32424       activation_29[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_31[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_0 (None, 42, 42, 168)  29736       activation_33[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_0[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_0[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_0[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_0[
__________________________________________________________________________________________________
normal_left3_0 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_0[0][0]
__________________________________________________________________________________________________
normal_left4_0 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
normal_right4_0 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_0[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_0[0
__________________________________________________________________________________________________
normal_add_1_0 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_0 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_0 (Add)            (None, 42, 42, 168)  0           normal_left3_0[0][0]
                                                                 adjust_bn_0[0][0]
__________________________________________________________________________________________________
normal_add_4_0 (Add)            (None, 42, 42, 168)  0           normal_left4_0[0][0]
                                                                 normal_right4_0[0][0]
__________________________________________________________________________________________________
normal_add_5_0 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_0[0][0]
__________________________________________________________________________________________________
normal_concat_0 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_0[0][0]
                                                                 normal_add_1_0[0][0]
                                                                 normal_add_2_0[0][0]
                                                                 normal_add_3_0[0][0]
                                                                 normal_add_4_0[0][0]
                                                                 normal_add_5_0[0][0]
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 42, 42, 336)  0           reduction_concat_stem_2[0][0]
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 42, 42, 1008) 0           normal_concat_0[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_1 (Conv2 (None, 42, 42, 168)  56448       activation_34[0][0]
__________________________________________________________________________________________________
normal_conv_1_1 (Conv2D)        (None, 42, 42, 168)  169344      activation_35[0][0]
__________________________________________________________________________________________________
adjust_bn_1 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_1[0][0]
__________________________________________________________________________________________________
normal_bn_1_1 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_1[0][0]
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_1[0][0]
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_1[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 42, 42, 168)  32424       activation_36[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_38[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 42, 42, 168)  32424       activation_40[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_42[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 42, 42, 168)  29736       activation_44[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_1[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_1[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_1[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_1[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_1[0
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 42, 42, 168)  32424       activation_37[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_39[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 42, 42, 168)  32424       activation_41[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_43[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 42, 42, 168)  29736       activation_45[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_1[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_1[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_1[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_1[
__________________________________________________________________________________________________
normal_left3_1 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_1[0][0]
__________________________________________________________________________________________________
normal_left4_1 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
normal_right4_1 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_1[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_1[0
__________________________________________________________________________________________________
normal_add_1_1 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_1 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_1 (Add)            (None, 42, 42, 168)  0           normal_left3_1[0][0]
                                                                 adjust_bn_1[0][0]
__________________________________________________________________________________________________
normal_add_4_1 (Add)            (None, 42, 42, 168)  0           normal_left4_1[0][0]
                                                                 normal_right4_1[0][0]
__________________________________________________________________________________________________
normal_add_5_1 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_1[0][0]
__________________________________________________________________________________________________
normal_concat_1 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_1[0][0]
                                                                 normal_add_1_1[0][0]
                                                                 normal_add_2_1[0][0]
                                                                 normal_add_3_1[0][0]
                                                                 normal_add_4_1[0][0]
                                                                 normal_add_5_1[0][0]
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 42, 42, 1008) 0           normal_concat_0[0][0]
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 42, 42, 1008) 0           normal_concat_1[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_2 (Conv2 (None, 42, 42, 168)  169344      activation_46[0][0]
__________________________________________________________________________________________________
normal_conv_1_2 (Conv2D)        (None, 42, 42, 168)  169344      activation_47[0][0]
__________________________________________________________________________________________________
adjust_bn_2 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_2[0][0]
__________________________________________________________________________________________________
normal_bn_1_2 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_2[0][0]
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_2[0][0]
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_2[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_2 (None, 42, 42, 168)  32424       activation_48[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_50[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_2 (None, 42, 42, 168)  32424       activation_52[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_54[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_2 (None, 42, 42, 168)  29736       activation_56[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_2[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_2[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_2[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_2[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_2[0
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_2 (None, 42, 42, 168)  32424       activation_49[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_51[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_2 (None, 42, 42, 168)  32424       activation_53[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_55[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_2 (None, 42, 42, 168)  29736       activation_57[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_2[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_2[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_2[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_2[
__________________________________________________________________________________________________
normal_left3_2 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_2[0][0]
__________________________________________________________________________________________________
normal_left4_2 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
normal_right4_2 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_2[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_2[0
__________________________________________________________________________________________________
normal_add_1_2 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_2 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_2 (Add)            (None, 42, 42, 168)  0           normal_left3_2[0][0]
                                                                 adjust_bn_2[0][0]
__________________________________________________________________________________________________
normal_add_4_2 (Add)            (None, 42, 42, 168)  0           normal_left4_2[0][0]
                                                                 normal_right4_2[0][0]
__________________________________________________________________________________________________
normal_add_5_2 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_2[0][0]
__________________________________________________________________________________________________
normal_concat_2 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_2[0][0]
                                                                 normal_add_1_2[0][0]
                                                                 normal_add_2_2[0][0]
                                                                 normal_add_3_2[0][0]
                                                                 normal_add_4_2[0][0]
                                                                 normal_add_5_2[0][0]
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 42, 42, 1008) 0           normal_concat_1[0][0]
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 42, 42, 1008) 0           normal_concat_2[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_3 (Conv2 (None, 42, 42, 168)  169344      activation_58[0][0]
__________________________________________________________________________________________________
normal_conv_1_3 (Conv2D)        (None, 42, 42, 168)  169344      activation_59[0][0]
__________________________________________________________________________________________________
adjust_bn_3 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_3[0][0]
__________________________________________________________________________________________________
normal_bn_1_3 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_3[0][0]
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_3[0][0]
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_3[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_3 (None, 42, 42, 168)  32424       activation_60[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_62[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_3 (None, 42, 42, 168)  32424       activation_64[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_66[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_3 (None, 42, 42, 168)  29736       activation_68[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_3[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_3[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_3[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_3[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_3[0
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_3 (None, 42, 42, 168)  32424       activation_61[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_63[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_3 (None, 42, 42, 168)  32424       activation_65[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_67[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_3 (None, 42, 42, 168)  29736       activation_69[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_3[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_3[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_3[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_3[
__________________________________________________________________________________________________
normal_left3_3 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_3[0][0]
__________________________________________________________________________________________________
normal_left4_3 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
normal_right4_3 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_3[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_3[0
__________________________________________________________________________________________________
normal_add_1_3 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_3 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_3 (Add)            (None, 42, 42, 168)  0           normal_left3_3[0][0]
                                                                 adjust_bn_3[0][0]
__________________________________________________________________________________________________
normal_add_4_3 (Add)            (None, 42, 42, 168)  0           normal_left4_3[0][0]
                                                                 normal_right4_3[0][0]
__________________________________________________________________________________________________
normal_add_5_3 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_3[0][0]
__________________________________________________________________________________________________
normal_concat_3 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_3[0][0]
                                                                 normal_add_1_3[0][0]
                                                                 normal_add_2_3[0][0]
                                                                 normal_add_3_3[0][0]
                                                                 normal_add_4_3[0][0]
                                                                 normal_add_5_3[0][0]
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 42, 42, 1008) 0           normal_concat_2[0][0]
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 42, 42, 1008) 0           normal_concat_3[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_4 (Conv2 (None, 42, 42, 168)  169344      activation_70[0][0]
__________________________________________________________________________________________________
normal_conv_1_4 (Conv2D)        (None, 42, 42, 168)  169344      activation_71[0][0]
__________________________________________________________________________________________________
adjust_bn_4 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_4[0][0]
__________________________________________________________________________________________________
normal_bn_1_4 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_4[0][0]
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_4[0][0]
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_4[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_4 (None, 42, 42, 168)  32424       activation_72[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_74[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_4 (None, 42, 42, 168)  32424       activation_76[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_78[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_4 (None, 42, 42, 168)  29736       activation_80[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_4[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_4[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_4[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_4[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_4[0
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_4 (None, 42, 42, 168)  32424       activation_73[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_75[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_4 (None, 42, 42, 168)  32424       activation_77[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_79[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_4 (None, 42, 42, 168)  29736       activation_81[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_4[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_4[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_4[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_4[
__________________________________________________________________________________________________
normal_left3_4 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_4[0][0]
__________________________________________________________________________________________________
normal_left4_4 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
normal_right4_4 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_4[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_4[0
__________________________________________________________________________________________________
normal_add_1_4 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_4 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_4 (Add)            (None, 42, 42, 168)  0           normal_left3_4[0][0]
                                                                 adjust_bn_4[0][0]
__________________________________________________________________________________________________
normal_add_4_4 (Add)            (None, 42, 42, 168)  0           normal_left4_4[0][0]
                                                                 normal_right4_4[0][0]
__________________________________________________________________________________________________
normal_add_5_4 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_4[0][0]
__________________________________________________________________________________________________
normal_concat_4 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_4[0][0]
                                                                 normal_add_1_4[0][0]
                                                                 normal_add_2_4[0][0]
                                                                 normal_add_3_4[0][0]
                                                                 normal_add_4_4[0][0]
                                                                 normal_add_5_4[0][0]
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 42, 42, 1008) 0           normal_concat_3[0][0]
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 42, 42, 1008) 0           normal_concat_4[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_5 (Conv2 (None, 42, 42, 168)  169344      activation_82[0][0]
__________________________________________________________________________________________________
normal_conv_1_5 (Conv2D)        (None, 42, 42, 168)  169344      activation_83[0][0]
__________________________________________________________________________________________________
adjust_bn_5 (BatchNormalization (None, 42, 42, 168)  672         adjust_conv_projection_5[0][0]
__________________________________________________________________________________________________
normal_bn_1_5 (BatchNormalizati (None, 42, 42, 168)  672         normal_conv_1_5[0][0]
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_5[0][0]
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 42, 42, 168)  0           normal_bn_1_5[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_5 (None, 42, 42, 168)  32424       activation_84[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 42, 42, 168)  29736       activation_86[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_5 (None, 42, 42, 168)  32424       activation_88[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 42, 42, 168)  29736       activation_90[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_5 (None, 42, 42, 168)  29736       activation_92[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left1_5[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right1_5[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left2_5[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_1_normal_right2_5[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 42, 42, 168)  672         separable_conv_1_normal_left5_5[0
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 42, 42, 168)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_5 (None, 42, 42, 168)  32424       activation_85[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 42, 42, 168)  29736       activation_87[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_5 (None, 42, 42, 168)  32424       activation_89[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 42, 42, 168)  29736       activation_91[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_5 (None, 42, 42, 168)  29736       activation_93[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left1_5[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right1_5[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left2_5[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 42, 42, 168)  672         separable_conv_2_normal_right2_5[
__________________________________________________________________________________________________
normal_left3_5 (AveragePooling2 (None, 42, 42, 168)  0           normal_bn_1_5[0][0]
__________________________________________________________________________________________________
normal_left4_5 (AveragePooling2 (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
normal_right4_5 (AveragePooling (None, 42, 42, 168)  0           adjust_bn_5[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 42, 42, 168)  672         separable_conv_2_normal_left5_5[0
__________________________________________________________________________________________________
normal_add_1_5 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_5 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_5 (Add)            (None, 42, 42, 168)  0           normal_left3_5[0][0]
                                                                 adjust_bn_5[0][0]
__________________________________________________________________________________________________
normal_add_4_5 (Add)            (None, 42, 42, 168)  0           normal_left4_5[0][0]
                                                                 normal_right4_5[0][0]
__________________________________________________________________________________________________
normal_add_5_5 (Add)            (None, 42, 42, 168)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_5[0][0]
__________________________________________________________________________________________________
normal_concat_5 (Concatenate)   (None, 42, 42, 1008) 0           adjust_bn_5[0][0]
                                                                 normal_add_1_5[0][0]
                                                                 normal_add_2_5[0][0]
                                                                 normal_add_3_5[0][0]
                                                                 normal_add_4_5[0][0]
                                                                 normal_add_5_5[0][0]
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 42, 42, 1008) 0           normal_concat_5[0][0]
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 42, 42, 1008) 0           normal_concat_4[0][0]
__________________________________________________________________________________________________
reduction_conv_1_reduce_6 (Conv (None, 42, 42, 336)  338688      activation_95[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_reduce_6 (None, 42, 42, 336)  338688      activation_94[0][0]
__________________________________________________________________________________________________
reduction_bn_1_reduce_6 (BatchN (None, 42, 42, 336)  1344        reduction_conv_1_reduce_6[0][0]
__________________________________________________________________________________________________
adjust_bn_reduce_6 (BatchNormal (None, 42, 42, 336)  1344        adjust_conv_projection_reduce_6[0
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 42, 42, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 42, 42, 336)  0           adjust_bn_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 21, 21, 336)  121296      activation_96[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_re (None, 21, 21, 336)  129360      activation_98[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 21, 21, 336)  1344        separable_conv_1_reduction_1_redu
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 21, 21, 336)  121296      activation_97[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_re (None, 21, 21, 336)  129360      activation_99[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 21, 21, 336)  1344        separable_conv_2_reduction_1_redu
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 42, 42, 336)  0           adjust_bn_reduce_6[0][0]
__________________________________________________________________________________________________
reduction_add_1_reduce_6 (Add)  (None, 21, 21, 336)  0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 21, 21, 336)  129360      activation_100[0][0]
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 42, 42, 336)  0           adjust_bn_reduce_6[0][0]
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 21, 21, 336)  0           reduction_add_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 21, 21, 336)  121296      activation_102[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 21, 21, 336)  115920      activation_104[0][0]
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 21, 21, 336)  129360      activation_101[0][0]
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_reduce_6 (MaxPo (None, 21, 21, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 21, 21, 336)  121296      activation_103[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 21, 21, 336)  115920      activation_105[0][0]
__________________________________________________________________________________________________
adjust_relu_1_7 (Activation)    (None, 42, 42, 1008) 0           normal_concat_5[0][0]
__________________________________________________________________________________________________
reduction_add_2_reduce_6 (Add)  (None, 21, 21, 336)  0           reduction_left2_reduce_6[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_reduce_6 (Avera (None, 21, 21, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 21, 21, 336)  1344        separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_reduce_6 (Avera (None, 21, 21, 336)  0           reduction_add_1_reduce_6[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 21, 21, 336)  1344        separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_reduce_6 (MaxP (None, 21, 21, 336)  0           reduction_bn_1_reduce_6[0][0]
__________________________________________________________________________________________________
zero_padding2d_3 (ZeroPadding2D (None, 43, 43, 1008) 0           adjust_relu_1_7[0][0]
__________________________________________________________________________________________________
reduction_add3_reduce_6 (Add)   (None, 21, 21, 336)  0           reduction_left3_reduce_6[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_3 (Add)                     (None, 21, 21, 336)  0           reduction_add_2_reduce_6[0][0]
                                                                 reduction_left4_reduce_6[0][0]
__________________________________________________________________________________________________
reduction_add4_reduce_6 (Add)   (None, 21, 21, 336)  0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_reduce_6[0][0]
__________________________________________________________________________________________________
cropping2d_3 (Cropping2D)       (None, 42, 42, 1008) 0           zero_padding2d_3[0][0]
__________________________________________________________________________________________________
reduction_concat_reduce_6 (Conc (None, 21, 21, 1344) 0           reduction_add_2_reduce_6[0][0]
                                                                 reduction_add3_reduce_6[0][0]
                                                                 add_3[0][0]
                                                                 reduction_add4_reduce_6[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_7 (AveragePoo (None, 21, 21, 1008) 0           adjust_relu_1_7[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_7 (AveragePoo (None, 21, 21, 1008) 0           cropping2d_3[0][0]
__________________________________________________________________________________________________
adjust_conv_1_7 (Conv2D)        (None, 21, 21, 168)  169344      adjust_avg_pool_1_7[0][0]
__________________________________________________________________________________________________
adjust_conv_2_7 (Conv2D)        (None, 21, 21, 168)  169344      adjust_avg_pool_2_7[0][0]
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 21, 21, 1344) 0           reduction_concat_reduce_6[0][0]
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 21, 336)  0           adjust_conv_1_7[0][0]
                                                                 adjust_conv_2_7[0][0]
__________________________________________________________________________________________________
normal_conv_1_7 (Conv2D)        (None, 21, 21, 336)  451584      activation_106[0][0]
__________________________________________________________________________________________________
adjust_bn_7 (BatchNormalization (None, 21, 21, 336)  1344        concatenate_3[0][0]
__________________________________________________________________________________________________
normal_bn_1_7 (BatchNormalizati (None, 21, 21, 336)  1344        normal_conv_1_7[0][0]
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_7[0][0]
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_7[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_7 (None, 21, 21, 336)  121296      activation_107[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_109[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_7 (None, 21, 21, 336)  121296      activation_111[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_113[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_7 (None, 21, 21, 336)  115920      activation_115[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_7[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_7[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_7[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_7[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_7[0
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_7 (None, 21, 21, 336)  121296      activation_108[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_110[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_7 (None, 21, 21, 336)  121296      activation_112[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_114[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_7 (None, 21, 21, 336)  115920      activation_116[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_7[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_7[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_7[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_7[
__________________________________________________________________________________________________
normal_left3_7 (AveragePooling2 (None, 21, 21, 336)  0           normal_bn_1_7[0][0]
__________________________________________________________________________________________________
normal_left4_7 (AveragePooling2 (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
normal_right4_7 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_7[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_7[0
__________________________________________________________________________________________________
normal_add_1_7 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_7 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_7 (Add)            (None, 21, 21, 336)  0           normal_left3_7[0][0]
                                                                 adjust_bn_7[0][0]
__________________________________________________________________________________________________
normal_add_4_7 (Add)            (None, 21, 21, 336)  0           normal_left4_7[0][0]
                                                                 normal_right4_7[0][0]
__________________________________________________________________________________________________
normal_add_5_7 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_7[0][0]
__________________________________________________________________________________________________
normal_concat_7 (Concatenate)   (None, 21, 21, 2016) 0           adjust_bn_7[0][0]
                                                                 normal_add_1_7[0][0]
                                                                 normal_add_2_7[0][0]
                                                                 normal_add_3_7[0][0]
                                                                 normal_add_4_7[0][0]
                                                                 normal_add_5_7[0][0]
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 21, 21, 1344) 0           reduction_concat_reduce_6[0][0]
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 21, 21, 2016) 0           normal_concat_7[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_8 (Conv2 (None, 21, 21, 336)  451584      activation_117[0][0]
__________________________________________________________________________________________________
normal_conv_1_8 (Conv2D)        (None, 21, 21, 336)  677376      activation_118[0][0]
__________________________________________________________________________________________________
adjust_bn_8 (BatchNormalization (None, 21, 21, 336)  1344        adjust_conv_projection_8[0][0]
__________________________________________________________________________________________________
normal_bn_1_8 (BatchNormalizati (None, 21, 21, 336)  1344        normal_conv_1_8[0][0]
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_8[0][0]
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_8[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_8 (None, 21, 21, 336)  121296      activation_119[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_121[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_8 (None, 21, 21, 336)  121296      activation_123[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_125[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_8 (None, 21, 21, 336)  115920      activation_127[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_8[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_8[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_8[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_8[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_8[0
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_8 (None, 21, 21, 336)  121296      activation_120[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_122[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_8 (None, 21, 21, 336)  121296      activation_124[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_126[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_8 (None, 21, 21, 336)  115920      activation_128[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_8[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_8[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_8[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_8[
__________________________________________________________________________________________________
normal_left3_8 (AveragePooling2 (None, 21, 21, 336)  0           normal_bn_1_8[0][0]
__________________________________________________________________________________________________
normal_left4_8 (AveragePooling2 (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
normal_right4_8 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_8[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_8[0
__________________________________________________________________________________________________
normal_add_1_8 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_8 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_8 (Add)            (None, 21, 21, 336)  0           normal_left3_8[0][0]
                                                                 adjust_bn_8[0][0]
__________________________________________________________________________________________________
normal_add_4_8 (Add)            (None, 21, 21, 336)  0           normal_left4_8[0][0]
                                                                 normal_right4_8[0][0]
__________________________________________________________________________________________________
normal_add_5_8 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_8[0][0]
__________________________________________________________________________________________________
normal_concat_8 (Concatenate)   (None, 21, 21, 2016) 0           adjust_bn_8[0][0]
                                                                 normal_add_1_8[0][0]
                                                                 normal_add_2_8[0][0]
                                                                 normal_add_3_8[0][0]
                                                                 normal_add_4_8[0][0]
                                                                 normal_add_5_8[0][0]
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 21, 21, 2016) 0           normal_concat_7[0][0]
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 21, 21, 2016) 0           normal_concat_8[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_9 (Conv2 (None, 21, 21, 336)  677376      activation_129[0][0]
__________________________________________________________________________________________________
normal_conv_1_9 (Conv2D)        (None, 21, 21, 336)  677376      activation_130[0][0]
__________________________________________________________________________________________________
adjust_bn_9 (BatchNormalization (None, 21, 21, 336)  1344        adjust_conv_projection_9[0][0]
__________________________________________________________________________________________________
normal_bn_1_9 (BatchNormalizati (None, 21, 21, 336)  1344        normal_conv_1_9[0][0]
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_9[0][0]
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_9[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_9 (None, 21, 21, 336)  121296      activation_131[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_133[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_9 (None, 21, 21, 336)  121296      activation_135[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_137[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_9 (None, 21, 21, 336)  115920      activation_139[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_9[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_9[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_9[0
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_9[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_9[0
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_9 (None, 21, 21, 336)  121296      activation_132[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_134[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_9 (None, 21, 21, 336)  121296      activation_136[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_138[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_9 (None, 21, 21, 336)  115920      activation_140[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_9[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_9[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_9[0
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_9[
__________________________________________________________________________________________________
normal_left3_9 (AveragePooling2 (None, 21, 21, 336)  0           normal_bn_1_9[0][0]
__________________________________________________________________________________________________
normal_left4_9 (AveragePooling2 (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
normal_right4_9 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_9[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_9[0
__________________________________________________________________________________________________
normal_add_1_9 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_9 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_9 (Add)            (None, 21, 21, 336)  0           normal_left3_9[0][0]
                                                                 adjust_bn_9[0][0]
__________________________________________________________________________________________________
normal_add_4_9 (Add)            (None, 21, 21, 336)  0           normal_left4_9[0][0]
                                                                 normal_right4_9[0][0]
__________________________________________________________________________________________________
normal_add_5_9 (Add)            (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_9[0][0]
__________________________________________________________________________________________________
normal_concat_9 (Concatenate)   (None, 21, 21, 2016) 0           adjust_bn_9[0][0]
                                                                 normal_add_1_9[0][0]
                                                                 normal_add_2_9[0][0]
                                                                 normal_add_3_9[0][0]
                                                                 normal_add_4_9[0][0]
                                                                 normal_add_5_9[0][0]
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 21, 21, 2016) 0           normal_concat_8[0][0]
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 21, 21, 2016) 0           normal_concat_9[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_10 (Conv (None, 21, 21, 336)  677376      activation_141[0][0]
__________________________________________________________________________________________________
normal_conv_1_10 (Conv2D)       (None, 21, 21, 336)  677376      activation_142[0][0]
__________________________________________________________________________________________________
adjust_bn_10 (BatchNormalizatio (None, 21, 21, 336)  1344        adjust_conv_projection_10[0][0]
__________________________________________________________________________________________________
normal_bn_1_10 (BatchNormalizat (None, 21, 21, 336)  1344        normal_conv_1_10[0][0]
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_10[0][0]
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_10[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 21, 21, 336)  121296      activation_143[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_145[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 21, 21, 336)  121296      activation_147[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_149[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 21, 21, 336)  115920      activation_151[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_10[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_10
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_10[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_10
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_10[
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 21, 21, 336)  121296      activation_144[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_146[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 21, 21, 336)  121296      activation_148[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_150[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 21, 21, 336)  115920      activation_152[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_10[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_10
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_10[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_10
__________________________________________________________________________________________________
normal_left3_10 (AveragePooling (None, 21, 21, 336)  0           normal_bn_1_10[0][0]
__________________________________________________________________________________________________
normal_left4_10 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
normal_right4_10 (AveragePoolin (None, 21, 21, 336)  0           adjust_bn_10[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_10[
__________________________________________________________________________________________________
normal_add_1_10 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_10 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_10 (Add)           (None, 21, 21, 336)  0           normal_left3_10[0][0]
                                                                 adjust_bn_10[0][0]
__________________________________________________________________________________________________
normal_add_4_10 (Add)           (None, 21, 21, 336)  0           normal_left4_10[0][0]
                                                                 normal_right4_10[0][0]
__________________________________________________________________________________________________
normal_add_5_10 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_10[0][0]
__________________________________________________________________________________________________
normal_concat_10 (Concatenate)  (None, 21, 21, 2016) 0           adjust_bn_10[0][0]
                                                                 normal_add_1_10[0][0]
                                                                 normal_add_2_10[0][0]
                                                                 normal_add_3_10[0][0]
                                                                 normal_add_4_10[0][0]
                                                                 normal_add_5_10[0][0]
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 21, 21, 2016) 0           normal_concat_9[0][0]
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 21, 21, 2016) 0           normal_concat_10[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_11 (Conv (None, 21, 21, 336)  677376      activation_153[0][0]
__________________________________________________________________________________________________
normal_conv_1_11 (Conv2D)       (None, 21, 21, 336)  677376      activation_154[0][0]
__________________________________________________________________________________________________
adjust_bn_11 (BatchNormalizatio (None, 21, 21, 336)  1344        adjust_conv_projection_11[0][0]
__________________________________________________________________________________________________
normal_bn_1_11 (BatchNormalizat (None, 21, 21, 336)  1344        normal_conv_1_11[0][0]
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_11[0][0]
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_11[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 21, 21, 336)  121296      activation_155[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_157[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 21, 21, 336)  121296      activation_159[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_161[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 21, 21, 336)  115920      activation_163[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_11[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_11
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_11[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_11
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_11[
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 21, 21, 336)  121296      activation_156[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_158[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 21, 21, 336)  121296      activation_160[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_162[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 21, 21, 336)  115920      activation_164[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_11[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_11
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_11[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_11
__________________________________________________________________________________________________
normal_left3_11 (AveragePooling (None, 21, 21, 336)  0           normal_bn_1_11[0][0]
__________________________________________________________________________________________________
normal_left4_11 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
normal_right4_11 (AveragePoolin (None, 21, 21, 336)  0           adjust_bn_11[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_11[
__________________________________________________________________________________________________
normal_add_1_11 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_11 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_11 (Add)           (None, 21, 21, 336)  0           normal_left3_11[0][0]
                                                                 adjust_bn_11[0][0]
__________________________________________________________________________________________________
normal_add_4_11 (Add)           (None, 21, 21, 336)  0           normal_left4_11[0][0]
                                                                 normal_right4_11[0][0]
__________________________________________________________________________________________________
normal_add_5_11 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_11[0][0]
__________________________________________________________________________________________________
normal_concat_11 (Concatenate)  (None, 21, 21, 2016) 0           adjust_bn_11[0][0]
                                                                 normal_add_1_11[0][0]
                                                                 normal_add_2_11[0][0]
                                                                 normal_add_3_11[0][0]
                                                                 normal_add_4_11[0][0]
                                                                 normal_add_5_11[0][0]
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 21, 21, 2016) 0           normal_concat_10[0][0]
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 21, 21, 2016) 0           normal_concat_11[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_12 (Conv (None, 21, 21, 336)  677376      activation_165[0][0]
__________________________________________________________________________________________________
normal_conv_1_12 (Conv2D)       (None, 21, 21, 336)  677376      activation_166[0][0]
__________________________________________________________________________________________________
adjust_bn_12 (BatchNormalizatio (None, 21, 21, 336)  1344        adjust_conv_projection_12[0][0]
__________________________________________________________________________________________________
normal_bn_1_12 (BatchNormalizat (None, 21, 21, 336)  1344        normal_conv_1_12[0][0]
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_12[0][0]
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 21, 21, 336)  0           normal_bn_1_12[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 21, 21, 336)  121296      activation_167[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 21, 21, 336)  115920      activation_169[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 21, 21, 336)  121296      activation_171[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 21, 21, 336)  115920      activation_173[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 21, 21, 336)  115920      activation_175[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left1_12[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right1_12
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left2_12[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_1_normal_right2_12
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_1_normal_left5_12[
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 21, 21, 336)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 21, 21, 336)  121296      activation_168[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 21, 21, 336)  115920      activation_170[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 21, 21, 336)  121296      activation_172[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 21, 21, 336)  115920      activation_174[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 21, 21, 336)  115920      activation_176[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left1_12[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right1_12
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left2_12[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 21, 21, 336)  1344        separable_conv_2_normal_right2_12
__________________________________________________________________________________________________
normal_left3_12 (AveragePooling (None, 21, 21, 336)  0           normal_bn_1_12[0][0]
__________________________________________________________________________________________________
normal_left4_12 (AveragePooling (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
normal_right4_12 (AveragePoolin (None, 21, 21, 336)  0           adjust_bn_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 21, 21, 336)  1344        separable_conv_2_normal_left5_12[
__________________________________________________________________________________________________
normal_add_1_12 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_12 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_12 (Add)           (None, 21, 21, 336)  0           normal_left3_12[0][0]
                                                                 adjust_bn_12[0][0]
__________________________________________________________________________________________________
normal_add_4_12 (Add)           (None, 21, 21, 336)  0           normal_left4_12[0][0]
                                                                 normal_right4_12[0][0]
__________________________________________________________________________________________________
normal_add_5_12 (Add)           (None, 21, 21, 336)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_12[0][0]
__________________________________________________________________________________________________
normal_concat_12 (Concatenate)  (None, 21, 21, 2016) 0           adjust_bn_12[0][0]
                                                                 normal_add_1_12[0][0]
                                                                 normal_add_2_12[0][0]
                                                                 normal_add_3_12[0][0]
                                                                 normal_add_4_12[0][0]
                                                                 normal_add_5_12[0][0]
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 21, 21, 2016) 0           normal_concat_12[0][0]
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 21, 21, 2016) 0           normal_concat_11[0][0]
__________________________________________________________________________________________________
reduction_conv_1_reduce_12 (Con (None, 21, 21, 672)  1354752     activation_178[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_reduce_1 (None, 21, 21, 672)  1354752     activation_177[0][0]
__________________________________________________________________________________________________
reduction_bn_1_reduce_12 (Batch (None, 21, 21, 672)  2688        reduction_conv_1_reduce_12[0][0]
__________________________________________________________________________________________________
adjust_bn_reduce_12 (BatchNorma (None, 21, 21, 672)  2688        adjust_conv_projection_reduce_12[
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 21, 21, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 21, 21, 672)  0           adjust_bn_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 11, 11, 672)  468384      activation_179[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_1_re (None, 11, 11, 672)  484512      activation_181[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_1_reduction_left1_
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_1 (None, 11, 11, 672)  2688        separable_conv_1_reduction_1_redu
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 11, 11, 672)  468384      activation_180[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_1_re (None, 11, 11, 672)  484512      activation_182[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_2_reduction_left1_
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_1 (None, 11, 11, 672)  2688        separable_conv_2_reduction_1_redu
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 21, 21, 672)  0           adjust_bn_reduce_12[0][0]
__________________________________________________________________________________________________
reduction_add_1_reduce_12 (Add) (None, 11, 11, 672)  0           separable_conv_2_bn_reduction_lef
                                                                 separable_conv_2_bn_reduction_1_r
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 11, 11, 672)  484512      activation_183[0][0]
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 21, 21, 672)  0           adjust_bn_reduce_12[0][0]
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 11, 11, 672)  0           reduction_add_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_1_reduction_right2
__________________________________________________________________________________________________
separable_conv_1_reduction_righ (None, 11, 11, 672)  468384      activation_185[0][0]
__________________________________________________________________________________________________
separable_conv_1_reduction_left (None, 11, 11, 672)  457632      activation_187[0][0]
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_1_reduction_right3
__________________________________________________________________________________________________
separable_conv_1_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_1_reduction_left4_
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 11, 11, 672)  484512      activation_184[0][0]
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_rig
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_reduction_lef
__________________________________________________________________________________________________
reduction_left2_reduce_12 (MaxP (None, 11, 11, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_2_reduction_right2
__________________________________________________________________________________________________
separable_conv_2_reduction_righ (None, 11, 11, 672)  468384      activation_186[0][0]
__________________________________________________________________________________________________
separable_conv_2_reduction_left (None, 11, 11, 672)  457632      activation_188[0][0]
__________________________________________________________________________________________________
adjust_relu_1_13 (Activation)   (None, 21, 21, 2016) 0           normal_concat_12[0][0]
__________________________________________________________________________________________________
reduction_add_2_reduce_12 (Add) (None, 11, 11, 672)  0           reduction_left2_reduce_12[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
reduction_left3_reduce_12 (Aver (None, 11, 11, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_r (None, 11, 11, 672)  2688        separable_conv_2_reduction_right3
__________________________________________________________________________________________________
reduction_left4_reduce_12 (Aver (None, 11, 11, 672)  0           reduction_add_1_reduce_12[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_reduction_l (None, 11, 11, 672)  2688        separable_conv_2_reduction_left4_
__________________________________________________________________________________________________
reduction_right5_reduce_12 (Max (None, 11, 11, 672)  0           reduction_bn_1_reduce_12[0][0]
__________________________________________________________________________________________________
zero_padding2d_4 (ZeroPadding2D (None, 22, 22, 2016) 0           adjust_relu_1_13[0][0]
__________________________________________________________________________________________________
reduction_add3_reduce_12 (Add)  (None, 11, 11, 672)  0           reduction_left3_reduce_12[0][0]
                                                                 separable_conv_2_bn_reduction_rig
__________________________________________________________________________________________________
add_4 (Add)                     (None, 11, 11, 672)  0           reduction_add_2_reduce_12[0][0]
                                                                 reduction_left4_reduce_12[0][0]
__________________________________________________________________________________________________
reduction_add4_reduce_12 (Add)  (None, 11, 11, 672)  0           separable_conv_2_bn_reduction_lef
                                                                 reduction_right5_reduce_12[0][0]
__________________________________________________________________________________________________
cropping2d_4 (Cropping2D)       (None, 21, 21, 2016) 0           zero_padding2d_4[0][0]
__________________________________________________________________________________________________
reduction_concat_reduce_12 (Con (None, 11, 11, 2688) 0           reduction_add_2_reduce_12[0][0]
                                                                 reduction_add3_reduce_12[0][0]
                                                                 add_4[0][0]
                                                                 reduction_add4_reduce_12[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_1_13 (AveragePo (None, 11, 11, 2016) 0           adjust_relu_1_13[0][0]
__________________________________________________________________________________________________
adjust_avg_pool_2_13 (AveragePo (None, 11, 11, 2016) 0           cropping2d_4[0][0]
__________________________________________________________________________________________________
adjust_conv_1_13 (Conv2D)       (None, 11, 11, 336)  677376      adjust_avg_pool_1_13[0][0]
__________________________________________________________________________________________________
adjust_conv_2_13 (Conv2D)       (None, 11, 11, 336)  677376      adjust_avg_pool_2_13[0][0]
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 11, 11, 2688) 0           reduction_concat_reduce_12[0][0]
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 11, 11, 672)  0           adjust_conv_1_13[0][0]
                                                                 adjust_conv_2_13[0][0]
__________________________________________________________________________________________________
normal_conv_1_13 (Conv2D)       (None, 11, 11, 672)  1806336     activation_189[0][0]
__________________________________________________________________________________________________
adjust_bn_13 (BatchNormalizatio (None, 11, 11, 672)  2688        concatenate_4[0][0]
__________________________________________________________________________________________________
normal_bn_1_13 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_13[0][0]
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_13[0][0]
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_13[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_190[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_192[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_194[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_196[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_198[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_13[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_13
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_13[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_13
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_13[
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_191[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_193[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_195[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_197[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_199[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_13[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_13
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_13[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_13
__________________________________________________________________________________________________
normal_left3_13 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_13[0][0]
__________________________________________________________________________________________________
normal_left4_13 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
normal_right4_13 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_13[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_13[
__________________________________________________________________________________________________
normal_add_1_13 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_13 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_13 (Add)           (None, 11, 11, 672)  0           normal_left3_13[0][0]
                                                                 adjust_bn_13[0][0]
__________________________________________________________________________________________________
normal_add_4_13 (Add)           (None, 11, 11, 672)  0           normal_left4_13[0][0]
                                                                 normal_right4_13[0][0]
__________________________________________________________________________________________________
normal_add_5_13 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_13[0][0]
__________________________________________________________________________________________________
normal_concat_13 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_13[0][0]
                                                                 normal_add_1_13[0][0]
                                                                 normal_add_2_13[0][0]
                                                                 normal_add_3_13[0][0]
                                                                 normal_add_4_13[0][0]
                                                                 normal_add_5_13[0][0]
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 11, 11, 2688) 0           reduction_concat_reduce_12[0][0]
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 11, 11, 4032) 0           normal_concat_13[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_14 (Conv (None, 11, 11, 672)  1806336     activation_200[0][0]
__________________________________________________________________________________________________
normal_conv_1_14 (Conv2D)       (None, 11, 11, 672)  2709504     activation_201[0][0]
__________________________________________________________________________________________________
adjust_bn_14 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_14[0][0]
__________________________________________________________________________________________________
normal_bn_1_14 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_14[0][0]
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_14[0][0]
__________________________________________________________________________________________________
activation_204 (Activation)     (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
activation_206 (Activation)     (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
activation_208 (Activation)     (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
activation_210 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_14[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_202[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_204[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_206[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_208[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_210[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_14[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_14
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_14[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_14
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_14[
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_205 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_207 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_209 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_211 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_203[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_205[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_207[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_209[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_211[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_14[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_14
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_14[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_14
__________________________________________________________________________________________________
normal_left3_14 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_14[0][0]
__________________________________________________________________________________________________
normal_left4_14 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
normal_right4_14 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_14[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_14[
__________________________________________________________________________________________________
normal_add_1_14 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_14 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_14 (Add)           (None, 11, 11, 672)  0           normal_left3_14[0][0]
                                                                 adjust_bn_14[0][0]
__________________________________________________________________________________________________
normal_add_4_14 (Add)           (None, 11, 11, 672)  0           normal_left4_14[0][0]
                                                                 normal_right4_14[0][0]
__________________________________________________________________________________________________
normal_add_5_14 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_14[0][0]
__________________________________________________________________________________________________
normal_concat_14 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_14[0][0]
                                                                 normal_add_1_14[0][0]
                                                                 normal_add_2_14[0][0]
                                                                 normal_add_3_14[0][0]
                                                                 normal_add_4_14[0][0]
                                                                 normal_add_5_14[0][0]
__________________________________________________________________________________________________
activation_212 (Activation)     (None, 11, 11, 4032) 0           normal_concat_13[0][0]
__________________________________________________________________________________________________
activation_213 (Activation)     (None, 11, 11, 4032) 0           normal_concat_14[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_15 (Conv (None, 11, 11, 672)  2709504     activation_212[0][0]
__________________________________________________________________________________________________
normal_conv_1_15 (Conv2D)       (None, 11, 11, 672)  2709504     activation_213[0][0]
__________________________________________________________________________________________________
adjust_bn_15 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_15[0][0]
__________________________________________________________________________________________________
normal_bn_1_15 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_15[0][0]
__________________________________________________________________________________________________
activation_214 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_15[0][0]
__________________________________________________________________________________________________
activation_216 (Activation)     (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
activation_218 (Activation)     (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
activation_220 (Activation)     (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
activation_222 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_15[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_214[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_216[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_218[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_220[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_222[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_15[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_15
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_15[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_15
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_15[
__________________________________________________________________________________________________
activation_215 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_217 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_219 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_221 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_223 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_215[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_217[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_219[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_221[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_223[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_15[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_15
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_15[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_15
__________________________________________________________________________________________________
normal_left3_15 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_15[0][0]
__________________________________________________________________________________________________
normal_left4_15 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
normal_right4_15 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_15[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_15[
__________________________________________________________________________________________________
normal_add_1_15 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_15 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_15 (Add)           (None, 11, 11, 672)  0           normal_left3_15[0][0]
                                                                 adjust_bn_15[0][0]
__________________________________________________________________________________________________
normal_add_4_15 (Add)           (None, 11, 11, 672)  0           normal_left4_15[0][0]
                                                                 normal_right4_15[0][0]
__________________________________________________________________________________________________
normal_add_5_15 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_15[0][0]
__________________________________________________________________________________________________
normal_concat_15 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_15[0][0]
                                                                 normal_add_1_15[0][0]
                                                                 normal_add_2_15[0][0]
                                                                 normal_add_3_15[0][0]
                                                                 normal_add_4_15[0][0]
                                                                 normal_add_5_15[0][0]
__________________________________________________________________________________________________
activation_224 (Activation)     (None, 11, 11, 4032) 0           normal_concat_14[0][0]
__________________________________________________________________________________________________
activation_225 (Activation)     (None, 11, 11, 4032) 0           normal_concat_15[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_16 (Conv (None, 11, 11, 672)  2709504     activation_224[0][0]
__________________________________________________________________________________________________
normal_conv_1_16 (Conv2D)       (None, 11, 11, 672)  2709504     activation_225[0][0]
__________________________________________________________________________________________________
adjust_bn_16 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_16[0][0]
__________________________________________________________________________________________________
normal_bn_1_16 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_16[0][0]
__________________________________________________________________________________________________
activation_226 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_16[0][0]
__________________________________________________________________________________________________
activation_228 (Activation)     (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
activation_230 (Activation)     (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
activation_232 (Activation)     (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
activation_234 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_16[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_226[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_228[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_230[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_232[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_234[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_16[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_16
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_16[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_16
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_16[
__________________________________________________________________________________________________
activation_227 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_229 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_231 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_233 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_235 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_227[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_229[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_231[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_233[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_235[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_16[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_16
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_16[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_16
__________________________________________________________________________________________________
normal_left3_16 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_16[0][0]
__________________________________________________________________________________________________
normal_left4_16 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
normal_right4_16 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_16[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_16[
__________________________________________________________________________________________________
normal_add_1_16 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_16 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_16 (Add)           (None, 11, 11, 672)  0           normal_left3_16[0][0]
                                                                 adjust_bn_16[0][0]
__________________________________________________________________________________________________
normal_add_4_16 (Add)           (None, 11, 11, 672)  0           normal_left4_16[0][0]
                                                                 normal_right4_16[0][0]
__________________________________________________________________________________________________
normal_add_5_16 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_16[0][0]
__________________________________________________________________________________________________
normal_concat_16 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_16[0][0]
                                                                 normal_add_1_16[0][0]
                                                                 normal_add_2_16[0][0]
                                                                 normal_add_3_16[0][0]
                                                                 normal_add_4_16[0][0]
                                                                 normal_add_5_16[0][0]
__________________________________________________________________________________________________
activation_236 (Activation)     (None, 11, 11, 4032) 0           normal_concat_15[0][0]
__________________________________________________________________________________________________
activation_237 (Activation)     (None, 11, 11, 4032) 0           normal_concat_16[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_17 (Conv (None, 11, 11, 672)  2709504     activation_236[0][0]
__________________________________________________________________________________________________
normal_conv_1_17 (Conv2D)       (None, 11, 11, 672)  2709504     activation_237[0][0]
__________________________________________________________________________________________________
adjust_bn_17 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_17[0][0]
__________________________________________________________________________________________________
normal_bn_1_17 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_17[0][0]
__________________________________________________________________________________________________
activation_238 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_17[0][0]
__________________________________________________________________________________________________
activation_240 (Activation)     (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
activation_242 (Activation)     (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
activation_244 (Activation)     (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
activation_246 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_17[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_238[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_240[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_242[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_244[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_246[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_17[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_17
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_17[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_17
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_17[
__________________________________________________________________________________________________
activation_239 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_241 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_243 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_245 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_247 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_239[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_241[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_243[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_245[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_247[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_17[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_17
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_17[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_17
__________________________________________________________________________________________________
normal_left3_17 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_17[0][0]
__________________________________________________________________________________________________
normal_left4_17 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
normal_right4_17 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_17[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_17[
__________________________________________________________________________________________________
normal_add_1_17 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_17 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_17 (Add)           (None, 11, 11, 672)  0           normal_left3_17[0][0]
                                                                 adjust_bn_17[0][0]
__________________________________________________________________________________________________
normal_add_4_17 (Add)           (None, 11, 11, 672)  0           normal_left4_17[0][0]
                                                                 normal_right4_17[0][0]
__________________________________________________________________________________________________
normal_add_5_17 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_17[0][0]
__________________________________________________________________________________________________
normal_concat_17 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_17[0][0]
                                                                 normal_add_1_17[0][0]
                                                                 normal_add_2_17[0][0]
                                                                 normal_add_3_17[0][0]
                                                                 normal_add_4_17[0][0]
                                                                 normal_add_5_17[0][0]
__________________________________________________________________________________________________
activation_248 (Activation)     (None, 11, 11, 4032) 0           normal_concat_16[0][0]
__________________________________________________________________________________________________
activation_249 (Activation)     (None, 11, 11, 4032) 0           normal_concat_17[0][0]
__________________________________________________________________________________________________
adjust_conv_projection_18 (Conv (None, 11, 11, 672)  2709504     activation_248[0][0]
__________________________________________________________________________________________________
normal_conv_1_18 (Conv2D)       (None, 11, 11, 672)  2709504     activation_249[0][0]
__________________________________________________________________________________________________
adjust_bn_18 (BatchNormalizatio (None, 11, 11, 672)  2688        adjust_conv_projection_18[0][0]
__________________________________________________________________________________________________
normal_bn_1_18 (BatchNormalizat (None, 11, 11, 672)  2688        normal_conv_1_18[0][0]
__________________________________________________________________________________________________
activation_250 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_18[0][0]
__________________________________________________________________________________________________
activation_252 (Activation)     (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
activation_254 (Activation)     (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
activation_256 (Activation)     (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
activation_258 (Activation)     (None, 11, 11, 672)  0           normal_bn_1_18[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left1_1 (None, 11, 11, 672)  468384      activation_250[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right1_ (None, 11, 11, 672)  457632      activation_252[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left2_1 (None, 11, 11, 672)  468384      activation_254[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_right2_ (None, 11, 11, 672)  457632      activation_256[0][0]
__________________________________________________________________________________________________
separable_conv_1_normal_left5_1 (None, 11, 11, 672)  457632      activation_258[0][0]
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left1_18[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right1_18
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left2_18[
__________________________________________________________________________________________________
separable_conv_1_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_1_normal_right2_18
__________________________________________________________________________________________________
separable_conv_1_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_1_normal_left5_18[
__________________________________________________________________________________________________
activation_251 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left1_
__________________________________________________________________________________________________
activation_253 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right1
__________________________________________________________________________________________________
activation_255 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left2_
__________________________________________________________________________________________________
activation_257 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_right2
__________________________________________________________________________________________________
activation_259 (Activation)     (None, 11, 11, 672)  0           separable_conv_1_bn_normal_left5_
__________________________________________________________________________________________________
separable_conv_2_normal_left1_1 (None, 11, 11, 672)  468384      activation_251[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right1_ (None, 11, 11, 672)  457632      activation_253[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left2_1 (None, 11, 11, 672)  468384      activation_255[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_right2_ (None, 11, 11, 672)  457632      activation_257[0][0]
__________________________________________________________________________________________________
separable_conv_2_normal_left5_1 (None, 11, 11, 672)  457632      activation_259[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left1_18[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right1_18
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left2_18[
__________________________________________________________________________________________________
separable_conv_2_bn_normal_righ (None, 11, 11, 672)  2688        separable_conv_2_normal_right2_18
__________________________________________________________________________________________________
normal_left3_18 (AveragePooling (None, 11, 11, 672)  0           normal_bn_1_18[0][0]
__________________________________________________________________________________________________
normal_left4_18 (AveragePooling (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
normal_right4_18 (AveragePoolin (None, 11, 11, 672)  0           adjust_bn_18[0][0]
__________________________________________________________________________________________________
separable_conv_2_bn_normal_left (None, 11, 11, 672)  2688        separable_conv_2_normal_left5_18[
__________________________________________________________________________________________________
normal_add_1_18 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left1_
                                                                 separable_conv_2_bn_normal_right1
__________________________________________________________________________________________________
normal_add_2_18 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left2_
                                                                 separable_conv_2_bn_normal_right2
__________________________________________________________________________________________________
normal_add_3_18 (Add)           (None, 11, 11, 672)  0           normal_left3_18[0][0]
                                                                 adjust_bn_18[0][0]
__________________________________________________________________________________________________
normal_add_4_18 (Add)           (None, 11, 11, 672)  0           normal_left4_18[0][0]
                                                                 normal_right4_18[0][0]
__________________________________________________________________________________________________
normal_add_5_18 (Add)           (None, 11, 11, 672)  0           separable_conv_2_bn_normal_left5_
                                                                 normal_bn_1_18[0][0]
__________________________________________________________________________________________________
normal_concat_18 (Concatenate)  (None, 11, 11, 4032) 0           adjust_bn_18[0][0]
                                                                 normal_add_1_18[0][0]
                                                                 normal_add_2_18[0][0]
                                                                 normal_add_3_18[0][0]
                                                                 normal_add_4_18[0][0]
                                                                 normal_add_5_18[0][0]
__________________________________________________________________________________________________
activation_260 (Activation)     (None, 11, 11, 4032) 0           normal_concat_18[0][0]
__________________________________________________________________________________________________
global_average_pooling2d_1 (Glo (None, 4032)         0           activation_260[0][0]
==================================================================================================
Total params: 84,916,818
Trainable params: 0
Non-trainable params: 84,916,818
__________________________________________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 4032)          84916818
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 4032)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                161720
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 33
=================================================================
Total params: 85,078,571
Trainable params: 161,753
Non-trainable params: 84,916,818
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 30
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model NASNetLarge_inc_top_seqLen16_lstm10_output3_inEpochs1_outEpochs30_AdamOpt_lr-0.000100_2019-01-25_03-11
-29
All frames and annotations from 20 datasets have been read by 2019-01-25 03:11:34.035642
1. set (Dataset 22) being trained for epoch 1 by 2019-01-25 03:11:40.372603!
Epoch 1/1
Traceback (most recent call last):
  File "runCNN_LSTM.py", line 160, in <module>
    main()
  File "runCNN_LSTM.py", line 157, in main
    runCNN_LSTM(record = RECORD)
  File "runCNN_LSTM.py", line 140, in runCNN_LSTM
    batch_size = train_batch_size, in_epochs = in_epochs, stateful = STATEFUL, record = record)
  File "runCNN_LSTM.py", line 44, in trainCNN_LSTM
    in_epochs = in_epochs, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/LSTM_VGG16Helper.py", line 56, in t
rainImageModelForEpochs
    model = trainImageModelOnSets(model, e, trainingSubjects, trainingBiwi, timesteps, output_begin, num_outputs, bat
ch_size, in_epochs, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/LSTM_VGG16Helper.py", line 46, in t
rainImageModelOnSets
    model.fit_generator(data_gen, steps_per_epoch=len(data_gen), epochs=in_epochs, verbose=1)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/models.py", line 1315, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 2230, in fit_generator
    class_weight=class_weight)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 1877, in train_on_batch
    class_weight=class_weight)
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 1476, in _standardize_user
_data
    exception_prefix='input')
  File "/home/mcicek/anaconda3/lib/python3.6/site-packages/keras/engine/training.py", line 123, in _standardize_input
_data
    str(data_shape))
ValueError: Error when checking input: expected tdVGG16_input to have shape (16, 331, 331, 3) but got array with shap
e (16, 224, 224, 3)
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 03:13:09.107145: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 03:13:09.204687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 03:13:09.204946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 03:13:09.204959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 03:13:09.360886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 03:13:09.360911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 03:13:09.360916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 03:13:09.361052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-25_03-13-09 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 4096)          134260544
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                164280
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 30
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen16_lstm10_output3_inEpochs1_outEpochs30_AdamOpt_lr-0.000100_2019-01-25_03-13-09
All frames and annotations from 20 datasets have been read by 2019-01-25 03:13:14.563697
1. set (Dataset 22) being trained for epoch 1 by 2019-01-25 03:13:20.964032!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0184 - mean_absolute_error: 0.0930
2. set (Dataset 24) being trained for epoch 1 by 2019-01-25 03:14:40.740873!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0145 - mean_absolute_error: 0.0873
3. set (Dataset 15) being trained for epoch 1 by 2019-01-25 03:15:41.777563!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0201 - mean_absolute_error: 0.1042
4. set (Dataset 19) being trained for epoch 1 by 2019-01-25 03:17:00.152913!
Epoch 1/1
486/486 [==============================] - 54s 110ms/step - loss: 0.0180 - mean_absolute_error: 0.0976
5. set (Dataset 8) being trained for epoch 1 by 2019-01-25 03:18:01.498297!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0532 - mean_absolute_error: 0.1659
6. set (Dataset 23) being trained for epoch 1 by 2019-01-25 03:19:34.119709!
Epoch 1/1
553/553 [==============================] - 63s 114ms/step - loss: 0.0445 - mean_absolute_error: 0.1592
7. set (Dataset 21) being trained for epoch 1 by 2019-01-25 03:20:43.214424!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0307 - mean_absolute_error: 0.1332
8. set (Dataset 16) being trained for epoch 1 by 2019-01-25 03:22:03.164688!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0131 - mean_absolute_error: 0.0846
9. set (Dataset 7) being trained for epoch 1 by 2019-01-25 03:23:54.606329!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 0.0281 - mean_absolute_error: 0.1245
10. set (Dataset 12) being trained for epoch 1 by 2019-01-25 03:25:25.734644!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 0.0142 - mean_absolute_error: 0.0819
11. set (Dataset 10) being trained for epoch 1 by 2019-01-25 03:26:55.527346!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0224 - mean_absolute_error: 0.1019
12. set (Dataset 1) being trained for epoch 1 by 2019-01-25 03:28:22.959048!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0292 - mean_absolute_error: 0.1221
13. set (Dataset 18) being trained for epoch 1 by 2019-01-25 03:29:24.239933!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0273 - mean_absolute_error: 0.1245
14. set (Dataset 2) being trained for epoch 1 by 2019-01-25 03:30:37.850131!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0327 - mean_absolute_error: 0.1269
15. set (Dataset 4) being trained for epoch 1 by 2019-01-25 03:31:42.006450!
Epoch 1/1
728/728 [==============================] - 83s 114ms/step - loss: 0.0294 - mean_absolute_error: 0.1160
16. set (Dataset 20) being trained for epoch 1 by 2019-01-25 03:33:10.674054!
Epoch 1/1
540/540 [==============================] - 62s 114ms/step - loss: 0.0196 - mean_absolute_error: 0.0996
17. set (Dataset 17) being trained for epoch 1 by 2019-01-25 03:34:16.050225!
Epoch 1/1
379/379 [==============================] - 43s 114ms/step - loss: 0.0165 - mean_absolute_error: 0.0941
18. set (Dataset 6) being trained for epoch 1 by 2019-01-25 03:35:04.482325!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0409 - mean_absolute_error: 0.1384
19. set (Dataset 13) being trained for epoch 1 by 2019-01-25 03:36:10.155844!
Epoch 1/1
469/469 [==============================] - 54s 114ms/step - loss: 0.0090 - mean_absolute_error: 0.0686
20. set (Dataset 11) being trained for epoch 1 by 2019-01-25 03:37:09.422316!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0175 - mean_absolute_error: 0.0917
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 03:38:18.198249
1. set (Dataset 6) being trained for epoch 2 by 2019-01-25 03:38:23.380867!
Epoch 1/1
526/526 [==============================] - 60s 115ms/step - loss: 0.0223 - mean_absolute_error: 0.1053
2. set (Dataset 11) being trained for epoch 2 by 2019-01-25 03:39:29.388008!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0094 - mean_absolute_error: 0.0721
3. set (Dataset 10) being trained for epoch 2 by 2019-01-25 03:40:40.731229!
Epoch 1/1
710/710 [==============================] - 81s 115ms/step - loss: 0.0118 - mean_absolute_error: 0.0757
4. set (Dataset 4) being trained for epoch 2 by 2019-01-25 03:42:09.447691!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0162 - mean_absolute_error: 0.0853
5. set (Dataset 23) being trained for epoch 2 by 2019-01-25 03:43:39.036245!
Epoch 1/1
553/553 [==============================] - 63s 115ms/step - loss: 0.0276 - mean_absolute_error: 0.1203
6. set (Dataset 13) being trained for epoch 2 by 2019-01-25 03:44:47.355355!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0101 - mean_absolute_error: 0.0721
7. set (Dataset 17) being trained for epoch 2 by 2019-01-25 03:45:45.233891!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0117 - mean_absolute_error: 0.0827
8. set (Dataset 1) being trained for epoch 2 by 2019-01-25 03:46:34.108431!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0143 - mean_absolute_error: 0.0859
9. set (Dataset 8) being trained for epoch 2 by 2019-01-25 03:47:37.240830!
Epoch 1/1
756/756 [==============================] - 87s 116ms/step - loss: 0.0198 - mean_absolute_error: 0.1037
10. set (Dataset 7) being trained for epoch 2 by 2019-01-25 03:49:12.263351!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 0.0093 - mean_absolute_error: 0.0714
11. set (Dataset 21) being trained for epoch 2 by 2019-01-25 03:50:42.022780!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0183 - mean_absolute_error: 0.0999
12. set (Dataset 22) being trained for epoch 2 by 2019-01-25 03:51:59.376502!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0095 - mean_absolute_error: 0.0668
13. set (Dataset 2) being trained for epoch 2 by 2019-01-25 03:53:19.428875!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 0.0109 - mean_absolute_error: 0.0785
14. set (Dataset 24) being trained for epoch 2 by 2019-01-25 03:54:21.292802!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0082 - mean_absolute_error: 0.0649
15. set (Dataset 15) being trained for epoch 2 by 2019-01-25 03:55:22.366499!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0133 - mean_absolute_error: 0.0825
16. set (Dataset 20) being trained for epoch 2 by 2019-01-25 03:56:41.146458!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0128 - mean_absolute_error: 0.0783
17. set (Dataset 18) being trained for epoch 2 by 2019-01-25 03:57:49.216291!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0178 - mean_absolute_error: 0.0995
18. set (Dataset 19) being trained for epoch 2 by 2019-01-25 03:59:03.244914!
Epoch 1/1
486/486 [==============================] - 56s 114ms/step - loss: 0.0105 - mean_absolute_error: 0.0716
19. set (Dataset 12) being trained for epoch 2 by 2019-01-25 04:00:06.091143!
Epoch 1/1
716/716 [==============================] - 82s 115ms/step - loss: 0.0068 - mean_absolute_error: 0.0599
20. set (Dataset 16) being trained for epoch 2 by 2019-01-25 04:01:37.252081!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0081 - mean_absolute_error: 0.0626
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 04:03:25.838495
1. set (Dataset 19) being trained for epoch 3 by 2019-01-25 04:03:30.706489!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0073 - mean_absolute_error: 0.0610
2. set (Dataset 16) being trained for epoch 3 by 2019-01-25 04:04:35.315890!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0044 - mean_absolute_error: 0.0469
3. set (Dataset 21) being trained for epoch 3 by 2019-01-25 04:06:25.237913!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0117 - mean_absolute_error: 0.0804
4. set (Dataset 15) being trained for epoch 3 by 2019-01-25 04:07:42.942466!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0079 - mean_absolute_error: 0.0648
5. set (Dataset 13) being trained for epoch 3 by 2019-01-25 04:09:01.437423!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0125 - mean_absolute_error: 0.0816
6. set (Dataset 12) being trained for epoch 3 by 2019-01-25 04:10:02.420805!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 0.0113 - mean_absolute_error: 0.0814
7. set (Dataset 18) being trained for epoch 3 by 2019-01-25 04:11:31.228681!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0112 - mean_absolute_error: 0.0799
8. set (Dataset 22) being trained for epoch 3 by 2019-01-25 04:12:46.705986!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0064 - mean_absolute_error: 0.0561
9. set (Dataset 23) being trained for epoch 3 by 2019-01-25 04:14:07.014994!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0139 - mean_absolute_error: 0.0864
10. set (Dataset 8) being trained for epoch 3 by 2019-01-25 04:15:18.629271!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0093 - mean_absolute_error: 0.0740
11. set (Dataset 17) being trained for epoch 3 by 2019-01-25 04:16:49.680360!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0069 - mean_absolute_error: 0.0621
12. set (Dataset 6) being trained for epoch 3 by 2019-01-25 04:17:38.495457!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0218 - mean_absolute_error: 0.1009
13. set (Dataset 24) being trained for epoch 3 by 2019-01-25 04:18:43.700641!
Epoch 1/1
476/476 [==============================] - 54s 114ms/step - loss: 0.0058 - mean_absolute_error: 0.0553
14. set (Dataset 11) being trained for epoch 3 by 2019-01-25 04:19:43.872019!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0084 - mean_absolute_error: 0.0645
15. set (Dataset 10) being trained for epoch 3 by 2019-01-25 04:20:55.078060!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0079 - mean_absolute_error: 0.0644
16. set (Dataset 20) being trained for epoch 3 by 2019-01-25 04:22:22.610709!
Epoch 1/1
540/540 [==============================] - 62s 116ms/step - loss: 0.0077 - mean_absolute_error: 0.0635
17. set (Dataset 2) being trained for epoch 3 by 2019-01-25 04:23:30.095010!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0092 - mean_absolute_error: 0.0702
18. set (Dataset 4) being trained for epoch 3 by 2019-01-25 04:24:34.283487!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0081 - mean_absolute_error: 0.0664
19. set (Dataset 7) being trained for epoch 3 by 2019-01-25 04:26:05.816694!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0048 - mean_absolute_error: 0.0509
20. set (Dataset 1) being trained for epoch 3 by 2019-01-25 04:27:35.151616!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0073 - mean_absolute_error: 0.0601
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 04:28:35.165864
1. set (Dataset 4) being trained for epoch 4 by 2019-01-25 04:28:42.544250!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0042 - mean_absolute_error: 0.0497
2. set (Dataset 1) being trained for epoch 4 by 2019-01-25 04:30:11.466470!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0046 - mean_absolute_error: 0.0480
3. set (Dataset 17) being trained for epoch 4 by 2019-01-25 04:31:11.018194!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0057 - mean_absolute_error: 0.0554
4. set (Dataset 10) being trained for epoch 4 by 2019-01-25 04:32:01.940779!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0030 - mean_absolute_error: 0.0420
5. set (Dataset 12) being trained for epoch 4 by 2019-01-25 04:33:31.305485!
Epoch 1/1
716/716 [==============================] - 82s 115ms/step - loss: 0.0033 - mean_absolute_error: 0.0420
6. set (Dataset 7) being trained for epoch 4 by 2019-01-25 04:35:00.919340!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0382
7. set (Dataset 2) being trained for epoch 4 by 2019-01-25 04:36:30.382903!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0037 - mean_absolute_error: 0.0449
8. set (Dataset 6) being trained for epoch 4 by 2019-01-25 04:37:32.742502!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0118 - mean_absolute_error: 0.0780
9. set (Dataset 13) being trained for epoch 4 by 2019-01-25 04:38:38.331509!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 0.0047 - mean_absolute_error: 0.0486
10. set (Dataset 23) being trained for epoch 4 by 2019-01-25 04:39:38.214586!
Epoch 1/1
553/553 [==============================] - 63s 115ms/step - loss: 0.0093 - mean_absolute_error: 0.0713
11. set (Dataset 18) being trained for epoch 4 by 2019-01-25 04:40:47.578129!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0113 - mean_absolute_error: 0.0771
12. set (Dataset 19) being trained for epoch 4 by 2019-01-25 04:42:01.496165!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0076 - mean_absolute_error: 0.0670
13. set (Dataset 11) being trained for epoch 4 by 2019-01-25 04:43:03.280135!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0033 - mean_absolute_error: 0.0419
14. set (Dataset 16) being trained for epoch 4 by 2019-01-25 04:44:16.091410!
Epoch 1/1
898/898 [==============================] - 104s 115ms/step - loss: 0.0047 - mean_absolute_error: 0.0502
15. set (Dataset 21) being trained for epoch 4 by 2019-01-25 04:46:05.698047!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0111 - mean_absolute_error: 0.0788
16. set (Dataset 20) being trained for epoch 4 by 2019-01-25 04:47:22.051526!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0059 - mean_absolute_error: 0.0581
17. set (Dataset 24) being trained for epoch 4 by 2019-01-25 04:48:29.061246!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0436
18. set (Dataset 15) being trained for epoch 4 by 2019-01-25 04:49:30.271704!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0062 - mean_absolute_error: 0.0591
19. set (Dataset 8) being trained for epoch 4 by 2019-01-25 04:50:51.311105!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0060 - mean_absolute_error: 0.0558
20. set (Dataset 22) being trained for epoch 4 by 2019-01-25 04:52:25.251437!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0046 - mean_absolute_error: 0.0470
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 04:53:44.821554
1. set (Dataset 15) being trained for epoch 5 by 2019-01-25 04:53:51.164478!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0051 - mean_absolute_error: 0.0530
2. set (Dataset 22) being trained for epoch 5 by 2019-01-25 04:55:11.167831!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0034 - mean_absolute_error: 0.0408
3. set (Dataset 18) being trained for epoch 5 by 2019-01-25 04:56:32.019542!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0074 - mean_absolute_error: 0.0647
4. set (Dataset 21) being trained for epoch 5 by 2019-01-25 04:57:46.750575!
Epoch 1/1
618/618 [==============================] - 72s 116ms/step - loss: 0.0071 - mean_absolute_error: 0.0630
5. set (Dataset 7) being trained for epoch 5 by 2019-01-25 04:59:05.990993!
Epoch 1/1
729/729 [==============================] - 83s 114ms/step - loss: 0.0031 - mean_absolute_error: 0.0408
6. set (Dataset 8) being trained for epoch 5 by 2019-01-25 05:00:36.699851!
Epoch 1/1
756/756 [==============================] - 87s 116ms/step - loss: 0.0038 - mean_absolute_error: 0.0467
7. set (Dataset 24) being trained for epoch 5 by 2019-01-25 05:02:08.829980!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 0.0033 - mean_absolute_error: 0.0431
8. set (Dataset 19) being trained for epoch 5 by 2019-01-25 05:03:08.864158!
Epoch 1/1
486/486 [==============================] - 55s 114ms/step - loss: 0.0060 - mean_absolute_error: 0.0590
9. set (Dataset 12) being trained for epoch 5 by 2019-01-25 05:04:11.565900!
Epoch 1/1
716/716 [==============================] - 82s 114ms/step - loss: 0.0025 - mean_absolute_error: 0.0381
10. set (Dataset 13) being trained for epoch 5 by 2019-01-25 05:05:37.930692!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 0.0037 - mean_absolute_error: 0.0421
11. set (Dataset 2) being trained for epoch 5 by 2019-01-25 05:06:37.230851!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0034 - mean_absolute_error: 0.0431
12. set (Dataset 4) being trained for epoch 5 by 2019-01-25 05:07:41.675958!
Epoch 1/1
728/728 [==============================] - 83s 114ms/step - loss: 0.0040 - mean_absolute_error: 0.0470
13. set (Dataset 16) being trained for epoch 5 by 2019-01-25 05:09:13.529605!
Epoch 1/1
898/898 [==============================] - 104s 115ms/step - loss: 0.0043 - mean_absolute_error: 0.0461
14. set (Dataset 1) being trained for epoch 5 by 2019-01-25 05:11:02.113196!
Epoch 1/1
482/482 [==============================] - 56s 115ms/step - loss: 0.0057 - mean_absolute_error: 0.0523
15. set (Dataset 17) being trained for epoch 5 by 2019-01-25 05:12:01.446164!
Epoch 1/1
379/379 [==============================] - 43s 113ms/step - loss: 0.0047 - mean_absolute_error: 0.0495
16. set (Dataset 20) being trained for epoch 5 by 2019-01-25 05:12:49.779214!
Epoch 1/1
540/540 [==============================] - 62s 114ms/step - loss: 0.0047 - mean_absolute_error: 0.0511
17. set (Dataset 11) being trained for epoch 5 by 2019-01-25 05:13:57.128651!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0372
18. set (Dataset 10) being trained for epoch 5 by 2019-01-25 05:15:08.288585!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0027 - mean_absolute_error: 0.0399
19. set (Dataset 23) being trained for epoch 5 by 2019-01-25 05:16:35.820042!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0091 - mean_absolute_error: 0.0693
20. set (Dataset 6) being trained for epoch 5 by 2019-01-25 05:17:44.854213!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0107 - mean_absolute_error: 0.0714
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 05:18:50.354032
1. set (Dataset 10) being trained for epoch 6 by 2019-01-25 05:18:57.559426!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0328
2. set (Dataset 6) being trained for epoch 6 by 2019-01-25 05:20:24.659609!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0062 - mean_absolute_error: 0.0564
3. set (Dataset 2) being trained for epoch 6 by 2019-01-25 05:21:30.353343!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0366
4. set (Dataset 17) being trained for epoch 6 by 2019-01-25 05:22:30.869749!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0043 - mean_absolute_error: 0.0479
5. set (Dataset 8) being trained for epoch 6 by 2019-01-25 05:23:22.484626!
Epoch 1/1
756/756 [==============================] - 86s 114ms/step - loss: 0.0038 - mean_absolute_error: 0.0475
6. set (Dataset 23) being trained for epoch 6 by 2019-01-25 05:24:54.170075!
Epoch 1/1
553/553 [==============================] - 63s 115ms/step - loss: 0.0073 - mean_absolute_error: 0.0627
7. set (Dataset 11) being trained for epoch 6 by 2019-01-25 05:26:03.291543!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0311
8. set (Dataset 4) being trained for epoch 6 by 2019-01-25 05:27:14.985129!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0030 - mean_absolute_error: 0.0415
9. set (Dataset 7) being trained for epoch 6 by 2019-01-25 05:28:46.529751!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0332
10. set (Dataset 12) being trained for epoch 6 by 2019-01-25 05:30:17.387747!
Epoch 1/1
716/716 [==============================] - 82s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0321
11. set (Dataset 24) being trained for epoch 6 by 2019-01-25 05:31:44.365423!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0398
12. set (Dataset 15) being trained for epoch 6 by 2019-01-25 05:32:45.891892!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0054 - mean_absolute_error: 0.0556
13. set (Dataset 1) being trained for epoch 6 by 2019-01-25 05:34:04.434924!
Epoch 1/1
482/482 [==============================] - 55s 114ms/step - loss: 0.0042 - mean_absolute_error: 0.0467
14. set (Dataset 22) being trained for epoch 6 by 2019-01-25 05:35:05.663887!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0038 - mean_absolute_error: 0.0426
15. set (Dataset 18) being trained for epoch 6 by 2019-01-25 05:36:26.618235!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0062 - mean_absolute_error: 0.0591
16. set (Dataset 20) being trained for epoch 6 by 2019-01-25 05:37:40.568557!
Epoch 1/1
540/540 [==============================] - 63s 116ms/step - loss: 0.0038 - mean_absolute_error: 0.0470
17. set (Dataset 16) being trained for epoch 6 by 2019-01-25 05:38:51.946749!
Epoch 1/1
898/898 [==============================] - 104s 115ms/step - loss: 0.0033 - mean_absolute_error: 0.0412
18. set (Dataset 21) being trained for epoch 6 by 2019-01-25 05:40:41.665538!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0063 - mean_absolute_error: 0.0601
19. set (Dataset 13) being trained for epoch 6 by 2019-01-25 05:41:57.704049!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0042 - mean_absolute_error: 0.0452
20. set (Dataset 19) being trained for epoch 6 by 2019-01-25 05:42:56.748620!
Epoch 1/1
486/486 [==============================] - 56s 114ms/step - loss: 0.0050 - mean_absolute_error: 0.0531
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 05:43:56.991260
1. set (Dataset 21) being trained for epoch 7 by 2019-01-25 05:44:02.989414!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0047 - mean_absolute_error: 0.0522
2. set (Dataset 19) being trained for epoch 7 by 2019-01-25 05:45:19.073200!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0039 - mean_absolute_error: 0.0469
3. set (Dataset 24) being trained for epoch 7 by 2019-01-25 05:46:20.105819!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0342
4. set (Dataset 18) being trained for epoch 7 by 2019-01-25 05:47:21.124712!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0050 - mean_absolute_error: 0.0534
5. set (Dataset 23) being trained for epoch 7 by 2019-01-25 05:48:35.181038!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0106 - mean_absolute_error: 0.0718
6. set (Dataset 13) being trained for epoch 7 by 2019-01-25 05:49:43.747498!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0389
7. set (Dataset 16) being trained for epoch 7 by 2019-01-25 05:50:46.353165!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0030 - mean_absolute_error: 0.0392
8. set (Dataset 15) being trained for epoch 7 by 2019-01-25 05:52:36.988009!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0047 - mean_absolute_error: 0.0512
9. set (Dataset 8) being trained for epoch 7 by 2019-01-25 05:53:57.883057!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0433
10. set (Dataset 7) being trained for epoch 7 by 2019-01-25 05:55:32.602353!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0322
11. set (Dataset 11) being trained for epoch 7 by 2019-01-25 05:57:02.676229!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0315
12. set (Dataset 10) being trained for epoch 7 by 2019-01-25 05:58:13.976323!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0348
13. set (Dataset 22) being trained for epoch 7 by 2019-01-25 05:59:42.304586!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0033 - mean_absolute_error: 0.0401
14. set (Dataset 6) being trained for epoch 7 by 2019-01-25 06:01:02.556756!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0074 - mean_absolute_error: 0.0614
15. set (Dataset 2) being trained for epoch 7 by 2019-01-25 06:02:08.549625!
Epoch 1/1
495/495 [==============================] - 57s 114ms/step - loss: 0.0025 - mean_absolute_error: 0.0359
16. set (Dataset 20) being trained for epoch 7 by 2019-01-25 06:03:10.454356!
Epoch 1/1
540/540 [==============================] - 63s 116ms/step - loss: 0.0034 - mean_absolute_error: 0.0446
17. set (Dataset 1) being trained for epoch 7 by 2019-01-25 06:04:18.023141!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0030 - mean_absolute_error: 0.0401
18. set (Dataset 17) being trained for epoch 7 by 2019-01-25 06:05:17.241427!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0419
19. set (Dataset 12) being trained for epoch 7 by 2019-01-25 06:06:08.261729!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0308
20. set (Dataset 4) being trained for epoch 7 by 2019-01-25 06:07:38.621725!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0383
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 06:09:07.352755
1. set (Dataset 17) being trained for epoch 8 by 2019-01-25 06:09:11.092456!
Epoch 1/1
379/379 [==============================] - 43s 113ms/step - loss: 0.0032 - mean_absolute_error: 0.0431
2. set (Dataset 4) being trained for epoch 8 by 2019-01-25 06:10:01.328228!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0345
3. set (Dataset 11) being trained for epoch 8 by 2019-01-25 06:11:31.336999!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0292
4. set (Dataset 2) being trained for epoch 8 by 2019-01-25 06:12:40.680931!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0319
5. set (Dataset 13) being trained for epoch 8 by 2019-01-25 06:13:42.638526!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0325
6. set (Dataset 12) being trained for epoch 8 by 2019-01-25 06:14:44.053263!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
7. set (Dataset 1) being trained for epoch 8 by 2019-01-25 06:16:12.109012!
Epoch 1/1
482/482 [==============================] - 55s 114ms/step - loss: 0.0026 - mean_absolute_error: 0.0382
8. set (Dataset 10) being trained for epoch 8 by 2019-01-25 06:17:14.475750!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0319
9. set (Dataset 23) being trained for epoch 8 by 2019-01-25 06:18:42.149353!
Epoch 1/1
553/553 [==============================] - 63s 114ms/step - loss: 0.0075 - mean_absolute_error: 0.0621
10. set (Dataset 8) being trained for epoch 8 by 2019-01-25 06:19:53.123280!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0027 - mean_absolute_error: 0.0390
11. set (Dataset 16) being trained for epoch 8 by 2019-01-25 06:21:29.807886!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0029 - mean_absolute_error: 0.0375
12. set (Dataset 21) being trained for epoch 8 by 2019-01-25 06:23:19.679043!
Epoch 1/1
618/618 [==============================] - 72s 116ms/step - loss: 0.0054 - mean_absolute_error: 0.0559
13. set (Dataset 6) being trained for epoch 8 by 2019-01-25 06:24:36.579383!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0062 - mean_absolute_error: 0.0566
14. set (Dataset 19) being trained for epoch 8 by 2019-01-25 06:25:42.269063!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0048 - mean_absolute_error: 0.0509
15. set (Dataset 24) being trained for epoch 8 by 2019-01-25 06:26:42.954554!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0331
16. set (Dataset 20) being trained for epoch 8 by 2019-01-25 06:27:43.656239!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0030 - mean_absolute_error: 0.0422
17. set (Dataset 22) being trained for epoch 8 by 2019-01-25 06:28:52.309134!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0023 - mean_absolute_error: 0.0354
18. set (Dataset 18) being trained for epoch 8 by 2019-01-25 06:30:13.202744!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0050 - mean_absolute_error: 0.0533
19. set (Dataset 7) being trained for epoch 8 by 2019-01-25 06:31:29.661479!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0317
20. set (Dataset 15) being trained for epoch 8 by 2019-01-25 06:33:00.164058!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0042 - mean_absolute_error: 0.0483
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 06:34:18.740643
1. set (Dataset 18) being trained for epoch 9 by 2019-01-25 06:34:24.602686!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0038 - mean_absolute_error: 0.0459
2. set (Dataset 15) being trained for epoch 9 by 2019-01-25 06:35:39.833239!
Epoch 1/1
638/638 [==============================] - 73s 114ms/step - loss: 0.0036 - mean_absolute_error: 0.0449
3. set (Dataset 16) being trained for epoch 9 by 2019-01-25 06:37:01.588998!
Epoch 1/1
898/898 [==============================] - 101s 113ms/step - loss: 0.0025 - mean_absolute_error: 0.0359
4. set (Dataset 24) being trained for epoch 9 by 2019-01-25 06:38:47.395016!
Epoch 1/1
476/476 [==============================] - 54s 114ms/step - loss: 0.0016 - mean_absolute_error: 0.0302
5. set (Dataset 12) being trained for epoch 9 by 2019-01-25 06:39:49.140893!
Epoch 1/1
716/716 [==============================] - 81s 113ms/step - loss: 0.0018 - mean_absolute_error: 0.0291
6. set (Dataset 7) being trained for epoch 9 by 2019-01-25 06:41:17.749837!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
7. set (Dataset 22) being trained for epoch 9 by 2019-01-25 06:42:48.429202!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0022 - mean_absolute_error: 0.0344
8. set (Dataset 21) being trained for epoch 9 by 2019-01-25 06:44:09.476106!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0048 - mean_absolute_error: 0.0533
9. set (Dataset 13) being trained for epoch 9 by 2019-01-25 06:45:25.431824!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0339
10. set (Dataset 23) being trained for epoch 9 by 2019-01-25 06:46:24.905210!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0064 - mean_absolute_error: 0.0577
11. set (Dataset 1) being trained for epoch 9 by 2019-01-25 06:47:33.999368!
Epoch 1/1
482/482 [==============================] - 56s 115ms/step - loss: 0.0025 - mean_absolute_error: 0.0367
12. set (Dataset 17) being trained for epoch 9 by 2019-01-25 06:48:33.277144!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0034 - mean_absolute_error: 0.0427
13. set (Dataset 19) being trained for epoch 9 by 2019-01-25 06:49:21.746411!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0038 - mean_absolute_error: 0.0463
14. set (Dataset 4) being trained for epoch 9 by 2019-01-25 06:50:25.091449!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0021 - mean_absolute_error: 0.0346
15. set (Dataset 11) being trained for epoch 9 by 2019-01-25 06:51:54.931773!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
16. set (Dataset 20) being trained for epoch 9 by 2019-01-25 06:53:04.694506!
Epoch 1/1
540/540 [==============================] - 62s 116ms/step - loss: 0.0031 - mean_absolute_error: 0.0426
17. set (Dataset 6) being trained for epoch 9 by 2019-01-25 06:54:12.366303!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0057 - mean_absolute_error: 0.0542
18. set (Dataset 2) being trained for epoch 9 by 2019-01-25 06:55:18.114693!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
19. set (Dataset 8) being trained for epoch 9 by 2019-01-25 06:56:23.370787!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0388
20. set (Dataset 10) being trained for epoch 9 by 2019-01-25 06:57:58.189085!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0323
Epoch 9 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 06:59:24.930068
1. set (Dataset 2) being trained for epoch 10 by 2019-01-25 06:59:29.998270!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
2. set (Dataset 10) being trained for epoch 10 by 2019-01-25 07:00:33.913363!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0301
3. set (Dataset 1) being trained for epoch 10 by 2019-01-25 07:02:01.260385!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0023 - mean_absolute_error: 0.0357
4. set (Dataset 11) being trained for epoch 10 by 2019-01-25 07:03:02.898795!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0269
5. set (Dataset 7) being trained for epoch 10 by 2019-01-25 07:04:14.747722!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
6. set (Dataset 8) being trained for epoch 10 by 2019-01-25 07:05:46.409161!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0024 - mean_absolute_error: 0.0379
7. set (Dataset 6) being trained for epoch 10 by 2019-01-25 07:07:19.202118!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0059 - mean_absolute_error: 0.0561
8. set (Dataset 17) being trained for epoch 10 by 2019-01-25 07:08:23.629313!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0035 - mean_absolute_error: 0.0427
9. set (Dataset 12) being trained for epoch 10 by 2019-01-25 07:09:14.950259!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0248
10. set (Dataset 13) being trained for epoch 10 by 2019-01-25 07:10:42.303964!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0332
11. set (Dataset 22) being trained for epoch 10 by 2019-01-25 07:11:42.767739!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0334
12. set (Dataset 18) being trained for epoch 10 by 2019-01-25 07:13:03.704729!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0046 - mean_absolute_error: 0.0492
13. set (Dataset 4) being trained for epoch 10 by 2019-01-25 07:14:19.936637!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0330
14. set (Dataset 15) being trained for epoch 10 by 2019-01-25 07:15:50.258759!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0037 - mean_absolute_error: 0.0453
15. set (Dataset 16) being trained for epoch 10 by 2019-01-25 07:17:12.693500!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0025 - mean_absolute_error: 0.0355
16. set (Dataset 20) being trained for epoch 10 by 2019-01-25 07:19:02.034861!
Epoch 1/1
540/540 [==============================] - 63s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0392
17. set (Dataset 19) being trained for epoch 10 by 2019-01-25 07:20:09.497007!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0036 - mean_absolute_error: 0.0435
18. set (Dataset 24) being trained for epoch 10 by 2019-01-25 07:21:10.156542!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0312
19. set (Dataset 23) being trained for epoch 10 by 2019-01-25 07:22:10.370804!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0055 - mean_absolute_error: 0.0541
20. set (Dataset 21) being trained for epoch 10 by 2019-01-25 07:23:20.030617!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0043 - mean_absolute_error: 0.0495
Epoch 10 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 07:24:36.040672
1. set (Dataset 24) being trained for epoch 11 by 2019-01-25 07:24:40.716363!
Epoch 1/1
476/476 [==============================] - 54s 114ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
2. set (Dataset 21) being trained for epoch 11 by 2019-01-25 07:25:41.014369!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0034 - mean_absolute_error: 0.0446
3. set (Dataset 22) being trained for epoch 11 by 2019-01-25 07:26:58.816052!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0022 - mean_absolute_error: 0.0344
4. set (Dataset 16) being trained for epoch 11 by 2019-01-25 07:28:22.716712!
Epoch 1/1
898/898 [==============================] - 103s 115ms/step - loss: 0.0025 - mean_absolute_error: 0.0359
5. set (Dataset 8) being trained for epoch 11 by 2019-01-25 07:30:13.805087!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0352
6. set (Dataset 23) being trained for epoch 11 by 2019-01-25 07:31:46.503453!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0053 - mean_absolute_error: 0.0532
7. set (Dataset 19) being trained for epoch 11 by 2019-01-25 07:32:55.320908!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0421
8. set (Dataset 18) being trained for epoch 11 by 2019-01-25 07:33:57.265282!
Epoch 1/1
598/598 [==============================] - 68s 114ms/step - loss: 0.0037 - mean_absolute_error: 0.0456
9. set (Dataset 7) being trained for epoch 11 by 2019-01-25 07:35:12.827655!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0010 - mean_absolute_error: 0.0246
10. set (Dataset 12) being trained for epoch 11 by 2019-01-25 07:36:44.399533!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0249
11. set (Dataset 6) being trained for epoch 11 by 2019-01-25 07:38:12.349595!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0052 - mean_absolute_error: 0.0522
12. set (Dataset 2) being trained for epoch 11 by 2019-01-25 07:39:17.981386!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0015 - mean_absolute_error: 0.0291
13. set (Dataset 15) being trained for epoch 11 by 2019-01-25 07:40:21.074686!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0036 - mean_absolute_error: 0.0443
14. set (Dataset 10) being trained for epoch 11 by 2019-01-25 07:41:41.966109!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0304
15. set (Dataset 1) being trained for epoch 11 by 2019-01-25 07:43:08.710458!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0343
16. set (Dataset 20) being trained for epoch 11 by 2019-01-25 07:44:09.566497!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0028 - mean_absolute_error: 0.0408
17. set (Dataset 4) being trained for epoch 11 by 2019-01-25 07:45:19.029743!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0338
18. set (Dataset 11) being trained for epoch 11 by 2019-01-25 07:46:49.015890!
Epoch 1/1
556/556 [==============================] - 64s 114ms/step - loss: 0.0012 - mean_absolute_error: 0.0256
19. set (Dataset 13) being trained for epoch 11 by 2019-01-25 07:47:57.449080!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0302
20. set (Dataset 17) being trained for epoch 11 by 2019-01-25 07:48:55.352417!
Epoch 1/1
379/379 [==============================] - 43s 114ms/step - loss: 0.0031 - mean_absolute_error: 0.0419
Epoch 11 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 07:49:43.279979
1. set (Dataset 11) being trained for epoch 12 by 2019-01-25 07:49:48.972897!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 9.3947e-04 - mean_absolute_error: 0.0235
2. set (Dataset 17) being trained for epoch 12 by 2019-01-25 07:50:57.079793!
Epoch 1/1
379/379 [==============================] - 43s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0368
3. set (Dataset 6) being trained for epoch 12 by 2019-01-25 07:51:45.771123!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0048 - mean_absolute_error: 0.0498
4. set (Dataset 1) being trained for epoch 12 by 2019-01-25 07:52:51.389333!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0330
5. set (Dataset 23) being trained for epoch 12 by 2019-01-25 07:53:52.230751!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0043 - mean_absolute_error: 0.0484
6. set (Dataset 13) being trained for epoch 12 by 2019-01-25 07:55:00.737404!
Epoch 1/1
469/469 [==============================] - 53s 114ms/step - loss: 0.0016 - mean_absolute_error: 0.0287
7. set (Dataset 4) being trained for epoch 12 by 2019-01-25 07:56:01.551397!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0309
8. set (Dataset 2) being trained for epoch 12 by 2019-01-25 07:57:30.487948!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0270
9. set (Dataset 8) being trained for epoch 12 by 2019-01-25 07:58:35.227787!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0329
10. set (Dataset 7) being trained for epoch 12 by 2019-01-25 08:00:09.674241!
Epoch 1/1
729/729 [==============================] - 83s 114ms/step - loss: 0.0010 - mean_absolute_error: 0.0245
11. set (Dataset 19) being trained for epoch 12 by 2019-01-25 08:01:37.591508!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0033 - mean_absolute_error: 0.0425
12. set (Dataset 24) being trained for epoch 12 by 2019-01-25 08:02:38.408290!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0311
13. set (Dataset 10) being trained for epoch 12 by 2019-01-25 08:03:40.605342!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
14. set (Dataset 21) being trained for epoch 12 by 2019-01-25 08:05:08.113655!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0038 - mean_absolute_error: 0.0467
15. set (Dataset 22) being trained for epoch 12 by 2019-01-25 08:06:25.895263!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0321
16. set (Dataset 20) being trained for epoch 12 by 2019-01-25 08:07:46.141325!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0025 - mean_absolute_error: 0.0385
17. set (Dataset 15) being trained for epoch 12 by 2019-01-25 08:08:54.638602!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0033 - mean_absolute_error: 0.0431
18. set (Dataset 16) being trained for epoch 12 by 2019-01-25 08:10:17.188756!
Epoch 1/1
898/898 [==============================] - 104s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0328
19. set (Dataset 12) being trained for epoch 12 by 2019-01-25 08:12:08.015432!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 0.0014 - mean_absolute_error: 0.0261
20. set (Dataset 18) being trained for epoch 12 by 2019-01-25 08:13:36.726064!
Epoch 1/1
598/598 [==============================] - 68s 115ms/step - loss: 0.0037 - mean_absolute_error: 0.0456
Epoch 12 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 08:14:49.828649
1. set (Dataset 16) being trained for epoch 13 by 2019-01-25 08:14:58.550052!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0021 - mean_absolute_error: 0.0331
2. set (Dataset 18) being trained for epoch 13 by 2019-01-25 08:16:48.245940!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0399
3. set (Dataset 19) being trained for epoch 13 by 2019-01-25 08:18:02.026014!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0028 - mean_absolute_error: 0.0400
4. set (Dataset 22) being trained for epoch 13 by 2019-01-25 08:19:04.495784!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0317
5. set (Dataset 13) being trained for epoch 13 by 2019-01-25 08:20:24.372054!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0310
6. set (Dataset 12) being trained for epoch 13 by 2019-01-25 08:21:25.615185!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 8.6600e-04 - mean_absolute_error: 0.0228
7. set (Dataset 15) being trained for epoch 13 by 2019-01-25 08:22:54.636723!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0035 - mean_absolute_error: 0.0448
8. set (Dataset 24) being trained for epoch 13 by 2019-01-25 08:24:13.054821!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
9. set (Dataset 23) being trained for epoch 13 by 2019-01-25 08:25:13.189340!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0046 - mean_absolute_error: 0.0489
10. set (Dataset 8) being trained for epoch 13 by 2019-01-25 08:26:24.761220!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0326
11. set (Dataset 4) being trained for epoch 13 by 2019-01-25 08:27:59.346280!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0015 - mean_absolute_error: 0.0304
12. set (Dataset 11) being trained for epoch 13 by 2019-01-25 08:29:29.083760!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
13. set (Dataset 21) being trained for epoch 13 by 2019-01-25 08:30:39.037453!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0040 - mean_absolute_error: 0.0480
14. set (Dataset 17) being trained for epoch 13 by 2019-01-25 08:31:54.076801!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0031 - mean_absolute_error: 0.0411
15. set (Dataset 6) being trained for epoch 13 by 2019-01-25 08:32:42.986598!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0043 - mean_absolute_error: 0.0459
16. set (Dataset 20) being trained for epoch 13 by 2019-01-25 08:33:49.119167!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0375
17. set (Dataset 10) being trained for epoch 13 by 2019-01-25 08:34:58.662420!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
18. set (Dataset 1) being trained for epoch 13 by 2019-01-25 08:36:25.608474!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0327
19. set (Dataset 7) being trained for epoch 13 by 2019-01-25 08:37:28.971167!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 9.3027e-04 - mean_absolute_error: 0.0230
20. set (Dataset 2) being trained for epoch 13 by 2019-01-25 08:38:58.301751!
Epoch 1/1
495/495 [==============================] - 56s 113ms/step - loss: 0.0014 - mean_absolute_error: 0.0276
Epoch 13 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 08:39:58.782578
1. set (Dataset 1) being trained for epoch 14 by 2019-01-25 08:40:03.816912!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0304
2. set (Dataset 2) being trained for epoch 14 by 2019-01-25 08:41:04.267605!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 8.8871e-04 - mean_absolute_error: 0.0235
3. set (Dataset 4) being trained for epoch 14 by 2019-01-25 08:42:08.830307!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0321
4. set (Dataset 6) being trained for epoch 14 by 2019-01-25 08:43:38.141171!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0046 - mean_absolute_error: 0.0482
5. set (Dataset 12) being trained for epoch 14 by 2019-01-25 08:44:46.062107!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 7.7974e-04 - mean_absolute_error: 0.0213
6. set (Dataset 7) being trained for epoch 14 by 2019-01-25 08:46:16.293254!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0010 - mean_absolute_error: 0.0240
7. set (Dataset 10) being trained for epoch 14 by 2019-01-25 08:47:47.928512!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0271
8. set (Dataset 11) being trained for epoch 14 by 2019-01-25 08:49:15.999187!
Epoch 1/1
556/556 [==============================] - 63s 114ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
9. set (Dataset 13) being trained for epoch 14 by 2019-01-25 08:50:24.168930!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0279
10. set (Dataset 23) being trained for epoch 14 by 2019-01-25 08:51:23.712178!
Epoch 1/1
553/553 [==============================] - 63s 115ms/step - loss: 0.0043 - mean_absolute_error: 0.0475
11. set (Dataset 15) being trained for epoch 14 by 2019-01-25 08:52:33.553082!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0425
12. set (Dataset 16) being trained for epoch 14 by 2019-01-25 08:53:55.884497!
Epoch 1/1
898/898 [==============================] - 103s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0326
13. set (Dataset 17) being trained for epoch 14 by 2019-01-25 08:55:42.952686!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0026 - mean_absolute_error: 0.0380
14. set (Dataset 18) being trained for epoch 14 by 2019-01-25 08:56:32.412064!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0037 - mean_absolute_error: 0.0444
15. set (Dataset 19) being trained for epoch 14 by 2019-01-25 08:57:46.150432!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0358
16. set (Dataset 20) being trained for epoch 14 by 2019-01-25 08:58:47.627303!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0370
17. set (Dataset 21) being trained for epoch 14 by 2019-01-25 08:59:55.808107!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0035 - mean_absolute_error: 0.0455
18. set (Dataset 22) being trained for epoch 14 by 2019-01-25 09:01:13.461132!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0290
19. set (Dataset 8) being trained for epoch 14 by 2019-01-25 09:02:35.867263!
Epoch 1/1
756/756 [==============================] - 87s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0328
20. set (Dataset 24) being trained for epoch 14 by 2019-01-25 09:04:08.073063!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0015 - mean_absolute_error: 0.0292
Epoch 14 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 09:05:07.504999
1. set (Dataset 22) being trained for epoch 15 by 2019-01-25 09:05:13.888972!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0282
2. set (Dataset 24) being trained for epoch 15 by 2019-01-25 09:06:33.343133!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0268
3. set (Dataset 15) being trained for epoch 15 by 2019-01-25 09:07:34.598989!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0406
4. set (Dataset 19) being trained for epoch 15 by 2019-01-25 09:08:53.109883!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0362
5. set (Dataset 7) being trained for epoch 15 by 2019-01-25 09:09:56.613427!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 9.8737e-04 - mean_absolute_error: 0.0235
6. set (Dataset 8) being trained for epoch 15 by 2019-01-25 09:11:28.579902!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0321
7. set (Dataset 21) being trained for epoch 15 by 2019-01-25 09:13:02.132215!
Epoch 1/1
618/618 [==============================] - 72s 116ms/step - loss: 0.0035 - mean_absolute_error: 0.0447
8. set (Dataset 16) being trained for epoch 15 by 2019-01-25 09:14:22.376486!
Epoch 1/1
898/898 [==============================] - 103s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0327
9. set (Dataset 12) being trained for epoch 15 by 2019-01-25 09:16:12.792506!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 9.1602e-04 - mean_absolute_error: 0.0234
10. set (Dataset 13) being trained for epoch 15 by 2019-01-25 09:17:40.211845!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0280
11. set (Dataset 10) being trained for epoch 15 by 2019-01-25 09:18:41.553311!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0260
12. set (Dataset 1) being trained for epoch 15 by 2019-01-25 09:20:08.184233!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0332
13. set (Dataset 18) being trained for epoch 15 by 2019-01-25 09:21:09.775425!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0035 - mean_absolute_error: 0.0434
14. set (Dataset 2) being trained for epoch 15 by 2019-01-25 09:22:23.675422!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0270
15. set (Dataset 4) being trained for epoch 15 by 2019-01-25 09:23:28.072654!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
16. set (Dataset 20) being trained for epoch 15 by 2019-01-25 09:24:57.104281!
Epoch 1/1
540/540 [==============================] - 62s 116ms/step - loss: 0.0023 - mean_absolute_error: 0.0365
17. set (Dataset 17) being trained for epoch 15 by 2019-01-25 09:26:03.341418!
Epoch 1/1
379/379 [==============================] - 43s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0369
18. set (Dataset 6) being trained for epoch 15 by 2019-01-25 09:26:52.039266!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0044 - mean_absolute_error: 0.0476
19. set (Dataset 23) being trained for epoch 15 by 2019-01-25 09:27:58.136925!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0037 - mean_absolute_error: 0.0446
20. set (Dataset 11) being trained for epoch 15 by 2019-01-25 09:29:07.420335!
Epoch 1/1
556/556 [==============================] - 64s 114ms/step - loss: 0.0012 - mean_absolute_error: 0.0258
Epoch 15 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 09:30:15.596432
1. set (Dataset 6) being trained for epoch 16 by 2019-01-25 09:30:20.767676!
Epoch 1/1
526/526 [==============================] - 60s 115ms/step - loss: 0.0036 - mean_absolute_error: 0.0424
2. set (Dataset 11) being trained for epoch 16 by 2019-01-25 09:31:26.962406!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 8.9328e-04 - mean_absolute_error: 0.0226
3. set (Dataset 10) being trained for epoch 16 by 2019-01-25 09:32:38.656929!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0257
4. set (Dataset 4) being trained for epoch 16 by 2019-01-25 09:34:07.924941!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0295
5. set (Dataset 8) being trained for epoch 16 by 2019-01-25 09:35:39.533944!
Epoch 1/1
756/756 [==============================] - 87s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
6. set (Dataset 23) being trained for epoch 16 by 2019-01-25 09:37:12.305795!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0042 - mean_absolute_error: 0.0469
7. set (Dataset 17) being trained for epoch 16 by 2019-01-25 09:38:19.862143!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0359
8. set (Dataset 1) being trained for epoch 16 by 2019-01-25 09:39:08.519945!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0308
9. set (Dataset 7) being trained for epoch 16 by 2019-01-25 09:40:11.380234!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 9.1515e-04 - mean_absolute_error: 0.0233
10. set (Dataset 12) being trained for epoch 16 by 2019-01-25 09:41:42.675581!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 7.7077e-04 - mean_absolute_error: 0.0211
11. set (Dataset 21) being trained for epoch 16 by 2019-01-25 09:43:11.389177!
Epoch 1/1
618/618 [==============================] - 72s 116ms/step - loss: 0.0034 - mean_absolute_error: 0.0447
12. set (Dataset 22) being trained for epoch 16 by 2019-01-25 09:44:29.320297!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0317
13. set (Dataset 2) being trained for epoch 16 by 2019-01-25 09:45:48.939320!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
14. set (Dataset 24) being trained for epoch 16 by 2019-01-25 09:46:50.856487!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
15. set (Dataset 15) being trained for epoch 16 by 2019-01-25 09:47:51.841309!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0028 - mean_absolute_error: 0.0400
16. set (Dataset 20) being trained for epoch 16 by 2019-01-25 09:49:10.427560!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0355
17. set (Dataset 18) being trained for epoch 16 by 2019-01-25 09:50:18.534524!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0403
18. set (Dataset 19) being trained for epoch 16 by 2019-01-25 09:51:32.224692!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0357
19. set (Dataset 13) being trained for epoch 16 by 2019-01-25 09:52:33.093581!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0295
20. set (Dataset 16) being trained for epoch 16 by 2019-01-25 09:53:35.735951!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0313
Epoch 16 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 09:55:24.145410
1. set (Dataset 19) being trained for epoch 17 by 2019-01-25 09:55:29.018864!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0333
2. set (Dataset 16) being trained for epoch 17 by 2019-01-25 09:56:33.940654!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0285
3. set (Dataset 21) being trained for epoch 17 by 2019-01-25 09:58:23.783481!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0032 - mean_absolute_error: 0.0426
4. set (Dataset 15) being trained for epoch 17 by 2019-01-25 09:59:41.601406!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0028 - mean_absolute_error: 0.0398
5. set (Dataset 23) being trained for epoch 17 by 2019-01-25 10:01:00.979321!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0035 - mean_absolute_error: 0.0441
6. set (Dataset 13) being trained for epoch 17 by 2019-01-25 10:02:09.520750!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0273
7. set (Dataset 18) being trained for epoch 17 by 2019-01-25 10:03:09.568720!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0368
8. set (Dataset 22) being trained for epoch 17 by 2019-01-25 10:04:24.732220!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0302
9. set (Dataset 8) being trained for epoch 17 by 2019-01-25 10:05:47.085939!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0311
10. set (Dataset 7) being trained for epoch 17 by 2019-01-25 10:07:21.455808!
Epoch 1/1
729/729 [==============================] - 84s 115ms/step - loss: 8.0556e-04 - mean_absolute_error: 0.0219
11. set (Dataset 17) being trained for epoch 17 by 2019-01-25 10:08:49.060130!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0363
12. set (Dataset 6) being trained for epoch 17 by 2019-01-25 10:09:37.829175!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0041 - mean_absolute_error: 0.0459
13. set (Dataset 24) being trained for epoch 17 by 2019-01-25 10:10:43.273150!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0261
14. set (Dataset 11) being trained for epoch 17 by 2019-01-25 10:11:44.049388!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0242
15. set (Dataset 10) being trained for epoch 17 by 2019-01-25 10:12:55.194049!
Epoch 1/1
710/710 [==============================] - 81s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
16. set (Dataset 20) being trained for epoch 17 by 2019-01-25 10:14:22.064077!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0355
17. set (Dataset 2) being trained for epoch 17 by 2019-01-25 10:15:29.128969!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0254
18. set (Dataset 4) being trained for epoch 17 by 2019-01-25 10:16:33.385696!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0290
19. set (Dataset 12) being trained for epoch 17 by 2019-01-25 10:18:04.434930!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 7.9589e-04 - mean_absolute_error: 0.0212
20. set (Dataset 1) being trained for epoch 17 by 2019-01-25 10:19:32.704104!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0321
Epoch 17 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 10:20:32.648592
1. set (Dataset 4) being trained for epoch 18 by 2019-01-25 10:20:40.023054!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0275
2. set (Dataset 1) being trained for epoch 18 by 2019-01-25 10:22:09.306192!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0264
3. set (Dataset 17) being trained for epoch 18 by 2019-01-25 10:23:09.012457!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0358
4. set (Dataset 10) being trained for epoch 18 by 2019-01-25 10:23:59.922709!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0259
5. set (Dataset 13) being trained for epoch 18 by 2019-01-25 10:25:26.681188!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0245
6. set (Dataset 12) being trained for epoch 18 by 2019-01-25 10:26:28.142768!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 6.9864e-04 - mean_absolute_error: 0.0202
7. set (Dataset 2) being trained for epoch 18 by 2019-01-25 10:27:56.266078!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0262
8. set (Dataset 6) being trained for epoch 18 by 2019-01-25 10:28:58.513922!
Epoch 1/1
526/526 [==============================] - 60s 114ms/step - loss: 0.0046 - mean_absolute_error: 0.0485
9. set (Dataset 23) being trained for epoch 18 by 2019-01-25 10:30:04.178852!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0406
10. set (Dataset 8) being trained for epoch 18 by 2019-01-25 10:31:15.558346!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0292
11. set (Dataset 18) being trained for epoch 18 by 2019-01-25 10:32:48.647116!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0025 - mean_absolute_error: 0.0373
12. set (Dataset 19) being trained for epoch 18 by 2019-01-25 10:34:02.806950!
Epoch 1/1
486/486 [==============================] - 56s 114ms/step - loss: 0.0020 - mean_absolute_error: 0.0336
13. set (Dataset 11) being trained for epoch 18 by 2019-01-25 10:35:04.022553!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0249
14. set (Dataset 16) being trained for epoch 18 by 2019-01-25 10:36:17.175634!
Epoch 1/1
898/898 [==============================] - 103s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0302
15. set (Dataset 21) being trained for epoch 18 by 2019-01-25 10:38:06.653294!
Epoch 1/1
618/618 [==============================] - 72s 116ms/step - loss: 0.0030 - mean_absolute_error: 0.0411
16. set (Dataset 20) being trained for epoch 18 by 2019-01-25 10:39:23.553748!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0354
17. set (Dataset 24) being trained for epoch 18 by 2019-01-25 10:40:30.141739!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0248
18. set (Dataset 15) being trained for epoch 18 by 2019-01-25 10:41:31.376286!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0385
19. set (Dataset 7) being trained for epoch 18 by 2019-01-25 10:42:52.662798!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0240
20. set (Dataset 22) being trained for epoch 18 by 2019-01-25 10:44:23.417866!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0275
Epoch 18 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 10:45:42.849859
1. set (Dataset 15) being trained for epoch 19 by 2019-01-25 10:45:49.181746!
Epoch 1/1
638/638 [==============================] - 73s 115ms/step - loss: 0.0025 - mean_absolute_error: 0.0375
2. set (Dataset 22) being trained for epoch 19 by 2019-01-25 10:47:09.035415!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0266
3. set (Dataset 18) being trained for epoch 19 by 2019-01-25 10:48:30.215602!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0362
4. set (Dataset 21) being trained for epoch 19 by 2019-01-25 10:49:44.964286!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0026 - mean_absolute_error: 0.0387
5. set (Dataset 12) being trained for epoch 19 by 2019-01-25 10:51:03.505670!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 9.0608e-04 - mean_absolute_error: 0.0225
6. set (Dataset 7) being trained for epoch 19 by 2019-01-25 10:52:33.998025!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 7.9949e-04 - mean_absolute_error: 0.0220
7. set (Dataset 24) being trained for epoch 19 by 2019-01-25 10:54:02.904844!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0264
8. set (Dataset 19) being trained for epoch 19 by 2019-01-25 10:55:02.637530!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0348
9. set (Dataset 13) being trained for epoch 19 by 2019-01-25 10:56:03.458368!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0263
10. set (Dataset 23) being trained for epoch 19 by 2019-01-25 10:57:02.999732!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0030 - mean_absolute_error: 0.0417
11. set (Dataset 2) being trained for epoch 19 by 2019-01-25 10:58:12.054826!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 9.3868e-04 - mean_absolute_error: 0.0236
12. set (Dataset 4) being trained for epoch 19 by 2019-01-25 10:59:16.471863!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0288
13. set (Dataset 16) being trained for epoch 19 by 2019-01-25 11:00:49.200519!
Epoch 1/1
898/898 [==============================] - 104s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0292
14. set (Dataset 1) being trained for epoch 19 by 2019-01-25 11:02:37.955096!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0316
15. set (Dataset 17) being trained for epoch 19 by 2019-01-25 11:03:37.161194!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0362
16. set (Dataset 20) being trained for epoch 19 by 2019-01-25 11:04:26.236149!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0334
17. set (Dataset 11) being trained for epoch 19 by 2019-01-25 11:05:33.898984!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 9.6745e-04 - mean_absolute_error: 0.0237
18. set (Dataset 10) being trained for epoch 19 by 2019-01-25 11:06:45.101789!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0253
19. set (Dataset 8) being trained for epoch 19 by 2019-01-25 11:08:14.821798!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0016 - mean_absolute_error: 0.0307
20. set (Dataset 6) being trained for epoch 19 by 2019-01-25 11:09:46.829428!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0040 - mean_absolute_error: 0.0462
Epoch 19 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 11:10:52.197481
1. set (Dataset 10) being trained for epoch 20 by 2019-01-25 11:10:59.405251!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 9.2322e-04 - mean_absolute_error: 0.0232
2. set (Dataset 6) being trained for epoch 20 by 2019-01-25 11:12:26.502949!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0032 - mean_absolute_error: 0.0398
3. set (Dataset 2) being trained for epoch 20 by 2019-01-25 11:13:32.501600!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 0.0010 - mean_absolute_error: 0.0235
4. set (Dataset 17) being trained for epoch 20 by 2019-01-25 11:14:33.611631!
Epoch 1/1
379/379 [==============================] - 43s 114ms/step - loss: 0.0025 - mean_absolute_error: 0.0358
5. set (Dataset 7) being trained for epoch 20 by 2019-01-25 11:15:24.439087!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 6.8284e-04 - mean_absolute_error: 0.0201
6. set (Dataset 8) being trained for epoch 20 by 2019-01-25 11:16:56.446547!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0291
7. set (Dataset 11) being trained for epoch 20 by 2019-01-25 11:18:29.298772!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 8.3024e-04 - mean_absolute_error: 0.0220
8. set (Dataset 4) being trained for epoch 20 by 2019-01-25 11:19:40.805248!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0269
9. set (Dataset 12) being trained for epoch 20 by 2019-01-25 11:21:11.976563!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 6.2242e-04 - mean_absolute_error: 0.0193
10. set (Dataset 13) being trained for epoch 20 by 2019-01-25 11:22:39.533421!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0236
11. set (Dataset 24) being trained for epoch 20 by 2019-01-25 11:23:38.421937!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0015 - mean_absolute_error: 0.0289
12. set (Dataset 15) being trained for epoch 20 by 2019-01-25 11:24:39.646087!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0027 - mean_absolute_error: 0.0387
13. set (Dataset 1) being trained for epoch 20 by 2019-01-25 11:25:58.247257!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0339
14. set (Dataset 22) being trained for epoch 20 by 2019-01-25 11:27:00.065087!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0306
15. set (Dataset 18) being trained for epoch 20 by 2019-01-25 11:28:20.476404!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0025 - mean_absolute_error: 0.0372
16. set (Dataset 20) being trained for epoch 20 by 2019-01-25 11:29:35.000706!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0319
17. set (Dataset 16) being trained for epoch 20 by 2019-01-25 11:30:46.010262!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0284
18. set (Dataset 21) being trained for epoch 20 by 2019-01-25 11:32:35.922237!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0033 - mean_absolute_error: 0.0419
19. set (Dataset 23) being trained for epoch 20 by 2019-01-25 11:33:52.516577!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0034 - mean_absolute_error: 0.0428
20. set (Dataset 19) being trained for epoch 20 by 2019-01-25 11:35:00.974617!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0326
Epoch 20 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 11:36:01.603688
1. set (Dataset 21) being trained for epoch 21 by 2019-01-25 11:36:07.594103!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0371
2. set (Dataset 19) being trained for epoch 21 by 2019-01-25 11:37:23.468603!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
3. set (Dataset 24) being trained for epoch 21 by 2019-01-25 11:38:24.282319!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0255
4. set (Dataset 18) being trained for epoch 21 by 2019-01-25 11:39:24.941316!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0352
5. set (Dataset 8) being trained for epoch 21 by 2019-01-25 11:40:41.293821!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0015 - mean_absolute_error: 0.0303
6. set (Dataset 23) being trained for epoch 21 by 2019-01-25 11:42:13.927153!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0404
7. set (Dataset 16) being trained for epoch 21 by 2019-01-25 11:43:26.305024!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0278
8. set (Dataset 15) being trained for epoch 21 by 2019-01-25 11:45:16.758063!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0360
9. set (Dataset 7) being trained for epoch 21 by 2019-01-25 11:46:37.922403!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 8.9108e-04 - mean_absolute_error: 0.0226
10. set (Dataset 12) being trained for epoch 21 by 2019-01-25 11:48:09.625040!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 7.6397e-04 - mean_absolute_error: 0.0204
11. set (Dataset 11) being trained for epoch 21 by 2019-01-25 11:49:38.244215!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 7.5097e-04 - mean_absolute_error: 0.0211
12. set (Dataset 10) being trained for epoch 21 by 2019-01-25 11:50:49.456274!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 9.5720e-04 - mean_absolute_error: 0.0236
13. set (Dataset 22) being trained for epoch 21 by 2019-01-25 11:52:18.128697!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0304
14. set (Dataset 6) being trained for epoch 21 by 2019-01-25 11:53:38.448087!
Epoch 1/1
526/526 [==============================] - 60s 115ms/step - loss: 0.0039 - mean_absolute_error: 0.0447
15. set (Dataset 2) being trained for epoch 21 by 2019-01-25 11:54:43.909716!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 0.0010 - mean_absolute_error: 0.0238
16. set (Dataset 20) being trained for epoch 21 by 2019-01-25 11:55:46.349336!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0318
17. set (Dataset 1) being trained for epoch 21 by 2019-01-25 11:56:53.724661!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0317
18. set (Dataset 17) being trained for epoch 21 by 2019-01-25 11:57:53.228370!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
19. set (Dataset 13) being trained for epoch 21 by 2019-01-25 11:58:41.861768!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0247
20. set (Dataset 4) being trained for epoch 21 by 2019-01-25 11:59:43.175702!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0284
Epoch 21 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 12:01:11.712881
1. set (Dataset 17) being trained for epoch 22 by 2019-01-25 12:01:15.450446!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0331
2. set (Dataset 4) being trained for epoch 22 by 2019-01-25 12:02:06.397077!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0256
3. set (Dataset 11) being trained for epoch 22 by 2019-01-25 12:03:36.279202!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 7.9929e-04 - mean_absolute_error: 0.0217
4. set (Dataset 2) being trained for epoch 22 by 2019-01-25 12:04:45.542184!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 8.2181e-04 - mean_absolute_error: 0.0216
5. set (Dataset 23) being trained for epoch 22 by 2019-01-25 12:05:48.086166!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0034 - mean_absolute_error: 0.0435
6. set (Dataset 13) being trained for epoch 22 by 2019-01-25 12:06:56.901427!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0241
7. set (Dataset 1) being trained for epoch 22 by 2019-01-25 12:07:56.088144!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0306
8. set (Dataset 10) being trained for epoch 22 by 2019-01-25 12:08:58.980833!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 9.1866e-04 - mean_absolute_error: 0.0235
9. set (Dataset 8) being trained for epoch 22 by 2019-01-25 12:10:28.479581!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0277
10. set (Dataset 7) being trained for epoch 22 by 2019-01-25 12:12:03.174133!
Epoch 1/1
729/729 [==============================] - 85s 116ms/step - loss: 6.9174e-04 - mean_absolute_error: 0.0204
11. set (Dataset 16) being trained for epoch 22 by 2019-01-25 12:13:36.423298!
Epoch 1/1
898/898 [==============================] - 102s 114ms/step - loss: 0.0016 - mean_absolute_error: 0.0290
12. set (Dataset 21) being trained for epoch 22 by 2019-01-25 12:15:24.866307!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0031 - mean_absolute_error: 0.0415
13. set (Dataset 6) being trained for epoch 22 by 2019-01-25 12:16:41.524042!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0034 - mean_absolute_error: 0.0417
14. set (Dataset 19) being trained for epoch 22 by 2019-01-25 12:17:47.083791!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0333
15. set (Dataset 24) being trained for epoch 22 by 2019-01-25 12:18:47.808978!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0251
16. set (Dataset 20) being trained for epoch 22 by 2019-01-25 12:19:48.117756!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0323
17. set (Dataset 22) being trained for epoch 22 by 2019-01-25 12:20:56.716091!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0272
18. set (Dataset 18) being trained for epoch 22 by 2019-01-25 12:22:17.911328!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0024 - mean_absolute_error: 0.0366
19. set (Dataset 12) being trained for epoch 22 by 2019-01-25 12:23:34.221899!
Epoch 1/1
716/716 [==============================] - 82s 115ms/step - loss: 8.6051e-04 - mean_absolute_error: 0.0216
20. set (Dataset 15) being trained for epoch 22 by 2019-01-25 12:25:02.995231!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0026 - mean_absolute_error: 0.0377
Epoch 22 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 12:26:21.268552
1. set (Dataset 18) being trained for epoch 23 by 2019-01-25 12:26:27.129838!
Epoch 1/1
598/598 [==============================] - 69s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0341
2. set (Dataset 15) being trained for epoch 23 by 2019-01-25 12:27:42.365553!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0340
3. set (Dataset 16) being trained for epoch 23 by 2019-01-25 12:29:05.039666!
Epoch 1/1
898/898 [==============================] - 104s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0273
4. set (Dataset 24) being trained for epoch 23 by 2019-01-25 12:30:53.425563!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 9.7104e-04 - mean_absolute_error: 0.0239
5. set (Dataset 13) being trained for epoch 23 by 2019-01-25 12:31:53.492956!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0273
6. set (Dataset 12) being trained for epoch 23 by 2019-01-25 12:32:54.903800!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 7.1085e-04 - mean_absolute_error: 0.0204
7. set (Dataset 22) being trained for epoch 23 by 2019-01-25 12:34:24.058466!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0276
8. set (Dataset 21) being trained for epoch 23 by 2019-01-25 12:35:44.999950!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0028 - mean_absolute_error: 0.0400
9. set (Dataset 23) being trained for epoch 23 by 2019-01-25 12:37:01.845495!
Epoch 1/1
553/553 [==============================] - 63s 115ms/step - loss: 0.0026 - mean_absolute_error: 0.0382
10. set (Dataset 8) being trained for epoch 23 by 2019-01-25 12:38:13.022948!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0014 - mean_absolute_error: 0.0289
11. set (Dataset 1) being trained for epoch 23 by 2019-01-25 12:39:45.756769!
Epoch 1/1
482/482 [==============================] - 56s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0301
12. set (Dataset 17) being trained for epoch 23 by 2019-01-25 12:40:45.104354!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0330
13. set (Dataset 19) being trained for epoch 23 by 2019-01-25 12:41:33.832475!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0317
14. set (Dataset 4) being trained for epoch 23 by 2019-01-25 12:42:37.360181!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0271
15. set (Dataset 11) being trained for epoch 23 by 2019-01-25 12:44:07.392201!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 7.4903e-04 - mean_absolute_error: 0.0211
16. set (Dataset 20) being trained for epoch 23 by 2019-01-25 12:45:16.567948!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0330
17. set (Dataset 6) being trained for epoch 23 by 2019-01-25 12:46:24.106571!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0042 - mean_absolute_error: 0.0461
18. set (Dataset 2) being trained for epoch 23 by 2019-01-25 12:47:29.915652!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 8.0365e-04 - mean_absolute_error: 0.0220
19. set (Dataset 7) being trained for epoch 23 by 2019-01-25 12:48:34.558363!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 7.3845e-04 - mean_absolute_error: 0.0208
20. set (Dataset 10) being trained for epoch 23 by 2019-01-25 12:50:06.012437!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 9.9173e-04 - mean_absolute_error: 0.0241
Epoch 23 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 12:51:32.905086
1. set (Dataset 2) being trained for epoch 24 by 2019-01-25 12:51:37.972543!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 6.5657e-04 - mean_absolute_error: 0.0197
2. set (Dataset 10) being trained for epoch 24 by 2019-01-25 12:52:42.040448!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 8.0068e-04 - mean_absolute_error: 0.0217
3. set (Dataset 1) being trained for epoch 24 by 2019-01-25 12:54:09.436560!
Epoch 1/1
482/482 [==============================] - 56s 115ms/step - loss: 0.0018 - mean_absolute_error: 0.0306
4. set (Dataset 11) being trained for epoch 24 by 2019-01-25 12:55:10.678645!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 7.1182e-04 - mean_absolute_error: 0.0206
5. set (Dataset 12) being trained for epoch 24 by 2019-01-25 12:56:21.745357!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 5.8872e-04 - mean_absolute_error: 0.0186
6. set (Dataset 7) being trained for epoch 24 by 2019-01-25 12:57:52.004758!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 8.2625e-04 - mean_absolute_error: 0.0220
7. set (Dataset 6) being trained for epoch 24 by 2019-01-25 12:59:21.590099!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0036 - mean_absolute_error: 0.0429
8. set (Dataset 17) being trained for epoch 24 by 2019-01-25 13:00:26.094138!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0338
9. set (Dataset 13) being trained for epoch 24 by 2019-01-25 13:01:14.770815!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 8.6773e-04 - mean_absolute_error: 0.0220
10. set (Dataset 23) being trained for epoch 24 by 2019-01-25 13:02:14.656623!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0027 - mean_absolute_error: 0.0396
11. set (Dataset 22) being trained for epoch 24 by 2019-01-25 13:03:25.291465!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0280
12. set (Dataset 18) being trained for epoch 24 by 2019-01-25 13:04:46.000228!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0022 - mean_absolute_error: 0.0358
13. set (Dataset 4) being trained for epoch 24 by 2019-01-25 13:06:02.734660!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0267
14. set (Dataset 15) being trained for epoch 24 by 2019-01-25 13:07:33.189041!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0024 - mean_absolute_error: 0.0361
15. set (Dataset 16) being trained for epoch 24 by 2019-01-25 13:08:55.747201!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0288
16. set (Dataset 20) being trained for epoch 24 by 2019-01-25 13:10:45.216538!
Epoch 1/1
540/540 [==============================] - 63s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0310
17. set (Dataset 19) being trained for epoch 24 by 2019-01-25 13:11:52.800560!
Epoch 1/1
486/486 [==============================] - 56s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0312
18. set (Dataset 24) being trained for epoch 24 by 2019-01-25 13:12:53.565325!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 9.9600e-04 - mean_absolute_error: 0.0243
19. set (Dataset 8) being trained for epoch 24 by 2019-01-25 13:13:56.194104!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0290
20. set (Dataset 21) being trained for epoch 24 by 2019-01-25 13:15:29.378864!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0027 - mean_absolute_error: 0.0394
Epoch 24 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 13:16:45.488952
1. set (Dataset 24) being trained for epoch 25 by 2019-01-25 13:16:50.144733!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 8.8256e-04 - mean_absolute_error: 0.0226
2. set (Dataset 21) being trained for epoch 25 by 2019-01-25 13:17:50.865370!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0022 - mean_absolute_error: 0.0362
3. set (Dataset 22) being trained for epoch 25 by 2019-01-25 13:19:08.610168!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0014 - mean_absolute_error: 0.0275
4. set (Dataset 16) being trained for epoch 25 by 2019-01-25 13:20:32.464948!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0014 - mean_absolute_error: 0.0271
5. set (Dataset 7) being trained for epoch 25 by 2019-01-25 13:22:23.948298!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 8.4344e-04 - mean_absolute_error: 0.0220
6. set (Dataset 8) being trained for epoch 25 by 2019-01-25 13:23:56.154126!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0276
7. set (Dataset 19) being trained for epoch 25 by 2019-01-25 13:25:28.562698!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0340
8. set (Dataset 18) being trained for epoch 25 by 2019-01-25 13:26:30.618724!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0333
9. set (Dataset 12) being trained for epoch 25 by 2019-01-25 13:27:46.998472!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 7.8550e-04 - mean_absolute_error: 0.0213
10. set (Dataset 13) being trained for epoch 25 by 2019-01-25 13:29:14.736980!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 8.4136e-04 - mean_absolute_error: 0.0215
11. set (Dataset 6) being trained for epoch 25 by 2019-01-25 13:30:14.210475!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0037 - mean_absolute_error: 0.0444
12. set (Dataset 2) being trained for epoch 25 by 2019-01-25 13:31:20.130146!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 7.3836e-04 - mean_absolute_error: 0.0206
13. set (Dataset 15) being trained for epoch 25 by 2019-01-25 13:32:23.897677!
Epoch 1/1
638/638 [==============================] - 74s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0355
14. set (Dataset 10) being trained for epoch 25 by 2019-01-25 13:33:44.809132!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0252
15. set (Dataset 1) being trained for epoch 25 by 2019-01-25 13:35:11.486354!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0300
16. set (Dataset 20) being trained for epoch 25 by 2019-01-25 13:36:12.603405!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0316
17. set (Dataset 4) being trained for epoch 25 by 2019-01-25 13:37:22.305777!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0262
18. set (Dataset 11) being trained for epoch 25 by 2019-01-25 13:38:52.041703!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 7.2496e-04 - mean_absolute_error: 0.0206
19. set (Dataset 23) being trained for epoch 25 by 2019-01-25 13:40:01.375886!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0026 - mean_absolute_error: 0.0391
20. set (Dataset 17) being trained for epoch 25 by 2019-01-25 13:41:09.091069!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0319
Epoch 25 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 13:41:57.425167
1. set (Dataset 11) being trained for epoch 26 by 2019-01-25 13:42:03.118418!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 7.1312e-04 - mean_absolute_error: 0.0204
2. set (Dataset 17) being trained for epoch 26 by 2019-01-25 13:43:11.243074!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0304
3. set (Dataset 6) being trained for epoch 26 by 2019-01-25 13:44:00.240415!
Epoch 1/1
526/526 [==============================] - 60s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0402
4. set (Dataset 1) being trained for epoch 26 by 2019-01-25 13:45:05.674166!
Epoch 1/1
482/482 [==============================] - 56s 115ms/step - loss: 0.0017 - mean_absolute_error: 0.0298
5. set (Dataset 8) being trained for epoch 26 by 2019-01-25 13:46:08.987598!
Epoch 1/1
756/756 [==============================] - 87s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0266
6. set (Dataset 23) being trained for epoch 26 by 2019-01-25 13:47:41.809563!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0025 - mean_absolute_error: 0.0378
7. set (Dataset 4) being trained for epoch 26 by 2019-01-25 13:48:53.032779!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0259
8. set (Dataset 2) being trained for epoch 26 by 2019-01-25 13:50:22.239929!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 7.3808e-04 - mean_absolute_error: 0.0206
9. set (Dataset 7) being trained for epoch 26 by 2019-01-25 13:51:26.946470!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 7.1150e-04 - mean_absolute_error: 0.0204
10. set (Dataset 12) being trained for epoch 26 by 2019-01-25 13:52:58.563882!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 6.2111e-04 - mean_absolute_error: 0.0191
11. set (Dataset 19) being trained for epoch 26 by 2019-01-25 13:54:26.311494!
Epoch 1/1
486/486 [==============================] - 56s 114ms/step - loss: 0.0021 - mean_absolute_error: 0.0344
12. set (Dataset 24) being trained for epoch 26 by 2019-01-25 13:55:26.603282!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0249
13. set (Dataset 10) being trained for epoch 26 by 2019-01-25 13:56:28.823980!
Epoch 1/1
710/710 [==============================] - 82s 115ms/step - loss: 9.4836e-04 - mean_absolute_error: 0.0234
14. set (Dataset 21) being trained for epoch 26 by 2019-01-25 13:57:56.824156!
Epoch 1/1
618/618 [==============================] - 70s 114ms/step - loss: 0.0027 - mean_absolute_error: 0.0388
15. set (Dataset 22) being trained for epoch 26 by 2019-01-25 13:59:13.529993!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0278
16. set (Dataset 20) being trained for epoch 26 by 2019-01-25 14:00:33.707813!
Epoch 1/1
540/540 [==============================] - 63s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0297
17. set (Dataset 15) being trained for epoch 26 by 2019-01-25 14:01:42.673514!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0021 - mean_absolute_error: 0.0343
18. set (Dataset 16) being trained for epoch 26 by 2019-01-25 14:03:05.679631!
Epoch 1/1
898/898 [==============================] - 103s 114ms/step - loss: 0.0013 - mean_absolute_error: 0.0270
19. set (Dataset 13) being trained for epoch 26 by 2019-01-25 14:04:53.200086!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0257
20. set (Dataset 18) being trained for epoch 26 by 2019-01-25 14:05:53.102697!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0021 - mean_absolute_error: 0.0351
Epoch 26 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 14:07:07.016252
1. set (Dataset 16) being trained for epoch 27 by 2019-01-25 14:07:15.757831!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0249
2. set (Dataset 18) being trained for epoch 27 by 2019-01-25 14:09:05.904013!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0308
3. set (Dataset 19) being trained for epoch 27 by 2019-01-25 14:10:19.933587!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0015 - mean_absolute_error: 0.0293
4. set (Dataset 22) being trained for epoch 27 by 2019-01-25 14:11:22.642975!
Epoch 1/1
649/649 [==============================] - 75s 116ms/step - loss: 0.0014 - mean_absolute_error: 0.0278
5. set (Dataset 23) being trained for epoch 27 by 2019-01-25 14:12:43.172308!
Epoch 1/1
553/553 [==============================] - 64s 116ms/step - loss: 0.0024 - mean_absolute_error: 0.0363
6. set (Dataset 13) being trained for epoch 27 by 2019-01-25 14:13:51.931701!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 9.9943e-04 - mean_absolute_error: 0.0237
7. set (Dataset 15) being trained for epoch 27 by 2019-01-25 14:14:52.309623!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0340
8. set (Dataset 24) being trained for epoch 27 by 2019-01-25 14:16:10.736583!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 9.4238e-04 - mean_absolute_error: 0.0239
9. set (Dataset 8) being trained for epoch 27 by 2019-01-25 14:17:13.324854!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0270
10. set (Dataset 7) being trained for epoch 27 by 2019-01-25 14:18:48.127626!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 7.1483e-04 - mean_absolute_error: 0.0205
11. set (Dataset 4) being trained for epoch 27 by 2019-01-25 14:20:19.819446!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0265
12. set (Dataset 11) being trained for epoch 27 by 2019-01-25 14:21:49.793027!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 7.4403e-04 - mean_absolute_error: 0.0208
13. set (Dataset 21) being trained for epoch 27 by 2019-01-25 14:23:00.185750!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0025 - mean_absolute_error: 0.0378
14. set (Dataset 17) being trained for epoch 27 by 2019-01-25 14:24:15.451861!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0072 - mean_absolute_error: 0.0570
15. set (Dataset 6) being trained for epoch 27 by 2019-01-25 14:25:04.147020!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0033 - mean_absolute_error: 0.0398
16. set (Dataset 20) being trained for epoch 27 by 2019-01-25 14:26:10.310363!
Epoch 1/1
540/540 [==============================] - 62s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0305
17. set (Dataset 10) being trained for epoch 27 by 2019-01-25 14:27:19.924238!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 9.8683e-04 - mean_absolute_error: 0.0232
18. set (Dataset 1) being trained for epoch 27 by 2019-01-25 14:28:46.979922!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0019 - mean_absolute_error: 0.0308
19. set (Dataset 12) being trained for epoch 27 by 2019-01-25 14:29:49.712576!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 5.8512e-04 - mean_absolute_error: 0.0187
20. set (Dataset 2) being trained for epoch 27 by 2019-01-25 14:31:17.527619!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 7.9306e-04 - mean_absolute_error: 0.0212
Epoch 27 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 14:32:19.455655
1. set (Dataset 1) being trained for epoch 28 by 2019-01-25 14:32:24.493825!
Epoch 1/1
482/482 [==============================] - 55s 115ms/step - loss: 0.0015 - mean_absolute_error: 0.0285
2. set (Dataset 2) being trained for epoch 28 by 2019-01-25 14:33:24.905184!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 7.6780e-04 - mean_absolute_error: 0.0214
3. set (Dataset 4) being trained for epoch 28 by 2019-01-25 14:34:29.588086!
Epoch 1/1
728/728 [==============================] - 84s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0284
4. set (Dataset 6) being trained for epoch 28 by 2019-01-25 14:35:58.507228!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0032 - mean_absolute_error: 0.0402
5. set (Dataset 13) being trained for epoch 28 by 2019-01-25 14:37:03.970651!
Epoch 1/1
469/469 [==============================] - 54s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0246
6. set (Dataset 12) being trained for epoch 28 by 2019-01-25 14:38:05.596120!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 6.1791e-04 - mean_absolute_error: 0.0189
7. set (Dataset 10) being trained for epoch 28 by 2019-01-25 14:39:35.379681!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 8.4834e-04 - mean_absolute_error: 0.0223
8. set (Dataset 11) being trained for epoch 28 by 2019-01-25 14:41:03.113070!
Epoch 1/1
556/556 [==============================] - 64s 116ms/step - loss: 7.5246e-04 - mean_absolute_error: 0.0211
9. set (Dataset 23) being trained for epoch 28 by 2019-01-25 14:42:12.840972!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0030 - mean_absolute_error: 0.0409
10. set (Dataset 8) being trained for epoch 28 by 2019-01-25 14:43:24.229647!
Epoch 1/1
756/756 [==============================] - 86s 114ms/step - loss: 0.0012 - mean_absolute_error: 0.0268
11. set (Dataset 15) being trained for epoch 28 by 2019-01-25 14:44:56.596499!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0021 - mean_absolute_error: 0.0340
12. set (Dataset 16) being trained for epoch 28 by 2019-01-25 14:46:19.203272!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0263
13. set (Dataset 17) being trained for epoch 28 by 2019-01-25 14:48:06.761387!
Epoch 1/1
379/379 [==============================] - 44s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0329
14. set (Dataset 18) being trained for epoch 28 by 2019-01-25 14:48:56.558966!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0334
15. set (Dataset 19) being trained for epoch 28 by 2019-01-25 14:50:10.730904!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
16. set (Dataset 20) being trained for epoch 28 by 2019-01-25 14:51:12.336956!
Epoch 1/1
540/540 [==============================] - 62s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0309
17. set (Dataset 21) being trained for epoch 28 by 2019-01-25 14:52:20.846603!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0023 - mean_absolute_error: 0.0359
18. set (Dataset 22) being trained for epoch 28 by 2019-01-25 14:53:38.388957!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0012 - mean_absolute_error: 0.0255
19. set (Dataset 7) being trained for epoch 28 by 2019-01-25 14:55:00.849419!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 7.8792e-04 - mean_absolute_error: 0.0213
20. set (Dataset 24) being trained for epoch 28 by 2019-01-25 14:56:29.909416!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 9.8928e-04 - mean_absolute_error: 0.0244
Epoch 28 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 14:57:29.588265
1. set (Dataset 22) being trained for epoch 29 by 2019-01-25 14:57:35.965086!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0011 - mean_absolute_error: 0.0242
2. set (Dataset 24) being trained for epoch 29 by 2019-01-25 14:58:55.353063!
Epoch 1/1
476/476 [==============================] - 55s 116ms/step - loss: 9.5340e-04 - mean_absolute_error: 0.0237
3. set (Dataset 15) being trained for epoch 29 by 2019-01-25 14:59:56.781841!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0023 - mean_absolute_error: 0.0362
4. set (Dataset 19) being trained for epoch 29 by 2019-01-25 15:01:15.400149!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0306
5. set (Dataset 12) being trained for epoch 29 by 2019-01-25 15:02:19.113440!
Epoch 1/1
716/716 [==============================] - 83s 115ms/step - loss: 8.2115e-04 - mean_absolute_error: 0.0209
6. set (Dataset 7) being trained for epoch 29 by 2019-01-25 15:03:49.196831!
Epoch 1/1
729/729 [==============================] - 84s 116ms/step - loss: 7.0339e-04 - mean_absolute_error: 0.0205
7. set (Dataset 21) being trained for epoch 29 by 2019-01-25 15:05:19.410290!
Epoch 1/1
618/618 [==============================] - 71s 116ms/step - loss: 0.0024 - mean_absolute_error: 0.0368
8. set (Dataset 16) being trained for epoch 29 by 2019-01-25 15:06:39.579456!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0013 - mean_absolute_error: 0.0273
9. set (Dataset 13) being trained for epoch 29 by 2019-01-25 15:08:28.337366!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 0.0010 - mean_absolute_error: 0.0235
10. set (Dataset 23) being trained for epoch 29 by 2019-01-25 15:09:27.921479!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0026 - mean_absolute_error: 0.0379
11. set (Dataset 10) being trained for epoch 29 by 2019-01-25 15:10:38.691178!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 9.4238e-04 - mean_absolute_error: 0.0227
12. set (Dataset 1) being trained for epoch 29 by 2019-01-25 15:12:05.817119!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0308
13. set (Dataset 18) being trained for epoch 29 by 2019-01-25 15:13:07.417511!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0020 - mean_absolute_error: 0.0337
14. set (Dataset 2) being trained for epoch 29 by 2019-01-25 15:14:21.618955!
Epoch 1/1
495/495 [==============================] - 57s 115ms/step - loss: 7.1293e-04 - mean_absolute_error: 0.0203
15. set (Dataset 4) being trained for epoch 29 by 2019-01-25 15:15:25.844900!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0258
16. set (Dataset 20) being trained for epoch 29 by 2019-01-25 15:16:55.402707!
Epoch 1/1
540/540 [==============================] - 62s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0301
17. set (Dataset 17) being trained for epoch 29 by 2019-01-25 15:18:01.638888!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0341
18. set (Dataset 6) being trained for epoch 29 by 2019-01-25 15:18:50.553145!
Epoch 1/1
526/526 [==============================] - 61s 116ms/step - loss: 0.0030 - mean_absolute_error: 0.0388
19. set (Dataset 8) being trained for epoch 29 by 2019-01-25 15:19:59.147967!
Epoch 1/1
756/756 [==============================] - 87s 115ms/step - loss: 0.0013 - mean_absolute_error: 0.0269
20. set (Dataset 11) being trained for epoch 29 by 2019-01-25 15:21:32.010380!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 8.2024e-04 - mean_absolute_error: 0.0221
Epoch 29 completed!
All frames and annotations from 20 datasets have been read by 2019-01-25 15:22:40.793639
1. set (Dataset 6) being trained for epoch 30 by 2019-01-25 15:22:45.974515!
Epoch 1/1
526/526 [==============================] - 61s 115ms/step - loss: 0.0029 - mean_absolute_error: 0.0384
2. set (Dataset 11) being trained for epoch 30 by 2019-01-25 15:23:52.382841!
Epoch 1/1
556/556 [==============================] - 64s 115ms/step - loss: 5.9961e-04 - mean_absolute_error: 0.0188
3. set (Dataset 10) being trained for epoch 30 by 2019-01-25 15:25:03.535759!
Epoch 1/1
710/710 [==============================] - 82s 116ms/step - loss: 8.5098e-04 - mean_absolute_error: 0.0224
4. set (Dataset 4) being trained for epoch 30 by 2019-01-25 15:26:33.182375!
Epoch 1/1
728/728 [==============================] - 84s 116ms/step - loss: 0.0010 - mean_absolute_error: 0.0252
5. set (Dataset 7) being trained for epoch 30 by 2019-01-25 15:28:05.047792!
Epoch 1/1
729/729 [==============================] - 85s 116ms/step - loss: 6.2555e-04 - mean_absolute_error: 0.0192
6. set (Dataset 8) being trained for epoch 30 by 2019-01-25 15:29:37.350748!
Epoch 1/1
756/756 [==============================] - 88s 116ms/step - loss: 0.0011 - mean_absolute_error: 0.0259
7. set (Dataset 17) being trained for epoch 30 by 2019-01-25 15:31:08.710131!
Epoch 1/1
379/379 [==============================] - 44s 115ms/step - loss: 0.0021 - mean_absolute_error: 0.0345
8. set (Dataset 1) being trained for epoch 30 by 2019-01-25 15:31:57.522515!
Epoch 1/1
482/482 [==============================] - 56s 116ms/step - loss: 0.0017 - mean_absolute_error: 0.0295
9. set (Dataset 12) being trained for epoch 30 by 2019-01-25 15:33:00.535678!
Epoch 1/1
716/716 [==============================] - 83s 116ms/step - loss: 6.0618e-04 - mean_absolute_error: 0.0188
10. set (Dataset 13) being trained for epoch 30 by 2019-01-25 15:34:28.120184!
Epoch 1/1
469/469 [==============================] - 54s 115ms/step - loss: 9.4643e-04 - mean_absolute_error: 0.0220
11. set (Dataset 21) being trained for epoch 30 by 2019-01-25 15:35:27.922506!
Epoch 1/1
618/618 [==============================] - 71s 115ms/step - loss: 0.0025 - mean_absolute_error: 0.0374
12. set (Dataset 22) being trained for epoch 30 by 2019-01-25 15:36:45.562926!
Epoch 1/1
649/649 [==============================] - 75s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0276
13. set (Dataset 2) being trained for epoch 30 by 2019-01-25 15:38:05.336981!
Epoch 1/1
495/495 [==============================] - 57s 116ms/step - loss: 7.2412e-04 - mean_absolute_error: 0.0204
14. set (Dataset 24) being trained for epoch 30 by 2019-01-25 15:39:07.192682!
Epoch 1/1
476/476 [==============================] - 55s 115ms/step - loss: 9.8922e-04 - mean_absolute_error: 0.0244
15. set (Dataset 15) being trained for epoch 30 by 2019-01-25 15:40:08.189776!
Epoch 1/1
638/638 [==============================] - 74s 116ms/step - loss: 0.0019 - mean_absolute_error: 0.0331
16. set (Dataset 20) being trained for epoch 30 by 2019-01-25 15:41:27.376366!
Epoch 1/1
540/540 [==============================] - 62s 115ms/step - loss: 0.0014 - mean_absolute_error: 0.0286
17. set (Dataset 18) being trained for epoch 30 by 2019-01-25 15:42:35.443098!
Epoch 1/1
598/598 [==============================] - 69s 116ms/step - loss: 0.0018 - mean_absolute_error: 0.0313
18. set (Dataset 19) being trained for epoch 30 by 2019-01-25 15:43:49.431142!
Epoch 1/1
486/486 [==============================] - 56s 116ms/step - loss: 0.0016 - mean_absolute_error: 0.0301
19. set (Dataset 23) being trained for epoch 30 by 2019-01-25 15:44:51.091655!
Epoch 1/1
553/553 [==============================] - 64s 115ms/step - loss: 0.0020 - mean_absolute_error: 0.0342
20. set (Dataset 16) being trained for epoch 30 by 2019-01-25 15:46:03.451069!
Epoch 1/1
898/898 [==============================] - 104s 116ms/step - loss: 0.0012 - mean_absolute_error: 0.0260
Epoch 30 completed!
Exp2019-01-25_03-13-09.h5 has been saved.
The subjects are trained: [(6, 'F06'), (11, 'M05'), (10, 'M04'), (4, 'F04'), (7, 'M01'), (8, 'M02'), (17, 'M10'), (1,
 'F01'), (12, 'M06'), (13, 'M07'), (21, 'F02'), (22, 'M01'), (2, 'F02'), (24, 'M14'), (15, 'F03'), (20, 'M12'), (18,
'F05'), (19, 'M11'), (23, 'M13'), (16, 'M09')]
Evaluating model VGG16_inc_top_seqLen16_lstm10_output3_inEpochs1_outEpochs30_AdamOpt_lr-0.000100_2019-01-25_03-13-09
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 15:47:50.109459
For the Subject 3 (F03):
730/730 [==============================] - 60s 82ms/step
Traceback (most recent call last):
  File "runCNN_LSTM.py", line 160, in <module>
    main()
  File "runCNN_LSTM.py", line 157, in main
    runCNN_LSTM(record = RECORD)
  File "runCNN_LSTM.py", line 150, in runCNN_LSTM
    num_outputs = num_outputs, batch_size = test_batch_size, stateful = STATEFUL, record = record)
  File "runCNN_LSTM.py", line 90, in evaluateCNN_LSTM
    outputs = evaluateSubject(full_model, subject, test_gen, test_labels, timesteps, num_outputs, angles, batch_size
= batch_size, stateful = stateful, record = record)
  File "runCNN_LSTM.py", line 63, in evaluateSubject
    matrix = numpy.concatenate((test_labels[timesteps:, i:i+1], predictions[:, i:i+1]), axis=1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-25_03-13-09
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 18:17:15.435101: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 18:17:15.532336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 18:17:15.532594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 18:17:15.532612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 18:17:15.687658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 18:17:15.687684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 18:17:15.687689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 18:17:15.687822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10471 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-25_03-13-09.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 4096)          134260544
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                164280
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 30
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11,
'M05'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21,
'F02'), (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-25_03-13-09_and_2019-01-25_18-17-16
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 18:17:18.623197
For the Subject 3 (F03):
730/730 [==============================] - 58s 80ms/step
(714, 1) (730, 1)
Traceback (most recent call last):
  File "continueTrainigCNN_LSTM.py", line 74, in <module>
    main()
  File "continueTrainigCNN_LSTM.py", line 71, in main
    continueTrainigCNN_LSTM(record = RECORD)
  File "continueTrainigCNN_LSTM.py", line 64, in continueTrainigCNN_LSTM
    num_outputs = num_outputs, batch_size = test_batch_size, stateful = STATEFUL, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/runCNN_LSTM.py", line 91, in evalua
teCNN_LSTM
    outputs = evaluateSubject(full_model, subject, test_gen, test_labels, timesteps, num_outputs, angles, batch_size
= batch_size, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/runCNN_LSTM.py", line 64, in evalua
teSubject
    matrix = numpy.concatenate((test_labels[timesteps:, i:i+1], predictions[:, i:i+1]), axis=1)
ValueError: all the input array dimensions except for the concatenation axis must match exactly
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-25_03-13-09
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 18:19:48.786476: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 18:19:48.882389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 18:19:48.882692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 18:19:48.882707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 18:19:49.038317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 18:19:49.038344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 18:19:49.038349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 18:19:49.038525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-25_03-13-09.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 4096)          134260544
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                164280
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 30
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11,
'M05'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21,
'F02'), (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 18:19:51.984968
For the Subject 3 (F03):
730/730 [==============================] - 59s 81ms/step
(730, 1) (730, 1)
        The absolute mean error on Pitch angle estimation: 8.64 Degree
(730, 1) (730, 1)
        The absolute mean error on Yaw angle estimation: 27.16 Degree
(730, 1) (730, 1)
        The absolute mean error on Roll angle estimation: 5.80 Degree
For the Subject 5 (F05):
946/946 [==============================] - 78s 82ms/step
(946, 1) (946, 1)
        The absolute mean error on Pitch angle estimation: 5.74 Degree
(946, 1) (946, 1)
        The absolute mean error on Yaw angle estimation: 19.72 Degree
(946, 1) (946, 1)
        The absolute mean error on Roll angle estimation: 5.28 Degree
For the Subject 9 (M03):
882/882 [==============================] - 73s 83ms/step
(882, 1) (882, 1)
        The absolute mean error on Pitch angle estimation: 27.54 Degree
(882, 1) (882, 1)
        The absolute mean error on Yaw angle estimation: 36.32 Degree
(882, 1) (882, 1)
        The absolute mean error on Roll angle estimation: 9.94 Degree
For the Subject 14 (M08):
797/797 [==============================] - 66s 83ms/step
(797, 1) (797, 1)
        The absolute mean error on Pitch angle estimation: 18.87 Degree
(797, 1) (797, 1)
        The absolute mean error on Yaw angle estimation: 42.55 Degree
(797, 1) (797, 1)
        The absolute mean error on Roll angle estimation: 34.30 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 15.20 Degree
        The absolute mean error on Yaw angle estimations: 31.44 Degree
        The absolute mean error on Roll angle estimations: 13.83 Degree
subject3_Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49.png has been saved by 2019-01-25 18:25:01.643703.
subject5_Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49.png has been saved by 2019-01-25 18:25:01.840532.
subject9_Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49.png has been saved by 2019-01-25 18:25:02.040890.
subject14_Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49.png has been saved by 2019-01-25 18:25:02.257325.
Model Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49 has been evaluated successfully.
Model Exp2019-01-25_03-13-09_and_2019-01-25_18-19-49 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-25_03-13-09
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 18:50:03.057010: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 18:50:03.152630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 18:50:03.152886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 18:50:03.152900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 18:50:03.308227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 18:50:03.308254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 18:50:03.308259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 18:50:03.308396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-25_03-13-09.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 4096)          134260544
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                164280
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 30
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11,
'M05'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21,
'F02'), (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-25_03-13-09_and_2019-01-25_18-50-04
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 18:50:06.283436
For the Subject 3 (F03):
Traceback (most recent call last):
  File "continueTrainigCNN_LSTM.py", line 74, in <module>
    main()
  File "continueTrainigCNN_LSTM.py", line 71, in main
    continueTrainigCNN_LSTM(record = RECORD)
  File "continueTrainigCNN_LSTM.py", line 64, in continueTrainigCNN_LSTM
    num_outputs = num_outputs, batch_size = test_batch_size, stateful = STATEFUL, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/runCNN_LSTM.py", line 92, in evalua
teCNN_LSTM
    outputs = evaluateSubject(full_model, subject, test_gen, test_labels, timesteps, num_outputs, angles, batch_size
= batch_size, stateful = stateful, record = record)
  File "/home/mcicek/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16/runCNN_LSTM.py", line 52, in evalua
teSubject
    model.reset_states()
NameError: name 'model' is not defined
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python continueTrainigCNN_LSTM.py Ex
p2019-01-25_03-13-09
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argum
ent of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dty
pe(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-25 18:51:24.032334: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that
this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-25 18:51:24.129107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read fro
m SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-25 18:51:24.129369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.82GiB
2019-01-25 18:51:24.129384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-25 18:51:24.285845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecuto
r with strength 1 edge matrix:
2019-01-25 18:51:24.285872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-25 18:51:24.285879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-25 18:51:24.286020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:
localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X,
pci bus id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-25_03-13-09.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 4096)          134260544
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 4096)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 10)                164280
_________________________________________________________________
dense_1 (Dense)              (None, 3)                 33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'CNN_LSTM_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 16 # TimeseriesGenerator Handles overlapping
learning_rate = 0.0001
in_epochs = 1
out_epochs = 30
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [1] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.0
lstm_recurrent_dropout = 0.25
include_vgg_top = True

angles = ['Pitch', 'Yaw', 'Roll']
######### CONF_ends_Here ###########
The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11,
'M05'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21,
'F02'), (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-25 18:51:27.299800
For the Subject 3 (F03):
730/730 [==============================] - 58s 80ms/step
(730, 1) (730, 1)
        The absolute mean error on Pitch angle estimation: 8.64 Degree
(730, 1) (730, 1)
        The absolute mean error on Yaw angle estimation: 27.16 Degree
(730, 1) (730, 1)
        The absolute mean error on Roll angle estimation: 5.80 Degree
For the Subject 5 (F05):
946/946 [==============================] - 77s 82ms/step
(946, 1) (946, 1)
        The absolute mean error on Pitch angle estimation: 5.74 Degree
(946, 1) (946, 1)
        The absolute mean error on Yaw angle estimation: 19.72 Degree
(946, 1) (946, 1)
        The absolute mean error on Roll angle estimation: 5.28 Degree
For the Subject 9 (M03):
882/882 [==============================] - 72s 82ms/step
(882, 1) (882, 1)
        The absolute mean error on Pitch angle estimation: 27.54 Degree
(882, 1) (882, 1)
        The absolute mean error on Yaw angle estimation: 36.32 Degree
(882, 1) (882, 1)
        The absolute mean error on Roll angle estimation: 9.94 Degree
For the Subject 14 (M08):
797/797 [==============================] - 65s 82ms/step
(797, 1) (797, 1)
        The absolute mean error on Pitch angle estimation: 18.87 Degree
(797, 1) (797, 1)
        The absolute mean error on Yaw angle estimation: 42.55 Degree
(797, 1) (797, 1)
        The absolute mean error on Roll angle estimation: 34.30 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 15.20 Degree
        The absolute mean error on Yaw angle estimations: 31.44 Degree
        The absolute mean error on Roll angle estimations: 13.83 Degree
subject3_Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25.png has been saved by 2019-01-25 18:56:34.782819.
subject5_Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25.png has been saved by 2019-01-25 18:56:34.978974.
subject9_Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25.png has been saved by 2019-01-25 18:56:35.178593.
subject14_Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25.png has been saved by 2019-01-25 18:56:35.394346.
Model Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25 has been evaluated successfully.
Model Exp2019-01-25_03-13-09_and_2019-01-25_18-51-25 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$
