mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE$ cd LSTM_VGG16/
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ python runCNN_LSTM.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument
 of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(flo
at).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-21 04:23:48.372529: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that thi
s TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-21 04:23:48.444097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from S
ysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-21 04:23:48.444351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 9.86GiB
2019-01-21 04:23:48.444362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-21 04:23:48.597741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor w
ith strength 1 edge matrix:
2019-01-21 04:23:48.597766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-21 04:23:48.597772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-21 04:23:48.597907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:loc
alhost/replica:0/task:0/device:GPU:0 with 9536 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bus
 id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-01-21_04-23-48 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
=================================================================
Total params: 14,714,688
Trainable params: 0
Non-trainable params: 14,714,688
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdVGG16 (TimeDistributed)    (None, 16, 7, 7, 512)     14714688
_________________________________________________________________
time_distributed_1 (TimeDist (None, 16, 25088)         0
_________________________________________________________________
time_distributed_2 (TimeDist (None, 16, 25088)         0
_________________________________________________________________
fc10 (TimeDistributed)       (None, 16, 1024)          25691136
_________________________________________________________________
time_distributed_3 (TimeDist (None, 16, 1024)          0
_________________________________________________________________
lstm_1 (LSTM)                (None, 32)                135296
_________________________________________________________________
dense_2 (Dense)              (None, 3)                 99
=================================================================
Total params: 40,541,219
Trainable params: 25,826,531
Non-trainable params: 14,714,688
_________________________________________________________________

Training model VGG16_seqLen16_lstm32_output3_inEpochs1_outEpochs20_AdamOpt_lr-0.000100__2019-01-21_04-23-48
All frames and annotations from 20 datasets have been read by 2019-01-21 04:23:54.332216
1. set (Subject 20, M12) being trained for epoch 1!
Epoch 1/1
108/108 [==============================] - 40s 374ms/step - loss: 0.1644 - mean_absolute_error: 0.3117
2. set (Subject 23, M13) being trained for epoch 1!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0917 - mean_absolute_error: 0.2339
3. set (Subject 12, M06) being trained for epoch 1!
Epoch 1/1
144/144 [==============================] - 52s 361ms/step - loss: 0.0750 - mean_absolute_error: 0.2099
4. set (Subject 16, M09) being trained for epoch 1!
Epoch 1/1
180/180 [==============================] - 64s 357ms/step - loss: 0.0620 - mean_absolute_error: 0.1814
5. set (Subject 6, F06) being trained for epoch 1!
Epoch 1/1
106/106 [==============================] - 38s 356ms/step - loss: 0.0793 - mean_absolute_error: 0.1890
6. set (Subject 22, M01) being trained for epoch 1!
Epoch 1/1
130/130 [==============================] - 48s 371ms/step - loss: 0.0320 - mean_absolute_error: 0.1151
7. set (Subject 19, M11) being trained for epoch 1!
Epoch 1/1
98/98 [==============================] - 35s 357ms/step - loss: 0.0580 - mean_absolute_error: 0.1755
8. set (Subject 13, M07) being trained for epoch 1!
Epoch 1/1
94/94 [==============================] - 34s 358ms/step - loss: 0.0458 - mean_absolute_error: 0.1579
9. set (Subject 5, F05) being trained for epoch 1!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0756 - mean_absolute_error: 0.2010
10. set (Subject 10, M04) being trained for epoch 1!
Epoch 1/1
142/142 [==============================] - 51s 359ms/step - loss: 0.0669 - mean_absolute_error: 0.1878
11. set (Subject 7, M01) being trained for epoch 1!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0929 - mean_absolute_error: 0.2306
12. set (Subject 1, F01) being trained for epoch 1!
Epoch 1/1
97/97 [==============================] - 36s 369ms/step - loss: 0.0962 - mean_absolute_error: 0.2285
13. set (Subject 15, F03) being trained for epoch 1!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0621 - mean_absolute_error: 0.1674
14. set (Subject 2, F02) being trained for epoch 1!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.1061 - mean_absolute_error: 0.2579
15. set (Subject 3, F03) being trained for epoch 1!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0773 - mean_absolute_error: 0.1993
16. set (Subject 17, M10) being trained for epoch 1!
Epoch 1/1
76/76 [==============================] - 27s 362ms/step - loss: 0.0264 - mean_absolute_error: 0.1078
17. set (Subject 14, M08) being trained for epoch 1!
Epoch 1/1
157/157 [==============================] - 56s 357ms/step - loss: 0.1203 - mean_absolute_error: 0.2726
18. set (Subject 4, F04) being trained for epoch 1!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0811 - mean_absolute_error: 0.2193
19. set (Subject 11, M05) being trained for epoch 1!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0560 - mean_absolute_error: 0.1596
20. set (Subject 8, M02) being trained for epoch 1!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0757 - mean_absolute_error: 0.2081
Epoch 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 04:41:30.416752
1. set (Subject 4, F04) being trained for epoch 2!
Epoch 1/1
146/146 [==============================] - 52s 357ms/step - loss: 0.0797 - mean_absolute_error: 0.2157
2. set (Subject 8, M02) being trained for epoch 2!
Epoch 1/1
152/152 [==============================] - 55s 360ms/step - loss: 0.0733 - mean_absolute_error: 0.2021
3. set (Subject 7, M01) being trained for epoch 2!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0823 - mean_absolute_error: 0.2137
4. set (Subject 3, F03) being trained for epoch 2!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0755 - mean_absolute_error: 0.2047
5. set (Subject 22, M01) being trained for epoch 2!
Epoch 1/1
130/130 [==============================] - 47s 361ms/step - loss: 0.0308 - mean_absolute_error: 0.1117
6. set (Subject 11, M05) being trained for epoch 2!
Epoch 1/1
112/112 [==============================] - 40s 360ms/step - loss: 0.0534 - mean_absolute_error: 0.1542
7. set (Subject 14, M08) being trained for epoch 2!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1232 - mean_absolute_error: 0.2797
8. set (Subject 1, F01) being trained for epoch 2!
Epoch 1/1
97/97 [==============================] - 35s 358ms/step - loss: 0.0949 - mean_absolute_error: 0.2261
9. set (Subject 6, F06) being trained for epoch 2!
Epoch 1/1
106/106 [==============================] - 38s 357ms/step - loss: 0.0748 - mean_absolute_error: 0.1821
10. set (Subject 5, F05) being trained for epoch 2!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0730 - mean_absolute_error: 0.1980
11. set (Subject 19, M11) being trained for epoch 2!
Epoch 1/1
98/98 [==============================] - 35s 359ms/step - loss: 0.0483 - mean_absolute_error: 0.1583
12. set (Subject 20, M12) being trained for epoch 2!
Epoch 1/1
108/108 [==============================] - 39s 363ms/step - loss: 0.0632 - mean_absolute_error: 0.2003
13. set (Subject 2, F02) being trained for epoch 2!
Epoch 1/1
99/99 [==============================] - 36s 361ms/step - loss: 0.0876 - mean_absolute_error: 0.2257
14. set (Subject 23, M13) being trained for epoch 2!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0866 - mean_absolute_error: 0.2269
15. set (Subject 12, M06) being trained for epoch 2!
Epoch 1/1
144/144 [==============================] - 52s 358ms/step - loss: 0.0524 - mean_absolute_error: 0.1745
16. set (Subject 17, M10) being trained for epoch 2!
Epoch 1/1
76/76 [==============================] - 27s 360ms/step - loss: 0.0392 - mean_absolute_error: 0.1485
17. set (Subject 15, F03) being trained for epoch 2!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0653 - mean_absolute_error: 0.1837
18. set (Subject 16, M09) being trained for epoch 2!
Epoch 1/1
180/180 [==============================] - 65s 359ms/step - loss: 0.0526 - mean_absolute_error: 0.1596
19. set (Subject 10, M04) being trained for epoch 2!
Epoch 1/1
142/142 [==============================] - 51s 361ms/step - loss: 0.0633 - mean_absolute_error: 0.1851
20. set (Subject 13, M07) being trained for epoch 2!
Epoch 1/1
94/94 [==============================] - 34s 360ms/step - loss: 0.0418 - mean_absolute_error: 0.1495
Epoch 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 04:59:03.817501
1. set (Subject 16, M09) being trained for epoch 3!
Epoch 1/1
180/180 [==============================] - 64s 357ms/step - loss: 0.0519 - mean_absolute_error: 0.1559
2. set (Subject 13, M07) being trained for epoch 3!
Epoch 1/1
94/94 [==============================] - 34s 361ms/step - loss: 0.0417 - mean_absolute_error: 0.1498
3. set (Subject 19, M11) being trained for epoch 3!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0433 - mean_absolute_error: 0.1472
4. set (Subject 12, M06) being trained for epoch 3!
Epoch 1/1
144/144 [==============================] - 52s 359ms/step - loss: 0.0514 - mean_absolute_error: 0.1748
5. set (Subject 11, M05) being trained for epoch 3!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0512 - mean_absolute_error: 0.1679
6. set (Subject 10, M04) being trained for epoch 3!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0614 - mean_absolute_error: 0.1797
7. set (Subject 15, F03) being trained for epoch 3!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0588 - mean_absolute_error: 0.1630
8. set (Subject 20, M12) being trained for epoch 3!
Epoch 1/1
108/108 [==============================] - 39s 358ms/step - loss: 0.0418 - mean_absolute_error: 0.1400
9. set (Subject 22, M01) being trained for epoch 3!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0330 - mean_absolute_error: 0.1218
10. set (Subject 6, F06) being trained for epoch 3!
Epoch 1/1
106/106 [==============================] - 38s 360ms/step - loss: 0.0751 - mean_absolute_error: 0.1833
11. set (Subject 14, M08) being trained for epoch 3!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1281 - mean_absolute_error: 0.2902
12. set (Subject 4, F04) being trained for epoch 3!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0963 - mean_absolute_error: 0.2350
13. set (Subject 23, M13) being trained for epoch 3!
Epoch 1/1
111/111 [==============================] - 40s 361ms/step - loss: 0.0723 - mean_absolute_error: 0.1957
14. set (Subject 8, M02) being trained for epoch 3!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0740 - mean_absolute_error: 0.2016
15. set (Subject 7, M01) being trained for epoch 3!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0837 - mean_absolute_error: 0.2128
16. set (Subject 17, M10) being trained for epoch 3!
Epoch 1/1
76/76 [==============================] - 28s 362ms/step - loss: 0.0264 - mean_absolute_error: 0.1077
17. set (Subject 2, F02) being trained for epoch 3!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0832 - mean_absolute_error: 0.2206
18. set (Subject 3, F03) being trained for epoch 3!
Epoch 1/1
143/143 [==============================] - 51s 359ms/step - loss: 0.0796 - mean_absolute_error: 0.2080
19. set (Subject 5, F05) being trained for epoch 3!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0751 - mean_absolute_error: 0.1977
20. set (Subject 1, F01) being trained for epoch 3!
Epoch 1/1
97/97 [==============================] - 35s 360ms/step - loss: 0.0936 - mean_absolute_error: 0.2251
Epoch 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 05:16:36.329008
1. set (Subject 3, F03) being trained for epoch 4!
Epoch 1/1
143/143 [==============================] - 51s 357ms/step - loss: 0.0778 - mean_absolute_error: 0.2049
2. set (Subject 1, F01) being trained for epoch 4!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0921 - mean_absolute_error: 0.2227
3. set (Subject 14, M08) being trained for epoch 4!
Epoch 1/1
157/157 [==============================] - 56s 359ms/step - loss: 0.1297 - mean_absolute_error: 0.2885
4. set (Subject 7, M01) being trained for epoch 4!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0812 - mean_absolute_error: 0.2101
5. set (Subject 10, M04) being trained for epoch 4!
Epoch 1/1
142/142 [==============================] - 51s 359ms/step - loss: 0.0584 - mean_absolute_error: 0.1713
6. set (Subject 5, F05) being trained for epoch 4!
Epoch 1/1
186/186 [==============================] - 67s 361ms/step - loss: 0.0708 - mean_absolute_error: 0.1908
7. set (Subject 2, F02) being trained for epoch 4!
Epoch 1/1
99/99 [==============================] - 36s 359ms/step - loss: 0.0796 - mean_absolute_error: 0.2158
8. set (Subject 4, F04) being trained for epoch 4!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0877 - mean_absolute_error: 0.2218
9. set (Subject 11, M05) being trained for epoch 4!
Epoch 1/1
112/112 [==============================] - 40s 357ms/step - loss: 0.0470 - mean_absolute_error: 0.1493
10. set (Subject 22, M01) being trained for epoch 4!
Epoch 1/1
130/130 [==============================] - 47s 360ms/step - loss: 0.0330 - mean_absolute_error: 0.1239
11. set (Subject 15, F03) being trained for epoch 4!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0572 - mean_absolute_error: 0.1598
12. set (Subject 16, M09) being trained for epoch 4!
Epoch 1/1
180/180 [==============================] - 65s 361ms/step - loss: 0.0521 - mean_absolute_error: 0.1554
13. set (Subject 8, M02) being trained for epoch 4!
Epoch 1/1
152/152 [==============================] - 55s 360ms/step - loss: 0.0690 - mean_absolute_error: 0.1913
14. set (Subject 13, M07) being trained for epoch 4!
Epoch 1/1
94/94 [==============================] - 34s 360ms/step - loss: 0.0369 - mean_absolute_error: 0.1393
15. set (Subject 19, M11) being trained for epoch 4!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0415 - mean_absolute_error: 0.1535
16. set (Subject 17, M10) being trained for epoch 4!
Epoch 1/1
76/76 [==============================] - 27s 360ms/step - loss: 0.0252 - mean_absolute_error: 0.1082
17. set (Subject 23, M13) being trained for epoch 4!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0702 - mean_absolute_error: 0.1911
18. set (Subject 12, M06) being trained for epoch 4!
Epoch 1/1
144/144 [==============================] - 52s 358ms/step - loss: 0.0495 - mean_absolute_error: 0.1644
19. set (Subject 6, F06) being trained for epoch 4!
Epoch 1/1
106/106 [==============================] - 38s 358ms/step - loss: 0.0737 - mean_absolute_error: 0.1808
20. set (Subject 20, M12) being trained for epoch 4!
Epoch 1/1
108/108 [==============================] - 39s 362ms/step - loss: 0.0399 - mean_absolute_error: 0.1324
Epoch 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 05:34:08.623122
1. set (Subject 12, M06) being trained for epoch 5!
Epoch 1/1
144/144 [==============================] - 51s 356ms/step - loss: 0.0468 - mean_absolute_error: 0.1583
2. set (Subject 20, M12) being trained for epoch 5!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0400 - mean_absolute_error: 0.1320
3. set (Subject 15, F03) being trained for epoch 5!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0567 - mean_absolute_error: 0.1583
4. set (Subject 19, M11) being trained for epoch 5!
Epoch 1/1
98/98 [==============================] - 35s 357ms/step - loss: 0.0384 - mean_absolute_error: 0.1442
5. set (Subject 5, F05) being trained for epoch 5!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0684 - mean_absolute_error: 0.1863
6. set (Subject 6, F06) being trained for epoch 5!
Epoch 1/1
106/106 [==============================] - 38s 359ms/step - loss: 0.0727 - mean_absolute_error: 0.1794
7. set (Subject 23, M13) being trained for epoch 5!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0691 - mean_absolute_error: 0.1894
8. set (Subject 16, M09) being trained for epoch 5!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0520 - mean_absolute_error: 0.1543
9. set (Subject 10, M04) being trained for epoch 5!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0564 - mean_absolute_error: 0.1661
10. set (Subject 11, M05) being trained for epoch 5!
Epoch 1/1
112/112 [==============================] - 40s 357ms/step - loss: 0.0465 - mean_absolute_error: 0.1458
11. set (Subject 2, F02) being trained for epoch 5!
Epoch 1/1
99/99 [==============================] - 36s 362ms/step - loss: 0.0786 - mean_absolute_error: 0.2143
12. set (Subject 3, F03) being trained for epoch 5!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0750 - mean_absolute_error: 0.2040
13. set (Subject 13, M07) being trained for epoch 5!
Epoch 1/1
94/94 [==============================] - 34s 360ms/step - loss: 0.0358 - mean_absolute_error: 0.1347
14. set (Subject 1, F01) being trained for epoch 5!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0879 - mean_absolute_error: 0.2128
15. set (Subject 14, M08) being trained for epoch 5!
Epoch 1/1
157/157 [==============================] - 56s 359ms/step - loss: 0.1169 - mean_absolute_error: 0.2710
16. set (Subject 17, M10) being trained for epoch 5!
Epoch 1/1
76/76 [==============================] - 27s 362ms/step - loss: 0.0261 - mean_absolute_error: 0.1109
17. set (Subject 8, M02) being trained for epoch 5!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0700 - mean_absolute_error: 0.1921
18. set (Subject 7, M01) being trained for epoch 5!
Epoch 1/1
146/146 [==============================] - 52s 360ms/step - loss: 0.0816 - mean_absolute_error: 0.2122
19. set (Subject 22, M01) being trained for epoch 5!
Epoch 1/1
130/130 [==============================] - 47s 362ms/step - loss: 0.0341 - mean_absolute_error: 0.1185
20. set (Subject 4, F04) being trained for epoch 5!
Epoch 1/1
146/146 [==============================] - 53s 362ms/step - loss: 0.0837 - mean_absolute_error: 0.2158
Epoch 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 05:51:41.868451
1. set (Subject 7, M01) being trained for epoch 6!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0813 - mean_absolute_error: 0.2121
2. set (Subject 4, F04) being trained for epoch 6!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0804 - mean_absolute_error: 0.2094
3. set (Subject 2, F02) being trained for epoch 6!
Epoch 1/1
99/99 [==============================] - 36s 361ms/step - loss: 0.0776 - mean_absolute_error: 0.2115
4. set (Subject 14, M08) being trained for epoch 6!
Epoch 1/1
157/157 [==============================] - 56s 359ms/step - loss: 0.1148 - mean_absolute_error: 0.2683
5. set (Subject 6, F06) being trained for epoch 6!
Epoch 1/1
106/106 [==============================] - 38s 359ms/step - loss: 0.0749 - mean_absolute_error: 0.1848
6. set (Subject 22, M01) being trained for epoch 6!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0292 - mean_absolute_error: 0.1116
7. set (Subject 8, M02) being trained for epoch 6!
Epoch 1/1
152/152 [==============================] - 55s 359ms/step - loss: 0.0636 - mean_absolute_error: 0.1786
8. set (Subject 3, F03) being trained for epoch 6!
Epoch 1/1
143/143 [==============================] - 51s 359ms/step - loss: 0.0703 - mean_absolute_error: 0.1987
9. set (Subject 5, F05) being trained for epoch 6!
Epoch 1/1
186/186 [==============================] - 67s 362ms/step - loss: 0.0684 - mean_absolute_error: 0.1859
10. set (Subject 10, M04) being trained for epoch 6!
Epoch 1/1
142/142 [==============================] - 51s 361ms/step - loss: 0.0541 - mean_absolute_error: 0.1601
11. set (Subject 23, M13) being trained for epoch 6!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0673 - mean_absolute_error: 0.1864
12. set (Subject 12, M06) being trained for epoch 6!
Epoch 1/1
144/144 [==============================] - 52s 359ms/step - loss: 0.0435 - mean_absolute_error: 0.1539
13. set (Subject 1, F01) being trained for epoch 6!
Epoch 1/1
97/97 [==============================] - 35s 358ms/step - loss: 0.0868 - mean_absolute_error: 0.2082
14. set (Subject 20, M12) being trained for epoch 6!
Epoch 1/1
108/108 [==============================] - 39s 362ms/step - loss: 0.0370 - mean_absolute_error: 0.1281
15. set (Subject 15, F03) being trained for epoch 6!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0561 - mean_absolute_error: 0.1626
16. set (Subject 17, M10) being trained for epoch 6!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0246 - mean_absolute_error: 0.1075
17. set (Subject 13, M07) being trained for epoch 6!
Epoch 1/1
94/94 [==============================] - 34s 361ms/step - loss: 0.0322 - mean_absolute_error: 0.1272
18. set (Subject 19, M11) being trained for epoch 6!
Epoch 1/1
98/98 [==============================] - 35s 359ms/step - loss: 0.0383 - mean_absolute_error: 0.1522
19. set (Subject 11, M05) being trained for epoch 6!
Epoch 1/1
112/112 [==============================] - 40s 359ms/step - loss: 0.0474 - mean_absolute_error: 0.1435
20. set (Subject 16, M09) being trained for epoch 6!
Epoch 1/1
180/180 [==============================] - 63s 353ms/step - loss: 0.0498 - mean_absolute_error: 0.1571
Epoch 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 06:09:14.098225
1. set (Subject 19, M11) being trained for epoch 7!
Epoch 1/1
98/98 [==============================] - 35s 355ms/step - loss: 0.0379 - mean_absolute_error: 0.1491
2. set (Subject 16, M09) being trained for epoch 7!
Epoch 1/1
180/180 [==============================] - 65s 359ms/step - loss: 0.0527 - mean_absolute_error: 0.1588
3. set (Subject 23, M13) being trained for epoch 7!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0809 - mean_absolute_error: 0.2107
4. set (Subject 15, F03) being trained for epoch 7!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0573 - mean_absolute_error: 0.1571
5. set (Subject 22, M01) being trained for epoch 7!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0281 - mean_absolute_error: 0.1079
6. set (Subject 11, M05) being trained for epoch 7!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0468 - mean_absolute_error: 0.1451
7. set (Subject 13, M07) being trained for epoch 7!
Epoch 1/1
94/94 [==============================] - 34s 360ms/step - loss: 0.0346 - mean_absolute_error: 0.1340
8. set (Subject 12, M06) being trained for epoch 7!
Epoch 1/1
144/144 [==============================] - 52s 359ms/step - loss: 0.0424 - mean_absolute_error: 0.1506
9. set (Subject 6, F06) being trained for epoch 7!
Epoch 1/1
106/106 [==============================] - 38s 361ms/step - loss: 0.0729 - mean_absolute_error: 0.1811
10. set (Subject 5, F05) being trained for epoch 7!
Epoch 1/1
186/186 [==============================] - 67s 359ms/step - loss: 0.0663 - mean_absolute_error: 0.1844
11. set (Subject 8, M02) being trained for epoch 7!
Epoch 1/1
152/152 [==============================] - 55s 361ms/step - loss: 0.0648 - mean_absolute_error: 0.1803
12. set (Subject 7, M01) being trained for epoch 7!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0788 - mean_absolute_error: 0.2093
13. set (Subject 20, M12) being trained for epoch 7!
Epoch 1/1
108/108 [==============================] - 39s 362ms/step - loss: 0.0370 - mean_absolute_error: 0.1254
14. set (Subject 4, F04) being trained for epoch 7!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0810 - mean_absolute_error: 0.2125
15. set (Subject 2, F02) being trained for epoch 7!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0734 - mean_absolute_error: 0.2057
16. set (Subject 17, M10) being trained for epoch 7!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0241 - mean_absolute_error: 0.1051
17. set (Subject 1, F01) being trained for epoch 7!
Epoch 1/1
97/97 [==============================] - 35s 358ms/step - loss: 0.0849 - mean_absolute_error: 0.2072
18. set (Subject 14, M08) being trained for epoch 7!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1149 - mean_absolute_error: 0.2721
19. set (Subject 10, M04) being trained for epoch 7!
Epoch 1/1
142/142 [==============================] - 51s 362ms/step - loss: 0.0520 - mean_absolute_error: 0.1563
20. set (Subject 3, F03) being trained for epoch 7!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0693 - mean_absolute_error: 0.1977
Epoch 7 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 06:26:46.824836
1. set (Subject 14, M08) being trained for epoch 8!
Epoch 1/1
157/157 [==============================] - 56s 356ms/step - loss: 0.1111 - mean_absolute_error: 0.2647
2. set (Subject 3, F03) being trained for epoch 8!
Epoch 1/1
143/143 [==============================] - 51s 359ms/step - loss: 0.0728 - mean_absolute_error: 0.2007
3. set (Subject 8, M02) being trained for epoch 8!
Epoch 1/1
152/152 [==============================] - 54s 357ms/step - loss: 0.0621 - mean_absolute_error: 0.1778
4. set (Subject 2, F02) being trained for epoch 8!
Epoch 1/1
99/99 [==============================] - 36s 361ms/step - loss: 0.0704 - mean_absolute_error: 0.1989
5. set (Subject 11, M05) being trained for epoch 8!
Epoch 1/1
112/112 [==============================] - 40s 359ms/step - loss: 0.0466 - mean_absolute_error: 0.1455
6. set (Subject 10, M04) being trained for epoch 8!
Epoch 1/1
142/142 [==============================] - 51s 359ms/step - loss: 0.0515 - mean_absolute_error: 0.1543
7. set (Subject 1, F01) being trained for epoch 8!
Epoch 1/1
97/97 [==============================] - 35s 357ms/step - loss: 0.0829 - mean_absolute_error: 0.2022
8. set (Subject 7, M01) being trained for epoch 8!
Epoch 1/1
146/146 [==============================] - 52s 357ms/step - loss: 0.0751 - mean_absolute_error: 0.1999
9. set (Subject 22, M01) being trained for epoch 8!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0289 - mean_absolute_error: 0.1065
10. set (Subject 6, F06) being trained for epoch 8!
Epoch 1/1
106/106 [==============================] - 38s 356ms/step - loss: 0.0720 - mean_absolute_error: 0.1799
11. set (Subject 13, M07) being trained for epoch 8!
Epoch 1/1
94/94 [==============================] - 34s 359ms/step - loss: 0.0318 - mean_absolute_error: 0.1271
12. set (Subject 19, M11) being trained for epoch 8!
Epoch 1/1
98/98 [==============================] - 35s 357ms/step - loss: 0.0439 - mean_absolute_error: 0.1581
13. set (Subject 4, F04) being trained for epoch 8!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0771 - mean_absolute_error: 0.2048
14. set (Subject 16, M09) being trained for epoch 8!
Epoch 1/1
180/180 [==============================] - 64s 358ms/step - loss: 0.0544 - mean_absolute_error: 0.1613
15. set (Subject 23, M13) being trained for epoch 8!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0683 - mean_absolute_error: 0.1892
16. set (Subject 17, M10) being trained for epoch 8!
Epoch 1/1
76/76 [==============================] - 27s 358ms/step - loss: 0.0224 - mean_absolute_error: 0.0997
17. set (Subject 20, M12) being trained for epoch 8!
Epoch 1/1
108/108 [==============================] - 39s 359ms/step - loss: 0.0395 - mean_absolute_error: 0.1317
18. set (Subject 15, F03) being trained for epoch 8!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0534 - mean_absolute_error: 0.1551
19. set (Subject 5, F05) being trained for epoch 8!
Epoch 1/1
186/186 [==============================] - 67s 361ms/step - loss: 0.0658 - mean_absolute_error: 0.1820
20. set (Subject 12, M06) being trained for epoch 8!
Epoch 1/1
144/144 [==============================] - 52s 360ms/step - loss: 0.0410 - mean_absolute_error: 0.1471
Epoch 8 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 06:44:17.539145
1. set (Subject 15, F03) being trained for epoch 9!
Epoch 1/1
128/128 [==============================] - 46s 357ms/step - loss: 0.0525 - mean_absolute_error: 0.1551
2. set (Subject 12, M06) being trained for epoch 9!
Epoch 1/1
144/144 [==============================] - 52s 358ms/step - loss: 0.0411 - mean_absolute_error: 0.1464
3. set (Subject 13, M07) being trained for epoch 9!
Epoch 1/1
94/94 [==============================] - 34s 359ms/step - loss: 0.0315 - mean_absolute_error: 0.1261
4. set (Subject 23, M13) being trained for epoch 9!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0641 - mean_absolute_error: 0.1812
5. set (Subject 10, M04) being trained for epoch 9!
Epoch 1/1
142/142 [==============================] - 51s 361ms/step - loss: 0.0506 - mean_absolute_error: 0.1525
6. set (Subject 5, F05) being trained for epoch 9!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0639 - mean_absolute_error: 0.1784
7. set (Subject 20, M12) being trained for epoch 9!
Epoch 1/1
108/108 [==============================] - 39s 361ms/step - loss: 0.0376 - mean_absolute_error: 0.1271
8. set (Subject 19, M11) being trained for epoch 9!
Epoch 1/1
98/98 [==============================] - 35s 359ms/step - loss: 0.0382 - mean_absolute_error: 0.1571
9. set (Subject 11, M05) being trained for epoch 9!
Epoch 1/1
112/112 [==============================] - 40s 357ms/step - loss: 0.0453 - mean_absolute_error: 0.1416
10. set (Subject 22, M01) being trained for epoch 9!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0293 - mean_absolute_error: 0.1079
11. set (Subject 1, F01) being trained for epoch 9!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0808 - mean_absolute_error: 0.2000
12. set (Subject 14, M08) being trained for epoch 9!
Epoch 1/1
157/157 [==============================] - 57s 360ms/step - loss: 0.1064 - mean_absolute_error: 0.2581
13. set (Subject 16, M09) being trained for epoch 9!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0538 - mean_absolute_error: 0.1618
14. set (Subject 3, F03) being trained for epoch 9!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0694 - mean_absolute_error: 0.1959
15. set (Subject 8, M02) being trained for epoch 9!
Epoch 1/1
152/152 [==============================] - 55s 359ms/step - loss: 0.0618 - mean_absolute_error: 0.1757
16. set (Subject 17, M10) being trained for epoch 9!
Epoch 1/1
76/76 [==============================] - 27s 361ms/step - loss: 0.0224 - mean_absolute_error: 0.1049
17. set (Subject 4, F04) being trained for epoch 9!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0756 - mean_absolute_error: 0.2016
18. set (Subject 2, F02) being trained for epoch 9!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0691 - mean_absolute_error: 0.1962
19. set (Subject 6, F06) being trained for epoch 9!
Epoch 1/1
106/106 [==============================] - 38s 357ms/step - loss: 0.0738 - mean_absolute_error: 0.1894
20. set (Subject 7, M01) being trained for epoch 9!
Epoch 1/1
146/146 [==============================] - 52s 360ms/step - loss: 0.0724 - mean_absolute_error: 0.1919
Epoch 9 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 07:01:50.530482
1. set (Subject 2, F02) being trained for epoch 10!
Epoch 1/1
99/99 [==============================] - 35s 358ms/step - loss: 0.0694 - mean_absolute_error: 0.1988
2. set (Subject 7, M01) being trained for epoch 10!
Epoch 1/1
146/146 [==============================] - 53s 363ms/step - loss: 0.0731 - mean_absolute_error: 0.1951
3. set (Subject 1, F01) being trained for epoch 10!
Epoch 1/1
97/97 [==============================] - 35s 360ms/step - loss: 0.0801 - mean_absolute_error: 0.1972
4. set (Subject 8, M02) being trained for epoch 10!
Epoch 1/1
152/152 [==============================] - 55s 360ms/step - loss: 0.0584 - mean_absolute_error: 0.1689
5. set (Subject 5, F05) being trained for epoch 10!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0629 - mean_absolute_error: 0.1785
6. set (Subject 6, F06) being trained for epoch 10!
Epoch 1/1
106/106 [==============================] - 38s 358ms/step - loss: 0.0701 - mean_absolute_error: 0.1803
7. set (Subject 4, F04) being trained for epoch 10!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0769 - mean_absolute_error: 0.2069
8. set (Subject 14, M08) being trained for epoch 10!
Epoch 1/1
157/157 [==============================] - 56s 359ms/step - loss: 0.1081 - mean_absolute_error: 0.2595
9. set (Subject 10, M04) being trained for epoch 10!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0504 - mean_absolute_error: 0.1524
10. set (Subject 11, M05) being trained for epoch 10!
Epoch 1/1
112/112 [==============================] - 40s 359ms/step - loss: 0.0462 - mean_absolute_error: 0.1431
11. set (Subject 20, M12) being trained for epoch 10!
Epoch 1/1
108/108 [==============================] - 39s 361ms/step - loss: 0.0340 - mean_absolute_error: 0.1235
12. set (Subject 15, F03) being trained for epoch 10!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0544 - mean_absolute_error: 0.1611
13. set (Subject 3, F03) being trained for epoch 10!
Epoch 1/1
143/143 [==============================] - 51s 360ms/step - loss: 0.0668 - mean_absolute_error: 0.1935
14. set (Subject 12, M06) being trained for epoch 10!
Epoch 1/1
144/144 [==============================] - 52s 361ms/step - loss: 0.0390 - mean_absolute_error: 0.1425
15. set (Subject 13, M07) being trained for epoch 10!
Epoch 1/1
94/94 [==============================] - 34s 361ms/step - loss: 0.0307 - mean_absolute_error: 0.1200
16. set (Subject 17, M10) being trained for epoch 10!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0217 - mean_absolute_error: 0.1059
17. set (Subject 16, M09) being trained for epoch 10!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0466 - mean_absolute_error: 0.1492
18. set (Subject 23, M13) being trained for epoch 10!
Epoch 1/1
111/111 [==============================] - 40s 359ms/step - loss: 0.0654 - mean_absolute_error: 0.1865
19. set (Subject 22, M01) being trained for epoch 10!
Epoch 1/1
130/130 [==============================] - 47s 360ms/step - loss: 0.0268 - mean_absolute_error: 0.1070
20. set (Subject 19, M11) being trained for epoch 10!
Epoch 1/1
98/98 [==============================] - 35s 356ms/step - loss: 0.0409 - mean_absolute_error: 0.1633
Epoch 10 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 07:19:24.007456
1. set (Subject 23, M13) being trained for epoch 11!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0642 - mean_absolute_error: 0.1832
2. set (Subject 19, M11) being trained for epoch 11!
Epoch 1/1
98/98 [==============================] - 35s 359ms/step - loss: 0.0370 - mean_absolute_error: 0.1550
3. set (Subject 20, M12) being trained for epoch 11!
Epoch 1/1
108/108 [==============================] - 39s 363ms/step - loss: 0.0342 - mean_absolute_error: 0.1224
4. set (Subject 13, M07) being trained for epoch 11!
Epoch 1/1
94/94 [==============================] - 34s 361ms/step - loss: 0.0292 - mean_absolute_error: 0.1208
5. set (Subject 6, F06) being trained for epoch 11!
Epoch 1/1
106/106 [==============================] - 38s 358ms/step - loss: 0.0751 - mean_absolute_error: 0.1836
6. set (Subject 22, M01) being trained for epoch 11!
Epoch 1/1
130/130 [==============================] - 47s 362ms/step - loss: 0.0269 - mean_absolute_error: 0.1040
7. set (Subject 16, M09) being trained for epoch 11!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0467 - mean_absolute_error: 0.1485
8. set (Subject 15, F03) being trained for epoch 11!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0507 - mean_absolute_error: 0.1566
9. set (Subject 5, F05) being trained for epoch 11!
Epoch 1/1
186/186 [==============================] - 67s 361ms/step - loss: 0.0635 - mean_absolute_error: 0.1811
10. set (Subject 10, M04) being trained for epoch 11!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0493 - mean_absolute_error: 0.1527
11. set (Subject 4, F04) being trained for epoch 11!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0764 - mean_absolute_error: 0.2032
12. set (Subject 2, F02) being trained for epoch 11!
Epoch 1/1
99/99 [==============================] - 36s 363ms/step - loss: 0.0683 - mean_absolute_error: 0.1948
13. set (Subject 12, M06) being trained for epoch 11!
Epoch 1/1
144/144 [==============================] - 52s 359ms/step - loss: 0.0382 - mean_absolute_error: 0.1398
14. set (Subject 7, M01) being trained for epoch 11!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0725 - mean_absolute_error: 0.1922
15. set (Subject 1, F01) being trained for epoch 11!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0806 - mean_absolute_error: 0.1994
16. set (Subject 17, M10) being trained for epoch 11!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0249 - mean_absolute_error: 0.1043
17. set (Subject 3, F03) being trained for epoch 11!
Epoch 1/1
143/143 [==============================] - 51s 358ms/step - loss: 0.0669 - mean_absolute_error: 0.1913
18. set (Subject 8, M02) being trained for epoch 11!
Epoch 1/1
152/152 [==============================] - 55s 361ms/step - loss: 0.0584 - mean_absolute_error: 0.1716
19. set (Subject 11, M05) being trained for epoch 11!
Epoch 1/1
112/112 [==============================] - 40s 357ms/step - loss: 0.0464 - mean_absolute_error: 0.1473
20. set (Subject 14, M08) being trained for epoch 11!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1036 - mean_absolute_error: 0.2538
Epoch 11 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 07:36:57.395666
1. set (Subject 8, M02) being trained for epoch 12!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0584 - mean_absolute_error: 0.1676
2. set (Subject 14, M08) being trained for epoch 12!
Epoch 1/1
157/157 [==============================] - 56s 360ms/step - loss: 0.1022 - mean_absolute_error: 0.2528
3. set (Subject 4, F04) being trained for epoch 12!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0735 - mean_absolute_error: 0.2012
4. set (Subject 1, F01) being trained for epoch 12!
Epoch 1/1
97/97 [==============================] - 35s 357ms/step - loss: 0.0812 - mean_absolute_error: 0.2005
5. set (Subject 22, M01) being trained for epoch 12!
Epoch 1/1
130/130 [==============================] - 47s 362ms/step - loss: 0.0276 - mean_absolute_error: 0.1086
6. set (Subject 11, M05) being trained for epoch 12!
Epoch 1/1
112/112 [==============================] - 40s 356ms/step - loss: 0.0442 - mean_absolute_error: 0.1415
7. set (Subject 3, F03) being trained for epoch 12!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0664 - mean_absolute_error: 0.1947
8. set (Subject 2, F02) being trained for epoch 12!
Epoch 1/1
99/99 [==============================] - 36s 361ms/step - loss: 0.0672 - mean_absolute_error: 0.1902
9. set (Subject 6, F06) being trained for epoch 12!
Epoch 1/1
106/106 [==============================] - 38s 357ms/step - loss: 0.0727 - mean_absolute_error: 0.1785
10. set (Subject 5, F05) being trained for epoch 12!
Epoch 1/1
186/186 [==============================] - 67s 361ms/step - loss: 0.0633 - mean_absolute_error: 0.1790
11. set (Subject 16, M09) being trained for epoch 12!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0466 - mean_absolute_error: 0.1479
12. set (Subject 23, M13) being trained for epoch 12!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0645 - mean_absolute_error: 0.1822
13. set (Subject 7, M01) being trained for epoch 12!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0673 - mean_absolute_error: 0.1813
14. set (Subject 19, M11) being trained for epoch 12!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0360 - mean_absolute_error: 0.1541
15. set (Subject 20, M12) being trained for epoch 12!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0328 - mean_absolute_error: 0.1203
16. set (Subject 17, M10) being trained for epoch 12!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0252 - mean_absolute_error: 0.1062
17. set (Subject 12, M06) being trained for epoch 12!
Epoch 1/1
144/144 [==============================] - 52s 360ms/step - loss: 0.0384 - mean_absolute_error: 0.1406
18. set (Subject 13, M07) being trained for epoch 12!
Epoch 1/1
94/94 [==============================] - 34s 362ms/step - loss: 0.0300 - mean_absolute_error: 0.1231
19. set (Subject 10, M04) being trained for epoch 12!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0527 - mean_absolute_error: 0.1601
20. set (Subject 15, F03) being trained for epoch 12!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0497 - mean_absolute_error: 0.1550
Epoch 12 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 07:54:30.551249
1. set (Subject 13, M07) being trained for epoch 13!
Epoch 1/1
94/94 [==============================] - 34s 357ms/step - loss: 0.0297 - mean_absolute_error: 0.1228
2. set (Subject 15, F03) being trained for epoch 13!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0500 - mean_absolute_error: 0.1526
3. set (Subject 16, M09) being trained for epoch 13!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0428 - mean_absolute_error: 0.1415
4. set (Subject 20, M12) being trained for epoch 13!
Epoch 1/1
108/108 [==============================] - 39s 362ms/step - loss: 0.0370 - mean_absolute_error: 0.1294
5. set (Subject 11, M05) being trained for epoch 13!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0441 - mean_absolute_error: 0.1424
6. set (Subject 10, M04) being trained for epoch 13!
Epoch 1/1
142/142 [==============================] - 51s 361ms/step - loss: 0.0482 - mean_absolute_error: 0.1506
7. set (Subject 12, M06) being trained for epoch 13!
Epoch 1/1
144/144 [==============================] - 52s 358ms/step - loss: 0.0380 - mean_absolute_error: 0.1386
8. set (Subject 23, M13) being trained for epoch 13!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0685 - mean_absolute_error: 0.1882
9. set (Subject 22, M01) being trained for epoch 13!
Epoch 1/1
130/130 [==============================] - 47s 361ms/step - loss: 0.0253 - mean_absolute_error: 0.1045
10. set (Subject 6, F06) being trained for epoch 13!
Epoch 1/1
106/106 [==============================] - 38s 356ms/step - loss: 0.0735 - mean_absolute_error: 0.1800
11. set (Subject 3, F03) being trained for epoch 13!
Epoch 1/1
143/143 [==============================] - 51s 360ms/step - loss: 0.0665 - mean_absolute_error: 0.1937
12. set (Subject 8, M02) being trained for epoch 13!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0587 - mean_absolute_error: 0.1713
13. set (Subject 19, M11) being trained for epoch 13!
Epoch 1/1
98/98 [==============================] - 35s 357ms/step - loss: 0.0366 - mean_absolute_error: 0.1518
14. set (Subject 14, M08) being trained for epoch 13!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1030 - mean_absolute_error: 0.2545
15. set (Subject 4, F04) being trained for epoch 13!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0773 - mean_absolute_error: 0.2125
16. set (Subject 17, M10) being trained for epoch 13!
Epoch 1/1
76/76 [==============================] - 27s 360ms/step - loss: 0.0224 - mean_absolute_error: 0.1021
17. set (Subject 7, M01) being trained for epoch 13!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0739 - mean_absolute_error: 0.1950
18. set (Subject 1, F01) being trained for epoch 13!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0866 - mean_absolute_error: 0.2079
19. set (Subject 5, F05) being trained for epoch 13!
Epoch 1/1
186/186 [==============================] - 67s 361ms/step - loss: 0.0623 - mean_absolute_error: 0.1793
20. set (Subject 2, F02) being trained for epoch 13!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0647 - mean_absolute_error: 0.1874
Epoch 13 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 08:12:02.614804
1. set (Subject 1, F01) being trained for epoch 14!
Epoch 1/1
97/97 [==============================] - 34s 355ms/step - loss: 0.0751 - mean_absolute_error: 0.1914
2. set (Subject 2, F02) being trained for epoch 14!
Epoch 1/1
99/99 [==============================] - 36s 361ms/step - loss: 0.0631 - mean_absolute_error: 0.1849
3. set (Subject 3, F03) being trained for epoch 14!
Epoch 1/1
143/143 [==============================] - 52s 361ms/step - loss: 0.0669 - mean_absolute_error: 0.1934
4. set (Subject 4, F04) being trained for epoch 14!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0740 - mean_absolute_error: 0.1983
5. set (Subject 10, M04) being trained for epoch 14!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0473 - mean_absolute_error: 0.1494
6. set (Subject 5, F05) being trained for epoch 14!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0604 - mean_absolute_error: 0.1752
7. set (Subject 7, M01) being trained for epoch 14!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0692 - mean_absolute_error: 0.1880
8. set (Subject 8, M02) being trained for epoch 14!
Epoch 1/1
152/152 [==============================] - 55s 360ms/step - loss: 0.0583 - mean_absolute_error: 0.1685
9. set (Subject 11, M05) being trained for epoch 14!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0453 - mean_absolute_error: 0.1365
10. set (Subject 22, M01) being trained for epoch 14!
Epoch 1/1
130/130 [==============================] - 47s 360ms/step - loss: 0.0250 - mean_absolute_error: 0.1046
11. set (Subject 12, M06) being trained for epoch 14!
Epoch 1/1
144/144 [==============================] - 52s 358ms/step - loss: 0.0368 - mean_absolute_error: 0.1361
12. set (Subject 13, M07) being trained for epoch 14!
Epoch 1/1
94/94 [==============================] - 34s 360ms/step - loss: 0.0281 - mean_absolute_error: 0.1205
13. set (Subject 14, M08) being trained for epoch 14!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1012 - mean_absolute_error: 0.2516
14. set (Subject 15, F03) being trained for epoch 14!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0505 - mean_absolute_error: 0.1575
15. set (Subject 16, M09) being trained for epoch 14!
Epoch 1/1
180/180 [==============================] - 65s 359ms/step - loss: 0.0446 - mean_absolute_error: 0.1446
16. set (Subject 17, M10) being trained for epoch 14!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0246 - mean_absolute_error: 0.1041
17. set (Subject 19, M11) being trained for epoch 14!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0388 - mean_absolute_error: 0.1587
18. set (Subject 20, M12) being trained for epoch 14!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0336 - mean_absolute_error: 0.1217
19. set (Subject 6, F06) being trained for epoch 14!
Epoch 1/1
106/106 [==============================] - 38s 356ms/step - loss: 0.0729 - mean_absolute_error: 0.1783
20. set (Subject 23, M13) being trained for epoch 14!
Epoch 1/1
111/111 [==============================] - 40s 361ms/step - loss: 0.0675 - mean_absolute_error: 0.1861
Epoch 14 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 08:29:35.244597
1. set (Subject 20, M12) being trained for epoch 15!
Epoch 1/1
108/108 [==============================] - 39s 359ms/step - loss: 0.0347 - mean_absolute_error: 0.1241
2. set (Subject 23, M13) being trained for epoch 15!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0647 - mean_absolute_error: 0.1845
3. set (Subject 12, M06) being trained for epoch 15!
Epoch 1/1
144/144 [==============================] - 52s 359ms/step - loss: 0.0369 - mean_absolute_error: 0.1378
4. set (Subject 16, M09) being trained for epoch 15!
Epoch 1/1
180/180 [==============================] - 65s 359ms/step - loss: 0.0426 - mean_absolute_error: 0.1462
5. set (Subject 5, F05) being trained for epoch 15!
Epoch 1/1
186/186 [==============================] - 67s 362ms/step - loss: 0.0610 - mean_absolute_error: 0.1800
6. set (Subject 6, F06) being trained for epoch 15!
Epoch 1/1
106/106 [==============================] - 38s 359ms/step - loss: 0.0693 - mean_absolute_error: 0.1771
7. set (Subject 19, M11) being trained for epoch 15!
Epoch 1/1
98/98 [==============================] - 35s 357ms/step - loss: 0.0399 - mean_absolute_error: 0.1617
8. set (Subject 13, M07) being trained for epoch 15!
Epoch 1/1
94/94 [==============================] - 34s 362ms/step - loss: 0.0289 - mean_absolute_error: 0.1223
9. set (Subject 10, M04) being trained for epoch 15!
Epoch 1/1
142/142 [==============================] - 51s 361ms/step - loss: 0.0479 - mean_absolute_error: 0.1526
10. set (Subject 11, M05) being trained for epoch 15!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0435 - mean_absolute_error: 0.1390
11. set (Subject 7, M01) being trained for epoch 15!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0672 - mean_absolute_error: 0.1844
12. set (Subject 1, F01) being trained for epoch 15!
Epoch 1/1
97/97 [==============================] - 35s 358ms/step - loss: 0.0815 - mean_absolute_error: 0.2027
13. set (Subject 15, F03) being trained for epoch 15!
Epoch 1/1
128/128 [==============================] - 46s 358ms/step - loss: 0.0536 - mean_absolute_error: 0.1639
14. set (Subject 2, F02) being trained for epoch 15!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0724 - mean_absolute_error: 0.2001
15. set (Subject 3, F03) being trained for epoch 15!
Epoch 1/1
143/143 [==============================] - 52s 360ms/step - loss: 0.0676 - mean_absolute_error: 0.1954
16. set (Subject 17, M10) being trained for epoch 15!
Epoch 1/1
76/76 [==============================] - 27s 360ms/step - loss: 0.0300 - mean_absolute_error: 0.1331
17. set (Subject 14, M08) being trained for epoch 15!
Epoch 1/1
157/157 [==============================] - 56s 359ms/step - loss: 0.1015 - mean_absolute_error: 0.2552
18. set (Subject 4, F04) being trained for epoch 15!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0744 - mean_absolute_error: 0.2006
19. set (Subject 22, M01) being trained for epoch 15!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0361 - mean_absolute_error: 0.1338
20. set (Subject 8, M02) being trained for epoch 15!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0560 - mean_absolute_error: 0.1663
Epoch 15 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 08:47:07.625040
1. set (Subject 4, F04) being trained for epoch 16!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0739 - mean_absolute_error: 0.2060
2. set (Subject 8, M02) being trained for epoch 16!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0555 - mean_absolute_error: 0.1658
3. set (Subject 7, M01) being trained for epoch 16!
Epoch 1/1
146/146 [==============================] - 53s 362ms/step - loss: 0.0657 - mean_absolute_error: 0.1841
4. set (Subject 3, F03) being trained for epoch 16!
Epoch 1/1
143/143 [==============================] - 51s 358ms/step - loss: 0.0668 - mean_absolute_error: 0.1960
5. set (Subject 6, F06) being trained for epoch 16!
Epoch 1/1
106/106 [==============================] - 38s 361ms/step - loss: 0.0722 - mean_absolute_error: 0.1869
6. set (Subject 22, M01) being trained for epoch 16!
Epoch 1/1
130/130 [==============================] - 47s 360ms/step - loss: 0.0275 - mean_absolute_error: 0.1166
7. set (Subject 14, M08) being trained for epoch 16!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1050 - mean_absolute_error: 0.2566
8. set (Subject 1, F01) being trained for epoch 16!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0726 - mean_absolute_error: 0.1886
9. set (Subject 5, F05) being trained for epoch 16!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0579 - mean_absolute_error: 0.1718
10. set (Subject 10, M04) being trained for epoch 16!
Epoch 1/1
142/142 [==============================] - 51s 359ms/step - loss: 0.0474 - mean_absolute_error: 0.1539
11. set (Subject 19, M11) being trained for epoch 16!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0395 - mean_absolute_error: 0.1622
12. set (Subject 20, M12) being trained for epoch 16!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0372 - mean_absolute_error: 0.1354
13. set (Subject 2, F02) being trained for epoch 16!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0641 - mean_absolute_error: 0.1891
14. set (Subject 23, M13) being trained for epoch 16!
Epoch 1/1
111/111 [==============================] - 40s 358ms/step - loss: 0.0641 - mean_absolute_error: 0.1879
15. set (Subject 12, M06) being trained for epoch 16!
Epoch 1/1
144/144 [==============================] - 51s 357ms/step - loss: 0.0365 - mean_absolute_error: 0.1367
16. set (Subject 17, M10) being trained for epoch 16!
Epoch 1/1
76/76 [==============================] - 27s 359ms/step - loss: 0.0254 - mean_absolute_error: 0.1221
17. set (Subject 15, F03) being trained for epoch 16!
Epoch 1/1
128/128 [==============================] - 46s 361ms/step - loss: 0.0565 - mean_absolute_error: 0.1665
18. set (Subject 16, M09) being trained for epoch 16!
Epoch 1/1
180/180 [==============================] - 64s 357ms/step - loss: 0.0479 - mean_absolute_error: 0.1551
19. set (Subject 11, M05) being trained for epoch 16!
Epoch 1/1
112/112 [==============================] - 40s 359ms/step - loss: 0.0475 - mean_absolute_error: 0.1440
20. set (Subject 13, M07) being trained for epoch 16!
Epoch 1/1
94/94 [==============================] - 34s 361ms/step - loss: 0.0283 - mean_absolute_error: 0.1172
Epoch 16 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 09:04:39.549735
1. set (Subject 16, M09) being trained for epoch 17!
Epoch 1/1
180/180 [==============================] - 65s 360ms/step - loss: 0.0426 - mean_absolute_error: 0.1474
2. set (Subject 13, M07) being trained for epoch 17!
Epoch 1/1
94/94 [==============================] - 34s 359ms/step - loss: 0.0284 - mean_absolute_error: 0.1164
3. set (Subject 19, M11) being trained for epoch 17!
Epoch 1/1
98/98 [==============================] - 35s 361ms/step - loss: 0.0358 - mean_absolute_error: 0.1546
4. set (Subject 12, M06) being trained for epoch 17!
Epoch 1/1
144/144 [==============================] - 52s 358ms/step - loss: 0.0363 - mean_absolute_error: 0.1382
5. set (Subject 22, M01) being trained for epoch 17!
Epoch 1/1
130/130 [==============================] - 47s 359ms/step - loss: 0.0263 - mean_absolute_error: 0.1118
6. set (Subject 11, M05) being trained for epoch 17!
Epoch 1/1
112/112 [==============================] - 40s 357ms/step - loss: 0.0423 - mean_absolute_error: 0.1384
7. set (Subject 15, F03) being trained for epoch 17!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0537 - mean_absolute_error: 0.1683
8. set (Subject 20, M12) being trained for epoch 17!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0344 - mean_absolute_error: 0.1276
9. set (Subject 6, F06) being trained for epoch 17!
Epoch 1/1
106/106 [==============================] - 38s 360ms/step - loss: 0.0721 - mean_absolute_error: 0.1851
10. set (Subject 5, F05) being trained for epoch 17!
Epoch 1/1
186/186 [==============================] - 67s 361ms/step - loss: 0.0580 - mean_absolute_error: 0.1734
11. set (Subject 14, M08) being trained for epoch 17!
Epoch 1/1
157/157 [==============================] - 56s 359ms/step - loss: 0.1004 - mean_absolute_error: 0.2571
12. set (Subject 4, F04) being trained for epoch 17!
Epoch 1/1
146/146 [==============================] - 53s 360ms/step - loss: 0.0759 - mean_absolute_error: 0.2030
13. set (Subject 23, M13) being trained for epoch 17!
Epoch 1/1
111/111 [==============================] - 40s 360ms/step - loss: 0.0641 - mean_absolute_error: 0.1827
14. set (Subject 8, M02) being trained for epoch 17!
Epoch 1/1
152/152 [==============================] - 54s 358ms/step - loss: 0.0753 - mean_absolute_error: 0.1998
15. set (Subject 7, M01) being trained for epoch 17!
Epoch 1/1
146/146 [==============================] - 52s 360ms/step - loss: 0.0722 - mean_absolute_error: 0.1949
16. set (Subject 17, M10) being trained for epoch 17!
Epoch 1/1
76/76 [==============================] - 28s 362ms/step - loss: 0.0238 - mean_absolute_error: 0.1069
17. set (Subject 2, F02) being trained for epoch 17!
Epoch 1/1
99/99 [==============================] - 36s 361ms/step - loss: 0.0672 - mean_absolute_error: 0.1930
18. set (Subject 3, F03) being trained for epoch 17!
Epoch 1/1
143/143 [==============================] - 51s 359ms/step - loss: 0.0639 - mean_absolute_error: 0.1891
19. set (Subject 10, M04) being trained for epoch 17!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0473 - mean_absolute_error: 0.1517
20. set (Subject 1, F01) being trained for epoch 17!
Epoch 1/1
97/97 [==============================] - 35s 359ms/step - loss: 0.0747 - mean_absolute_error: 0.1931
Epoch 17 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 09:22:12.327301
1. set (Subject 3, F03) being trained for epoch 18!
Epoch 1/1
143/143 [==============================] - 51s 357ms/step - loss: 0.0648 - mean_absolute_error: 0.1900
2. set (Subject 1, F01) being trained for epoch 18!
Epoch 1/1
97/97 [==============================] - 35s 360ms/step - loss: 0.0752 - mean_absolute_error: 0.1932
3. set (Subject 14, M08) being trained for epoch 18!
Epoch 1/1
157/157 [==============================] - 56s 360ms/step - loss: 0.1008 - mean_absolute_error: 0.2566
4. set (Subject 7, M01) being trained for epoch 18!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0629 - mean_absolute_error: 0.1781
5. set (Subject 11, M05) being trained for epoch 18!
Epoch 1/1
112/112 [==============================] - 40s 357ms/step - loss: 0.0414 - mean_absolute_error: 0.1433
6. set (Subject 10, M04) being trained for epoch 18!
Epoch 1/1
142/142 [==============================] - 51s 360ms/step - loss: 0.0465 - mean_absolute_error: 0.1508
7. set (Subject 2, F02) being trained for epoch 18!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0665 - mean_absolute_error: 0.1894
8. set (Subject 4, F04) being trained for epoch 18!
Epoch 1/1
146/146 [==============================] - 52s 359ms/step - loss: 0.0720 - mean_absolute_error: 0.2006
9. set (Subject 22, M01) being trained for epoch 18!
Epoch 1/1
130/130 [==============================] - 47s 360ms/step - loss: 0.0258 - mean_absolute_error: 0.1065
10. set (Subject 6, F06) being trained for epoch 18!
Epoch 1/1
106/106 [==============================] - 38s 358ms/step - loss: 0.0649 - mean_absolute_error: 0.1687
11. set (Subject 15, F03) being trained for epoch 18!
Epoch 1/1
128/128 [==============================] - 46s 358ms/step - loss: 0.0477 - mean_absolute_error: 0.1575
12. set (Subject 16, M09) being trained for epoch 18!
Epoch 1/1
180/180 [==============================] - 65s 361ms/step - loss: 0.0524 - mean_absolute_error: 0.1514
13. set (Subject 8, M02) being trained for epoch 18!
Epoch 1/1
152/152 [==============================] - 55s 360ms/step - loss: 0.0641 - mean_absolute_error: 0.1800
14. set (Subject 13, M07) being trained for epoch 18!
Epoch 1/1
94/94 [==============================] - 34s 358ms/step - loss: 0.0306 - mean_absolute_error: 0.1227
15. set (Subject 19, M11) being trained for epoch 18!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0381 - mean_absolute_error: 0.1521
16. set (Subject 17, M10) being trained for epoch 18!
Epoch 1/1
76/76 [==============================] - 27s 360ms/step - loss: 0.0222 - mean_absolute_error: 0.1020
17. set (Subject 23, M13) being trained for epoch 18!
Epoch 1/1
111/111 [==============================] - 40s 359ms/step - loss: 0.0650 - mean_absolute_error: 0.1834
18. set (Subject 12, M06) being trained for epoch 18!
Epoch 1/1
144/144 [==============================] - 51s 357ms/step - loss: 0.0373 - mean_absolute_error: 0.1386
19. set (Subject 5, F05) being trained for epoch 18!
Epoch 1/1
186/186 [==============================] - 67s 359ms/step - loss: 0.0600 - mean_absolute_error: 0.1767
20. set (Subject 20, M12) being trained for epoch 18!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0348 - mean_absolute_error: 0.1240
Epoch 18 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 09:39:44.085308
1. set (Subject 12, M06) being trained for epoch 19!
Epoch 1/1
144/144 [==============================] - 51s 358ms/step - loss: 0.0375 - mean_absolute_error: 0.1386
2. set (Subject 20, M12) being trained for epoch 19!
Epoch 1/1
108/108 [==============================] - 39s 361ms/step - loss: 0.0334 - mean_absolute_error: 0.1221
3. set (Subject 15, F03) being trained for epoch 19!
Epoch 1/1
128/128 [==============================] - 46s 359ms/step - loss: 0.0695 - mean_absolute_error: 0.1965
4. set (Subject 19, M11) being trained for epoch 19!
Epoch 1/1
98/98 [==============================] - 35s 357ms/step - loss: 0.0354 - mean_absolute_error: 0.1532
5. set (Subject 10, M04) being trained for epoch 19!
Epoch 1/1
142/142 [==============================] - 51s 358ms/step - loss: 0.0456 - mean_absolute_error: 0.1513
6. set (Subject 5, F05) being trained for epoch 19!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0580 - mean_absolute_error: 0.1751
7. set (Subject 23, M13) being trained for epoch 19!
Epoch 1/1
111/111 [==============================] - 40s 359ms/step - loss: 0.0673 - mean_absolute_error: 0.1913
8. set (Subject 16, M09) being trained for epoch 19!
Epoch 1/1
180/180 [==============================] - 65s 359ms/step - loss: 0.0424 - mean_absolute_error: 0.1498
9. set (Subject 11, M05) being trained for epoch 19!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0466 - mean_absolute_error: 0.1416
10. set (Subject 22, M01) being trained for epoch 19!
Epoch 1/1
130/130 [==============================] - 47s 361ms/step - loss: 0.0245 - mean_absolute_error: 0.1075
11. set (Subject 2, F02) being trained for epoch 19!
Epoch 1/1
99/99 [==============================] - 36s 360ms/step - loss: 0.0633 - mean_absolute_error: 0.1873
12. set (Subject 3, F03) being trained for epoch 19!
Epoch 1/1
143/143 [==============================] - 51s 360ms/step - loss: 0.0653 - mean_absolute_error: 0.1952
13. set (Subject 13, M07) being trained for epoch 19!
Epoch 1/1
94/94 [==============================] - 34s 360ms/step - loss: 0.0280 - mean_absolute_error: 0.1149
14. set (Subject 1, F01) being trained for epoch 19!
Epoch 1/1
97/97 [==============================] - 35s 357ms/step - loss: 0.0727 - mean_absolute_error: 0.1896
15. set (Subject 14, M08) being trained for epoch 19!
Epoch 1/1
157/157 [==============================] - 56s 358ms/step - loss: 0.1021 - mean_absolute_error: 0.2569
16. set (Subject 17, M10) being trained for epoch 19!
Epoch 1/1
76/76 [==============================] - 27s 361ms/step - loss: 0.0233 - mean_absolute_error: 0.1166
17. set (Subject 8, M02) being trained for epoch 19!
Epoch 1/1
152/152 [==============================] - 55s 359ms/step - loss: 0.0575 - mean_absolute_error: 0.1711
18. set (Subject 7, M01) being trained for epoch 19!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0703 - mean_absolute_error: 0.1867
19. set (Subject 6, F06) being trained for epoch 19!
Epoch 1/1
106/106 [==============================] - 38s 357ms/step - loss: 0.0642 - mean_absolute_error: 0.1725
20. set (Subject 4, F04) being trained for epoch 19!
Epoch 1/1
146/146 [==============================] - 53s 361ms/step - loss: 0.0759 - mean_absolute_error: 0.2076
Epoch 19 completed!
All frames and annotations from 20 datasets have been read by 2019-01-21 09:57:16.432562
1. set (Subject 7, M01) being trained for epoch 20!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0635 - mean_absolute_error: 0.1782
2. set (Subject 4, F04) being trained for epoch 20!
Epoch 1/1
146/146 [==============================] - 52s 358ms/step - loss: 0.0745 - mean_absolute_error: 0.2040
3. set (Subject 2, F02) being trained for epoch 20!
Epoch 1/1
99/99 [==============================] - 36s 363ms/step - loss: 0.0705 - mean_absolute_error: 0.2031
4. set (Subject 14, M08) being trained for epoch 20!
Epoch 1/1
157/157 [==============================] - 56s 357ms/step - loss: 0.1067 - mean_absolute_error: 0.2686
5. set (Subject 5, F05) being trained for epoch 20!
Epoch 1/1
186/186 [==============================] - 67s 360ms/step - loss: 0.0582 - mean_absolute_error: 0.1763
6. set (Subject 6, F06) being trained for epoch 20!
Epoch 1/1
106/106 [==============================] - 38s 359ms/step - loss: 0.0654 - mean_absolute_error: 0.1731
7. set (Subject 8, M02) being trained for epoch 20!
Epoch 1/1
152/152 [==============================] - 55s 359ms/step - loss: 0.0565 - mean_absolute_error: 0.1647
8. set (Subject 3, F03) being trained for epoch 20!
Epoch 1/1
143/143 [==============================] - 51s 360ms/step - loss: 0.0643 - mean_absolute_error: 0.1951
9. set (Subject 10, M04) being trained for epoch 20!
Epoch 1/1
142/142 [==============================] - 51s 359ms/step - loss: 0.0457 - mean_absolute_error: 0.1515
10. set (Subject 11, M05) being trained for epoch 20!
Epoch 1/1
112/112 [==============================] - 40s 358ms/step - loss: 0.0400 - mean_absolute_error: 0.1404
11. set (Subject 23, M13) being trained for epoch 20!
Epoch 1/1
111/111 [==============================] - 40s 359ms/step - loss: 0.0635 - mean_absolute_error: 0.1844
12. set (Subject 12, M06) being trained for epoch 20!
Epoch 1/1
144/144 [==============================] - 52s 359ms/step - loss: 0.0406 - mean_absolute_error: 0.1476
13. set (Subject 1, F01) being trained for epoch 20!
Epoch 1/1
97/97 [==============================] - 35s 360ms/step - loss: 0.0747 - mean_absolute_error: 0.1935
14. set (Subject 20, M12) being trained for epoch 20!
Epoch 1/1
108/108 [==============================] - 39s 360ms/step - loss: 0.0317 - mean_absolute_error: 0.1223
15. set (Subject 15, F03) being trained for epoch 20!
Epoch 1/1
128/128 [==============================] - 46s 360ms/step - loss: 0.0532 - mean_absolute_error: 0.1661
16. set (Subject 17, M10) being trained for epoch 20!
Epoch 1/1
76/76 [==============================] - 27s 361ms/step - loss: 0.0298 - mean_absolute_error: 0.1356
17. set (Subject 13, M07) being trained for epoch 20!
Epoch 1/1
94/94 [==============================] - 34s 358ms/step - loss: 0.0286 - mean_absolute_error: 0.1192
18. set (Subject 19, M11) being trained for epoch 20!
Epoch 1/1
98/98 [==============================] - 35s 358ms/step - loss: 0.0348 - mean_absolute_error: 0.1523
19. set (Subject 22, M01) being trained for epoch 20!
Epoch 1/1
130/130 [==============================] - 47s 361ms/step - loss: 0.0265 - mean_absolute_error: 0.1161
20. set (Subject 16, M09) being trained for epoch 20!
Epoch 1/1
180/180 [==============================] - 64s 358ms/step - loss: 0.0420 - mean_absolute_error: 0.1511
Epoch 20 completed!
Exp2019-01-21_04-23-48.h5 has been saved.
The subjects are trained: [(7, 'M01'), (4, 'F04'), (2, 'F02'), (14, 'M08'), (5, 'F05'), (6, 'F06'), (8, 'M02'), (3, 'F03
'), (10, 'M04'), (11, 'M05'), (23, 'M13'), (12, 'M06'), (1, 'F01'), (20, 'M12'), (15, 'F03'), (17, 'M10'), (13, 'M07'),
(19, 'M11'), (22, 'M01'), (16, 'M09')]
Evaluating model VGG16_seqLen16_lstm32_output3_inEpochs1_outEpochs20_AdamOpt_lr-0.000100__2019-01-21_04-23-48
The subjects will be tested: [(9, 'M03'), (18, 'F05'), (21, 'F02'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-01-21 10:14:44.524907
For the Subject 9 (M03):
217/217 [==============================] - 55s 254ms/step
        The absolute mean error on Pitch angle estimation: 20.15 Degree
        The absolute mean error on Yaw angle estimation: 23.83 Degree
        The absolute mean error on Roll angle estimation: 6.72 Degree
For the Subject 18 (F05):
150/150 [==============================] - 39s 257ms/step
        The absolute mean error on Pitch angle estimation: 17.76 Degree
        The absolute mean error on Yaw angle estimation: 22.81 Degree
        The absolute mean error on Roll angle estimation: 12.26 Degree
For the Subject 21 (F02):
155/155 [==============================] - 40s 258ms/step
        The absolute mean error on Pitch angle estimation: 21.34 Degree
        The absolute mean error on Yaw angle estimation: 18.95 Degree
        The absolute mean error on Roll angle estimation: 15.93 Degree
For the Subject 24 (M14):
119/119 [==============================] - 31s 258ms/step
        The absolute mean error on Pitch angle estimation: 14.91 Degree
        The absolute mean error on Yaw angle estimation: 13.75 Degree
        The absolute mean error on Roll angle estimation: 5.45 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 18.54 Degree
        The absolute mean error on Yaw angle estimations: 19.83 Degree
        The absolute mean error on Roll angle estimations: 10.09 Degree
subject9_Exp2019-01-21_04-23-48.png has been saved by 2019-01-21 10:17:54.826360.
subject18_Exp2019-01-21_04-23-48.png has been saved by 2019-01-21 10:17:55.021909.
subject21_Exp2019-01-21_04-23-48.png has been saved by 2019-01-21 10:17:55.220530.
subject24_Exp2019-01-21_04-23-48.png has been saved by 2019-01-21 10:17:55.408392.
Model Exp2019-01-21_04-23-48 has been evaluated successfully.
Model Exp2019-01-21_04-23-48 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git add --all
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git commit -m "Results of Exp2019-01-21
_04-23-48"
[master 2e58c6c] Results of Exp2019-01-21_04-23-48
 6 files changed, 518 insertions(+), 72 deletions(-)
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-21_04-23-48/output_Exp2019-01-21_04-23-48.txt
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-21_04-23-48/subject18_Exp2019-01-21_04-23-48.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-21_04-23-48/subject21_Exp2019-01-21_04-23-48.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-21_04-23-48/subject24_Exp2019-01-21_04-23-48.png
 create mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Exp2019-01-21_04-23-48/subject9_Exp2019-01-21_04-23-48.png
 delete mode 100644 DeepRL_For_HPE/LSTM_VGG16/results/Last_Model/output_Last_Model.txt
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$ git push
Password for 'https://muratcancicek@bitbucket.org':
Counting objects: 11, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (11/11), done.
Writing objects: 100% (11/11), 485.28 KiB | 0 bytes/s, done.
Total 11 (delta 4), reused 0 (delta 0)
To https://muratcancicek@bitbucket.org/muratcancicek/deep_rl_for_head_pose_est.git
   0dee6f4..2e58c6c  master -> master
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/LSTM_VGG16$
