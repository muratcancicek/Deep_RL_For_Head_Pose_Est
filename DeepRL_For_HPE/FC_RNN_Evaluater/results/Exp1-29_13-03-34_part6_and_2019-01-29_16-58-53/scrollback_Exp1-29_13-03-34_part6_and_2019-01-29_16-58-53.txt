mcicek@harsimran:~$ cd Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/FC_RNN_Evaluater/
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/FC_RNN_Evaluater$ python continueFC_RNN_Experiment.
py Exp2019-01-29_04-28-57 trainMore
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument
 of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(flo
at).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-29 13:03:31.395267: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that thi
s TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-29 13:03:31.493045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from S
ysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-29 13:03:31.493303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.80GiB
2019-01-29 13:03:31.493315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-29 13:03:31.648404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor w
ith strength 1 edge matrix:
2019-01-29 13:03:31.648431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-29 13:03:31.648436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-29 13:03:31.648574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:loc
alhost/replica:0/task:0/device:GPU:0 with 10452 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bu
s id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-29_04-28-57.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 3)                 138458947
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   560
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 138,459,540
Trainable params: 4,198,996
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_FC_RNN_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 60
eva_epoch = 6
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True # False #

angles = ['Pitch', 'Yaw', 'Roll']
use_vgg16 = True # False #
######### CONF_ends_Here ###########
Training model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
All frames and annotations from 20 datasets have been read by 2019-01-29 13:03:38.448025
1. set (Dataset 22) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:03:44.852855!
Epoch 1/1
665/665 [==============================] - 16s 24ms/step - loss: 0.0595
2. set (Dataset 24) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:04:05.871484!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0628
3. set (Dataset 15) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:04:23.659639!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0855
4. set (Dataset 19) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:04:43.394006!
Epoch 1/1
502/502 [==============================] - 11s 22ms/step - loss: 0.0774
5. set (Dataset 8) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:05:02.594252!
Epoch 1/1
772/772 [==============================] - 17s 23ms/step - loss: 0.0975
6. set (Dataset 23) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:05:25.564083!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1202
7. set (Dataset 21) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:05:44.809897!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1305
8. set (Dataset 16) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:06:08.199111!
Epoch 1/1
914/914 [==============================] - 22s 24ms/step - loss: 0.0825
9. set (Dataset 7) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:06:37.678842!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0976
10. set (Dataset 12) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:07:02.048633!
Epoch 1/1
732/732 [==============================] - 16s 22ms/step - loss: 0.0841
11. set (Dataset 10) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:07:25.567754!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0878
12. set (Dataset 1) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:07:48.101703!
Epoch 1/1
498/498 [==============================] - 11s 22ms/step - loss: 0.1109
13. set (Dataset 18) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:08:05.225362!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1119
14. set (Dataset 2) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:08:24.328521!
Epoch 1/1
511/511 [==============================] - 11s 21ms/step - loss: 0.0999
15. set (Dataset 4) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:08:42.763899!
Epoch 1/1
744/744 [==============================] - 16s 21ms/step - loss: 0.0989
16. set (Dataset 20) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:09:04.193437!
Epoch 1/1
556/556 [==============================] - 12s 22ms/step - loss: 0.0824
17. set (Dataset 17) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:09:20.185824!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0832
18. set (Dataset 6) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:09:34.942081!
Epoch 1/1
542/542 [==============================] - 12s 21ms/step - loss: 0.1125
19. set (Dataset 13) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:09:51.502953!
Epoch 1/1
485/485 [==============================] - 10s 22ms/step - loss: 0.0735
20. set (Dataset 11) being trained for epoch 1 in Experiment 1 by 2019-01-29 13:10:07.750015!
Epoch 1/1
572/572 [==============================] - 13s 22ms/step - loss: 0.0660
Epoch 1 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:10:24.994052
1. set (Dataset 6) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:10:30.208424!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1133
2. set (Dataset 11) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:10:47.826999!
Epoch 1/1
572/572 [==============================] - 13s 22ms/step - loss: 0.0620
3. set (Dataset 10) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:11:07.987300!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0892
4. set (Dataset 4) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:11:32.058099!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0965
5. set (Dataset 23) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:11:54.642339!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1211
6. set (Dataset 13) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:12:12.493104!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0687
7. set (Dataset 17) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:12:27.557036!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0831
8. set (Dataset 1) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:12:42.040196!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1108
9. set (Dataset 8) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:13:01.118623!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0905
10. set (Dataset 7) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:13:26.681343!
Epoch 1/1
745/745 [==============================] - 17s 22ms/step - loss: 0.0924
11. set (Dataset 21) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:13:49.578012!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1431
12. set (Dataset 22) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:14:10.798968!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0633
13. set (Dataset 2) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:14:31.400470!
Epoch 1/1
511/511 [==============================] - 11s 22ms/step - loss: 0.1033
14. set (Dataset 24) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:14:47.186268!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0692
15. set (Dataset 15) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:15:05.049298!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0889
16. set (Dataset 20) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:15:26.202594!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0720
17. set (Dataset 18) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:15:45.100621!
Epoch 1/1
614/614 [==============================] - 14s 22ms/step - loss: 0.1054
18. set (Dataset 19) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:16:03.853898!
Epoch 1/1
502/502 [==============================] - 12s 23ms/step - loss: 0.0803
19. set (Dataset 12) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:16:22.977819!
Epoch 1/1
732/732 [==============================] - 17s 24ms/step - loss: 0.0842
20. set (Dataset 16) being trained for epoch 2 in Experiment 1 by 2019-01-29 13:16:49.093400!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0851
Epoch 2 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:17:14.638548
1. set (Dataset 19) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:17:19.531023!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0753
2. set (Dataset 16) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:17:40.383841!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0820
3. set (Dataset 21) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:18:07.758573!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1375
4. set (Dataset 15) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:18:28.194282!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0863
5. set (Dataset 13) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:18:48.821585!
Epoch 1/1
485/485 [==============================] - 11s 22ms/step - loss: 0.0729
6. set (Dataset 12) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:19:06.800285!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0845
7. set (Dataset 18) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:19:29.643685!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1062
8. set (Dataset 22) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:19:50.277209!
Epoch 1/1
665/665 [==============================] - 16s 23ms/step - loss: 0.0653
9. set (Dataset 23) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:20:11.413924!
Epoch 1/1
569/569 [==============================] - 13s 22ms/step - loss: 0.1191
10. set (Dataset 8) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:20:31.855352!
Epoch 1/1
772/772 [==============================] - 19s 24ms/step - loss: 0.0980
11. set (Dataset 17) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:20:54.209122!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0827
12. set (Dataset 6) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:21:08.758366!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1111
13. set (Dataset 24) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:21:25.992458!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0639
14. set (Dataset 11) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:21:43.161112!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0626
15. set (Dataset 10) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:22:03.778446!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0909
16. set (Dataset 20) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:22:26.687278!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0797
17. set (Dataset 2) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:22:44.740449!
Epoch 1/1
511/511 [==============================] - 11s 21ms/step - loss: 0.1068
18. set (Dataset 4) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:23:03.172645!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1015
19. set (Dataset 7) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:23:28.009176!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0919
20. set (Dataset 1) being trained for epoch 3 in Experiment 1 by 2019-01-29 13:23:50.630202!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1130
Epoch 3 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:24:06.462517
1. set (Dataset 4) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:24:13.860857!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.0962
2. set (Dataset 1) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:24:36.700602!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1115
3. set (Dataset 17) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:24:51.910144!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0871
4. set (Dataset 10) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:25:08.709663!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0889
5. set (Dataset 12) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:25:32.794743!
Epoch 1/1
732/732 [==============================] - 16s 22ms/step - loss: 0.0821
6. set (Dataset 7) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:25:56.800517!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0918
7. set (Dataset 2) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:26:19.044766!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1020
8. set (Dataset 6) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:26:36.107069!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1180
9. set (Dataset 13) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:26:53.501490!
Epoch 1/1
485/485 [==============================] - 12s 24ms/step - loss: 0.0698
10. set (Dataset 23) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:27:10.672699!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1232
11. set (Dataset 18) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:27:29.822272!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1076
12. set (Dataset 19) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:27:48.872109!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0815
13. set (Dataset 11) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:28:06.109735!
Epoch 1/1
572/572 [==============================] - 12s 22ms/step - loss: 0.0659
14. set (Dataset 16) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:28:27.344921!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0833
15. set (Dataset 21) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:28:54.629337!
Epoch 1/1
634/634 [==============================] - 14s 23ms/step - loss: 0.1341
16. set (Dataset 20) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:29:14.460684!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0736
17. set (Dataset 24) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:29:32.049634!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0631
18. set (Dataset 15) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:29:49.480244!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0900
19. set (Dataset 8) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:30:12.527379!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0990
20. set (Dataset 22) being trained for epoch 4 in Experiment 1 by 2019-01-29 13:30:36.705344!
Epoch 1/1
665/665 [==============================] - 16s 24ms/step - loss: 0.0628
Epoch 4 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:30:56.781411
1. set (Dataset 15) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:31:03.145618!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0860
2. set (Dataset 22) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:31:24.455312!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0613
3. set (Dataset 18) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:31:45.355303!
Epoch 1/1
614/614 [==============================] - 13s 22ms/step - loss: 0.1051
4. set (Dataset 21) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:32:04.990165!
Epoch 1/1
634/634 [==============================] - 15s 24ms/step - loss: 0.1358
5. set (Dataset 7) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:32:27.884484!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0991
6. set (Dataset 8) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:32:52.098230!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0938
7. set (Dataset 24) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:33:14.107889!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0706
8. set (Dataset 19) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:33:30.449545!
Epoch 1/1
502/502 [==============================] - 11s 22ms/step - loss: 0.0787
9. set (Dataset 12) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:33:49.022809!
Epoch 1/1
732/732 [==============================] - 16s 22ms/step - loss: 0.0864
10. set (Dataset 13) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:34:10.444149!
Epoch 1/1
485/485 [==============================] - 10s 21ms/step - loss: 0.0686
11. set (Dataset 2) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:34:26.074797!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1109
12. set (Dataset 4) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:34:45.215786!
Epoch 1/1
744/744 [==============================] - 16s 21ms/step - loss: 0.1009
13. set (Dataset 16) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:35:10.073162!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0871
14. set (Dataset 1) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:35:35.859769!
Epoch 1/1
498/498 [==============================] - 11s 22ms/step - loss: 0.1107
15. set (Dataset 17) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:35:50.888145!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0848
16. set (Dataset 20) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:36:05.444724!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0748
17. set (Dataset 11) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:36:24.117874!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0639
18. set (Dataset 10) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:36:45.064058!
Epoch 1/1
726/726 [==============================] - 16s 23ms/step - loss: 0.0884
19. set (Dataset 23) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:37:07.109230!
Epoch 1/1
569/569 [==============================] - 13s 24ms/step - loss: 0.1246
20. set (Dataset 6) being trained for epoch 5 in Experiment 1 by 2019-01-29 13:37:25.787403!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1142
Epoch 5 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:37:42.644479
1. set (Dataset 10) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:37:49.884699!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0880
2. set (Dataset 6) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:38:12.636943!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1141
3. set (Dataset 2) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:38:30.396998!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1017
4. set (Dataset 17) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:38:46.180608!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0854
5. set (Dataset 8) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:39:03.452252!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0893
6. set (Dataset 23) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:39:26.834958!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1210
7. set (Dataset 11) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:39:45.844022!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0639
8. set (Dataset 4) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:40:06.255144!
Epoch 1/1
744/744 [==============================] - 16s 22ms/step - loss: 0.1000
9. set (Dataset 7) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:40:30.312598!
Epoch 1/1
745/745 [==============================] - 18s 24ms/step - loss: 0.0912
10. set (Dataset 12) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:40:55.637908!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0826
11. set (Dataset 24) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:41:17.346613!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0727
12. set (Dataset 15) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:41:35.079396!
Epoch 1/1
654/654 [==============================] - 15s 22ms/step - loss: 0.0883
13. set (Dataset 1) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:41:54.934154!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1116
14. set (Dataset 22) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:42:12.921543!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0633
15. set (Dataset 18) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:42:34.354257!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1087
16. set (Dataset 20) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:42:53.874594!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0718
17. set (Dataset 16) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:43:15.278688!
Epoch 1/1
914/914 [==============================] - 22s 24ms/step - loss: 0.0850
18. set (Dataset 21) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:43:43.395014!
Epoch 1/1
634/634 [==============================] - 15s 24ms/step - loss: 0.1313
19. set (Dataset 13) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:44:03.586672!
Epoch 1/1
485/485 [==============================] - 10s 21ms/step - loss: 0.0830
20. set (Dataset 19) being trained for epoch 6 in Experiment 1 by 2019-01-29 13:44:19.003138!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0810
Epoch 6 for Experiment 1 completed!
Exp2019-01-29_13-03-34_part1.h5 has been saved.
The subjects are trained: [(10, 'M04'), (6, 'F06'), (2, 'F02'), (17, 'M10'), (8, 'M02'), (23, 'M13'), (11, 'M05'), (4, '
F04'), (7, 'M01'), (12, 'M06'), (24, 'M14'), (15, 'F03'), (1, 'F01'), (22, 'M01'), (18, 'F05'), (20, 'M12'), (16, 'M09')
, (21, 'F02'), (13, 'M07'), (19, 'M11')]
Evaluating model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-29 13:44:33.510751
For the Subject 3 (F03):
730/730 [==============================] - 12s 16ms/step
        The absolute mean error on Pitch angle estimation: 9.50 Degree
        The absolute mean error on Yaw angle estimation: 24.62 Degree
        The absolute mean error on Roll angle estimation: 13.09 Degree
For the Subject 5 (F05):
946/946 [==============================] - 15s 16ms/step
        The absolute mean error on Pitch angle estimation: 6.91 Degree
        The absolute mean error on Yaw angle estimation: 20.69 Degree
        The absolute mean error on Roll angle estimation: 4.01 Degree
For the Subject 9 (M03):
882/882 [==============================] - 13s 15ms/step
        The absolute mean error on Pitch angle estimation: 32.43 Degree
        The absolute mean error on Yaw angle estimation: 17.47 Degree
        The absolute mean error on Roll angle estimation: 6.55 Degree
For the Subject 14 (M08):
797/797 [==============================] - 13s 16ms/step
        The absolute mean error on Pitch angle estimation: 13.60 Degree
        The absolute mean error on Yaw angle estimation: 31.58 Degree
        The absolute mean error on Roll angle estimation: 12.89 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 15.61 Degree
        The absolute mean error on Yaw angle estimations: 23.59 Degree
        The absolute mean error on Roll angle estimations: 9.13 Degree
Exp2019-01-29_13-03-34_part1 completed!
Training model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
All frames and annotations from 20 datasets have been read by 2019-01-29 13:46:05.069657
1. set (Dataset 21) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:46:11.099805!
Epoch 1/1
634/634 [==============================] - 14s 23ms/step - loss: 0.1313
2. set (Dataset 19) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:46:30.367057!
Epoch 1/1
502/502 [==============================] - 11s 21ms/step - loss: 0.0738
3. set (Dataset 24) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:46:45.938578!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0642
4. set (Dataset 18) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:47:02.630210!
Epoch 1/1
614/614 [==============================] - 14s 22ms/step - loss: 0.1040
5. set (Dataset 23) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:47:21.882812!
Epoch 1/1
569/569 [==============================] - 12s 21ms/step - loss: 0.1127
6. set (Dataset 13) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:47:39.051927!
Epoch 1/1
485/485 [==============================] - 10s 22ms/step - loss: 0.0749
7. set (Dataset 16) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:47:58.367980!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0845
8. set (Dataset 15) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:48:25.852157!
Epoch 1/1
654/654 [==============================] - 14s 22ms/step - loss: 0.0853
9. set (Dataset 8) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:48:48.158857!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0983
10. set (Dataset 7) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:49:13.575604!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0907
11. set (Dataset 11) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:49:36.679327!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0656
12. set (Dataset 10) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:49:58.001709!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0886
13. set (Dataset 22) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:50:21.958712!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0636
14. set (Dataset 6) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:50:42.465625!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1152
15. set (Dataset 2) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:50:59.912830!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1065
16. set (Dataset 20) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:51:16.967557!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0737
17. set (Dataset 1) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:51:35.035104!
Epoch 1/1
498/498 [==============================] - 12s 24ms/step - loss: 0.1256
18. set (Dataset 17) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:51:50.840721!
Epoch 1/1
395/395 [==============================] - 9s 22ms/step - loss: 0.0809
19. set (Dataset 12) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:52:07.096151!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0802
20. set (Dataset 4) being trained for epoch 1 in Experiment 2 by 2019-01-29 13:52:31.630950!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0990
Epoch 1 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:52:53.117175
1. set (Dataset 17) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:52:56.874002!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0793
2. set (Dataset 4) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:53:13.299071!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0953
3. set (Dataset 11) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:53:36.247828!
Epoch 1/1
572/572 [==============================] - 13s 22ms/step - loss: 0.0660
4. set (Dataset 2) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:53:54.261411!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1054
5. set (Dataset 13) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:54:11.177839!
Epoch 1/1
485/485 [==============================] - 11s 22ms/step - loss: 0.0689
6. set (Dataset 12) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:54:29.178435!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0771
7. set (Dataset 1) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:54:51.411501!
Epoch 1/1
498/498 [==============================] - 11s 22ms/step - loss: 0.1127
8. set (Dataset 10) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:55:09.514958!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0832
9. set (Dataset 23) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:55:32.129713!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1246
10. set (Dataset 8) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:55:53.177485!
Epoch 1/1
772/772 [==============================] - 17s 23ms/step - loss: 0.0915
11. set (Dataset 16) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:56:19.484016!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0890
12. set (Dataset 21) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:56:46.764015!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1372
13. set (Dataset 6) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:57:06.845867!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1130
14. set (Dataset 19) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:57:24.690196!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0765
15. set (Dataset 24) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:57:40.885667!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0660
16. set (Dataset 20) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:57:57.571390!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0727
17. set (Dataset 22) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:58:16.853406!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0610
18. set (Dataset 18) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:58:38.096427!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1038
19. set (Dataset 7) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:59:00.546407!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0994
20. set (Dataset 15) being trained for epoch 2 in Experiment 2 by 2019-01-29 13:59:23.426061!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0837
Epoch 2 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 13:59:42.774702
1. set (Dataset 18) being trained for epoch 3 in Experiment 2 by 2019-01-29 13:59:48.669309!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1059
2. set (Dataset 15) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:00:09.402788!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0817
3. set (Dataset 16) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:00:33.948204!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0814
4. set (Dataset 24) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:01:00.087279!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0644
5. set (Dataset 12) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:01:18.713732!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0873
6. set (Dataset 7) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:01:42.949657!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0929
7. set (Dataset 22) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:02:05.849653!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0631
8. set (Dataset 21) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:02:27.091861!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1360
9. set (Dataset 13) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:02:46.626612!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0785
10. set (Dataset 23) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:03:03.379732!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1181
11. set (Dataset 1) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:03:22.238172!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1150
12. set (Dataset 17) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:03:37.759835!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0820
13. set (Dataset 19) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:03:52.210132!
Epoch 1/1
502/502 [==============================] - 12s 23ms/step - loss: 0.0820
14. set (Dataset 4) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:04:11.347127!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1033
15. set (Dataset 11) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:04:33.955426!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0636
16. set (Dataset 20) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:04:53.060176!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0769
17. set (Dataset 6) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:05:11.229628!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1143
18. set (Dataset 2) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:05:28.491567!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1069
19. set (Dataset 8) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:05:48.018618!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0938
20. set (Dataset 10) being trained for epoch 3 in Experiment 2 by 2019-01-29 14:06:12.502122!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0897
Epoch 3 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:06:33.969702
1. set (Dataset 2) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:06:39.064809!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1017
2. set (Dataset 10) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:06:58.166081!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0852
3. set (Dataset 1) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:07:19.596921!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1114
4. set (Dataset 11) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:07:37.003496!
Epoch 1/1
572/572 [==============================] - 14s 25ms/step - loss: 0.0678
5. set (Dataset 7) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:07:58.904133!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0941
6. set (Dataset 8) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:08:24.024933!
Epoch 1/1
772/772 [==============================] - 17s 23ms/step - loss: 0.0876
7. set (Dataset 6) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:08:46.750587!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1210
8. set (Dataset 17) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:09:02.309271!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0869
9. set (Dataset 12) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:09:19.079495!
Epoch 1/1
732/732 [==============================] - 18s 25ms/step - loss: 0.0787
10. set (Dataset 13) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:09:41.928448!
Epoch 1/1
485/485 [==============================] - 11s 24ms/step - loss: 0.0692
11. set (Dataset 22) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:09:59.891860!
Epoch 1/1
665/665 [==============================] - 14s 21ms/step - loss: 0.0646
12. set (Dataset 18) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:10:20.197666!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1080
13. set (Dataset 4) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:10:42.048225!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.1017
14. set (Dataset 15) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:11:06.321303!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0865
15. set (Dataset 16) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:11:30.890127!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0846
16. set (Dataset 20) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:11:57.361851!
Epoch 1/1
556/556 [==============================] - 12s 22ms/step - loss: 0.0726
17. set (Dataset 19) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:12:14.659057!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0783
18. set (Dataset 24) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:12:31.332381!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0633
19. set (Dataset 23) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:12:48.194520!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1156
20. set (Dataset 21) being trained for epoch 4 in Experiment 2 by 2019-01-29 14:13:08.001254!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1319
Epoch 4 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:13:27.123767
1. set (Dataset 24) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:13:31.812110!
Epoch 1/1
492/492 [==============================] - 12s 24ms/step - loss: 0.0652
2. set (Dataset 21) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:13:49.584070!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1321
3. set (Dataset 22) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:14:10.745202!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0604
4. set (Dataset 16) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:14:34.607046!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0835
5. set (Dataset 8) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:15:03.667231!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.1017
6. set (Dataset 23) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:15:27.243598!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1142
7. set (Dataset 19) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:15:45.751094!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0757
8. set (Dataset 18) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:16:03.219669!
Epoch 1/1
614/614 [==============================] - 14s 22ms/step - loss: 0.1067
9. set (Dataset 7) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:16:24.632366!
Epoch 1/1
745/745 [==============================] - 18s 24ms/step - loss: 0.0962
10. set (Dataset 12) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:16:50.001823!
Epoch 1/1
732/732 [==============================] - 16s 21ms/step - loss: 0.0860
11. set (Dataset 6) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:17:11.016281!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1091
12. set (Dataset 2) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:17:29.078113!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1050
13. set (Dataset 15) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:17:47.373585!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0901
14. set (Dataset 10) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:18:09.825041!
Epoch 1/1
726/726 [==============================] - 18s 24ms/step - loss: 0.0900
15. set (Dataset 1) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:18:32.494301!
Epoch 1/1
498/498 [==============================] - 12s 24ms/step - loss: 0.1124
16. set (Dataset 20) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:18:49.969383!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0781
17. set (Dataset 4) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:19:10.349244!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.1030
18. set (Dataset 11) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:19:33.743768!
Epoch 1/1
572/572 [==============================] - 12s 22ms/step - loss: 0.0660
19. set (Dataset 13) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:19:51.120238!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0690
20. set (Dataset 17) being trained for epoch 5 in Experiment 2 by 2019-01-29 14:20:06.074403!
Epoch 1/1
395/395 [==============================] - 8s 21ms/step - loss: 0.0838
Epoch 5 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:20:19.043011
1. set (Dataset 11) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:20:24.767384!
Epoch 1/1
572/572 [==============================] - 13s 22ms/step - loss: 0.0629
2. set (Dataset 17) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:20:41.235015!
Epoch 1/1
395/395 [==============================] - 9s 22ms/step - loss: 0.0808
3. set (Dataset 6) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:20:55.404735!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1120
4. set (Dataset 1) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:21:12.756106!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1190
5. set (Dataset 23) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:21:29.832449!
Epoch 1/1
569/569 [==============================] - 13s 24ms/step - loss: 0.1180
6. set (Dataset 13) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:21:48.163084!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0655
7. set (Dataset 4) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:22:06.627699!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0977
8. set (Dataset 2) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:22:28.923018!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1053
9. set (Dataset 8) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:22:48.914618!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0949
10. set (Dataset 7) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:23:13.719788!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0916
11. set (Dataset 19) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:23:35.591251!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0829
12. set (Dataset 24) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:23:52.372639!
Epoch 1/1
492/492 [==============================] - 11s 21ms/step - loss: 0.0710
13. set (Dataset 10) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:24:10.287387!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0921
14. set (Dataset 21) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:24:33.468225!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1412
15. set (Dataset 22) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:24:53.606217!
Epoch 1/1
665/665 [==============================] - 16s 24ms/step - loss: 0.0628
16. set (Dataset 20) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:25:15.148543!
Epoch 1/1
556/556 [==============================] - 12s 22ms/step - loss: 0.0770
17. set (Dataset 15) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:25:33.892142!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0836
18. set (Dataset 16) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:25:58.389754!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0819
19. set (Dataset 12) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:26:27.088258!
Epoch 1/1
732/732 [==============================] - 18s 24ms/step - loss: 0.0849
20. set (Dataset 18) being trained for epoch 6 in Experiment 2 by 2019-01-29 14:26:50.725662!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1077
Epoch 6 for Experiment 2 completed!
Exp2019-01-29_13-03-34_part2.h5 has been saved.
The subjects are trained: [(11, 'M05'), (17, 'M10'), (6, 'F06'), (1, 'F01'), (23, 'M13'), (13, 'M07'), (4, 'F04'), (2, '
F02'), (8, 'M02'), (7, 'M01'), (19, 'M11'), (24, 'M14'), (10, 'M04'), (21, 'F02'), (22, 'M01'), (20, 'M12'), (15, 'F03')
, (16, 'M09'), (12, 'M06'), (18, 'F05')]
Evaluating model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-29 14:27:08.056824
For the Subject 3 (F03):
730/730 [==============================] - 12s 16ms/step
        The absolute mean error on Pitch angle estimation: 9.61 Degree
        The absolute mean error on Yaw angle estimation: 23.02 Degree
        The absolute mean error on Roll angle estimation: 9.50 Degree
For the Subject 5 (F05):
946/946 [==============================] - 15s 16ms/step
        The absolute mean error on Pitch angle estimation: 7.23 Degree
        The absolute mean error on Yaw angle estimation: 22.75 Degree
        The absolute mean error on Roll angle estimation: 4.24 Degree
For the Subject 9 (M03):
882/882 [==============================] - 14s 16ms/step
        The absolute mean error on Pitch angle estimation: 33.17 Degree
        The absolute mean error on Yaw angle estimation: 22.98 Degree
        The absolute mean error on Roll angle estimation: 6.90 Degree
For the Subject 14 (M08):
797/797 [==============================] - 13s 17ms/step
        The absolute mean error on Pitch angle estimation: 14.01 Degree
        The absolute mean error on Yaw angle estimation: 30.25 Degree
        The absolute mean error on Roll angle estimation: 13.16 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 16.01 Degree
        The absolute mean error on Yaw angle estimations: 24.75 Degree
        The absolute mean error on Roll angle estimations: 8.45 Degree
Exp2019-01-29_13-03-34_part2 completed!
Training model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
All frames and annotations from 20 datasets have been read by 2019-01-29 14:28:39.933135
1. set (Dataset 16) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:28:48.700542!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0834
2. set (Dataset 18) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:29:15.986754!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1011
3. set (Dataset 19) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:29:34.922476!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0783
4. set (Dataset 22) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:29:52.772814!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0620
5. set (Dataset 13) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:30:13.110355!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0743
6. set (Dataset 12) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:30:31.707032!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0849
7. set (Dataset 15) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:30:54.841872!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0841
8. set (Dataset 24) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:31:15.379593!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0683
9. set (Dataset 23) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:31:32.246858!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1174
10. set (Dataset 8) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:31:53.226048!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0947
11. set (Dataset 4) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:32:18.319202!
Epoch 1/1
744/744 [==============================] - 16s 22ms/step - loss: 0.1015
12. set (Dataset 11) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:32:40.517740!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0646
13. set (Dataset 21) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:33:00.402205!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1374
14. set (Dataset 17) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:33:18.367520!
Epoch 1/1
395/395 [==============================] - 9s 22ms/step - loss: 0.0854
15. set (Dataset 6) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:33:32.302719!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1124
16. set (Dataset 20) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:33:49.461120!
Epoch 1/1
556/556 [==============================] - 12s 21ms/step - loss: 0.0739
17. set (Dataset 10) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:34:08.758026!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0932
18. set (Dataset 1) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:34:31.394630!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1197
19. set (Dataset 7) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:34:50.566424!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0894
20. set (Dataset 2) being trained for epoch 1 in Experiment 3 by 2019-01-29 14:35:13.082862!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1060
Epoch 1 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:35:29.820744
1. set (Dataset 1) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:35:34.879536!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1152
2. set (Dataset 2) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:35:51.343434!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1027
3. set (Dataset 4) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:36:10.759214!
Epoch 1/1
744/744 [==============================] - 17s 22ms/step - loss: 0.1005
4. set (Dataset 6) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:36:32.673357!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1159
5. set (Dataset 12) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:36:52.306329!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0800
6. set (Dataset 7) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:37:16.590929!
Epoch 1/1
745/745 [==============================] - 18s 24ms/step - loss: 0.0925
7. set (Dataset 10) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:37:41.797396!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0870
8. set (Dataset 11) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:38:04.465386!
Epoch 1/1
572/572 [==============================] - 13s 24ms/step - loss: 0.0645
9. set (Dataset 13) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:38:22.861479!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0716
10. set (Dataset 23) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:38:39.601507!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1228
11. set (Dataset 15) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:38:59.080127!
Epoch 1/1
654/654 [==============================] - 14s 22ms/step - loss: 0.0879
12. set (Dataset 16) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:39:22.406261!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0838
13. set (Dataset 17) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:39:47.418411!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0816
14. set (Dataset 18) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:40:02.639104!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1035
15. set (Dataset 19) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:40:22.392613!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0826
16. set (Dataset 20) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:40:39.824776!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0725
17. set (Dataset 21) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:40:58.959113!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1291
18. set (Dataset 22) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:41:20.227506!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0623
19. set (Dataset 8) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:41:42.810977!
Epoch 1/1
772/772 [==============================] - 18s 24ms/step - loss: 0.0970
20. set (Dataset 24) being trained for epoch 2 in Experiment 3 by 2019-01-29 14:42:05.801728!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0667
Epoch 2 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:42:21.491946
1. set (Dataset 22) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:42:27.908502!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0601
2. set (Dataset 24) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:42:47.866756!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0643
3. set (Dataset 15) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:43:05.338234!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0844
4. set (Dataset 19) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:43:25.514808!
Epoch 1/1
502/502 [==============================] - 11s 22ms/step - loss: 0.0749
5. set (Dataset 7) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:43:44.479669!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0972
6. set (Dataset 8) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:44:09.207143!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0924
7. set (Dataset 21) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:44:33.269206!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1376
8. set (Dataset 16) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:44:55.963590!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0830
9. set (Dataset 12) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:45:24.143805!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0829
10. set (Dataset 13) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:45:45.732143!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0709
11. set (Dataset 10) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:46:04.308088!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0916
12. set (Dataset 1) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:46:26.285578!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1135
13. set (Dataset 18) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:46:43.521574!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1103
14. set (Dataset 2) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:47:03.062805!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1038
15. set (Dataset 4) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:47:22.582949!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1007
16. set (Dataset 20) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:47:45.207402!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0810
17. set (Dataset 17) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:48:02.094800!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0842
18. set (Dataset 6) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:48:16.520669!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1129
19. set (Dataset 23) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:48:34.654345!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1164
20. set (Dataset 11) being trained for epoch 3 in Experiment 3 by 2019-01-29 14:48:53.815361!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0638
Epoch 3 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:49:11.995673
1. set (Dataset 6) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:49:17.251319!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1062
2. set (Dataset 11) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:49:35.812507!
Epoch 1/1
572/572 [==============================] - 12s 22ms/step - loss: 0.0626
3. set (Dataset 10) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:49:55.624687!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0885
4. set (Dataset 4) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:50:20.057333!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0995
5. set (Dataset 8) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:50:44.765521!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0911
6. set (Dataset 23) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:51:07.492438!
Epoch 1/1
569/569 [==============================] - 13s 22ms/step - loss: 0.1244
7. set (Dataset 17) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:51:24.020947!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0841
8. set (Dataset 1) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:51:38.539743!
Epoch 1/1
498/498 [==============================] - 11s 22ms/step - loss: 0.1133
9. set (Dataset 7) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:51:57.395272!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0925
10. set (Dataset 12) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:52:22.066166!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0771
11. set (Dataset 21) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:52:44.861721!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1379
12. set (Dataset 22) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:53:06.114052!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0627
13. set (Dataset 2) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:53:26.689457!
Epoch 1/1
511/511 [==============================] - 11s 21ms/step - loss: 0.1047
14. set (Dataset 24) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:53:42.484714!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0689
15. set (Dataset 15) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:53:59.915991!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0866
16. set (Dataset 20) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:54:20.169749!
Epoch 1/1
556/556 [==============================] - 13s 24ms/step - loss: 0.0743
17. set (Dataset 18) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:54:39.265044!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1055
18. set (Dataset 19) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:54:58.385464!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0792
19. set (Dataset 13) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:55:15.318907!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0743
20. set (Dataset 16) being trained for epoch 4 in Experiment 3 by 2019-01-29 14:55:35.286280!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0859
Epoch 4 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 14:56:00.368729
1. set (Dataset 19) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:56:05.268002!
Epoch 1/1
502/502 [==============================] - 12s 23ms/step - loss: 0.0757
2. set (Dataset 16) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:56:25.898919!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0802
3. set (Dataset 21) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:56:53.379795!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1289
4. set (Dataset 15) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:57:14.570920!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0898
5. set (Dataset 23) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:57:35.491377!
Epoch 1/1
569/569 [==============================] - 13s 24ms/step - loss: 0.1181
6. set (Dataset 13) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:57:53.869650!
Epoch 1/1
485/485 [==============================] - 10s 21ms/step - loss: 0.0715
7. set (Dataset 18) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:58:10.303285!
Epoch 1/1
614/614 [==============================] - 14s 22ms/step - loss: 0.1029
8. set (Dataset 22) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:58:30.431589!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0608
9. set (Dataset 8) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:58:53.416627!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0943
10. set (Dataset 7) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:59:17.979841!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0954
11. set (Dataset 17) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:59:38.234282!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0850
12. set (Dataset 6) being trained for epoch 5 in Experiment 3 by 2019-01-29 14:59:52.589172!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1100
13. set (Dataset 24) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:00:10.221270!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0650
14. set (Dataset 11) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:00:26.842748!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0642
15. set (Dataset 10) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:00:47.469136!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0858
16. set (Dataset 20) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:01:10.031689!
Epoch 1/1
556/556 [==============================] - 13s 24ms/step - loss: 0.0767
17. set (Dataset 2) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:01:28.395024!
Epoch 1/1
511/511 [==============================] - 11s 22ms/step - loss: 0.1098
18. set (Dataset 4) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:01:47.064222!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1002
19. set (Dataset 12) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:02:11.367735!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0804
20. set (Dataset 1) being trained for epoch 5 in Experiment 3 by 2019-01-29 15:02:33.407123!
Epoch 1/1
498/498 [==============================] - 11s 22ms/step - loss: 0.1152
Epoch 5 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 15:02:49.045341
1. set (Dataset 4) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:02:56.468528!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0989
2. set (Dataset 1) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:03:18.783655!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1095
3. set (Dataset 17) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:03:34.132455!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0852
4. set (Dataset 10) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:03:50.580432!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0856
5. set (Dataset 13) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:04:12.438574!
Epoch 1/1
485/485 [==============================] - 12s 24ms/step - loss: 0.0706
6. set (Dataset 12) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:04:31.520621!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0809
7. set (Dataset 2) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:04:53.837108!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1050
8. set (Dataset 6) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:05:11.479218!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1164
9. set (Dataset 23) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:05:29.588265!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1210
10. set (Dataset 8) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:05:50.488664!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0929
11. set (Dataset 18) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:06:14.387530!
Epoch 1/1
614/614 [==============================] - 14s 22ms/step - loss: 0.1100
12. set (Dataset 19) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:06:33.009714!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0820
13. set (Dataset 11) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:06:50.783608!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0654
14. set (Dataset 16) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:07:12.861260!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0833
15. set (Dataset 21) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:07:39.916201!
Epoch 1/1
634/634 [==============================] - 15s 24ms/step - loss: 0.1373
16. set (Dataset 20) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:08:00.390410!
Epoch 1/1
556/556 [==============================] - 12s 22ms/step - loss: 0.0751
17. set (Dataset 24) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:08:17.230610!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0654
18. set (Dataset 15) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:08:34.734071!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0831
19. set (Dataset 7) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:08:57.559869!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0991
20. set (Dataset 22) being trained for epoch 6 in Experiment 3 by 2019-01-29 15:09:20.486647!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0616
Epoch 6 for Experiment 3 completed!
Exp2019-01-29_13-03-34_part3.h5 has been saved.
The subjects are trained: [(4, 'F04'), (1, 'F01'), (17, 'M10'), (10, 'M04'), (13, 'M07'), (12, 'M06'), (2, 'F02'), (6, '
F06'), (23, 'M13'), (8, 'M02'), (18, 'F05'), (19, 'M11'), (11, 'M05'), (16, 'M09'), (21, 'F02'), (20, 'M12'), (24, 'M14'
), (15, 'F03'), (7, 'M01'), (22, 'M01')]
Evaluating model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-29 15:09:37.977354
For the Subject 3 (F03):
730/730 [==============================] - 12s 16ms/step
        The absolute mean error on Pitch angle estimation: 8.56 Degree
        The absolute mean error on Yaw angle estimation: 26.07 Degree
        The absolute mean error on Roll angle estimation: 10.74 Degree
For the Subject 5 (F05):
946/946 [==============================] - 15s 16ms/step
        The absolute mean error on Pitch angle estimation: 6.07 Degree
        The absolute mean error on Yaw angle estimation: 21.00 Degree
        The absolute mean error on Roll angle estimation: 3.80 Degree
For the Subject 9 (M03):
882/882 [==============================] - 14s 16ms/step
        The absolute mean error on Pitch angle estimation: 35.87 Degree
        The absolute mean error on Yaw angle estimation: 25.29 Degree
        The absolute mean error on Roll angle estimation: 7.92 Degree
For the Subject 14 (M08):
797/797 [==============================] - 13s 17ms/step
        The absolute mean error on Pitch angle estimation: 16.12 Degree
        The absolute mean error on Yaw angle estimation: 29.66 Degree
        The absolute mean error on Roll angle estimation: 13.25 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 16.66 Degree
        The absolute mean error on Yaw angle estimations: 25.50 Degree
        The absolute mean error on Roll angle estimations: 8.93 Degree
Exp2019-01-29_13-03-34_part3 completed!
Training model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
All frames and annotations from 20 datasets have been read by 2019-01-29 15:11:10.357797
1. set (Dataset 15) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:11:16.721339!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0846
2. set (Dataset 22) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:11:38.941484!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0603
3. set (Dataset 18) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:11:59.526276!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1037
4. set (Dataset 21) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:12:19.752021!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1277
5. set (Dataset 12) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:12:41.815225!
Epoch 1/1
732/732 [==============================] - 18s 24ms/step - loss: 0.0859
6. set (Dataset 7) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:13:07.115533!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0925
7. set (Dataset 24) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:13:28.735697!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0660
8. set (Dataset 19) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:13:44.979077!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0783
9. set (Dataset 13) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:14:01.411894!
Epoch 1/1
485/485 [==============================] - 11s 24ms/step - loss: 0.0735
10. set (Dataset 23) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:14:18.392159!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1193
11. set (Dataset 2) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:14:37.259634!
Epoch 1/1
511/511 [==============================] - 11s 22ms/step - loss: 0.1068
12. set (Dataset 4) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:14:55.778495!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1037
13. set (Dataset 16) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:15:21.868509!
Epoch 1/1
914/914 [==============================] - 22s 24ms/step - loss: 0.0834
14. set (Dataset 1) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:15:48.790569!
Epoch 1/1
498/498 [==============================] - 11s 22ms/step - loss: 0.1199
15. set (Dataset 17) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:16:03.511665!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0815
16. set (Dataset 20) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:16:18.063005!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0791
17. set (Dataset 11) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:16:36.689091!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0643
18. set (Dataset 10) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:16:57.451044!
Epoch 1/1
726/726 [==============================] - 16s 23ms/step - loss: 0.0878
19. set (Dataset 8) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:17:21.758936!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0915
20. set (Dataset 6) being trained for epoch 1 in Experiment 4 by 2019-01-29 15:17:45.154962!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1141
Epoch 1 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 15:18:02.604404
1. set (Dataset 10) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:18:09.840779!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0865
2. set (Dataset 6) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:18:31.655287!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1111
3. set (Dataset 2) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:18:49.354603!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1067
4. set (Dataset 17) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:19:05.023305!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0829
5. set (Dataset 7) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:19:21.936942!
Epoch 1/1
745/745 [==============================] - 17s 22ms/step - loss: 0.0899
6. set (Dataset 8) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:19:46.421057!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0907
7. set (Dataset 11) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:20:10.140905!
Epoch 1/1
572/572 [==============================] - 13s 22ms/step - loss: 0.0613
8. set (Dataset 4) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:20:30.448011!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.0999
9. set (Dataset 12) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:20:55.438173!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0804
10. set (Dataset 13) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:21:17.084635!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0680
11. set (Dataset 24) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:21:32.851226!
Epoch 1/1
492/492 [==============================] - 12s 24ms/step - loss: 0.0749
12. set (Dataset 15) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:21:51.164241!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0845
13. set (Dataset 1) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:22:11.498845!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1124
14. set (Dataset 22) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:22:29.289330!
Epoch 1/1
665/665 [==============================] - 16s 23ms/step - loss: 0.0659
15. set (Dataset 18) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:22:50.810600!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1092
16. set (Dataset 20) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:23:10.855202!
Epoch 1/1
556/556 [==============================] - 13s 22ms/step - loss: 0.0745
17. set (Dataset 16) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:23:32.246590!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0827
18. set (Dataset 21) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:23:59.204519!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1296
19. set (Dataset 23) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:24:19.045387!
Epoch 1/1
569/569 [==============================] - 13s 22ms/step - loss: 0.1158
20. set (Dataset 19) being trained for epoch 2 in Experiment 4 by 2019-01-29 15:24:36.769616!
Epoch 1/1
502/502 [==============================] - 11s 21ms/step - loss: 0.0786
Epoch 2 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 15:24:52.033415
1. set (Dataset 21) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:24:58.069457!
Epoch 1/1
634/634 [==============================] - 15s 24ms/step - loss: 0.1284
2. set (Dataset 19) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:25:18.021286!
Epoch 1/1
502/502 [==============================] - 11s 22ms/step - loss: 0.0741
3. set (Dataset 24) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:25:33.679001!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0597
4. set (Dataset 18) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:25:50.827571!
Epoch 1/1
614/614 [==============================] - 14s 22ms/step - loss: 0.1026
5. set (Dataset 8) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:26:12.411092!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.1000
6. set (Dataset 23) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:26:35.864660!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1198
7. set (Dataset 16) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:26:57.752185!
Epoch 1/1
914/914 [==============================] - 22s 24ms/step - loss: 0.0823
8. set (Dataset 15) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:27:25.896760!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0833
9. set (Dataset 7) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:27:48.602966!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0965
10. set (Dataset 12) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:28:12.383654!
Epoch 1/1
732/732 [==============================] - 18s 24ms/step - loss: 0.0849
11. set (Dataset 11) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:28:35.699371!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0658
12. set (Dataset 10) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:28:56.656740!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0875
13. set (Dataset 22) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:29:18.807472!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0643
14. set (Dataset 6) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:29:39.496629!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1146
15. set (Dataset 2) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:29:57.257606!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1047
16. set (Dataset 20) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:30:15.016455!
Epoch 1/1
556/556 [==============================] - 12s 22ms/step - loss: 0.0771
17. set (Dataset 1) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:30:32.562519!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1218
18. set (Dataset 17) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:30:48.118461!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0803
19. set (Dataset 13) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:31:02.036661!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0679
20. set (Dataset 4) being trained for epoch 3 in Experiment 4 by 2019-01-29 15:31:20.854142!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.1037
Epoch 3 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 15:31:43.278700
1. set (Dataset 17) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:31:47.032599!
Epoch 1/1
395/395 [==============================] - 9s 22ms/step - loss: 0.0851
2. set (Dataset 4) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:32:03.178223!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.0997
3. set (Dataset 11) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:32:26.219877!
Epoch 1/1
572/572 [==============================] - 13s 22ms/step - loss: 0.0674
4. set (Dataset 2) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:32:44.267953!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1082
5. set (Dataset 23) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:33:02.114513!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1219
6. set (Dataset 13) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:33:19.944811!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0655
7. set (Dataset 1) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:33:36.366684!
Epoch 1/1
498/498 [==============================] - 12s 24ms/step - loss: 0.1182
8. set (Dataset 10) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:33:55.730994!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0843
9. set (Dataset 8) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:34:19.640492!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0902
10. set (Dataset 7) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:34:45.250502!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0909
11. set (Dataset 16) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:35:11.580406!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0876
12. set (Dataset 21) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:35:38.732373!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1389
13. set (Dataset 6) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:35:58.183296!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1101
14. set (Dataset 19) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:36:16.142198!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0771
15. set (Dataset 24) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:36:32.852779!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0626
16. set (Dataset 20) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:36:49.369749!
Epoch 1/1
556/556 [==============================] - 12s 21ms/step - loss: 0.0699
17. set (Dataset 22) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:37:07.830728!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0589
18. set (Dataset 18) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:37:29.223627!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1038
19. set (Dataset 12) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:37:50.640421!
Epoch 1/1
732/732 [==============================] - 17s 24ms/step - loss: 0.0846
20. set (Dataset 15) being trained for epoch 4 in Experiment 4 by 2019-01-29 15:38:14.578400!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0833
Epoch 4 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 15:38:34.194620
1. set (Dataset 18) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:38:40.095896!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1036
2. set (Dataset 15) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:39:01.222486!
Epoch 1/1
654/654 [==============================] - 15s 22ms/step - loss: 0.0847
3. set (Dataset 16) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:39:24.757883!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0814
4. set (Dataset 24) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:39:50.973387!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0617
5. set (Dataset 13) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:40:07.143497!
Epoch 1/1
485/485 [==============================] - 11s 22ms/step - loss: 0.0741
6. set (Dataset 12) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:40:25.466539!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0831
7. set (Dataset 22) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:40:48.745708!
Epoch 1/1
665/665 [==============================] - 16s 23ms/step - loss: 0.0605
8. set (Dataset 21) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:41:10.437909!
Epoch 1/1
634/634 [==============================] - 15s 24ms/step - loss: 0.1322
9. set (Dataset 23) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:41:31.147643!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1158
10. set (Dataset 8) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:41:52.097923!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0971
11. set (Dataset 1) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:42:15.075317!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1206
12. set (Dataset 17) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:42:30.457817!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0843
13. set (Dataset 19) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:42:44.926663!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0798
14. set (Dataset 4) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:43:03.779395!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.1046
15. set (Dataset 11) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:43:27.469093!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0626
16. set (Dataset 20) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:43:45.982773!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0769
17. set (Dataset 6) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:44:04.206329!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1113
18. set (Dataset 2) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:44:21.952715!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1115
19. set (Dataset 7) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:44:41.225551!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0881
20. set (Dataset 10) being trained for epoch 5 in Experiment 4 by 2019-01-29 15:45:06.068962!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0872
Epoch 5 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 15:45:26.589308
1. set (Dataset 2) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:45:31.692427!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1013
2. set (Dataset 10) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:45:51.244694!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0844
3. set (Dataset 1) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:46:13.099249!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1080
4. set (Dataset 11) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:46:30.224440!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0656
5. set (Dataset 12) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:46:50.620916!
Epoch 1/1
732/732 [==============================] - 16s 22ms/step - loss: 0.0819
6. set (Dataset 7) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:47:14.625992!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0956
7. set (Dataset 6) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:47:37.231189!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1135
8. set (Dataset 17) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:47:53.015602!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0849
9. set (Dataset 13) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:48:07.319498!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0649
10. set (Dataset 23) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:48:24.166793!
Epoch 1/1
569/569 [==============================] - 13s 22ms/step - loss: 0.1163
11. set (Dataset 22) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:48:43.469116!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0603
12. set (Dataset 18) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:49:04.571802!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1009
13. set (Dataset 4) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:49:26.292418!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1046
14. set (Dataset 15) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:49:49.835844!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0863
15. set (Dataset 16) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:50:14.422616!
Epoch 1/1
914/914 [==============================] - 22s 24ms/step - loss: 0.0849
16. set (Dataset 20) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:50:41.965258!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0737
17. set (Dataset 19) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:50:59.922916!
Epoch 1/1
502/502 [==============================] - 12s 23ms/step - loss: 0.0769
18. set (Dataset 24) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:51:16.263570!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0632
19. set (Dataset 8) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:51:34.975466!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0966
20. set (Dataset 21) being trained for epoch 6 in Experiment 4 by 2019-01-29 15:51:58.365321!
Epoch 1/1
634/634 [==============================] - 14s 23ms/step - loss: 0.1339
Epoch 6 for Experiment 4 completed!
Exp2019-01-29_13-03-34_part4.h5 has been saved.
The subjects are trained: [(2, 'F02'), (10, 'M04'), (1, 'F01'), (11, 'M05'), (12, 'M06'), (7, 'M01'), (6, 'F06'), (17, '
M10'), (13, 'M07'), (23, 'M13'), (22, 'M01'), (18, 'F05'), (4, 'F04'), (15, 'F03'), (16, 'M09'), (20, 'M12'), (19, 'M11'
), (24, 'M14'), (8, 'M02'), (21, 'F02')]
Evaluating model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-29 15:52:14.962648
For the Subject 3 (F03):
730/730 [==============================] - 11s 16ms/step
        The absolute mean error on Pitch angle estimation: 7.82 Degree
        The absolute mean error on Yaw angle estimation: 23.81 Degree
        The absolute mean error on Roll angle estimation: 15.53 Degree
For the Subject 5 (F05):
946/946 [==============================] - 15s 16ms/step
        The absolute mean error on Pitch angle estimation: 8.36 Degree
        The absolute mean error on Yaw angle estimation: 20.17 Degree
        The absolute mean error on Roll angle estimation: 5.86 Degree
For the Subject 9 (M03):
882/882 [==============================] - 14s 16ms/step
        The absolute mean error on Pitch angle estimation: 31.25 Degree
        The absolute mean error on Yaw angle estimation: 23.78 Degree
        The absolute mean error on Roll angle estimation: 9.93 Degree
For the Subject 14 (M08):
797/797 [==============================] - 13s 16ms/step
        The absolute mean error on Pitch angle estimation: 13.65 Degree
        The absolute mean error on Yaw angle estimation: 30.20 Degree
        The absolute mean error on Roll angle estimation: 13.80 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 15.27 Degree
        The absolute mean error on Yaw angle estimations: 24.49 Degree
        The absolute mean error on Roll angle estimations: 11.28 Degree
Exp2019-01-29_13-03-34_part4 completed!
Training model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
All frames and annotations from 20 datasets have been read by 2019-01-29 15:53:46.750866
1. set (Dataset 24) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:53:51.450469!
Epoch 1/1
492/492 [==============================] - 12s 23ms/step - loss: 0.0652
2. set (Dataset 21) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:54:09.114787!
Epoch 1/1
634/634 [==============================] - 15s 24ms/step - loss: 0.1279
3. set (Dataset 22) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:54:30.903141!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0625
4. set (Dataset 16) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:54:55.270390!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0824
5. set (Dataset 7) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:55:24.234122!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0978
6. set (Dataset 8) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:55:49.321072!
Epoch 1/1
772/772 [==============================] - 17s 23ms/step - loss: 0.0925
7. set (Dataset 19) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:56:11.749420!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0813
8. set (Dataset 18) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:56:29.640595!
Epoch 1/1
614/614 [==============================] - 14s 24ms/step - loss: 0.1032
9. set (Dataset 12) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:56:51.491743!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0814
10. set (Dataset 13) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:57:13.029162!
Epoch 1/1
485/485 [==============================] - 11s 24ms/step - loss: 0.0695
11. set (Dataset 6) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:57:29.819095!
Epoch 1/1
542/542 [==============================] - 13s 23ms/step - loss: 0.1132
12. set (Dataset 2) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:57:47.646184!
Epoch 1/1
511/511 [==============================] - 11s 22ms/step - loss: 0.1029
13. set (Dataset 15) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:58:05.557781!
Epoch 1/1
654/654 [==============================] - 15s 22ms/step - loss: 0.0863
14. set (Dataset 10) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:58:27.573304!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0877
15. set (Dataset 1) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:58:50.211017!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1111
16. set (Dataset 20) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:59:07.390032!
Epoch 1/1
556/556 [==============================] - 13s 24ms/step - loss: 0.0795
17. set (Dataset 4) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:59:28.168223!
Epoch 1/1
744/744 [==============================] - 15s 20ms/step - loss: 0.1006
18. set (Dataset 11) being trained for epoch 1 in Experiment 5 by 2019-01-29 15:59:48.831870!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0669
19. set (Dataset 23) being trained for epoch 1 in Experiment 5 by 2019-01-29 16:00:07.805980!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1211
20. set (Dataset 17) being trained for epoch 1 in Experiment 5 by 2019-01-29 16:00:24.579323!
Epoch 1/1
395/395 [==============================] - 8s 21ms/step - loss: 0.0803
Epoch 1 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:00:37.490181
1. set (Dataset 11) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:00:43.207727!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0610
2. set (Dataset 17) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:01:00.223891!
Epoch 1/1
395/395 [==============================] - 9s 22ms/step - loss: 0.0834
3. set (Dataset 6) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:01:14.233523!
Epoch 1/1
542/542 [==============================] - 12s 21ms/step - loss: 0.1100
4. set (Dataset 1) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:01:31.033185!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1151
5. set (Dataset 8) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:01:50.525308!
Epoch 1/1
772/772 [==============================] - 17s 22ms/step - loss: 0.0955
6. set (Dataset 23) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:02:13.330376!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1178
7. set (Dataset 4) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:02:34.363457!
Epoch 1/1
744/744 [==============================] - 17s 22ms/step - loss: 0.1062
8. set (Dataset 2) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:02:56.157116!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1058
9. set (Dataset 7) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:03:16.004545!
Epoch 1/1
745/745 [==============================] - 18s 24ms/step - loss: 0.0928
10. set (Dataset 12) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:03:41.186919!
Epoch 1/1
732/732 [==============================] - 17s 24ms/step - loss: 0.0789
11. set (Dataset 19) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:04:03.399733!
Epoch 1/1
502/502 [==============================] - 12s 24ms/step - loss: 0.0862
12. set (Dataset 24) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:04:20.190826!
Epoch 1/1
492/492 [==============================] - 11s 21ms/step - loss: 0.0674
13. set (Dataset 10) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:04:38.108838!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0870
14. set (Dataset 21) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:05:01.077293!
Epoch 1/1
634/634 [==============================] - 14s 22ms/step - loss: 0.1362
15. set (Dataset 22) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:05:21.563997!
Epoch 1/1
665/665 [==============================] - 16s 24ms/step - loss: 0.0633
16. set (Dataset 20) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:05:42.733027!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0757
17. set (Dataset 15) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:06:01.942828!
Epoch 1/1
654/654 [==============================] - 15s 24ms/step - loss: 0.0847
18. set (Dataset 16) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:06:26.247071!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0821
19. set (Dataset 13) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:06:52.441081!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0739
20. set (Dataset 18) being trained for epoch 2 in Experiment 5 by 2019-01-29 16:07:09.481207!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1078
Epoch 2 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:07:28.049328
1. set (Dataset 16) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:07:36.815924!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0814
2. set (Dataset 18) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:08:03.997434!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.0994
3. set (Dataset 19) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:08:23.738826!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0816
4. set (Dataset 22) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:08:41.704352!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0639
5. set (Dataset 23) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:09:02.214931!
Epoch 1/1
569/569 [==============================] - 13s 24ms/step - loss: 0.1122
6. set (Dataset 13) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:09:20.576509!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0721
7. set (Dataset 15) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:09:38.190275!
Epoch 1/1
654/654 [==============================] - 16s 24ms/step - loss: 0.0883
8. set (Dataset 24) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:09:58.506127!
Epoch 1/1
492/492 [==============================] - 11s 21ms/step - loss: 0.0657
9. set (Dataset 8) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:10:16.952138!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0950
10. set (Dataset 7) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:10:42.234052!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0948
11. set (Dataset 4) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:11:07.183400!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1022
12. set (Dataset 11) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:11:29.837301!
Epoch 1/1
572/572 [==============================] - 13s 24ms/step - loss: 0.0684
13. set (Dataset 21) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:11:49.437531!
Epoch 1/1
634/634 [==============================] - 14s 23ms/step - loss: 0.1340
14. set (Dataset 17) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:12:07.551771!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0861
15. set (Dataset 6) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:12:22.302690!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1138
16. set (Dataset 20) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:12:40.620681!
Epoch 1/1
556/556 [==============================] - 13s 24ms/step - loss: 0.0706
17. set (Dataset 10) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:13:01.007965!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0895
18. set (Dataset 1) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:13:22.395103!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1136
19. set (Dataset 12) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:13:41.345900!
Epoch 1/1
732/732 [==============================] - 16s 22ms/step - loss: 0.0797
20. set (Dataset 2) being trained for epoch 3 in Experiment 5 by 2019-01-29 16:14:02.989780!
Epoch 1/1
511/511 [==============================] - 11s 22ms/step - loss: 0.1097
Epoch 3 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:14:18.775654
1. set (Dataset 1) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:14:23.826875!
Epoch 1/1
498/498 [==============================] - 12s 24ms/step - loss: 0.1081
2. set (Dataset 2) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:14:40.778960!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1013
3. set (Dataset 4) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:15:00.308018!
Epoch 1/1
744/744 [==============================] - 18s 24ms/step - loss: 0.1004
4. set (Dataset 6) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:15:23.376658!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1146
5. set (Dataset 13) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:15:40.217796!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0715
6. set (Dataset 12) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:15:58.886623!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0822
7. set (Dataset 10) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:16:22.834362!
Epoch 1/1
726/726 [==============================] - 16s 23ms/step - loss: 0.0864
8. set (Dataset 11) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:16:45.043365!
Epoch 1/1
572/572 [==============================] - 14s 24ms/step - loss: 0.0672
9. set (Dataset 23) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:17:04.250948!
Epoch 1/1
569/569 [==============================] - 12s 22ms/step - loss: 0.1201
10. set (Dataset 8) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:17:24.379441!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0890
11. set (Dataset 15) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:17:48.578929!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0902
12. set (Dataset 16) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:18:12.540221!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0846
13. set (Dataset 17) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:18:37.536732!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0808
14. set (Dataset 18) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:18:52.860567!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1040
15. set (Dataset 19) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:19:12.209265!
Epoch 1/1
502/502 [==============================] - 11s 22ms/step - loss: 0.0789
16. set (Dataset 20) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:19:28.623119!
Epoch 1/1
556/556 [==============================] - 12s 22ms/step - loss: 0.0698
17. set (Dataset 21) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:19:47.067998!
Epoch 1/1
634/634 [==============================] - 14s 23ms/step - loss: 0.1309
18. set (Dataset 22) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:20:08.060234!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0643
19. set (Dataset 7) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:20:30.617759!
Epoch 1/1
745/745 [==============================] - 16s 22ms/step - loss: 0.0981
20. set (Dataset 24) being trained for epoch 4 in Experiment 5 by 2019-01-29 16:20:51.485250!
Epoch 1/1
492/492 [==============================] - 11s 23ms/step - loss: 0.0681
Epoch 4 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:21:07.365098
1. set (Dataset 22) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:21:13.768116!
Epoch 1/1
665/665 [==============================] - 16s 24ms/step - loss: 0.0589
2. set (Dataset 24) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:21:34.609363!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0618
3. set (Dataset 15) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:21:51.677253!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0868
4. set (Dataset 19) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:22:11.742547!
Epoch 1/1
502/502 [==============================] - 12s 23ms/step - loss: 0.0784
5. set (Dataset 12) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:22:30.758830!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0852
6. set (Dataset 7) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:22:55.073003!
Epoch 1/1
745/745 [==============================] - 18s 24ms/step - loss: 0.0968
7. set (Dataset 21) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:23:18.734565!
Epoch 1/1
634/634 [==============================] - 14s 23ms/step - loss: 0.1397
8. set (Dataset 16) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:23:41.946523!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0855
9. set (Dataset 13) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:24:08.075619!
Epoch 1/1
485/485 [==============================] - 11s 22ms/step - loss: 0.0715
10. set (Dataset 23) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:24:24.247901!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1187
11. set (Dataset 10) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:24:44.772990!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0901
12. set (Dataset 1) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:25:05.785282!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1057
13. set (Dataset 18) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:25:23.392437!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1041
14. set (Dataset 2) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:25:42.702232!
Epoch 1/1
511/511 [==============================] - 11s 22ms/step - loss: 0.1073
15. set (Dataset 4) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:26:01.250669!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1003
16. set (Dataset 20) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:26:24.082317!
Epoch 1/1
556/556 [==============================] - 13s 24ms/step - loss: 0.0773
17. set (Dataset 17) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:26:41.212754!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0829
18. set (Dataset 6) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:26:55.700803!
Epoch 1/1
542/542 [==============================] - 12s 22ms/step - loss: 0.1093
19. set (Dataset 8) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:27:15.406355!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0905
20. set (Dataset 11) being trained for epoch 5 in Experiment 5 by 2019-01-29 16:27:38.814305!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0635
Epoch 5 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:27:56.514867
1. set (Dataset 6) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:28:01.723367!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1076
2. set (Dataset 11) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:28:20.513897!
Epoch 1/1
572/572 [==============================] - 13s 24ms/step - loss: 0.0621
3. set (Dataset 10) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:28:41.321091!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0889
4. set (Dataset 4) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:29:05.551882!
Epoch 1/1
744/744 [==============================] - 16s 22ms/step - loss: 0.1018
5. set (Dataset 7) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:29:29.458770!
Epoch 1/1
745/745 [==============================] - 17s 22ms/step - loss: 0.1006
6. set (Dataset 8) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:29:53.980251!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0920
7. set (Dataset 17) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:30:15.409362!
Epoch 1/1
395/395 [==============================] - 9s 22ms/step - loss: 0.0857
8. set (Dataset 1) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:30:29.420335!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1164
9. set (Dataset 12) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:30:48.542338!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0805
10. set (Dataset 13) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:31:10.448440!
Epoch 1/1
485/485 [==============================] - 10s 21ms/step - loss: 0.0667
11. set (Dataset 21) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:31:26.975066!
Epoch 1/1
634/634 [==============================] - 22s 35ms/step - loss: 0.1390
12. set (Dataset 22) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:31:55.880905!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0607
13. set (Dataset 2) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:32:16.264745!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1030
14. set (Dataset 24) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:32:32.915067!
Epoch 1/1
492/492 [==============================] - 12s 24ms/step - loss: 0.0693
15. set (Dataset 15) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:32:51.195955!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0894
16. set (Dataset 20) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:33:11.407430!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0716
17. set (Dataset 18) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:33:30.060501!
Epoch 1/1
614/614 [==============================] - 13s 21ms/step - loss: 0.1022
18. set (Dataset 19) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:33:48.251792!
Epoch 1/1
502/502 [==============================] - 12s 23ms/step - loss: 0.0773
19. set (Dataset 23) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:34:05.396803!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1140
20. set (Dataset 16) being trained for epoch 6 in Experiment 5 by 2019-01-29 16:34:27.957377!
Epoch 1/1
914/914 [==============================] - 20s 22ms/step - loss: 0.0817
Epoch 6 for Experiment 5 completed!
Exp2019-01-29_13-03-34_part5.h5 has been saved.
The subjects are trained: [(6, 'F06'), (11, 'M05'), (10, 'M04'), (4, 'F04'), (7, 'M01'), (8, 'M02'), (17, 'M10'), (1, 'F
01'), (12, 'M06'), (13, 'M07'), (21, 'F02'), (22, 'M01'), (2, 'F02'), (24, 'M14'), (15, 'F03'), (20, 'M12'), (18, 'F05')
, (19, 'M11'), (23, 'M13'), (16, 'M09')]
Evaluating model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-29 16:34:50.710846
For the Subject 3 (F03):
730/730 [==============================] - 12s 16ms/step
        The absolute mean error on Pitch angle estimation: 9.27 Degree
        The absolute mean error on Yaw angle estimation: 22.35 Degree
        The absolute mean error on Roll angle estimation: 12.97 Degree
For the Subject 5 (F05):
946/946 [==============================] - 15s 16ms/step
        The absolute mean error on Pitch angle estimation: 8.62 Degree
        The absolute mean error on Yaw angle estimation: 21.98 Degree
        The absolute mean error on Roll angle estimation: 4.67 Degree
For the Subject 9 (M03):
882/882 [==============================] - 14s 16ms/step
        The absolute mean error on Pitch angle estimation: 32.96 Degree
        The absolute mean error on Yaw angle estimation: 21.14 Degree
        The absolute mean error on Roll angle estimation: 7.75 Degree
For the Subject 14 (M08):
797/797 [==============================] - 13s 16ms/step
        The absolute mean error on Pitch angle estimation: 13.61 Degree
        The absolute mean error on Yaw angle estimation: 31.27 Degree
        The absolute mean error on Roll angle estimation: 13.23 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 16.11 Degree
        The absolute mean error on Yaw angle estimations: 24.18 Degree
        The absolute mean error on Roll angle estimations: 9.65 Degree
Exp2019-01-29_13-03-34_part5 completed!
Training model Exp2019-01-29_04-28-57_and_2019-01-29_13-03-34
All frames and annotations from 20 datasets have been read by 2019-01-29 16:36:22.554385
1. set (Dataset 19) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:36:27.449365!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0795
2. set (Dataset 16) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:36:47.812026!
Epoch 1/1
914/914 [==============================] - 22s 24ms/step - loss: 0.0823
3. set (Dataset 21) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:37:15.572452!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1324
4. set (Dataset 15) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:37:36.825703!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0893
5. set (Dataset 8) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:37:59.417865!
Epoch 1/1
772/772 [==============================] - 17s 23ms/step - loss: 0.0968
6. set (Dataset 23) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:38:22.387779!
Epoch 1/1
569/569 [==============================] - 14s 24ms/step - loss: 0.1179
7. set (Dataset 18) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:38:41.990897!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1022
8. set (Dataset 22) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:39:03.261676!
Epoch 1/1
665/665 [==============================] - 15s 23ms/step - loss: 0.0579
9. set (Dataset 7) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:39:26.081864!
Epoch 1/1
745/745 [==============================] - 17s 23ms/step - loss: 0.0947
10. set (Dataset 12) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:39:50.356439!
Epoch 1/1
732/732 [==============================] - 17s 24ms/step - loss: 0.0820
11. set (Dataset 17) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:40:11.622405!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0813
12. set (Dataset 6) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:40:26.272914!
Epoch 1/1
542/542 [==============================] - 12s 21ms/step - loss: 0.1089
13. set (Dataset 24) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:40:42.735305!
Epoch 1/1
492/492 [==============================] - 12s 24ms/step - loss: 0.0666
14. set (Dataset 11) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:41:00.395241!
Epoch 1/1
572/572 [==============================] - 12s 22ms/step - loss: 0.0646
15. set (Dataset 10) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:41:20.112581!
Epoch 1/1
726/726 [==============================] - 17s 23ms/step - loss: 0.0906
16. set (Dataset 20) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:41:42.146800!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0723
17. set (Dataset 2) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:42:00.221490!
Epoch 1/1
511/511 [==============================] - 12s 23ms/step - loss: 0.1127
18. set (Dataset 4) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:42:19.528798!
Epoch 1/1
744/744 [==============================] - 17s 23ms/step - loss: 0.1014
19. set (Dataset 13) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:42:41.348710!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0701
20. set (Dataset 1) being trained for epoch 1 in Experiment 6 by 2019-01-29 16:42:57.688614!
Epoch 1/1
498/498 [==============================] - 12s 23ms/step - loss: 0.1165
Epoch 1 for Experiment 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:43:13.676288
1. set (Dataset 4) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:43:21.083462!
Epoch 1/1
744/744 [==============================] - 16s 22ms/step - loss: 0.1016
2. set (Dataset 1) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:43:42.728386!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1078
3. set (Dataset 17) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:43:58.020103!
Epoch 1/1
395/395 [==============================] - 9s 24ms/step - loss: 0.0853
4. set (Dataset 10) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:44:14.792242!
Epoch 1/1
726/726 [==============================] - 16s 22ms/step - loss: 0.0867
5. set (Dataset 23) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:44:36.453456!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1239
6. set (Dataset 13) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:44:54.246058!
Epoch 1/1
485/485 [==============================] - 11s 22ms/step - loss: 0.0709
7. set (Dataset 2) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:45:10.156899!
Epoch 1/1
511/511 [==============================] - 12s 24ms/step - loss: 0.1071
8. set (Dataset 6) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:45:27.744005!
Epoch 1/1
542/542 [==============================] - 13s 24ms/step - loss: 0.1178
9. set (Dataset 8) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:45:48.718853!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0900
10. set (Dataset 7) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:46:14.343309!
Epoch 1/1
745/745 [==============================] - 17s 22ms/step - loss: 0.0928
11. set (Dataset 18) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:46:36.963084!
Epoch 1/1
614/614 [==============================] - 14s 23ms/step - loss: 0.1084
12. set (Dataset 19) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:46:56.127466!
Epoch 1/1
502/502 [==============================] - 11s 23ms/step - loss: 0.0797
13. set (Dataset 11) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:47:13.401548!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0659
14. set (Dataset 16) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:47:35.356088!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0817
15. set (Dataset 21) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:48:02.472771!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1342
16. set (Dataset 20) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:48:22.499152!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0740
17. set (Dataset 24) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:48:40.161223!
Epoch 1/1
492/492 [==============================] - 12s 24ms/step - loss: 0.0644
18. set (Dataset 15) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:48:58.459186!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0851
19. set (Dataset 12) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:49:20.759400!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0823
20. set (Dataset 22) being trained for epoch 2 in Experiment 6 by 2019-01-29 16:49:44.321170!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0630
Epoch 2 for Experiment 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:50:03.311730
1. set (Dataset 15) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:50:09.682799!
Epoch 1/1
654/654 [==============================] - 15s 23ms/step - loss: 0.0876
2. set (Dataset 22) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:50:31.015403!
Epoch 1/1
665/665 [==============================] - 15s 22ms/step - loss: 0.0619
3. set (Dataset 18) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:50:51.638107!
Epoch 1/1
614/614 [==============================] - 15s 24ms/step - loss: 0.1047
4. set (Dataset 21) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:51:12.565857!
Epoch 1/1
634/634 [==============================] - 15s 23ms/step - loss: 0.1333
5. set (Dataset 13) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:51:32.201591!
Epoch 1/1
485/485 [==============================] - 11s 23ms/step - loss: 0.0743
6. set (Dataset 12) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:51:50.652878!
Epoch 1/1
732/732 [==============================] - 17s 23ms/step - loss: 0.0853
7. set (Dataset 24) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:52:12.578114!
Epoch 1/1
492/492 [==============================] - 11s 22ms/step - loss: 0.0659
8. set (Dataset 19) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:52:28.295254!
Epoch 1/1
502/502 [==============================] - 11s 22ms/step - loss: 0.0754
9. set (Dataset 23) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:52:45.138092!
Epoch 1/1
569/569 [==============================] - 13s 23ms/step - loss: 0.1168
10. set (Dataset 8) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:53:06.077713!
Epoch 1/1
772/772 [==============================] - 18s 23ms/step - loss: 0.0945
11. set (Dataset 2) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:53:29.057583!
Epoch 1/1
511/511 [==============================] - 17s 34ms/step - loss: 0.1113
12. set (Dataset 4) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:53:53.884241!
Epoch 1/1
744/744 [==============================] - 16s 21ms/step - loss: 0.1033
13. set (Dataset 16) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:54:18.727866!
Epoch 1/1
914/914 [==============================] - 21s 23ms/step - loss: 0.0877
14. set (Dataset 1) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:54:44.624526!
Epoch 1/1
498/498 [==============================] - 11s 23ms/step - loss: 0.1206
15. set (Dataset 17) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:54:59.916685!
Epoch 1/1
395/395 [==============================] - 9s 23ms/step - loss: 0.0792
16. set (Dataset 20) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:55:14.593397!
Epoch 1/1
556/556 [==============================] - 13s 23ms/step - loss: 0.0763
17. set (Dataset 11) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:55:33.298573!
Epoch 1/1
572/572 [==============================] - 13s 23ms/step - loss: 0.0650
18. set (Dataset 10) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:55:53.539829!
Epoch 1/1
726/726 [==============================] - 17s 24ms/step - loss: 0.0912
19. set (Dataset 7) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:56:18.609484!
Epoch 1/1
745/745 [==============================] - 18s 24ms/step - loss: 0.0947
20. set (Dataset 6) being trained for epoch 3 in Experiment 6 by 2019-01-29 16:56:41.539259!
Epoch 1/1
542/542 [==============================] - 12s 23ms/step - loss: 0.1115
Epoch 3 for Experiment 6 completed!
All frames and annotations from 20 datasets have been read by 2019-01-29 16:56:58.432081
1. set (Dataset 10) being trained for epoch 4 in Experiment 6 by 2019-01-29 16:57:05.680919!
Epoch 1/1
194/726 [=======>......................] - ETA: 11s - loss: 0.0839^C
Model Exp2019-01-29_13-03-34_part6 has been interrupted.
Exp2019-01-29_13-03-34_part6.h5 has been saved.
Model Exp2019-01-29_13-03-34_part6 has been recorded successfully.
Terminating...
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/FC_RNN_Evaluater$ python continueFC_RNN_Experiment.
py Exp2019-01-29_13-03-34_part6
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument
 of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(flo
at).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-01-29 16:58:50.491150: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that thi
s TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-01-29 16:58:50.589391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from S
ysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-29 16:58:50.589647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.80GiB
2019-01-29 16:58:50.589659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-01-29 16:58:50.745877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor w
ith strength 1 edge matrix:
2019-01-29 16:58:50.745905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-01-29 16:58:50.745909: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-01-29 16:58:50.746048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:loc
alhost/replica:0/task:0/device:GPU:0 with 10453 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bu
s id: 0000:01:00.0, compute capability: 5.2)
Exp2019-01-29_13-03-34_part6.h5 has been saved.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (1, 1, 3)                 138458947
_________________________________________________________________
lstm_1 (LSTM)                (1, 10)                   560
_________________________________________________________________
dense_1 (Dense)              (1, 3)                    33
=================================================================
Total params: 138,459,540
Trainable params: 4,198,996
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_FC_RNN_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 60
eva_epoch = 6
train_batch_size = 1
test_batch_size = 1

subjectList = [i for i in range(1, 25)] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] # [9] #
testSubjects = [3, 5, 9, 14] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True # False #

angles = ['Pitch', 'Yaw', 'Roll']
use_vgg16 = True # False #
######### CONF_ends_Here ###########
The subjects are trained: [(1, 'F01'), (2, 'F02'), (4, 'F04'), (6, 'F06'), (7, 'M01'), (8, 'M02'), (10, 'M04'), (11, 'M0
5'), (12, 'M06'), (13, 'M07'), (15, 'F03'), (16, 'M09'), (17, 'M10'), (18, 'F05'), (19, 'M11'), (20, 'M12'), (21, 'F02')
, (22, 'M01'), (23, 'M13'), (24, 'M14')]
Evaluating model Exp2019-01-29_13-03-34_part6_and_2019-01-29_16-58-53
The subjects will be tested: [(3, 'F03'), (5, 'F05'), (9, 'M03'), (14, 'M08')]
All frames and annotations from 4 datasets have been read by 2019-01-29 16:58:55.168142
For the Subject 3 (F03):
730/730 [==============================] - 12s 17ms/step
        The absolute mean error on Pitch angle estimation: 9.67 Degree
        The absolute mean error on Yaw angle estimation: 23.48 Degree
        The absolute mean error on Roll angle estimation: 10.65 Degree
For the Subject 5 (F05):
946/946 [==============================] - 15s 16ms/step
        The absolute mean error on Pitch angle estimation: 8.36 Degree
        The absolute mean error on Yaw angle estimation: 20.27 Degree
        The absolute mean error on Roll angle estimation: 3.43 Degree
For the Subject 9 (M03):
882/882 [==============================] - 14s 16ms/step
        The absolute mean error on Pitch angle estimation: 30.01 Degree
        The absolute mean error on Yaw angle estimation: 20.74 Degree
        The absolute mean error on Roll angle estimation: 8.29 Degree
For the Subject 14 (M08):
797/797 [==============================] - 13s 16ms/step
        The absolute mean error on Pitch angle estimation: 13.86 Degree
        The absolute mean error on Yaw angle estimation: 31.66 Degree
        The absolute mean error on Roll angle estimation: 13.32 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 15.48 Degree
        The absolute mean error on Yaw angle estimations: 24.04 Degree
        The absolute mean error on Roll angle estimations: 8.92 Degree
subject3_Exp1-29_13-03-34_part6_and_2019-01-29_16-58-53.png has been saved by 2019-01-29 17:00:23.021290.
subject5_Exp1-29_13-03-34_part6_and_2019-01-29_16-58-53.png has been saved by 2019-01-29 17:00:23.219089.
subject9_Exp1-29_13-03-34_part6_and_2019-01-29_16-58-53.png has been saved by 2019-01-29 17:00:23.415595.
subject14_Exp1-29_13-03-34_part6_and_2019-01-29_16-58-53.png has been saved by 2019-01-29 17:00:23.679735.
Model Exp1-29_13-03-34_part6_and_2019-01-29_16-58-53 has been evaluated successfully.
Model Exp1-29_13-03-34_part6_and_2019-01-29_16-58-53 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/FC_RNN_Evaluater$
