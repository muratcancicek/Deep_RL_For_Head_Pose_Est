mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/FC_RNN_Evaluater$ python runFC_RNN_Experiment.py
/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument
 of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(flo
at).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
2019-02-05 04:11:12.573010: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that thi
s TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-02-05 04:11:12.670308: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from S
ysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-02-05 04:11:12.670565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1344] Found device 0 with properties:
name: GeForce GTX TITAN X major: 5 minor: 2 memoryClockRate(GHz): 1.2155
pciBusID: 0000:01:00.0
totalMemory: 11.92GiB freeMemory: 10.80GiB
2019-02-05 04:11:12.670578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2019-02-05 04:11:12.824450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor w
ith strength 1 edge matrix:
2019-02-05 04:11:12.824477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2019-02-05 04:11:12.824482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2019-02-05 04:11:12.824628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Created TensorFlow device (/job:loc
alhost/replica:0/task:0/device:GPU:0 with 10452 MB memory) -> physical GPU (device: 0, name: GeForce GTX TITAN X, pci bu
s id: 0000:01:00.0, compute capability: 5.2)
Model Exp2019-02-05_04-11-13 has been started to be evaluated.
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 224, 224, 3)       0
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0
_________________________________________________________________
flatten (Flatten)            (None, 25088)             0
_________________________________________________________________
fc1 (Dense)                  (None, 4096)              102764544
_________________________________________________________________
fc2 (Dense)                  (None, 4096)              16781312
_________________________________________________________________
dropout_025 (Dropout)        (None, 4096)              0
=================================================================
Total params: 134,260,544
Trainable params: 0
Non-trainable params: 134,260,544
_________________________________________________________________

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
tdCNN (TimeDistributed)      (10, 1, 4096)             134260544
_________________________________________________________________
lstm_1 (LSTM)                (10, 10)                  164280
_________________________________________________________________
dense_1 (Dense)              (10, 3)                   33
=================================================================
Total params: 134,424,857
Trainable params: 164,313
Non-trainable params: 134,260,544
_________________________________________________________________

######## CONF_Begins_Here ##########
confFile = 'Stateful_FC_RNN_Configuration.py'
RECORD = True # False #

output_begin = 3
num_outputs = 3

timesteps = 1 # TimeseriesGenerator Handles overlapping
learning_rate =  0.0001
in_epochs = 1
out_epochs = 50
eva_epoch = 10
train_batch_size = 10
test_batch_size = 10

subjectList = [i for i in range(1, 25)] # [9] # [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #
testSubjects = [6, 9, 14, 24] # [9, 18, 21, 24] # [9] #
trainingSubjects = [s for s in subjectList if not s in testSubjects] # subjectList #

num_datasets = len(subjectList)

lstm_nodes = 10
lstm_dropout = 0.25
lstm_recurrent_dropout = 0.25
include_vgg_top = True # False #

angles = ['Pitch', 'Yaw', 'Roll']
use_vgg16 = True # False #
######### CONF_ends_Here ###########
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_2019-
02-05_04-11-13
All frames and annotations from 20 datasets have been read by 2019-02-05 04:11:18.517572
1. set (Dataset 21) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:11:24.564138!
Epoch 1/1
63/63 [==============================] - 5s 81ms/step - loss: 0.2684
2. set (Dataset 23) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:11:35.499211!
Epoch 1/1
56/56 [==============================] - 3s 61ms/step - loss: 0.2468
3. set (Dataset 13) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:11:43.815958!
Epoch 1/1
48/48 [==============================] - 3s 61ms/step - loss: 0.1933
4. set (Dataset 18) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:11:52.696460!
Epoch 1/1
61/61 [==============================] - 4s 61ms/step - loss: 0.2283
5. set (Dataset 7) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:12:04.097419!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.2622
6. set (Dataset 22) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:12:15.169674!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.1369
7. set (Dataset 20) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:12:24.692969!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.1625
8. set (Dataset 15) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:12:34.489377!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.2039
9. set (Dataset 5) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:12:47.783295!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.2373
10. set (Dataset 11) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:12:59.401815!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1757
11. set (Dataset 8) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:13:10.741587!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.2356
12. set (Dataset 1) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:13:20.617687!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.2687
13. set (Dataset 17) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:13:27.455366!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1358
14. set (Dataset 2) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:13:35.005626!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.2600
15. set (Dataset 3) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:13:45.507939!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.2285
16. set (Dataset 19) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:13:54.977637!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.2006
17. set (Dataset 16) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:14:06.868543!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1764
18. set (Dataset 4) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:14:19.976158!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.2377
19. set (Dataset 12) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:14:31.893684!
Epoch 1/1
73/73 [==============================] - 4s 61ms/step - loss: 0.1780
20. set (Dataset 10) being trained for epoch 1 in Experiment 1 by 2019-02-05 04:14:43.625419!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1889
Epoch 1 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:14:53.126509
1. set (Dataset 4) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:15:00.510124!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1976
2. set (Dataset 10) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:15:12.373700!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1772
3. set (Dataset 8) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:15:24.622194!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1850
4. set (Dataset 3) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:15:36.802885!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.2050
5. set (Dataset 22) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:15:47.791263!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.1256
6. set (Dataset 12) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:15:59.216540!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1664
7. set (Dataset 16) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:16:12.533942!
Epoch 1/1
91/91 [==============================] - 6s 63ms/step - loss: 0.1586
8. set (Dataset 1) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:16:23.335304!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.2300
9. set (Dataset 7) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:16:33.999132!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.2099
10. set (Dataset 5) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:16:47.837819!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1863
11. set (Dataset 20) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:16:59.092154!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.1516
12. set (Dataset 21) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:08.588890!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.2338
13. set (Dataset 2) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:17.637726!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1879
14. set (Dataset 23) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:26.314695!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.2257
15. set (Dataset 13) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:34.669815!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1318
16. set (Dataset 19) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:42.570684!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1808
17. set (Dataset 17) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:49.478550!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1334
18. set (Dataset 18) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:17:57.855049!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.2118
19. set (Dataset 11) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:18:07.437801!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1608
20. set (Dataset 15) being trained for epoch 2 in Experiment 1 by 2019-02-05 04:18:17.389450!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1823
Epoch 2 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:18:26.400492
1. set (Dataset 18) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:18:32.275425!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.2097
2. set (Dataset 15) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:18:42.451963!
Epoch 1/1
65/65 [==============================] - 4s 63ms/step - loss: 0.1743
3. set (Dataset 20) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:18:51.961631!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.1357
4. set (Dataset 13) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:00.253309!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1151
5. set (Dataset 12) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:10.555187!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1535
6. set (Dataset 11) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:20.848772!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1541
7. set (Dataset 17) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:28.222916!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1277
8. set (Dataset 21) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:36.744111!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.2211
9. set (Dataset 22) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:47.096940!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.1062
10. set (Dataset 7) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:19:58.810011!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1904
11. set (Dataset 16) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:20:12.235937!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1357
12. set (Dataset 4) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:20:25.350610!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1736
13. set (Dataset 23) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:20:35.492537!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.2068
14. set (Dataset 10) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:20:46.249749!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1690
15. set (Dataset 8) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:20:58.502329!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1623
16. set (Dataset 19) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:21:08.265674!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1565
17. set (Dataset 2) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:21:16.542538!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1855
18. set (Dataset 3) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:21:27.067762!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1848
19. set (Dataset 5) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:21:40.835196!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1779
20. set (Dataset 1) being trained for epoch 3 in Experiment 1 by 2019-02-05 04:21:51.792969!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1932
Epoch 3 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:21:59.851370
1. set (Dataset 3) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:22:07.160504!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.1816
2. set (Dataset 1) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:22:16.821964!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1921
3. set (Dataset 16) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:22:28.666721!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1310
4. set (Dataset 8) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:22:42.135040!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1543
5. set (Dataset 11) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:22:52.717087!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1524
6. set (Dataset 5) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:23:05.530268!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1596
7. set (Dataset 2) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:23:16.528964!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1647
8. set (Dataset 4) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:23:27.146944!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1632
9. set (Dataset 12) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:23:39.067269!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1361
10. set (Dataset 22) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:23:50.061279!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0978
11. set (Dataset 17) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:23:57.954905!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1256
12. set (Dataset 18) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:24:06.313640!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1911
13. set (Dataset 10) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:24:17.371753!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1584
14. set (Dataset 15) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:24:28.261182!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1664
15. set (Dataset 20) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:24:37.738843!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.1181
16. set (Dataset 19) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:24:46.116220!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1422
17. set (Dataset 23) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:24:54.730356!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1935
18. set (Dataset 13) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:25:03.093237!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1205
19. set (Dataset 7) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:25:13.687857!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1543
20. set (Dataset 21) being trained for epoch 4 in Experiment 1 by 2019-02-05 04:25:24.384259!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.2148
Epoch 4 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:25:33.244037
1. set (Dataset 13) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:25:38.051560!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1093
2. set (Dataset 21) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:25:47.105671!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1989
3. set (Dataset 17) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:25:54.818438!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1181
4. set (Dataset 20) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:26:02.678530!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.1109
5. set (Dataset 5) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:26:15.340728!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1541
6. set (Dataset 7) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:26:28.834027!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1404
7. set (Dataset 23) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:26:38.942230!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1907
8. set (Dataset 18) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:26:48.372624!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1830
9. set (Dataset 11) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:26:57.919293!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1393
10. set (Dataset 12) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:27:08.867517!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1276
11. set (Dataset 2) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:27:18.533790!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1556
12. set (Dataset 3) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:27:29.048568!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1741
13. set (Dataset 15) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:27:40.004999!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1507
14. set (Dataset 1) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:27:49.155527!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1708
15. set (Dataset 16) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:28:01.013293!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1283
16. set (Dataset 19) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:28:11.629728!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1380
17. set (Dataset 10) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:28:22.033360!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1522
18. set (Dataset 8) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:28:34.334843!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1440
19. set (Dataset 22) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:28:45.570274!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0921
20. set (Dataset 4) being trained for epoch 5 in Experiment 1 by 2019-02-05 04:28:57.104584!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1661
Epoch 5 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:29:06.690168
1. set (Dataset 8) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:29:14.421363!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1394
2. set (Dataset 4) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:29:26.644566!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1484
3. set (Dataset 2) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:29:36.405110!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1522
4. set (Dataset 16) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:29:48.365943!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1203
5. set (Dataset 7) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:30:01.675276!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1305
6. set (Dataset 22) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:30:12.715388!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0923
7. set (Dataset 10) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:30:24.095875!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1494
8. set (Dataset 3) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:30:35.943650!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1730
9. set (Dataset 5) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:30:49.768924!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1473
10. set (Dataset 11) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:01.439382!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1416
11. set (Dataset 23) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:10.522083!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1847
12. set (Dataset 13) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:18.873244!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1049
13. set (Dataset 1) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:26.939529!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1644
14. set (Dataset 21) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:36.047216!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1993
15. set (Dataset 17) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:43.767450!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.1160
16. set (Dataset 19) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:31:51.115756!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1318
17. set (Dataset 15) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:32:00.646310!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1547
18. set (Dataset 20) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:32:10.103939!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.1049
19. set (Dataset 12) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:32:20.885747!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1228
20. set (Dataset 18) being trained for epoch 6 in Experiment 1 by 2019-02-05 04:32:31.370912!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1736
Epoch 6 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:32:40.284240
1. set (Dataset 20) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:32:45.654608!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0988
2. set (Dataset 18) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:32:54.995749!
Epoch 1/1
61/61 [==============================] - 4s 63ms/step - loss: 0.1709
3. set (Dataset 23) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:33:04.322453!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1736
4. set (Dataset 17) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:33:11.601391!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.1159
5. set (Dataset 22) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:33:20.457877!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0888
6. set (Dataset 12) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:33:31.896094!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1150
7. set (Dataset 15) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:33:42.841853!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1351
8. set (Dataset 13) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:33:51.768716!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1115
9. set (Dataset 7) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:34:02.389764!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1196
10. set (Dataset 5) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:34:16.212313!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1358
11. set (Dataset 10) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:34:29.359920!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1457
12. set (Dataset 8) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:34:41.653961!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1407
13. set (Dataset 21) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:34:52.505032!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1919
14. set (Dataset 4) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:35:03.849613!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1426
15. set (Dataset 2) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:35:13.586303!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1443
16. set (Dataset 19) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:35:21.717871!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1335
17. set (Dataset 1) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:35:29.937904!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1642
18. set (Dataset 16) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:35:41.766163!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1180
19. set (Dataset 11) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:35:53.187825!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1329
20. set (Dataset 3) being trained for epoch 7 in Experiment 1 by 2019-02-05 04:36:04.084026!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1667
Epoch 7 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:36:13.611141
1. set (Dataset 16) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:36:22.349720!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1100
2. set (Dataset 3) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:36:35.373705!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1621
3. set (Dataset 10) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:36:47.202722!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1426
4. set (Dataset 2) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:36:56.836091!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1406
5. set (Dataset 12) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:37:07.361084!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1164
6. set (Dataset 11) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:37:17.660434!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1311
7. set (Dataset 1) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:37:26.291583!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1566
8. set (Dataset 8) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:37:37.106473!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1313
9. set (Dataset 22) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:37:48.394621!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0869
10. set (Dataset 7) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:00.129651!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1141
11. set (Dataset 15) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:11.144200!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1296
12. set (Dataset 20) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:20.620505!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0980
13. set (Dataset 4) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:31.512173!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1378
14. set (Dataset 18) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:42.055590!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1664
15. set (Dataset 23) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:51.371769!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1735
16. set (Dataset 19) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:38:59.780543!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1285
17. set (Dataset 21) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:39:08.987132!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1872
18. set (Dataset 17) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:39:16.705245!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.1097
19. set (Dataset 5) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:39:28.382082!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1306
20. set (Dataset 13) being trained for epoch 8 in Experiment 1 by 2019-02-05 04:39:39.125864!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.1089
Epoch 8 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:39:47.066661
1. set (Dataset 17) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:39:50.812434!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1100
2. set (Dataset 13) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:39:58.103862!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0980
3. set (Dataset 15) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:40:07.507654!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1228
4. set (Dataset 23) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:40:17.053035!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1737
5. set (Dataset 11) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:40:26.302998!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1301
6. set (Dataset 5) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:40:39.094357!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1216
7. set (Dataset 21) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:40:51.034501!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1784
8. set (Dataset 20) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:41:00.388211!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0941
9. set (Dataset 12) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:41:11.137663!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1099
10. set (Dataset 22) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:41:22.136727!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0826
11. set (Dataset 1) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:41:31.341483!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1527
12. set (Dataset 16) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:41:43.181853!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1152
13. set (Dataset 18) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:41:54.793640!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1593
14. set (Dataset 3) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:42:05.940064!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1603
15. set (Dataset 10) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:42:17.769678!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1378
16. set (Dataset 19) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:42:27.183744!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1289
17. set (Dataset 4) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:42:37.739504!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1245
18. set (Dataset 2) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:42:47.465112!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1411
19. set (Dataset 7) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:42:58.280629!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.1048
20. set (Dataset 8) being trained for epoch 9 in Experiment 1 by 2019-02-05 04:43:10.706435!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1226
Epoch 9 for Experiment 1 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:43:20.465068
1. set (Dataset 2) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:43:25.567025!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1424
2. set (Dataset 8) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:43:36.535994!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1185
3. set (Dataset 1) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:43:46.428048!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1539
4. set (Dataset 10) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:43:56.756287!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1348
5. set (Dataset 5) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:44:10.507596!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1139
6. set (Dataset 7) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:44:23.992438!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1067
7. set (Dataset 4) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:44:36.065078!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1227
8. set (Dataset 16) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:44:49.493159!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1064
9. set (Dataset 11) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:00.928504!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1285
10. set (Dataset 12) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:11.799041!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1073
11. set (Dataset 21) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:22.414832!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1833
12. set (Dataset 17) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:30.129209!
Epoch 1/1
39/39 [==============================] - 2s 63ms/step - loss: 0.1119
13. set (Dataset 3) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:39.946578!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1627
14. set (Dataset 13) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:49.386563!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0961
15. set (Dataset 15) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:45:58.809116!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1249
16. set (Dataset 19) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:46:07.793686!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1298
17. set (Dataset 18) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:46:16.828727!
Epoch 1/1
61/61 [==============================] - 4s 63ms/step - loss: 0.1635
18. set (Dataset 23) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:46:26.155717!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1667
19. set (Dataset 22) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:46:36.066356!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0787
20. set (Dataset 20) being trained for epoch 10 in Experiment 1 by 2019-02-05 04:46:45.587618!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0973
Epoch 10 for Experiment 1 completed!
Exp2019-02-05_04-11-13_part1.h5 has been saved.
The subjects are trained: [(2, 'F02'), (8, 'M02'), (1, 'F01'), (10, 'M04'), (5, 'F05'), (7, 'M01'), (4, 'F04'), (16, 'M0
9'), (11, 'M05'), (12, 'M06'), (21, 'F02'), (17, 'M10'), (3, 'F03'), (13, 'M07'), (15, 'F03'), (19, 'M11'), (18, 'F05'),
 (23, 'M13'), (22, 'M01'), (20, 'M12')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_201
9-02-05_04-11-13
The subjects will be tested: [(6, 'F06'), (9, 'M03'), (14, 'M08'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-02-05 04:46:50.743483
For the Subject 6 (F06):
54/54 [==============================] - 3s 57ms/step
        The absolute mean error on Pitch angle estimation: 14.66 Degree
        The absolute mean error on Yaw angle estimation: 28.11 Degree
        The absolute mean error on Roll angle estimation: 15.54 Degree
For the Subject 9 (M03):
88/88 [==============================] - 5s 56ms/step
        The absolute mean error on Pitch angle estimation: 26.83 Degree
        The absolute mean error on Yaw angle estimation: 31.20 Degree
        The absolute mean error on Roll angle estimation: 7.20 Degree
For the Subject 14 (M08):
79/79 [==============================] - 4s 55ms/step
        The absolute mean error on Pitch angle estimation: 22.66 Degree
        The absolute mean error on Yaw angle estimation: 26.12 Degree
        The absolute mean error on Roll angle estimation: 13.28 Degree
For the Subject 24 (M14):
49/49 [==============================] - 3s 55ms/step
        The absolute mean error on Pitch angle estimation: 11.62 Degree
        The absolute mean error on Yaw angle estimation: 27.77 Degree
        The absolute mean error on Roll angle estimation: 10.39 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 18.94 Degree
        The absolute mean error on Yaw angle estimations: 28.30 Degree
        The absolute mean error on Roll angle estimations: 11.60 Degree
Exp2019-02-05_04-11-13_part1 completed!
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_2019-
02-05_04-11-13
All frames and annotations from 20 datasets have been read by 2019-02-05 04:47:39.080382
1. set (Dataset 23) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:47:44.534588!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1505
2. set (Dataset 20) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:47:53.435641!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0909
3. set (Dataset 21) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:48:02.918062!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1734
4. set (Dataset 15) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:48:13.276872!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1126
5. set (Dataset 7) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:48:24.936988!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0972
6. set (Dataset 22) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:48:35.988882!
Epoch 1/1
66/66 [==============================] - 4s 56ms/step - loss: 0.0787
7. set (Dataset 18) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:48:45.693894!
Epoch 1/1
61/61 [==============================] - 3s 52ms/step - loss: 0.1572
8. set (Dataset 17) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:48:52.649427!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1048
9. set (Dataset 5) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:49:04.312195!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1119
10. set (Dataset 11) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:49:15.933794!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1317
11. set (Dataset 4) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:49:26.918008!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1206
12. set (Dataset 2) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:49:36.671753!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1274
13. set (Dataset 13) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:49:44.706707!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0921
14. set (Dataset 8) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:49:55.504051!
Epoch 1/1
77/77 [==============================] - 5s 60ms/step - loss: 0.1197
15. set (Dataset 1) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:50:05.214203!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1473
16. set (Dataset 19) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:50:13.187318!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1207
17. set (Dataset 3) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:50:23.638918!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.1622
18. set (Dataset 10) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:50:35.489620!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1341
19. set (Dataset 12) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:50:47.288970!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1028
20. set (Dataset 16) being trained for epoch 1 in Experiment 2 by 2019-02-05 04:51:00.628477!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.1005
Epoch 1 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:51:11.306559
1. set (Dataset 10) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:51:18.534988!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1277
2. set (Dataset 16) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:51:31.845857!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0948
3. set (Dataset 4) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:51:44.954807!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1106
4. set (Dataset 1) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:51:54.654015!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1450
5. set (Dataset 22) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:52:04.148286!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0789
6. set (Dataset 12) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:52:15.598220!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1014
7. set (Dataset 3) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:52:27.492875!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1530
8. set (Dataset 2) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:52:37.162982!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1265
9. set (Dataset 7) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:52:47.968448!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0954
10. set (Dataset 5) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:53:01.822419!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1105
11. set (Dataset 18) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:53:13.627406!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1510
12. set (Dataset 23) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:53:22.930004!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1521
13. set (Dataset 8) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:53:34.201196!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1095
14. set (Dataset 20) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:53:44.391443!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0899
15. set (Dataset 21) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:53:53.892067!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1684
16. set (Dataset 19) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:54:02.754253!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1126
17. set (Dataset 13) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:54:10.718306!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0987
18. set (Dataset 15) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:54:20.117998!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1065
19. set (Dataset 11) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:54:29.951701!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1263
20. set (Dataset 17) being trained for epoch 2 in Experiment 2 by 2019-02-05 04:54:37.323863!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1025
Epoch 2 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:54:44.694586
1. set (Dataset 15) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:54:51.045500!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1022
2. set (Dataset 17) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:54:58.893500!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1057
3. set (Dataset 18) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:55:07.271227!
Epoch 1/1
61/61 [==============================] - 4s 63ms/step - loss: 0.1459
4. set (Dataset 21) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:55:17.162428!
Epoch 1/1
63/63 [==============================] - 4s 63ms/step - loss: 0.1726
5. set (Dataset 12) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:55:28.443351!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.0994
6. set (Dataset 11) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:55:38.768700!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1118
7. set (Dataset 13) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:55:47.167893!
Epoch 1/1
48/48 [==============================] - 3s 61ms/step - loss: 0.0937
8. set (Dataset 23) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:55:55.618275!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1461
9. set (Dataset 22) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:56:05.555577!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0728
10. set (Dataset 7) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:56:17.297240!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0873
11. set (Dataset 3) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:56:29.257525!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.1482
12. set (Dataset 10) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:56:41.117999!
Epoch 1/1
72/72 [==============================] - 5s 63ms/step - loss: 0.1288
13. set (Dataset 20) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:56:51.045870!
Epoch 1/1
55/55 [==============================] - 3s 61ms/step - loss: 0.0861
14. set (Dataset 16) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:57:03.225831!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0966
15. set (Dataset 4) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:57:16.358172!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.1172
16. set (Dataset 19) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:57:25.952310!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1160
17. set (Dataset 8) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:57:36.868240!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1077
18. set (Dataset 1) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:57:46.791822!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1393
19. set (Dataset 5) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:57:59.085425!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.1043
20. set (Dataset 2) being trained for epoch 3 in Experiment 2 by 2019-02-05 04:58:10.093570!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1234
Epoch 3 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 04:58:18.180785
1. set (Dataset 1) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:58:23.226913!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1396
2. set (Dataset 2) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:58:31.413907!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1187
3. set (Dataset 3) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:58:41.944618!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1506
4. set (Dataset 4) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:58:53.957776!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1075
5. set (Dataset 11) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:59:04.334411!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1038
6. set (Dataset 5) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:59:17.133638!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0997
7. set (Dataset 8) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:59:30.816612!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1030
8. set (Dataset 10) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:59:42.834549!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1273
9. set (Dataset 12) being trained for epoch 4 in Experiment 2 by 2019-02-05 04:59:54.660124!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.0982
10. set (Dataset 22) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:00:05.669376!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0797
11. set (Dataset 13) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:00:14.635026!
Epoch 1/1
48/48 [==============================] - 3s 61ms/step - loss: 0.0904
12. set (Dataset 15) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:00:24.006434!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.1039
13. set (Dataset 16) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:00:36.856779!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0982
14. set (Dataset 17) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:00:46.349216!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1047
15. set (Dataset 18) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:00:54.735487!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1467
16. set (Dataset 19) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:01:03.463654!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1127
17. set (Dataset 20) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:01:12.004083!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0894
18. set (Dataset 21) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:01:21.499025!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1672
19. set (Dataset 7) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:01:33.067777!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0895
20. set (Dataset 23) being trained for epoch 4 in Experiment 2 by 2019-02-05 05:01:43.227522!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1474
Epoch 4 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:01:51.781991
1. set (Dataset 21) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:01:57.789756!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1620
2. set (Dataset 23) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:02:07.219336!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1409
3. set (Dataset 13) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:02:15.588719!
Epoch 1/1
48/48 [==============================] - 3s 63ms/step - loss: 0.0873
4. set (Dataset 18) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:02:24.546589!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1432
5. set (Dataset 5) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:02:37.577514!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0945
6. set (Dataset 7) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:02:51.076636!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0857
7. set (Dataset 20) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:03:01.106368!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0856
8. set (Dataset 15) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:03:10.930010!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0983
9. set (Dataset 11) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:03:20.749420!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.1038
10. set (Dataset 12) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:03:31.610386!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0993
11. set (Dataset 8) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:03:43.941124!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1026
12. set (Dataset 1) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:03:53.849386!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1383
13. set (Dataset 17) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:04:00.730955!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1010
14. set (Dataset 2) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:04:08.289543!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1122
15. set (Dataset 3) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:04:18.814310!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1440
16. set (Dataset 19) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:04:28.311047!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1111
17. set (Dataset 16) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:04:40.198095!
Epoch 1/1
91/91 [==============================] - 6s 63ms/step - loss: 0.0941
18. set (Dataset 4) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:04:53.333954!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1121
19. set (Dataset 22) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:05:04.384922!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0762
20. set (Dataset 10) being trained for epoch 5 in Experiment 2 by 2019-02-05 05:05:15.757494!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1236
Epoch 5 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:05:25.211135
1. set (Dataset 4) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:05:32.597450!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1025
2. set (Dataset 10) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:05:44.470450!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1194
3. set (Dataset 8) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:05:56.786139!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.1000
4. set (Dataset 3) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:06:08.947573!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1510
5. set (Dataset 7) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:06:21.133658!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0872
6. set (Dataset 22) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:06:32.211812!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0717
7. set (Dataset 16) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:06:45.111502!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0903
8. set (Dataset 1) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:06:55.903080!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1416
9. set (Dataset 5) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:07:08.199911!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0901
10. set (Dataset 11) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:07:19.829647!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0996
11. set (Dataset 20) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:07:28.792311!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0848
12. set (Dataset 21) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:07:38.291042!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1616
13. set (Dataset 2) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:07:47.311704!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1113
14. set (Dataset 23) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:07:56.023570!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1415
15. set (Dataset 13) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:08:04.386212!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0883
16. set (Dataset 19) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:08:12.318476!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1090
17. set (Dataset 17) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:08:19.233625!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1014
18. set (Dataset 18) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:08:27.574742!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1368
19. set (Dataset 12) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:08:38.684636!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0960
20. set (Dataset 15) being trained for epoch 6 in Experiment 2 by 2019-02-05 05:08:49.644388!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0991
Epoch 6 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:08:58.743830
1. set (Dataset 18) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:09:04.623754!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1335
2. set (Dataset 15) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:09:14.817931!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0946
3. set (Dataset 20) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:09:24.333693!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0814
4. set (Dataset 13) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:09:32.621821!
Epoch 1/1
48/48 [==============================] - 3s 60ms/step - loss: 0.0913
5. set (Dataset 22) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:09:41.959860!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0732
6. set (Dataset 12) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:09:53.450939!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0937
7. set (Dataset 17) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:10:01.789957!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0964
8. set (Dataset 21) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:10:10.269589!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1629
9. set (Dataset 7) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:10:21.832192!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0804
10. set (Dataset 5) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:10:35.681083!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0903
11. set (Dataset 16) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:10:50.348791!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0885
12. set (Dataset 4) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:11:03.469164!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.1034
13. set (Dataset 23) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:11:13.622610!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1435
14. set (Dataset 10) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:11:24.438817!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1186
15. set (Dataset 8) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:11:36.717783!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0963
16. set (Dataset 19) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:11:46.459622!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1129
17. set (Dataset 2) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:11:54.717708!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1053
18. set (Dataset 3) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:12:05.258936!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1379
19. set (Dataset 11) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:12:15.566772!
Epoch 1/1
57/57 [==============================] - 4s 63ms/step - loss: 0.0898
20. set (Dataset 1) being trained for epoch 7 in Experiment 2 by 2019-02-05 05:12:24.246458!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1359
Epoch 7 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:12:32.245699
1. set (Dataset 3) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:12:39.539751!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1352
2. set (Dataset 1) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:12:49.183246!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1338
3. set (Dataset 16) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:13:01.022582!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0861
4. set (Dataset 8) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:13:14.513262!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0930
5. set (Dataset 12) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:13:26.675531!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0872
6. set (Dataset 11) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:13:36.978348!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0865
7. set (Dataset 2) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:13:45.692506!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0987
8. set (Dataset 4) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:13:56.297446!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0977
9. set (Dataset 22) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:14:07.359079!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0729
10. set (Dataset 7) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:14:19.080351!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0806
11. set (Dataset 17) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:14:27.493358!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0968
12. set (Dataset 18) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:14:35.872486!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1364
13. set (Dataset 10) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:14:46.961113!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1143
14. set (Dataset 15) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:14:57.840861!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0931
15. set (Dataset 20) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:15:07.303273!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0818
16. set (Dataset 19) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:15:15.647249!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1036
17. set (Dataset 23) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:15:24.272897!
Epoch 1/1
56/56 [==============================] - 4s 63ms/step - loss: 0.1376
18. set (Dataset 13) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:15:32.669569!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0855
19. set (Dataset 5) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:15:44.889812!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0909
20. set (Dataset 21) being trained for epoch 8 in Experiment 2 by 2019-02-05 05:15:56.813145!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1568
Epoch 8 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:16:05.736956
1. set (Dataset 13) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:16:10.537070!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0855
2. set (Dataset 21) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:16:19.617768!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1557
3. set (Dataset 17) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:16:27.357296!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0969
4. set (Dataset 20) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:16:35.169088!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0803
5. set (Dataset 11) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:16:44.364287!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0855
6. set (Dataset 5) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:16:57.182571!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0916
7. set (Dataset 23) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:17:08.593035!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1345
8. set (Dataset 18) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:17:18.009727!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1321
9. set (Dataset 12) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:17:29.127902!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0886
10. set (Dataset 22) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:17:40.124288!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0708
11. set (Dataset 2) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:17:49.377487!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.1036
12. set (Dataset 3) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:17:59.923027!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1328
13. set (Dataset 15) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:18:10.864334!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0941
14. set (Dataset 1) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:18:20.011755!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1357
15. set (Dataset 16) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:18:31.828466!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0875
16. set (Dataset 19) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:18:42.443144!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1043
17. set (Dataset 10) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:18:52.801937!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1156
18. set (Dataset 8) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:19:05.054968!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0957
19. set (Dataset 7) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:19:17.456797!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0810
20. set (Dataset 4) being trained for epoch 9 in Experiment 2 by 2019-02-05 05:19:29.505169!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0998
Epoch 9 for Experiment 2 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:19:39.172667
1. set (Dataset 8) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:19:46.886721!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0922
2. set (Dataset 4) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:19:59.073642!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0918
3. set (Dataset 2) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:20:08.816821!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0921
4. set (Dataset 16) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:20:20.755265!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0820
5. set (Dataset 5) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:20:35.681145!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0832
6. set (Dataset 7) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:20:49.165122!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0774
7. set (Dataset 10) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:21:01.088592!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.1087
8. set (Dataset 3) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:21:12.902303!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1300
9. set (Dataset 11) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:21:23.193337!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0793
10. set (Dataset 12) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:21:34.050075!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.0877
11. set (Dataset 23) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:21:44.124293!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1399
12. set (Dataset 13) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:21:52.452320!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0923
13. set (Dataset 1) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:00.514540!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1310
14. set (Dataset 21) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:09.613709!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1551
15. set (Dataset 17) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:17.334966!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0970
16. set (Dataset 19) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:24.683018!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1043
17. set (Dataset 15) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:34.179772!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0967
18. set (Dataset 20) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:43.624135!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0828
19. set (Dataset 22) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:22:53.487479!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0731
20. set (Dataset 18) being trained for epoch 10 in Experiment 2 by 2019-02-05 05:23:03.520806!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1292
Epoch 10 for Experiment 2 completed!
Exp2019-02-05_04-11-13_part2.h5 has been saved.
The subjects are trained: [(8, 'M02'), (4, 'F04'), (2, 'F02'), (16, 'M09'), (5, 'F05'), (7, 'M01'), (10, 'M04'), (3, 'F0
3'), (11, 'M05'), (12, 'M06'), (23, 'M13'), (13, 'M07'), (1, 'F01'), (21, 'F02'), (17, 'M10'), (19, 'M11'), (15, 'F03'),
 (20, 'M12'), (22, 'M01'), (18, 'F05')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_201
9-02-05_04-11-13
The subjects will be tested: [(6, 'F06'), (9, 'M03'), (14, 'M08'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-02-05 05:23:08.973825
For the Subject 6 (F06):
54/54 [==============================] - 3s 55ms/step
        The absolute mean error on Pitch angle estimation: 16.23 Degree
        The absolute mean error on Yaw angle estimation: 28.94 Degree
        The absolute mean error on Roll angle estimation: 13.99 Degree
For the Subject 9 (M03):
88/88 [==============================] - 5s 56ms/step
        The absolute mean error on Pitch angle estimation: 29.02 Degree
        The absolute mean error on Yaw angle estimation: 37.91 Degree
        The absolute mean error on Roll angle estimation: 6.36 Degree
For the Subject 14 (M08):
79/79 [==============================] - 4s 56ms/step
        The absolute mean error on Pitch angle estimation: 21.90 Degree
        The absolute mean error on Yaw angle estimation: 29.12 Degree
        The absolute mean error on Roll angle estimation: 13.72 Degree
For the Subject 24 (M14):
49/49 [==============================] - 3s 56ms/step
        The absolute mean error on Pitch angle estimation: 9.54 Degree
        The absolute mean error on Yaw angle estimation: 7.56 Degree
        The absolute mean error on Roll angle estimation: 4.08 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 19.17 Degree
        The absolute mean error on Yaw angle estimations: 25.88 Degree
        The absolute mean error on Roll angle estimations: 9.54 Degree
Exp2019-02-05_04-11-13_part2 completed!
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_2019-
02-05_04-11-13
All frames and annotations from 20 datasets have been read by 2019-02-05 05:23:55.992303
1. set (Dataset 20) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:01.357496!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0777
2. set (Dataset 18) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:10.711152!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1249
3. set (Dataset 23) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:20.034787!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1310
4. set (Dataset 17) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:27.316734!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0948
5. set (Dataset 7) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:37.380444!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0775
6. set (Dataset 22) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:48.433974!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0692
7. set (Dataset 15) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:24:58.973591!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0917
8. set (Dataset 13) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:25:07.970310!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0866
9. set (Dataset 5) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:25:20.209334!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0845
10. set (Dataset 11) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:25:31.896198!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0869
11. set (Dataset 10) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:25:42.744476!
Epoch 1/1
72/72 [==============================] - 5s 63ms/step - loss: 0.1048
12. set (Dataset 8) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:25:55.033129!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0908
13. set (Dataset 21) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:26:05.900953!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1550
14. set (Dataset 4) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:26:17.275671!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0942
15. set (Dataset 2) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:26:27.022407!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0875
16. set (Dataset 19) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:26:35.136201!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1090
17. set (Dataset 1) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:26:43.314594!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1310
18. set (Dataset 16) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:26:55.143548!
Epoch 1/1
91/91 [==============================] - 6s 63ms/step - loss: 0.0875
19. set (Dataset 12) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:27:08.194136!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0872
20. set (Dataset 3) being trained for epoch 1 in Experiment 3 by 2019-02-05 05:27:20.100680!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1278
Epoch 1 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:27:29.702773
1. set (Dataset 16) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:27:38.427752!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0819
2. set (Dataset 3) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:27:51.436562!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1273
3. set (Dataset 10) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:28:03.252496!
Epoch 1/1
72/72 [==============================] - 5s 63ms/step - loss: 0.1029
4. set (Dataset 2) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:28:12.882122!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0945
5. set (Dataset 22) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:28:22.524368!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0717
6. set (Dataset 12) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:28:33.960020!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0832
7. set (Dataset 1) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:28:43.587370!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1300
8. set (Dataset 8) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:28:54.408689!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0873
9. set (Dataset 7) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:29:06.840038!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0777
10. set (Dataset 5) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:29:20.661612!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0832
11. set (Dataset 15) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:29:32.956268!
Epoch 1/1
65/65 [==============================] - 4s 61ms/step - loss: 0.0943
12. set (Dataset 20) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:29:42.375495!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0780
13. set (Dataset 4) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:29:53.246440!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0905
14. set (Dataset 18) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:03.778356!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1235
15. set (Dataset 23) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:13.083384!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1336
16. set (Dataset 19) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:21.483002!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1067
17. set (Dataset 21) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:30.659217!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1575
18. set (Dataset 17) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:38.404967!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0945
19. set (Dataset 11) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:46.603222!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0750
20. set (Dataset 13) being trained for epoch 2 in Experiment 3 by 2019-02-05 05:30:55.046236!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0913
Epoch 2 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:31:03.110653
1. set (Dataset 17) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:31:06.865690!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0966
2. set (Dataset 13) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:31:14.135414!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0830
3. set (Dataset 15) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:31:23.534811!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0941
4. set (Dataset 23) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:31:33.080358!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1304
5. set (Dataset 12) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:31:43.893740!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0836
6. set (Dataset 11) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:31:54.187965!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0768
7. set (Dataset 21) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:32:03.764263!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1521
8. set (Dataset 20) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:32:13.136759!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0744
9. set (Dataset 22) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:32:23.004749!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0703
10. set (Dataset 7) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:32:34.754349!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0758
11. set (Dataset 1) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:32:44.452013!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1250
12. set (Dataset 16) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:32:56.266587!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0850
13. set (Dataset 18) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:33:07.852772!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1215
14. set (Dataset 3) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:33:18.987056!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1229
15. set (Dataset 10) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:33:30.794332!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0982
16. set (Dataset 19) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:33:40.202555!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1007
17. set (Dataset 4) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:33:50.739186!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0889
18. set (Dataset 2) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:34:00.490035!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0881
19. set (Dataset 5) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:34:12.895691!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0797
20. set (Dataset 8) being trained for epoch 3 in Experiment 3 by 2019-02-05 05:34:26.526020!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0910
Epoch 3 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:34:36.342813
1. set (Dataset 2) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:34:41.411072!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0933
2. set (Dataset 8) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:34:52.347291!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0858
3. set (Dataset 1) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:35:02.249816!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1250
4. set (Dataset 10) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:35:12.556870!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0972
5. set (Dataset 11) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:35:22.844964!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0728
6. set (Dataset 5) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:35:35.616336!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0784
7. set (Dataset 4) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:35:48.924494!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0905
8. set (Dataset 16) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:36:02.312169!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0817
9. set (Dataset 12) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:36:15.346946!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.0825
10. set (Dataset 22) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:36:26.379275!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0673
11. set (Dataset 21) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:36:36.619719!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1497
12. set (Dataset 17) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:36:44.353553!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.1075
13. set (Dataset 3) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:36:54.146172!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1173
14. set (Dataset 13) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:37:03.541582!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0891
15. set (Dataset 15) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:37:12.902323!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0913
16. set (Dataset 19) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:37:21.868107!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1016
17. set (Dataset 18) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:37:30.912854!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1234
18. set (Dataset 23) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:37:40.224252!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1300
19. set (Dataset 7) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:37:51.335332!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0765
20. set (Dataset 20) being trained for epoch 4 in Experiment 3 by 2019-02-05 05:38:01.358886!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0780
Epoch 4 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:38:09.766637
1. set (Dataset 23) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:38:15.219997!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1261
2. set (Dataset 20) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:38:24.120941!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0765
3. set (Dataset 21) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:38:33.615453!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1504
4. set (Dataset 15) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:38:43.983025!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0876
5. set (Dataset 5) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:38:57.273323!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0787
6. set (Dataset 7) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:39:10.802368!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0733
7. set (Dataset 18) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:39:21.407185!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1189
8. set (Dataset 17) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:39:28.994439!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0912
9. set (Dataset 11) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:39:37.165728!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0709
10. set (Dataset 12) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:39:48.060656!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0819
11. set (Dataset 4) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:00.039586!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0863
12. set (Dataset 2) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:09.807904!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0870
13. set (Dataset 13) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:17.838904!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0858
14. set (Dataset 8) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:28.620740!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0888
15. set (Dataset 1) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:38.522677!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1210
16. set (Dataset 19) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:46.473596!
Epoch 1/1
50/50 [==============================] - 3s 63ms/step - loss: 0.1019
17. set (Dataset 3) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:40:56.980906!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1257
18. set (Dataset 10) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:41:08.810421!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0943
19. set (Dataset 22) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:41:19.760569!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0675
20. set (Dataset 16) being trained for epoch 5 in Experiment 3 by 2019-02-05 05:41:32.650156!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0856
Epoch 5 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:41:43.298626
1. set (Dataset 10) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:41:50.501987!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0901
2. set (Dataset 16) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:42:03.748919!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0792
3. set (Dataset 4) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:42:16.863215!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0866
4. set (Dataset 1) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:42:26.588265!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1219
5. set (Dataset 7) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:42:37.286266!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0734
6. set (Dataset 22) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:42:48.337960!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0665
7. set (Dataset 3) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:42:59.786713!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1166
8. set (Dataset 2) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:43:09.452899!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0866
9. set (Dataset 5) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:43:21.888877!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0736
10. set (Dataset 11) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:43:33.483953!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0738
11. set (Dataset 18) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:43:42.964068!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1217
12. set (Dataset 23) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:43:52.272610!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1277
13. set (Dataset 8) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:44:03.555526!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0843
14. set (Dataset 20) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:44:13.768735!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0767
15. set (Dataset 21) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:44:23.248912!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1503
16. set (Dataset 19) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:44:32.123890!
Epoch 1/1
50/50 [==============================] - 3s 61ms/step - loss: 0.0987
17. set (Dataset 13) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:44:40.042149!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0842
18. set (Dataset 15) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:44:49.450414!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0950
19. set (Dataset 12) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:45:00.838418!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0854
20. set (Dataset 17) being trained for epoch 6 in Experiment 3 by 2019-02-05 05:45:09.160652!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0929
Epoch 6 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:45:16.533718
1. set (Dataset 15) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:45:22.877540!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0875
2. set (Dataset 17) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:45:30.717351!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0860
3. set (Dataset 18) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:45:39.089742!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1161
4. set (Dataset 21) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:45:48.934470!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1486
5. set (Dataset 22) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:45:59.281339!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0664
6. set (Dataset 12) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:46:10.712492!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0774
7. set (Dataset 13) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:46:20.129450!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0844
8. set (Dataset 23) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:46:28.604567!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1273
9. set (Dataset 7) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:46:39.702958!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0758
10. set (Dataset 5) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:46:53.556429!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0762
11. set (Dataset 3) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:47:06.775157!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1166
12. set (Dataset 10) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:47:18.575088!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0953
13. set (Dataset 20) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:47:28.523521!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0729
14. set (Dataset 16) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:47:40.720119!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0803
15. set (Dataset 4) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:47:53.835424!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0860
16. set (Dataset 19) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:48:03.387775!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0970
17. set (Dataset 8) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:48:14.286635!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0860
18. set (Dataset 1) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:48:24.167802!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1123
19. set (Dataset 11) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:48:32.995174!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0729
20. set (Dataset 2) being trained for epoch 7 in Experiment 3 by 2019-02-05 05:48:41.660477!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0839
Epoch 7 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:48:49.720996
1. set (Dataset 1) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:48:54.753889!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1072
2. set (Dataset 2) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:49:02.929826!
Epoch 1/1
51/51 [==============================] - 3s 61ms/step - loss: 0.0841
3. set (Dataset 3) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:49:13.438564!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1147
4. set (Dataset 4) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:49:25.450864!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0926
5. set (Dataset 12) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:49:37.387555!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0800
6. set (Dataset 11) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:49:47.685549!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0678
7. set (Dataset 8) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:49:59.026658!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0856
8. set (Dataset 10) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:50:11.117612!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0939
9. set (Dataset 22) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:50:22.041827!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0668
10. set (Dataset 7) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:50:33.769137!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0711
11. set (Dataset 13) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:50:43.233823!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0792
12. set (Dataset 15) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:50:52.604864!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0916
13. set (Dataset 16) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:51:05.493998!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0839
14. set (Dataset 17) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:51:14.994401!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0886
15. set (Dataset 18) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:51:23.358740!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1170
16. set (Dataset 19) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:51:32.102881!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1054
17. set (Dataset 20) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:51:40.648191!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0710
18. set (Dataset 21) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:51:50.138051!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1495
19. set (Dataset 5) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:52:03.309872!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0734
20. set (Dataset 23) being trained for epoch 8 in Experiment 3 by 2019-02-05 05:52:14.671192!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1250
Epoch 8 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:52:23.196335
1. set (Dataset 21) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:52:29.204597!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1395
2. set (Dataset 23) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:52:38.624792!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1226
3. set (Dataset 13) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:52:46.987747!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0796
4. set (Dataset 18) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:52:55.934882!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1143
5. set (Dataset 11) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:53:05.493310!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0803
6. set (Dataset 5) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:53:18.278554!
Epoch 1/1
94/94 [==============================] - 6s 63ms/step - loss: 0.0742
7. set (Dataset 20) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:53:29.584692!
Epoch 1/1
55/55 [==============================] - 3s 63ms/step - loss: 0.0725
8. set (Dataset 15) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:53:39.459065!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0893
9. set (Dataset 12) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:53:50.842059!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0792
10. set (Dataset 22) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:01.818375!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0653
11. set (Dataset 8) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:13.713844!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0871
12. set (Dataset 1) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:23.626437!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1105
13. set (Dataset 17) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:30.468706!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0889
14. set (Dataset 2) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:38.006430!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0941
15. set (Dataset 3) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:48.509304!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1142
16. set (Dataset 19) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:54:57.978275!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1036
17. set (Dataset 16) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:55:09.882525!
Epoch 1/1
91/91 [==============================] - 6s 63ms/step - loss: 0.0825
18. set (Dataset 4) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:55:23.061836!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0859
19. set (Dataset 7) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:55:35.306181!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0705
20. set (Dataset 10) being trained for epoch 9 in Experiment 3 by 2019-02-05 05:55:47.197951!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0917
Epoch 9 for Experiment 3 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 05:55:56.593955
1. set (Dataset 4) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:56:03.965490!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0825
2. set (Dataset 10) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:56:15.867095!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0851
3. set (Dataset 8) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:56:28.133029!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0836
4. set (Dataset 3) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:56:40.278891!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1126
5. set (Dataset 5) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:56:54.071726!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0710
6. set (Dataset 7) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:57:07.578865!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0717
7. set (Dataset 16) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:57:21.003523!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0789
8. set (Dataset 1) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:57:31.778077!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1091
9. set (Dataset 11) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:57:40.587410!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0724
10. set (Dataset 12) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:57:51.482178!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0796
11. set (Dataset 20) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:01.431152!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0723
12. set (Dataset 21) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:10.923859!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1440
13. set (Dataset 2) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:19.998517!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0892
14. set (Dataset 23) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:28.707417!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1225
15. set (Dataset 13) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:37.058503!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0857
16. set (Dataset 19) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:44.975224!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0989
17. set (Dataset 17) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:58:51.865264!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0909
18. set (Dataset 18) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:59:00.241684!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1140
19. set (Dataset 22) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:59:10.492041!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0661
20. set (Dataset 15) being trained for epoch 10 in Experiment 3 by 2019-02-05 05:59:21.009169!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0917
Epoch 10 for Experiment 3 completed!
Exp2019-02-05_04-11-13_part3.h5 has been saved.
The subjects are trained: [(4, 'F04'), (10, 'M04'), (8, 'M02'), (3, 'F03'), (5, 'F05'), (7, 'M01'), (16, 'M09'), (1, 'F0
1'), (11, 'M05'), (12, 'M06'), (20, 'M12'), (21, 'F02'), (2, 'F02'), (23, 'M13'), (13, 'M07'), (19, 'M11'), (17, 'M10'),
 (18, 'F05'), (22, 'M01'), (15, 'F03')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_201
9-02-05_04-11-13
The subjects will be tested: [(6, 'F06'), (9, 'M03'), (14, 'M08'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-02-05 05:59:26.752660
For the Subject 6 (F06):
54/54 [==============================] - 3s 55ms/step
        The absolute mean error on Pitch angle estimation: 16.05 Degree
        The absolute mean error on Yaw angle estimation: 22.85 Degree
        The absolute mean error on Roll angle estimation: 13.92 Degree
For the Subject 9 (M03):
88/88 [==============================] - 5s 56ms/step
        The absolute mean error on Pitch angle estimation: 25.63 Degree
        The absolute mean error on Yaw angle estimation: 33.17 Degree
        The absolute mean error on Roll angle estimation: 6.91 Degree
For the Subject 14 (M08):
79/79 [==============================] - 4s 56ms/step
        The absolute mean error on Pitch angle estimation: 21.96 Degree
        The absolute mean error on Yaw angle estimation: 30.07 Degree
        The absolute mean error on Roll angle estimation: 14.41 Degree
For the Subject 24 (M14):
49/49 [==============================] - 3s 57ms/step
        The absolute mean error on Pitch angle estimation: 9.89 Degree
        The absolute mean error on Yaw angle estimation: 8.85 Degree
        The absolute mean error on Roll angle estimation: 3.85 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 18.38 Degree
        The absolute mean error on Yaw angle estimations: 23.74 Degree
        The absolute mean error on Roll angle estimations: 9.77 Degree
Exp2019-02-05_04-11-13_part3 completed!
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_2019-
02-05_04-11-13
All frames and annotations from 20 datasets have been read by 2019-02-05 06:00:13.623485
1. set (Dataset 18) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:00:19.496411!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1098
2. set (Dataset 15) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:00:29.685579!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0868
3. set (Dataset 20) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:00:39.131376!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0720
4. set (Dataset 13) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:00:47.439229!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0793
5. set (Dataset 7) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:00:58.059966!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0692
6. set (Dataset 22) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:01:09.105319!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0649
7. set (Dataset 17) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:01:17.011773!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0865
8. set (Dataset 21) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:01:25.485415!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1423
9. set (Dataset 5) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:01:38.646320!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0693
10. set (Dataset 11) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:01:50.267071!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0704
11. set (Dataset 16) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:02:02.630750!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0775
12. set (Dataset 4) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:02:15.747288!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0834
13. set (Dataset 23) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:02:25.835840!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1220
14. set (Dataset 10) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:02:36.597760!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0885
15. set (Dataset 8) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:02:48.887240!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0828
16. set (Dataset 19) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:02:58.623330!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0947
17. set (Dataset 2) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:03:06.851531!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0904
18. set (Dataset 3) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:03:17.404244!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1131
19. set (Dataset 12) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:03:29.296164!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0791
20. set (Dataset 1) being trained for epoch 1 in Experiment 4 by 2019-02-05 06:03:38.910566!
Epoch 1/1
49/49 [==============================] - 3s 63ms/step - loss: 0.1009
Epoch 1 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:03:46.920157
1. set (Dataset 3) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:03:54.205659!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1110
2. set (Dataset 1) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:04:03.846179!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.1004
3. set (Dataset 16) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:04:15.685387!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0787
4. set (Dataset 8) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:04:29.161000!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0810
5. set (Dataset 22) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:04:40.440468!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0640
6. set (Dataset 12) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:04:51.849758!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0730
7. set (Dataset 2) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:05:01.508846!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0854
8. set (Dataset 4) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:05:12.124990!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0829
9. set (Dataset 7) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:05:24.386779!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0689
10. set (Dataset 5) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:05:38.234560!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0702
11. set (Dataset 17) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:05:47.874224!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0844
12. set (Dataset 18) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:05:56.206803!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1109
13. set (Dataset 10) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:06:07.310589!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0861
14. set (Dataset 15) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:06:18.197517!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0895
15. set (Dataset 20) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:06:27.626364!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0739
16. set (Dataset 19) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:06:35.989380!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0975
17. set (Dataset 23) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:06:44.591146!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1278
18. set (Dataset 13) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:06:52.951879!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0801
19. set (Dataset 11) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:07:01.688389!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0816
20. set (Dataset 21) being trained for epoch 2 in Experiment 4 by 2019-02-05 06:07:11.299003!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1441
Epoch 2 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:07:20.168657
1. set (Dataset 13) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:07:24.979746!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0830
2. set (Dataset 21) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:07:33.996409!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1394
3. set (Dataset 17) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:07:41.715467!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0849
4. set (Dataset 20) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:07:49.545757!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0700
5. set (Dataset 12) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:08:00.284587!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0774
6. set (Dataset 11) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:08:10.603100!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0669
7. set (Dataset 23) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:08:19.649736!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1194
8. set (Dataset 18) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:08:29.082074!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1081
9. set (Dataset 22) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:08:39.323897!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0647
10. set (Dataset 7) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:08:51.089754!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0693
11. set (Dataset 2) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:09:00.826233!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0845
12. set (Dataset 3) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:09:11.332406!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1096
13. set (Dataset 15) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:09:22.320811!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0875
14. set (Dataset 1) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:09:31.479925!
Epoch 1/1
49/49 [==============================] - 3s 61ms/step - loss: 0.0975
15. set (Dataset 16) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:09:43.219228!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0820
16. set (Dataset 19) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:09:53.850363!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0959
17. set (Dataset 10) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:10:04.275453!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0848
18. set (Dataset 8) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:10:16.525432!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0839
19. set (Dataset 5) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:10:30.565596!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0725
20. set (Dataset 4) being trained for epoch 3 in Experiment 4 by 2019-02-05 06:10:43.873116!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0792
Epoch 3 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:10:53.466017
1. set (Dataset 8) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:11:01.192462!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0837
2. set (Dataset 4) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:11:13.392832!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0781
3. set (Dataset 2) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:11:23.119910!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0767
4. set (Dataset 16) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:11:35.105136!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0784
5. set (Dataset 11) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:11:46.526351!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0680
6. set (Dataset 5) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:11:59.325814!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0708
7. set (Dataset 10) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:12:12.466830!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0827
8. set (Dataset 3) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:12:24.343317!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1083
9. set (Dataset 12) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:12:36.251357!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0738
10. set (Dataset 22) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:12:47.248906!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0626
11. set (Dataset 23) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:12:56.859669!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1284
12. set (Dataset 13) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:05.227002!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0816
13. set (Dataset 1) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:13.304426!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0904
14. set (Dataset 21) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:22.427753!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1357
15. set (Dataset 17) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:30.148083!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0834
16. set (Dataset 19) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:37.521942!
Epoch 1/1
50/50 [==============================] - 3s 61ms/step - loss: 0.0976
17. set (Dataset 15) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:47.032530!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0867
18. set (Dataset 20) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:13:56.512273!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0720
19. set (Dataset 7) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:14:07.551727!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0689
20. set (Dataset 18) being trained for epoch 4 in Experiment 4 by 2019-02-05 06:14:18.118882!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1085
Epoch 4 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:14:26.943134
1. set (Dataset 20) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:14:32.302262!
Epoch 1/1
55/55 [==============================] - 3s 60ms/step - loss: 0.0714
2. set (Dataset 18) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:14:41.573588!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1055
3. set (Dataset 23) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:14:50.865260!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1191
4. set (Dataset 17) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:14:58.159881!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0855
5. set (Dataset 5) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:15:09.804518!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0692
6. set (Dataset 7) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:15:23.317936!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0665
7. set (Dataset 15) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:15:34.375577!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0870
8. set (Dataset 13) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:15:43.313050!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0840
9. set (Dataset 11) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:15:52.063549!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0700
10. set (Dataset 12) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:16:02.947768!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0732
11. set (Dataset 10) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:16:14.778508!
Epoch 1/1
72/72 [==============================] - 5s 63ms/step - loss: 0.0821
12. set (Dataset 8) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:16:27.065546!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0848
13. set (Dataset 21) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:16:37.946530!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1345
14. set (Dataset 4) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:16:49.299117!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0826
15. set (Dataset 2) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:16:59.013929!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0851
16. set (Dataset 19) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:17:07.134884!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0956
17. set (Dataset 1) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:17:15.344594!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0988
18. set (Dataset 16) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:17:27.195127!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0767
19. set (Dataset 22) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:17:39.320953!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0672
20. set (Dataset 3) being trained for epoch 5 in Experiment 4 by 2019-02-05 06:17:50.793862!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1129
Epoch 5 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:18:00.286763
1. set (Dataset 16) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:18:09.016521!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0761
2. set (Dataset 3) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:18:22.052857!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1082
3. set (Dataset 10) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:18:33.881789!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0822
4. set (Dataset 2) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:18:43.474018!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0884
5. set (Dataset 7) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:18:54.262169!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0687
6. set (Dataset 22) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:19:05.320865!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0640
7. set (Dataset 1) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:19:14.502167!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0962
8. set (Dataset 8) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:19:25.349546!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0816
9. set (Dataset 5) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:19:39.389604!
Epoch 1/1
94/94 [==============================] - 6s 63ms/step - loss: 0.0716
10. set (Dataset 11) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:19:51.043604!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0679
11. set (Dataset 15) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:00.988908!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0855
12. set (Dataset 20) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:10.465551!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0717
13. set (Dataset 4) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:21.334542!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0777
14. set (Dataset 18) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:31.892926!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1057
15. set (Dataset 23) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:41.187108!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1171
16. set (Dataset 19) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:49.592865!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1027
17. set (Dataset 21) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:20:58.774884!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1341
18. set (Dataset 17) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:21:06.500848!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0828
19. set (Dataset 12) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:21:16.252686!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.0730
20. set (Dataset 13) being trained for epoch 6 in Experiment 4 by 2019-02-05 06:21:25.703608!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0825
Epoch 6 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:21:33.740149
1. set (Dataset 17) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:21:37.474523!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0832
2. set (Dataset 13) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:21:44.739920!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0751
3. set (Dataset 15) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:21:54.115429!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0857
4. set (Dataset 23) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:22:03.663227!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1192
5. set (Dataset 22) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:22:13.611221!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0640
6. set (Dataset 12) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:22:25.081298!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0716
7. set (Dataset 21) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:22:35.740958!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1338
8. set (Dataset 20) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:22:45.113819!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0722
9. set (Dataset 7) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:22:56.180127!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0659
10. set (Dataset 5) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:23:10.050215!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0695
11. set (Dataset 1) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:23:21.023543!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0953
12. set (Dataset 16) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:23:32.865936!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0748
13. set (Dataset 18) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:23:44.445438!
Epoch 1/1
61/61 [==============================] - 4s 63ms/step - loss: 0.1042
14. set (Dataset 3) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:23:55.651398!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1094
15. set (Dataset 10) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:24:07.465963!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0805
16. set (Dataset 19) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:24:16.891660!
Epoch 1/1
50/50 [==============================] - 3s 61ms/step - loss: 0.0999
17. set (Dataset 4) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:24:27.380606!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0754
18. set (Dataset 2) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:24:37.135354!
Epoch 1/1
51/51 [==============================] - 3s 63ms/step - loss: 0.0861
19. set (Dataset 11) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:24:46.088811!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0668
20. set (Dataset 8) being trained for epoch 7 in Experiment 4 by 2019-02-05 06:24:57.407795!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0809
Epoch 7 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:25:07.209602
1. set (Dataset 2) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:25:12.282308!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0858
2. set (Dataset 8) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:25:23.206263!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0796
3. set (Dataset 1) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:25:33.102369!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0899
4. set (Dataset 10) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:25:43.411320!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0791
5. set (Dataset 12) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:25:55.271459!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0713
6. set (Dataset 11) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:26:05.577976!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0640
7. set (Dataset 4) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:26:16.579648!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0734
8. set (Dataset 16) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:26:29.982049!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0745
9. set (Dataset 22) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:26:42.085393!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0641
10. set (Dataset 7) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:26:53.826552!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0672
11. set (Dataset 21) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:04.523658!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1339
12. set (Dataset 17) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:12.230549!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0838
13. set (Dataset 3) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:21.995687!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1088
14. set (Dataset 13) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:31.404146!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0801
15. set (Dataset 15) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:40.773062!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0897
16. set (Dataset 19) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:49.762994!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0959
17. set (Dataset 18) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:27:58.799450!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1055
18. set (Dataset 23) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:28:08.084960!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1158
19. set (Dataset 5) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:28:20.792607!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0727
20. set (Dataset 20) being trained for epoch 8 in Experiment 4 by 2019-02-05 06:28:32.060911!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0711
Epoch 8 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:28:40.604132
1. set (Dataset 23) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:28:46.048894!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1168
2. set (Dataset 20) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:28:54.916710!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0692
3. set (Dataset 21) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:29:04.387316!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1299
4. set (Dataset 15) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:29:14.739090!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0822
5. set (Dataset 11) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:29:24.549054!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0656
6. set (Dataset 5) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:29:37.339717!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0693
7. set (Dataset 18) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:29:49.146446!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1009
8. set (Dataset 17) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:29:56.759015!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0818
9. set (Dataset 12) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:30:06.499772!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0721
10. set (Dataset 22) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:30:17.551908!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0644
11. set (Dataset 4) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:30:29.101046!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0758
12. set (Dataset 2) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:30:38.855736!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0823
13. set (Dataset 13) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:30:46.880712!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0817
14. set (Dataset 8) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:30:57.640766!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0857
15. set (Dataset 1) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:31:07.554188!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0947
16. set (Dataset 19) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:31:15.565377!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0967
17. set (Dataset 3) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:31:26.028162!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1066
18. set (Dataset 10) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:31:37.839162!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0763
19. set (Dataset 7) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:31:49.950220!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0675
20. set (Dataset 16) being trained for epoch 9 in Experiment 4 by 2019-02-05 06:32:03.337015!
Epoch 1/1
91/91 [==============================] - 6s 63ms/step - loss: 0.0750
Epoch 9 for Experiment 4 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:32:14.007925
1. set (Dataset 10) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:32:21.235732!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0787
2. set (Dataset 16) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:32:34.497546!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0752
3. set (Dataset 4) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:32:47.608079!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0773
4. set (Dataset 1) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:32:57.336825!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0906
5. set (Dataset 5) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:33:09.633391!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0676
6. set (Dataset 7) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:33:23.108914!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0659
7. set (Dataset 3) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:33:35.112035!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.1066
8. set (Dataset 2) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:33:44.854136!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0876
9. set (Dataset 11) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:33:53.744069!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0620
10. set (Dataset 12) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:34:04.631329!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0724
11. set (Dataset 18) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:34:15.103923!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.1042
12. set (Dataset 23) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:34:24.404721!
Epoch 1/1
56/56 [==============================] - 4s 63ms/step - loss: 0.1259
13. set (Dataset 8) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:34:35.728336!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0807
14. set (Dataset 20) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:34:45.920474!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0718
15. set (Dataset 21) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:34:55.405270!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1306
16. set (Dataset 19) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:35:04.261683!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0947
17. set (Dataset 13) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:35:12.225043!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0811
18. set (Dataset 15) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:35:21.636414!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0863
19. set (Dataset 22) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:35:32.127467!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0633
20. set (Dataset 17) being trained for epoch 10 in Experiment 4 by 2019-02-05 06:35:40.046309!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0825
Epoch 10 for Experiment 4 completed!
Exp2019-02-05_04-11-13_part4.h5 has been saved.
The subjects are trained: [(10, 'M04'), (16, 'M09'), (4, 'F04'), (1, 'F01'), (5, 'F05'), (7, 'M01'), (3, 'F03'), (2, 'F0
2'), (11, 'M05'), (12, 'M06'), (18, 'F05'), (23, 'M13'), (8, 'M02'), (20, 'M12'), (21, 'F02'), (19, 'M11'), (13, 'M07'),
 (15, 'F03'), (22, 'M01'), (17, 'M10')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_201
9-02-05_04-11-13
The subjects will be tested: [(6, 'F06'), (9, 'M03'), (14, 'M08'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-02-05 06:35:44.116050
For the Subject 6 (F06):
54/54 [==============================] - 3s 55ms/step
        The absolute mean error on Pitch angle estimation: 19.12 Degree
        The absolute mean error on Yaw angle estimation: 24.83 Degree
        The absolute mean error on Roll angle estimation: 13.56 Degree
For the Subject 9 (M03):
88/88 [==============================] - 5s 56ms/step
        The absolute mean error on Pitch angle estimation: 26.47 Degree
        The absolute mean error on Yaw angle estimation: 30.35 Degree
        The absolute mean error on Roll angle estimation: 7.26 Degree
For the Subject 14 (M08):
79/79 [==============================] - 4s 56ms/step
        The absolute mean error on Pitch angle estimation: 21.32 Degree
        The absolute mean error on Yaw angle estimation: 28.08 Degree
        The absolute mean error on Roll angle estimation: 14.05 Degree
For the Subject 24 (M14):
49/49 [==============================] - 3s 56ms/step
        The absolute mean error on Pitch angle estimation: 10.62 Degree
        The absolute mean error on Yaw angle estimation: 9.20 Degree
        The absolute mean error on Roll angle estimation: 3.97 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 19.38 Degree
        The absolute mean error on Yaw angle estimations: 23.11 Degree
        The absolute mean error on Roll angle estimations: 9.71 Degree
Exp2019-02-05_04-11-13_part4 completed!
Training model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_2019-
02-05_04-11-13
All frames and annotations from 20 datasets have been read by 2019-02-05 06:36:30.936933
1. set (Dataset 15) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:36:37.280456!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0865
2. set (Dataset 17) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:36:45.090102!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0821
3. set (Dataset 18) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:36:53.442209!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0973
4. set (Dataset 21) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:37:03.307803!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1297
5. set (Dataset 7) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:37:14.838688!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0660
6. set (Dataset 22) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:37:25.888763!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0630
7. set (Dataset 13) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:37:34.836675!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0759
8. set (Dataset 23) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:37:43.341287!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1158
9. set (Dataset 5) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:37:56.099191!
Epoch 1/1
94/94 [==============================] - 5s 54ms/step - loss: 0.0707
10. set (Dataset 11) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:38:06.981137!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0684
11. set (Dataset 3) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:38:17.869759!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1053
12. set (Dataset 10) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:38:29.665875!
Epoch 1/1
72/72 [==============================] - 5s 63ms/step - loss: 0.0784
13. set (Dataset 20) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:38:39.604379!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0671
14. set (Dataset 16) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:38:51.813321!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0764
15. set (Dataset 4) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:39:04.898187!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0720
16. set (Dataset 19) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:39:14.421262!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0943
17. set (Dataset 8) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:39:25.295058!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0780
18. set (Dataset 1) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:39:35.163832!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0947
19. set (Dataset 12) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:39:45.502738!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0670
20. set (Dataset 2) being trained for epoch 1 in Experiment 5 by 2019-02-05 06:39:55.161642!
Epoch 1/1
51/51 [==============================] - 3s 63ms/step - loss: 0.0861
Epoch 1 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:40:03.293120
1. set (Dataset 1) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:40:08.316238!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0872
2. set (Dataset 2) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:40:16.470340!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0869
3. set (Dataset 3) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:40:26.989021!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1085
4. set (Dataset 4) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:40:38.958977!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0731
5. set (Dataset 22) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:40:49.989931!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0621
6. set (Dataset 12) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:41:01.446759!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.0687
7. set (Dataset 8) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:41:13.801379!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0805
8. set (Dataset 10) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:41:25.884386!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0774
9. set (Dataset 7) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:41:37.973695!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0676
10. set (Dataset 5) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:41:51.794781!
Epoch 1/1
94/94 [==============================] - 6s 63ms/step - loss: 0.0702
11. set (Dataset 13) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:02.564220!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0792
12. set (Dataset 15) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:11.988150!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0870
13. set (Dataset 16) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:24.812662!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0764
14. set (Dataset 17) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:34.248430!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0877
15. set (Dataset 18) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:42.603535!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0978
16. set (Dataset 19) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:51.336928!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.1035
17. set (Dataset 20) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:42:59.854724!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0705
18. set (Dataset 21) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:43:09.319685!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1296
19. set (Dataset 11) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:43:18.984390!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0689
20. set (Dataset 23) being trained for epoch 2 in Experiment 5 by 2019-02-05 06:43:28.049161!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1194
Epoch 2 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:43:36.519247
1. set (Dataset 21) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:43:42.513174!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1295
2. set (Dataset 23) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:43:51.974006!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1122
3. set (Dataset 13) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:00.316538!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0783
4. set (Dataset 18) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:09.216098!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0961
5. set (Dataset 12) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:20.351149!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0699
6. set (Dataset 11) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:30.633955!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0636
7. set (Dataset 20) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:39.606299!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0667
8. set (Dataset 15) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:49.371597!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0837
9. set (Dataset 22) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:44:59.872697!
Epoch 1/1
66/66 [==============================] - 4s 63ms/step - loss: 0.0641
10. set (Dataset 7) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:45:11.617992!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0648
11. set (Dataset 8) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:45:24.032569!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0793
12. set (Dataset 1) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:45:33.920261!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0928
13. set (Dataset 17) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:45:40.740255!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0787
14. set (Dataset 2) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:45:48.261821!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0812
15. set (Dataset 3) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:45:58.787688!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1061
16. set (Dataset 19) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:46:08.239047!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0977
17. set (Dataset 16) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:46:20.112040!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0748
18. set (Dataset 4) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:46:33.228867!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0707
19. set (Dataset 5) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:46:47.116418!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0707
20. set (Dataset 10) being trained for epoch 3 in Experiment 5 by 2019-02-05 06:47:00.250109!
Epoch 1/1
72/72 [==============================] - 5s 63ms/step - loss: 0.0763
Epoch 3 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:47:09.739312
1. set (Dataset 4) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:47:17.104593!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0704
2. set (Dataset 10) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:47:28.999450!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0746
3. set (Dataset 8) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:47:41.254475!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0777
4. set (Dataset 3) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:47:53.429807!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1056
5. set (Dataset 11) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:48:03.727226!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0636
6. set (Dataset 5) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:48:16.568242!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0697
7. set (Dataset 16) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:48:31.212306!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0735
8. set (Dataset 1) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:48:41.967549!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0868
9. set (Dataset 12) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:48:52.326330!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0681
10. set (Dataset 22) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:03.317909!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0621
11. set (Dataset 20) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:12.816867!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0680
12. set (Dataset 21) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:22.302407!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1232
13. set (Dataset 2) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:31.336514!
Epoch 1/1
51/51 [==============================] - 3s 61ms/step - loss: 0.0800
14. set (Dataset 23) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:39.918585!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1087
15. set (Dataset 13) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:48.267517!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0765
16. set (Dataset 19) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:49:56.166037!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0942
17. set (Dataset 17) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:50:03.042662!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0840
18. set (Dataset 18) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:50:11.386052!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0972
19. set (Dataset 7) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:50:22.792171!
Epoch 1/1
74/74 [==============================] - 5s 63ms/step - loss: 0.0657
20. set (Dataset 15) being trained for epoch 4 in Experiment 5 by 2019-02-05 06:50:33.818007!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0844
Epoch 4 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:50:42.873774
1. set (Dataset 18) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:50:48.735643!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0959
2. set (Dataset 15) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:50:58.919665!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0825
3. set (Dataset 20) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:51:08.362270!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0673
4. set (Dataset 13) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:51:16.630056!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0784
5. set (Dataset 5) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:51:28.869386!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0653
6. set (Dataset 7) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:51:42.356754!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0630
7. set (Dataset 17) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:51:50.733035!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0783
8. set (Dataset 21) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:51:59.238321!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1280
9. set (Dataset 11) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:52:08.894080!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0629
10. set (Dataset 12) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:52:19.752658!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0680
11. set (Dataset 16) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:52:33.067193!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0736
12. set (Dataset 4) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:52:46.142663!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0754
13. set (Dataset 23) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:52:56.270601!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1115
14. set (Dataset 10) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:53:07.070691!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0746
15. set (Dataset 8) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:53:19.313475!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0801
16. set (Dataset 19) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:53:29.018444!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0918
17. set (Dataset 2) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:53:37.265098!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0840
18. set (Dataset 3) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:53:47.788611!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.1046
19. set (Dataset 22) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:53:58.802942!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0624
20. set (Dataset 1) being trained for epoch 5 in Experiment 5 by 2019-02-05 06:54:07.991615!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0861
Epoch 5 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:54:15.989131
1. set (Dataset 3) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:54:23.262606!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1049
2. set (Dataset 1) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:54:32.868006!
Epoch 1/1
49/49 [==============================] - 3s 60ms/step - loss: 0.0893
3. set (Dataset 16) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:54:44.611510!
Epoch 1/1
91/91 [==============================] - 6s 63ms/step - loss: 0.0713
4. set (Dataset 8) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:54:58.089482!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0764
5. set (Dataset 7) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:55:10.510003!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0642
6. set (Dataset 22) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:55:21.543004!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0613
7. set (Dataset 2) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:55:30.796788!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0767
8. set (Dataset 4) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:55:41.396855!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0713
9. set (Dataset 5) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:55:55.229214!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0675
10. set (Dataset 11) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:56:06.843224!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0612
11. set (Dataset 17) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:56:14.181458!
Epoch 1/1
39/39 [==============================] - 2s 61ms/step - loss: 0.0806
12. set (Dataset 18) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:56:22.518422!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0933
13. set (Dataset 10) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:56:33.550050!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0729
14. set (Dataset 15) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:56:44.451068!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0817
15. set (Dataset 20) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:56:53.924026!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0681
16. set (Dataset 19) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:57:02.283105!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0955
17. set (Dataset 23) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:57:10.882775!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1062
18. set (Dataset 13) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:57:19.240027!
Epoch 1/1
48/48 [==============================] - 3s 63ms/step - loss: 0.0799
19. set (Dataset 12) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:57:29.548223!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0679
20. set (Dataset 21) being trained for epoch 6 in Experiment 5 by 2019-02-05 06:57:40.127387!
Epoch 1/1
63/63 [==============================] - 4s 63ms/step - loss: 0.1229
Epoch 6 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 06:57:49.162795
1. set (Dataset 13) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:57:53.956492!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0788
2. set (Dataset 21) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:02.971699!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1241
3. set (Dataset 17) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:10.683053!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0773
4. set (Dataset 20) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:18.538627!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0665
5. set (Dataset 22) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:28.393201!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0591
6. set (Dataset 12) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:39.847648!
Epoch 1/1
73/73 [==============================] - 4s 52ms/step - loss: 0.0647
7. set (Dataset 23) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:49.188829!
Epoch 1/1
56/56 [==============================] - 3s 53ms/step - loss: 0.1086
8. set (Dataset 18) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:58:58.074862!
Epoch 1/1
61/61 [==============================] - 4s 60ms/step - loss: 0.0942
9. set (Dataset 7) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:59:09.397896!
Epoch 1/1
74/74 [==============================] - 4s 59ms/step - loss: 0.0638
10. set (Dataset 5) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:59:23.037999!
Epoch 1/1
94/94 [==============================] - 5s 55ms/step - loss: 0.0673
11. set (Dataset 2) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:59:34.039773!
Epoch 1/1
51/51 [==============================] - 3s 59ms/step - loss: 0.0839
12. set (Dataset 3) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:59:44.516873!
Epoch 1/1
73/73 [==============================] - 4s 60ms/step - loss: 0.1029
13. set (Dataset 15) being trained for epoch 7 in Experiment 5 by 2019-02-05 06:59:55.281142!
Epoch 1/1
65/65 [==============================] - 3s 53ms/step - loss: 0.0811
14. set (Dataset 1) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:00:03.811053!
Epoch 1/1
49/49 [==============================] - 3s 59ms/step - loss: 0.0906
15. set (Dataset 16) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:00:15.575453!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0716
16. set (Dataset 19) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:00:26.168631!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0982
17. set (Dataset 10) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:00:36.555844!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0739
18. set (Dataset 8) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:00:48.832319!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0776
19. set (Dataset 11) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:00:59.383388!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0606
20. set (Dataset 4) being trained for epoch 7 in Experiment 5 by 2019-02-05 07:01:10.417006!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0703
Epoch 7 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 07:01:20.012911
1. set (Dataset 8) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:01:27.740751!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0777
2. set (Dataset 4) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:01:39.970501!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0686
3. set (Dataset 2) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:01:49.699939!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0810
4. set (Dataset 16) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:02:01.729189!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0738
5. set (Dataset 12) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:02:14.719015!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0657
6. set (Dataset 11) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:02:25.023381!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0634
7. set (Dataset 10) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:02:35.851308!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0712
8. set (Dataset 3) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:02:47.678505!
Epoch 1/1
73/73 [==============================] - 5s 63ms/step - loss: 0.1044
9. set (Dataset 22) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:02:58.674016!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0609
10. set (Dataset 7) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:03:10.380337!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0648
11. set (Dataset 23) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:03:20.481090!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1043
12. set (Dataset 13) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:03:28.818731!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0739
13. set (Dataset 1) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:03:36.875892!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0865
14. set (Dataset 21) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:03:45.987320!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1277
15. set (Dataset 17) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:03:53.683930!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0826
16. set (Dataset 19) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:04:01.018698!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0967
17. set (Dataset 15) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:04:10.532121!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0837
18. set (Dataset 20) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:04:20.037769!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0642
19. set (Dataset 5) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:04:32.730771!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0710
20. set (Dataset 18) being trained for epoch 8 in Experiment 5 by 2019-02-05 07:04:44.463423!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0942
Epoch 8 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 07:04:53.258353
1. set (Dataset 20) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:04:58.600677!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0644
2. set (Dataset 18) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:05:07.955198!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0942
3. set (Dataset 23) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:05:17.265008!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1051
4. set (Dataset 17) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:05:24.527404!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0771
5. set (Dataset 11) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:05:32.677170!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0609
6. set (Dataset 5) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:05:45.433455!
Epoch 1/1
94/94 [==============================] - 6s 63ms/step - loss: 0.0705
7. set (Dataset 15) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:05:57.719269!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0828
8. set (Dataset 13) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:06:06.628513!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0761
9. set (Dataset 12) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:06:16.936632!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0652
10. set (Dataset 22) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:06:27.914958!
Epoch 1/1
66/66 [==============================] - 4s 63ms/step - loss: 0.0589
11. set (Dataset 10) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:06:39.307403!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0736
12. set (Dataset 8) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:06:51.562650!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0762
13. set (Dataset 21) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:07:02.385825!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1245
14. set (Dataset 4) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:07:13.704919!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0731
15. set (Dataset 2) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:07:23.432896!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0831
16. set (Dataset 19) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:07:31.525732!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0921
17. set (Dataset 1) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:07:39.727857!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0929
18. set (Dataset 16) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:07:51.544166!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0759
19. set (Dataset 7) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:08:04.838951!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0640
20. set (Dataset 3) being trained for epoch 9 in Experiment 5 by 2019-02-05 07:08:16.796979!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1048
Epoch 9 for Experiment 5 completed!
All frames and annotations from 20 datasets have been read by 2019-02-05 07:08:26.283889
1. set (Dataset 16) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:08:34.990201!
Epoch 1/1
91/91 [==============================] - 6s 62ms/step - loss: 0.0721
2. set (Dataset 3) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:08:47.971265!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.1049
3. set (Dataset 10) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:08:59.774021!
Epoch 1/1
72/72 [==============================] - 4s 62ms/step - loss: 0.0717
4. set (Dataset 2) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:09:09.391595!
Epoch 1/1
51/51 [==============================] - 3s 62ms/step - loss: 0.0828
5. set (Dataset 5) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:09:21.764423!
Epoch 1/1
94/94 [==============================] - 6s 62ms/step - loss: 0.0643
6. set (Dataset 7) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:09:35.262244!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0621
7. set (Dataset 1) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:09:44.962489!
Epoch 1/1
49/49 [==============================] - 3s 62ms/step - loss: 0.0830
8. set (Dataset 8) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:09:55.761226!
Epoch 1/1
77/77 [==============================] - 5s 62ms/step - loss: 0.0787
9. set (Dataset 11) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:10:06.327196!
Epoch 1/1
57/57 [==============================] - 4s 62ms/step - loss: 0.0624
10. set (Dataset 12) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:10:17.195116!
Epoch 1/1
73/73 [==============================] - 5s 62ms/step - loss: 0.0620
11. set (Dataset 15) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:10:28.134373!
Epoch 1/1
65/65 [==============================] - 4s 62ms/step - loss: 0.0825
12. set (Dataset 20) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:10:37.582757!
Epoch 1/1
55/55 [==============================] - 3s 62ms/step - loss: 0.0645
13. set (Dataset 4) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:10:48.426798!
Epoch 1/1
74/74 [==============================] - 5s 62ms/step - loss: 0.0697
14. set (Dataset 18) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:10:58.936621!
Epoch 1/1
61/61 [==============================] - 4s 62ms/step - loss: 0.0969
15. set (Dataset 23) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:11:08.230227!
Epoch 1/1
56/56 [==============================] - 3s 62ms/step - loss: 0.1074
16. set (Dataset 19) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:11:16.629672!
Epoch 1/1
50/50 [==============================] - 3s 62ms/step - loss: 0.0947
17. set (Dataset 21) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:11:25.826616!
Epoch 1/1
63/63 [==============================] - 4s 62ms/step - loss: 0.1235
18. set (Dataset 17) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:11:33.527331!
Epoch 1/1
39/39 [==============================] - 2s 62ms/step - loss: 0.0794
19. set (Dataset 22) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:11:42.410377!
Epoch 1/1
66/66 [==============================] - 4s 62ms/step - loss: 0.0595
20. set (Dataset 13) being trained for epoch 10 in Experiment 5 by 2019-02-05 07:11:51.371967!
Epoch 1/1
48/48 [==============================] - 3s 62ms/step - loss: 0.0815
Epoch 10 for Experiment 5 completed!
Exp2019-02-05_04-11-13_part5.h5 has been saved.
The subjects are trained: [(16, 'M09'), (3, 'F03'), (10, 'M04'), (2, 'F02'), (5, 'F05'), (7, 'M01'), (1, 'F01'), (8, 'M0
2'), (11, 'M05'), (12, 'M06'), (15, 'F03'), (20, 'M12'), (4, 'F04'), (18, 'F05'), (23, 'M13'), (19, 'M11'), (21, 'F02'),
 (17, 'M10'), (22, 'M01'), (13, 'M07')]
Evaluating model VGG16_inc_top_seqLen1_stateful_lstm10_output3_BatchSize10_inEpochs1_outEpochs50_AdamOpt_lr-0.000100_201
9-02-05_04-11-13
The subjects will be tested: [(6, 'F06'), (9, 'M03'), (14, 'M08'), (24, 'M14')]
All frames and annotations from 4 datasets have been read by 2019-02-05 07:11:56.045558
For the Subject 6 (F06):
54/54 [==============================] - 3s 56ms/step
        The absolute mean error on Pitch angle estimation: 20.73 Degree
        The absolute mean error on Yaw angle estimation: 26.60 Degree
        The absolute mean error on Roll angle estimation: 13.38 Degree
For the Subject 9 (M03):
88/88 [==============================] - 5s 56ms/step
        The absolute mean error on Pitch angle estimation: 22.76 Degree
        The absolute mean error on Yaw angle estimation: 30.63 Degree
        The absolute mean error on Roll angle estimation: 7.43 Degree
For the Subject 14 (M08):
79/79 [==============================] - 4s 56ms/step
        The absolute mean error on Pitch angle estimation: 20.02 Degree
        The absolute mean error on Yaw angle estimation: 28.53 Degree
        The absolute mean error on Roll angle estimation: 13.72 Degree
For the Subject 24 (M14):
49/49 [==============================] - 3s 56ms/step
        The absolute mean error on Pitch angle estimation: 10.84 Degree
        The absolute mean error on Yaw angle estimation: 10.16 Degree
        The absolute mean error on Roll angle estimation: 5.00 Degree
On average in 4 test subjects:
        The absolute mean error on Pitch angle estimations: 18.59 Degree
        The absolute mean error on Yaw angle estimations: 23.98 Degree
        The absolute mean error on Roll angle estimations: 9.88 Degree
Exp2019-02-05_04-11-13_part5 completed!
Exp2019-02-05_04-11-13.h5 has been saved.
subject6_Exp2019-02-05_04-11-13.png has been saved by 2019-02-05 07:12:38.424618.
subject9_Exp2019-02-05_04-11-13.png has been saved by 2019-02-05 07:12:38.626431.
subject14_Exp2019-02-05_04-11-13.png has been saved by 2019-02-05 07:12:38.845206.
subject24_Exp2019-02-05_04-11-13.png has been saved by 2019-02-05 07:12:39.047057.
Model Exp2019-02-05_04-11-13 has been evaluated successfully.
Model Exp2019-02-05_04-11-13 has been recorded successfully.
Done
mcicek@harsimran:~/Projects/deep_rl_for_head_pose_est/DeepRL_For_HPE/FC_RNN_Evaluater$
