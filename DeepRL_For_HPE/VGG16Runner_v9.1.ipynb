{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DatasetHandler.BiwiBrowser import *\n",
    "from LSTM_VGG16.LSTM_VGG16Helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_begin = 4\n",
    "num_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 16 # TimeseriesGenerator Handles overlapping\n",
    "in_epochs = 30\n",
    "out_epochs = 1\n",
    "train_batch_size = 10\n",
    "test_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectList = [9] #, 2, 3, 4, 5, 7, 8, 11, 12, 14 except [6, 13, 10, ]\n",
    "testSubjects = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = len(subjectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalModel(num_outputs = num_outputs):\n",
    "    inp = (224, 224, 3) # BIWI_Frame_Shape\n",
    "    vgg_model = VGG16(weights='imagenet', input_shape = inp, include_top=False) #BIWI_Frame_Shape\n",
    "    \"\"\"\"\n",
    "    vgg_model.layers.pop()\n",
    "    vgg_model.outputs = [vgg_model.layers[-1].output]#\n",
    "    vgg_model.output_layers = [vgg_model.layers[-1]]#\n",
    "    vgg_model.layers[-1].outbound_nodes = []#\n",
    "    nb_pretrained_layers = len(vgg_model.layers)\n",
    "    \"\"\"\n",
    "    for layer in vgg_model.layers: #\n",
    "        layer.trainable = False#\n",
    "    #print(nb_pretrained_layers)\n",
    "    #vgg_model.summary()\n",
    "    rnn = Sequential()\n",
    "    rnn.add(TimeDistributed(vgg_model, input_shape=(timesteps, inp[0], inp[1], inp[2]), name = 'tdVGG16')) \n",
    "    rnn.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "   # rnn.add(TimeDistributed(Dense(4096, activation='relu'), name = 'fc1024')), activation='relu'\n",
    "   # rnn.add(TimeDistributed(Dense(4096, activation='relu'), name = 'fc104'))    \n",
    "   # rnn.add(TimeDistributed(Dropout(0.25)))\n",
    "   # rnn.add(TimeDistributed(Dense(124, activation='relu'), name = 'fc10'))#\n",
    "   # rnn.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "    rnn.add(LSTM(128, dropout=0.25, recurrent_dropout=0.25))\n",
    "   # rnn.add(Flatten())\n",
    "    rnn.add(Dense(num_outputs))\n",
    "    #print(len(rnn.layers))\n",
    "    for layer in rnn.layers[:-2]:#\n",
    "        layer.trainable = False#\n",
    "    rnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()#\n",
    "full_model = getFinalModel(num_outputs = num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tdVGG16 (TimeDistributed)    (None, 16, 7, 7, 512)     14714688  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 16, 25088)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               12911104  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 27,625,921\n",
      "Trainable params: 12,911,233\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frames and annotations from 1 datasets have been read by 2019-01-10 01:26:23.623494\n",
      "1. set (Dataset 9) being trained for epoch 1!\n",
      "Epoch 1/30\n",
      "87/87 [==============================] - 59s 678ms/step - loss: 0.1640 - mean_absolute_error: 0.3368\n",
      "Epoch 2/30\n",
      "87/87 [==============================] - 61s 700ms/step - loss: 0.1171 - mean_absolute_error: 0.2902\n",
      "Epoch 3/30\n",
      "87/87 [==============================] - 61s 705ms/step - loss: 0.1213 - mean_absolute_error: 0.2989\n",
      "Epoch 4/30\n",
      "87/87 [==============================] - 61s 704ms/step - loss: 0.1209 - mean_absolute_error: 0.2992\n",
      "Epoch 5/30\n",
      "87/87 [==============================] - 61s 706ms/step - loss: 0.1212 - mean_absolute_error: 0.2989\n",
      "Epoch 6/30\n",
      "75/87 [========================>.....] - ETA: 8s - loss: 0.1181 - mean_absolute_error: 0.2973"
     ]
    }
   ],
   "source": [
    "full_model = trainImageModelForEpochs(full_model, out_epochs, subjectList, testSubjects, timesteps, False, output_begin, num_outputs, batch_size = train_batch_size, in_epochs = in_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generators, test_labelSets = getTestBiwiForImageModel(testSubjects, timesteps, False, output_begin, num_outputs, batch_size = test_batch_size)\n",
    "test_gen, test_labels = test_generators[0], test_labelSets[0] #[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_model.predict_generator(test_gen, verbose = 1)\n",
    "#predictions = full_model.predict(test_gen[0][0], verbose = 1)\n",
    "output1 = numpy.concatenate((test_labels[timesteps:, :1], predictions[:, :1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i[0] for i in predictions[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.plot(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_gen[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen[23][0][0][0][124][110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
