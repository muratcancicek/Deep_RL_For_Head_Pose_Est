{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DatasetHandler.BiwiBrowser import *\n",
    "from LSTM_VGG16.LSTM_VGG16Helper import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_begin = 4\n",
    "num_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 16 # TimeseriesGenerator Handles overlapping\n",
    "learning_rate = 0.0001\n",
    "in_epochs = 1\n",
    "out_epochs = 5\n",
    "train_batch_size = 15\n",
    "test_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectList = [1, 2, 3, 4, 5, 7, 8, 11, 12, 14] #9[i for i in range(1, 9)] + [i for i in range(10, 25)] except [6, 13, 10, ]\n",
    "testSubjects = [9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datasets = len(subjectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalModel(num_outputs = num_outputs):\n",
    "    inp = (224, 224, 3) # BIWI_Frame_Shape\n",
    "    vgg_model = VGG16(weights='imagenet', input_shape = inp, include_top=False) #BIWI_Frame_Shape\n",
    "    \"\"\"\"\n",
    "    vgg_model.layers.pop()\n",
    "    vgg_model.outputs = [vgg_model.layers[-1].output]#\n",
    "    vgg_model.output_layers = [vgg_model.layers[-1]]#\n",
    "    vgg_model.layers[-1].outbound_nodes = []#\n",
    "    \"\"\"\n",
    "    nb_pretrained_layers = len(vgg_model.layers)\n",
    "     #for layer in vgg_model.layers:\n",
    "     #   layer.trainable = False\n",
    "    #print(nb_pretrained_layers)\n",
    "    #vgg_model.summary()\n",
    "    rnn = Sequential()\n",
    "    rnn.add(TimeDistributed(vgg_model, input_shape=(timesteps, inp[0], inp[1], inp[2]), name = 'tdVGG16')) \n",
    "    rnn.add(TimeDistributed(Flatten()))\n",
    "    \n",
    "    \"\"\"\n",
    "    rnn.add(TimeDistributed(Dropout(0.25)))#\n",
    "    rnn.add(TimeDistributed(Dense(4096, activation='relu'), name = 'fc1024'))#, activation='relu'\n",
    "    rnn.add(TimeDistributed(Dropout(0.25)))#\n",
    "    rnn.add(TimeDistributed(Dense(4096, activation='relu'), name = 'fc104'))   # \n",
    "    rnn.add(TimeDistributed(Dropout(0.25)))#\n",
    "    rnn.add(TimeDistributed(Dense(1024, activation='relu'), name = 'fc10'))#\n",
    "    rnn.add(TimeDistributed(Dropout(0.25)))\n",
    "    \"\"\"\n",
    "\n",
    "    rnn.add(LSTM(256, dropout=0.25, recurrent_dropout=0.25)) #\n",
    "   # rnn.add(Flatten())\n",
    "    rnn.add(Dense(num_outputs))\n",
    "    #print(len(rnn.layers))\n",
    "    for layer in rnn.layers[:1]:#\n",
    "        layer.trainable = False#\n",
    "    adam = optimizers.Adam(lr=learning_rate)\n",
    "    rnn.compile(optimizer=adam, loss='mean_squared_error', metrics=['mae'])\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()#\n",
    "full_model = getFinalModel(num_outputs = num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "tdVGG16 (TimeDistributed)    (None, 16, 7, 7, 512)     14714688  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 16, 25088)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               25953280  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 40,668,225\n",
      "Trainable params: 25,953,537\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "full_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frames and annotations from 10 datasets have been read by 2019-01-12 20:17:03.595686\n",
      "1. set (Dataset 12) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 49s 1s/step - loss: 0.2113 - mean_absolute_error: 0.3582\n",
      "2. set (Dataset 3) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 52s 1s/step - loss: 0.2066 - mean_absolute_error: 0.3441\n",
      "3. set (Dataset 1) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.1598 - mean_absolute_error: 0.3092\n",
      "4. set (Dataset 11) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0792 - mean_absolute_error: 0.2248\n",
      "5. set (Dataset 8) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.0898 - mean_absolute_error: 0.2426\n",
      "6. set (Dataset 14) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.1239 - mean_absolute_error: 0.2826\n",
      "7. set (Dataset 7) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "49/49 [==============================] - 51s 1s/step - loss: 0.0687 - mean_absolute_error: 0.1997\n",
      "8. set (Dataset 2) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.1165 - mean_absolute_error: 0.2638\n",
      "9. set (Dataset 5) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 65s 1s/step - loss: 0.0511 - mean_absolute_error: 0.1767\n",
      "10. set (Dataset 4) being trained for epoch 1!\n",
      "Epoch 1/1\n",
      "49/49 [==============================] - 53s 1s/step - loss: 0.0784 - mean_absolute_error: 0.2173\n",
      "Epoch 1 completed!\n",
      "All frames and annotations from 10 datasets have been read by 2019-01-12 20:26:21.602865\n",
      "1. set (Dataset 5) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 65s 1s/step - loss: 0.0159 - mean_absolute_error: 0.0992\n",
      "2. set (Dataset 1) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.0425 - mean_absolute_error: 0.1596\n",
      "3. set (Dataset 12) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.0313 - mean_absolute_error: 0.1349\n",
      "4. set (Dataset 2) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.0311 - mean_absolute_error: 0.1437\n",
      "5. set (Dataset 7) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "49/49 [==============================] - 51s 1s/step - loss: 0.0242 - mean_absolute_error: 0.1260\n",
      "6. set (Dataset 4) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "49/49 [==============================] - 51s 1s/step - loss: 0.0185 - mean_absolute_error: 0.1080\n",
      "7. set (Dataset 14) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0258 - mean_absolute_error: 0.1308\n",
      "8. set (Dataset 3) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.0433 - mean_absolute_error: 0.1624\n",
      "9. set (Dataset 8) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "51/51 [==============================] - 53s 1s/step - loss: 0.0272 - mean_absolute_error: 0.1311\n",
      "10. set (Dataset 11) being trained for epoch 2!\n",
      "Epoch 1/1\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0209 - mean_absolute_error: 0.1155\n",
      "Epoch 2 completed!\n",
      "All frames and annotations from 10 datasets have been read by 2019-01-12 20:35:35.910980\n",
      "1. set (Dataset 8) being trained for epoch 3!\n",
      "Epoch 1/1\n",
      "51/51 [==============================] - 52s 1s/step - loss: 0.0380 - mean_absolute_error: 0.1467\n",
      "2. set (Dataset 12) being trained for epoch 3!\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.0224 - mean_absolute_error: 0.1192\n",
      "3. set (Dataset 5) being trained for epoch 3!\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 65s 1s/step - loss: 0.0121 - mean_absolute_error: 0.0869\n",
      "4. set (Dataset 3) being trained for epoch 3!\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 50s 1s/step - loss: 0.0263 - mean_absolute_error: 0.1248\n",
      "5. set (Dataset 14) being trained for epoch 3!\n",
      "Epoch 1/1\n",
      "53/53 [==============================] - 54s 1s/step - loss: 0.0269 - mean_absolute_error: 0.1314\n",
      "6. set (Dataset 11) being trained for epoch 3!\n",
      "Epoch 1/1\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.0159 - mean_absolute_error: 0.0994\n"
     ]
    }
   ],
   "source": [
    "full_model = trainImageModelForEpochs(full_model, out_epochs, subjectList, testSubjects, timesteps, False, output_begin, num_outputs, batch_size = train_batch_size, in_epochs = in_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generators, test_labelSets = getTestBiwiForImageModel(testSubjects, timesteps, False, output_begin, num_outputs, batch_size = test_batch_size)\n",
    "test_gen, test_labels = test_generators[0], test_labelSets[0] #[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = full_model.predict_generator(test_gen, verbose = 1)\n",
    "#predictions = full_model.predict(test_gen[0][0], verbose = 1)\n",
    "output1 = numpy.concatenate((test_labels[timesteps:, :1], predictions[:, :1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17,5))\n",
    "plt.plot(output1*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = (test_labels[timesteps:, :1] - predictions[:, :1])*90\n",
    "print(\"The average error on Yaw angle estimation: %.2f Degree\" % (np.abs(dif).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error on Yaw angle estimation: 6.41 Degree\n"
     ]
    }
   ],
   "source": [
    "dif = (test_labels[timesteps:, :1] - predictions[:, :1])*90\n",
    "print(\"The average error on Yaw angle estimation: %.2f Degree\" % (np.abs(dif).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average error on Yaw angle estimation: 8.28 Degree\n"
     ]
    }
   ],
   "source": [
    "dif = (test_labels[timesteps:, :1] - predictions[:, :1])*90\n",
    "print(\"The average error on Yaw angle estimation: %.2f Degree\" % (np.abs(dif).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.evaluate_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
