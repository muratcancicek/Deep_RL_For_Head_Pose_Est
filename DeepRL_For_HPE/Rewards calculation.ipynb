{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.initializers import RandomNormal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSequencesToSequences(inputMatrix, labels):\n",
    "    offset = labels.shape[0]%timesteps\n",
    "    if offset > 0: offset = timesteps - offset\n",
    "    npad = ((offset+1, timesteps), (0, 0), (0, 0), (0, 0))\n",
    "    inputMatrix = np.pad(inputMatrix[1:], pad_width=npad, mode='constant', constant_values=0)\n",
    "    npad = ((offset+1, timesteps), (0, 0))\n",
    "    inputLabels = np.pad(labels[:-1], pad_width=npad, mode='constant', constant_values=0)\n",
    "    npad = ((timesteps+offset+1, 0), (0, 0))\n",
    "    targets = np.pad(labels[1:], pad_width=npad, mode='constant', constant_values=0)\n",
    "    outputLabels = np.zeros(targets.shape[:1]+(timesteps,)+targets.shape[1:])\n",
    "    il = np.zeros_like(inputLabels)\n",
    "    for i in range(0, inputLabels.shape[0], timesteps):\n",
    "        il[i] = inputLabels[i]\n",
    "    inputLabels = il\n",
    "    for i in range(0, len(targets), timesteps):\n",
    "        outputLabels[i] = targets[i:i+timesteps] \n",
    "    return inputMatrix, inputLabels, outputLabels\n",
    "\n",
    "timesteps = 10\n",
    "inputMatrix = np.random.rand(57,224,224,3)# np.array([[[[i, i, i]]] for i in range(57)])\n",
    "labels = np.array([[i, i, i] for i in range(57)])\n",
    "\n",
    "inputMatrix, inputLabels, outputLabels = getSequencesToSequences(inputMatrix, labels)\n",
    "batch_size=1    \n",
    "img_gen = TimeseriesGenerator(inputMatrix, outputLabels, length=timesteps, sampling_rate=1, stride=timesteps, batch_size=batch_size)\n",
    "ang_gen = TimeseriesGenerator(inputLabels, outputLabels, length=timesteps, sampling_rate=1, stride=timesteps, batch_size=batch_size)\n",
    "batch_01 = img_gen[0]\n",
    "batch_0 = ang_gen[0]\n",
    "inputFrames, y = batch_01\n",
    "inputSeq, y = batch_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.],\n",
       "        [5., 5., 5.],\n",
       "        [6., 6., 6.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = RandomNormal(mean=y, stddev=0.05, seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.initializers.RandomNormal at 0x7ffa5982f6a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.zeros((n,)+y.shape)\n",
    "with tf.Session():\n",
    "    for i in range(n):\n",
    "        m[i] = l(y.shape).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 10, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = np.repeat(y[np.newaxis, ...], n, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 10, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True],\n",
       "        [ True,  True,  True]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy[3] == y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros(y.shape[:-1]+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 10)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.abs(m - yy), axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = -np.average(np.abs(m - yy), axis=-1) - np.max(np.abs(m - yy), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.08360068, -0.04487692, -0.04801671, -0.08602771,\n",
       "         -0.10097557, -0.05753732, -0.11846288, -0.12682223,\n",
       "         -0.11370722, -0.08432992]],\n",
       "\n",
       "       [[-0.09932037, -0.04812137, -0.09128053, -0.06689561,\n",
       "         -0.09658355, -0.09452613, -0.10628947, -0.12478105,\n",
       "         -0.09613132, -0.0839475 ]],\n",
       "\n",
       "       [[-0.09153414, -0.06154102, -0.05533313, -0.06912199,\n",
       "         -0.09124817, -0.1070087 , -0.08625436, -0.12028225,\n",
       "         -0.09516319, -0.10839764]],\n",
       "\n",
       "       [[-0.0929417 , -0.05844967, -0.05712595, -0.08325633,\n",
       "         -0.12505345, -0.05964681, -0.12617008, -0.12541914,\n",
       "         -0.09897995, -0.11122735]],\n",
       "\n",
       "       [[-0.10906103, -0.06936556, -0.10556194, -0.094242  ,\n",
       "         -0.11758381, -0.06167269, -0.09130041, -0.12903476,\n",
       "         -0.08454641, -0.10865752]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtt = np.mean(rt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09529158, -0.05647091, -0.07146365, -0.07990873, -0.10628891,\n",
       "        -0.07607833, -0.10569544, -0.12526789, -0.09770562, -0.09931199]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = rtt, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45674152])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 10)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(rt - bt).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from FC_RNN_Evaluater.Stateful_FC_RNN_Configuration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model, full_model, modelID, preprocess_input = getFinalModel(timesteps = timesteps, lstm_nodes = lstm_nodes, lstm_dropout = lstm_dropout, lstm_recurrent_dropout = lstm_recurrent_dropout, \n",
    "                      num_outputs = num_outputs, lr = learning_rate, include_vgg_top = include_vgg_top, use_vgg16 = use_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(model):\n",
    "    \"\"\"Return the gradient of every trainable weight in model\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    model : a keras model instance\n",
    "\n",
    "    First, find all tensors which are trainable in the model. Surprisingly,\n",
    "    `model.trainable_weights` will return tensors for which\n",
    "    trainable=False has been set on their layer (last time I checked), hence the extra check.\n",
    "    Next, get the gradients of the loss with respect to the weights.\n",
    "\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    for tensor in model.trainable_weights:\n",
    "        print(tensor.name)\n",
    "        if model.get_layer(tensor.name.split('/')[0]).trainable:\n",
    "            weights.append(tensor)\n",
    "    optimizer = model.optimizer\n",
    "\n",
    "    return optimizer.get_gradients(model.total_loss, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_1/kernel:0\n",
      "lstm_1/recurrent_kernel:0\n",
      "lstm_1/bias:0\n",
      "time_distributed_1/kernel:0\n",
      "time_distributed_1/bias:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'gradients/AddN_5:0' shape=(4099, 4096) dtype=float32>,\n",
       " <tf.Tensor 'gradients/AddN_4:0' shape=(1024, 4096) dtype=float32>,\n",
       " <tf.Tensor 'gradients/AddN_3:0' shape=(4096,) dtype=float32>,\n",
       " <tf.Tensor 'gradients/time_distributed_1/while/MatMul/Enter_grad/b_acc_3:0' shape=(1024, 3) dtype=float32>,\n",
       " <tf.Tensor 'gradients/time_distributed_1/while/BiasAdd/Enter_grad/b_acc_3:0' shape=(3,) dtype=float32>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradients(full_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = full_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0243619 , -0.06632722,  0.0723459 ],\n",
       "       [ 0.04879396, -0.03963432,  0.01553073],\n",
       "       [ 0.04456819, -0.07137289, -0.06297336],\n",
       "       ...,\n",
       "       [-0.00244952, -0.00757853,  0.0511878 ],\n",
       "       [-0.06938513, -0.0087788 ,  0.07334001],\n",
       "       [-0.0620813 , -0.04785295, -0.05943701]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 3) (1, 10, 3)\n",
      "===BEFORE WALKING DOWN GRADIENT===\n",
      "outputs:\n",
      " [[[-5.8046376e+15 -5.8782211e+15 -5.8528937e+15]\n",
      "  [-7.0172963e+15 -7.1062532e+15 -7.0756333e+15]\n",
      "  [-7.2892150e+15 -7.3816180e+15 -7.3498116e+15]\n",
      "  [-7.3316278e+15 -7.4245693e+15 -7.3925777e+15]\n",
      "  [-7.3374416e+15 -7.4304566e+15 -7.3984393e+15]\n",
      "  [-7.3382292e+15 -7.4312523e+15 -7.3992328e+15]\n",
      "  [-7.3383344e+15 -7.4313607e+15 -7.3993401e+15]\n",
      "  [-7.3383494e+15 -7.4313768e+15 -7.3993562e+15]\n",
      "  [-7.3383516e+15 -7.4313768e+15 -7.3993562e+15]\n",
      "  [-7.3383516e+15 -7.4313768e+15 -7.3993568e+15]]]\n",
      "targets:\n",
      " [[[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [1. 1. 1.]\n",
      "  [2. 2. 2.]\n",
      "  [3. 3. 3.]\n",
      "  [4. 4. 4.]\n",
      "  [5. 5. 5.]\n",
      "  [6. 6. 6.]]]\n",
      "step 0 rmse: 18.499424244125578\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0eb5f3bf7157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputFrames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputSeq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" rmse:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[1;32m    237\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 238\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    239\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n\u001b[1;32m    240\u001b[0m                                weights=sample_weight)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import backend as k\n",
    "from keras import losses\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "model = full_model\n",
    "inputs = inputFrames\n",
    "outputs = model.predict([inputFrames, inputSeq])\n",
    "targets = y\n",
    "print(outputs.shape, targets.shape)\n",
    "rmse = sqrt(mean_squared_error(targets[0], outputs[0]))\n",
    "loss = losses.mean_squared_error(targets, model.output)\n",
    "\n",
    "#  ===== Symbolic Gradient =====\n",
    "gradients = k.gradients(loss, model.trainable_weights)\n",
    "\n",
    "print(\"===BEFORE WALKING DOWN GRADIENT===\")\n",
    "print(\"outputs:\\n\", outputs)\n",
    "print(\"targets:\\n\", targets)\n",
    "\n",
    "# Begin TensorFlow\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "steps = 100  # steps of gradient descent\n",
    "for s in range(steps):\n",
    "    #print(model.input)\n",
    "    # ===== Numerical gradient =====\n",
    "    evaluated_gradients = sess.run(gradients, feed_dict={'tdCNN_input:0': inputFrames, 'aux_input:0': inputSeq})\n",
    "\n",
    "    # Step down the gradient for each layer\n",
    "    for i in range(len(model.trainable_weights)):\n",
    "        sess.run(tf.assign_sub(model.trainable_weights[i], evaluated_gradients[i]))\n",
    "\n",
    "    # Every 10 steps print the RMSE\n",
    "    if s % 10 == 0:\n",
    "        outputs = model.predict([inputFrames, inputSeq])\n",
    "        rmse = sqrt(mean_squared_error(targets[0], outputs[0]))\n",
    "        print(\"step \" + str(s) + \" rmse:\", rmse)\n",
    "\n",
    "final_outputs = model.predict([inputFrames, inputSeq])\n",
    "final_rmse = sqrt(mean_squared_error(targets[0], outputs[0]))\n",
    "\n",
    "print(\"===AFTER STEPPING DOWN GRADIENT===\")\n",
    "print(\"outputs:\\n\", outputs)\n",
    "print(\"targets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
