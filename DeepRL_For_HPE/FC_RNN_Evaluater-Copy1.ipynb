{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mcicek/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from FC_RNN_Evaluater.FC_RNN_Evaluater import *\n",
    "from FC_RNN_Evaluater.Stateful_FC_RNN_Configuration import *\n",
    "from FC_RNN_Evaluater.runFC_RNN_Experiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import TimeDistributed, LSTM, Dense, Dropout, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalModel(timesteps = timesteps, lstm_nodes = lstm_nodes, lstm_dropout = lstm_dropout, \n",
    "                  lstm_recurrent_dropout = lstm_recurrent_dropout, num_outputs = num_outputs, \n",
    "                  lr = learning_rate, include_vgg_top = include_vgg_top, use_vgg16 = use_vgg16):\n",
    "\n",
    "    inp, cnn_model, modelID, preprocess_input = getCNN_Model(use_vgg16 = use_vgg16)\n",
    "\n",
    "    #finalModel = getLSTM_Model(inp, cnn_model, lstm_nodes = lstm_nodes, lstm_dropout = lstm_dropout, lstm_recurrent_dropout = lstm_recurrent_dropout)\n",
    "    #finalModel.add(Dense(num_outputs))\n",
    "\n",
    "    auxiliary_input = TimeDistributed(Input(shape=(num_outputs, ), name='aux_input')) # train_batch_size, timesteps\n",
    "    x = (concatenate([TimeDistributed(cnn_model).output, auxiliary_input]))#\n",
    "    midModel = Model(inputs=[cnn_model.input, auxiliary_input], outputs=x)\n",
    "    lstm_out = LSTM(lstm_nodes, dropout=lstm_dropout, recurrent_dropout=lstm_recurrent_dropout, stateful=True)(x.output)\n",
    "    main_output = Dense(num_outputs)(lstm_out)\n",
    "    #finalModel = getLSTM_Model(inp, midModel, lstm_nodes = lstm_nodes, lstm_dropout = lstm_dropout, lstm_recurrent_dropout = lstm_recurrent_dropout)\n",
    "    finalModel = Model(inputs=midModelmodel.input, outputs=main_output)\n",
    "\n",
    "    #finalModel = Sequential()\n",
    "    #finalModel.add(TimeDistributed(midModel,  input_shape=(train_batch_size, timesteps, 1027), name = 'tdCNN')) \n",
    "    #finalModel.add(LSTM(lstm_nodes, dropout=lstm_dropout, recurrent_dropout=lstm_recurrent_dropout, stateful=True))#, activation='relu'\n",
    "    #finalModel.add(Dense(num_outputs))\n",
    "\n",
    "    adam = Adam(lr=lr)\n",
    "    finalModel.compile(optimizer=adam, loss='mean_absolute_error') #'mean_squared_error', metrics=['mae'])# \n",
    "\n",
    "    modelID = modelID + '_seqLen%d' % timesteps; modelID = modelID + '_stateful'; modelID = modelID + '_lstm%d' % lstm_nodes\n",
    "    modelID = modelID + '_output%d' % num_outputs; modelID = modelID + '_BatchSize%d' % train_batch_size\n",
    "    modelID = modelID + '_inEpochs%d' % in_epochs; modelID = modelID + '_outEpochs%d' % out_epochs\n",
    "    modelID = modelID + '_AdamOpt_lr-%f' % lr; modelID = modelID + '_%s' % now()[:-7].replace(' ', '_').replace(':', '-')\n",
    "    \n",
    "    return cnn_model, finalModel, modelID, preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Layer time_distributed_6 has no inbound nodes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3b0839f0cb9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m vgg_model, full_model, modelID, preprocess_input = getFinalModel(timesteps = timesteps, lstm_nodes = lstm_nodes, lstm_dropout = lstm_dropout, lstm_recurrent_dropout = lstm_recurrent_dropout, \n\u001b[0;32m----> 2\u001b[0;31m                       num_outputs = num_outputs, lr = learning_rate, include_vgg_top = include_vgg_top)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-a13a90c4bdd8>\u001b[0m in \u001b[0;36mgetFinalModel\u001b[0;34m(timesteps, lstm_nodes, lstm_dropout, lstm_recurrent_dropout, num_outputs, lr, include_vgg_top, use_vgg16)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mauxiliary_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'aux_input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# train_batch_size, timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTimeDistributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauxiliary_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmidModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauxiliary_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlstm_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecurrent_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlstm_recurrent_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             raise AttributeError('Layer ' + self.name +\n\u001b[0;32m--> 810\u001b[0;31m                                  ' has no inbound nodes.')\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             raise AttributeError('Layer ' + self.name +\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer time_distributed_6 has no inbound nodes."
     ]
    }
   ],
   "source": [
    "vgg_model, full_model, modelID, preprocess_input = getFinalModel(timesteps = timesteps, lstm_nodes = lstm_nodes, lstm_dropout = lstm_dropout, lstm_recurrent_dropout = lstm_recurrent_dropout, \n",
    "                      num_outputs = num_outputs, lr = learning_rate, include_vgg_top = include_vgg_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frames and annotations from 1 datasets have been read by 2019-01-29 00:45:23.596839\n",
      "1. set (Dataset 9) being trained for epoch 1 by 2019-01-29 00:45:32.509373!\n",
      "Epoch 1/1\n",
      "882/882 [==============================] - 27s 31ms/step - loss: 0.3977\n",
      "Epoch 1 completed!\n"
     ]
    }
   ],
   "source": [
    "full_model = trainCNN_LSTM(full_model, modelID, out_epochs, trainingSubjects, timesteps, output_begin, num_outputs, \n",
    "                  batch_size = train_batch_size, in_epochs = in_epochs, stateful = STATEFUL, preprocess_input = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscaleEstimations(test_labels, predictions, scalers, output_begin, num_outputs):\n",
    "    \"\"\"* label_rescaling_factor * label_rescaling_factor\n",
    "    \"\"\"\n",
    "    sclrs = [scalers[0][output_begin:output_begin+num_outputs], scalers[1][output_begin:output_begin+num_outputs]]\n",
    "    test_labels = unscaleAnnoByScalers(test_labels, sclrs)\n",
    "    predictions = unscaleAnnoByScalers(predictions, sclrs)\n",
    "    return test_labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateSubject(full_model, subject, test_gen, test_labels, timesteps, output_begin, num_outputs, angles, batch_size, stateful = False, record = False):\n",
    "    if num_outputs == 1: angles = ['Yaw']\n",
    "    printLog('For the Subject %d (%s):' % (subject, BIWI_Subject_IDs[subject]), record = record)\n",
    "    predictions = full_model.predict_generator(test_gen, steps = int(len(test_labels)/batch_size), verbose = 1)\n",
    "    #kerasEval = full_model.evaluate_generator(test_gen) \n",
    "    test_labels, predictions = unscaleEstimations(test_labels, predictions, BIWI_Lebel_Scalers, output_begin, num_outputs)\n",
    "    full_model.reset_states()\n",
    "    outputs = []\n",
    "    for i in range(num_outputs):\n",
    "        if stateful:\n",
    "            start_index = (test_labels.shape[0] % batch_size) if batch_size > 1 else 0\n",
    "            matrix = numpy.concatenate((test_labels[start_index:, i:i+1], predictions[:, i:i+1]), axis=1)\n",
    "            differences = (test_labels[start_index:, i:i+1] - predictions[:, i:i+1])\n",
    "        else:\n",
    "            print(test_labels[:, i:i+1].shape, predictions[:, i:i+1].shape)\n",
    "            matrix = numpy.concatenate((test_labels[:, i:i+1], predictions[:, i:i+1]), axis=1)\n",
    "            differences = (test_labels[:, i:i+1] - predictions[:, i:i+1])\n",
    "        absolute_mean_error = np.abs(differences).mean()\n",
    "        printLog(\"\\tThe absolute mean error on %s angle estimation: %.2f Degree\" % (angles[i], absolute_mean_error), record = record)\n",
    "        outputs.append((matrix, absolute_mean_error))\n",
    "    return full_model, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateCNN_LSTM(full_model, label_rescaling_factor, testSubjects, timesteps, output_begin, \n",
    "                     num_outputs, batch_size, angles, stateful = False, record = False, preprocess_input = None):\n",
    "    if num_outputs == 1: angles = ['Yaw']\n",
    "    test_generators, test_labelSets = getTestBiwiForImageModel(testSubjects, timesteps, False, output_begin, num_outputs, \n",
    "                                            batch_size = batch_size, stateful = stateful, record = record, preprocess_input = preprocess_input)\n",
    "    results = []\n",
    "    for subject, test_gen, test_labels in zip(testSubjects, test_generators, test_labelSets):\n",
    "        full_model, outputs = evaluateSubject(full_model, subject, test_gen, test_labels, timesteps, output_begin, num_outputs, angles, batch_size = batch_size, stateful = stateful, record = record)\n",
    "        results.append((subject, outputs))\n",
    "    means = evaluateAverage(results, angles, num_outputs, record = record)\n",
    "    return full_model, means, results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frames and annotations from 1 datasets have been read by 2019-01-29 00:52:13.451180\n",
      "For the Subject 9 (M03):\n",
      "882/882 [==============================] - 12s 14ms/step\n",
      "\tThe absolute mean error on Pitch angle estimation: 20.35 Degree\n",
      "\tThe absolute mean error on Yaw angle estimation: 29.29 Degree\n",
      "\tThe absolute mean error on Roll angle estimation: 31.73 Degree\n"
     ]
    }
   ],
   "source": [
    " full_model, means, results = evaluateCNN_LSTM(full_model, label_rescaling_factor = label_rescaling_factor, \n",
    "                     testSubjects = testSubjects, timesteps = timesteps,  output_begin = output_begin, \n",
    "                    num_outputs = num_outputs, batch_size = test_batch_size, angles = angles, stateful = STATEFUL, preprocess_input = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All frames and annotations from 1 datasets have been read by 2019-01-28 23:01:54.311180\n"
     ]
    }
   ],
   "source": [
    "test_generators, test_labelSets = getTestBiwiForImageModel(testSubjects, timesteps, False, output_begin, num_outputs, \n",
    "                                            batch_size = 1, stateful = True, preprocess_input = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen, test_labels = test_generators[0], test_labelSets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.81540612, 1.01903605, 1.20626227],\n",
       "       [1.81104456, 1.02161907, 1.21798137],\n",
       "       [1.8071115 , 1.02693495, 1.2186752 ],\n",
       "       ...,\n",
       "       [1.86528669, 1.18353251, 1.28262154],\n",
       "       [1.86317814, 1.19736085, 1.28078107],\n",
       "       [1.85303369, 1.19928671, 1.2678096 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
